<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title xmlns="">Classic Tokenizer
        | Elasticsearch Reference [5.x]
      | Elastic
    </title><meta name="generator" content="DocBook XSL Stylesheets V1.78.1" /><link rel="home" href="index.html" title="Elasticsearch Reference [5.x]" /><link rel="up" href="analysis-tokenizers.html" title="Tokenizers" /><link rel="prev" href="analysis-uaxurlemail-tokenizer.html" title="UAX URL Email Tokenizer" /><link rel="next" href="analysis-thai-tokenizer.html" title="Thai Tokenizer" /><meta xmlns="" name="description" content="Get started with the documentation for Elasticsearch, Kibana, Logstash, Beats, X-Pack, Elastic Cloud, Elasticsearch for Apache Hadoop, and our language clients." /><meta xmlns="" name="DC.type" content="Docs/Elasticsearch/Reference/5.x" /></head><body><div xmlns="" class="page_header">You are looking at preliminary documentation for a future release.
Not what you want? See the
<a href="../current/index.html">current release documentation</a>.
</div><div xmlns="" class="breadcrumbs"><span class="breadcrumb-link"><a href="index.html">Elasticsearch Reference
      [5.x]
    </a></span> » <span class="breadcrumb-link"><a href="analysis.html">Analysis</a></span> » <span class="breadcrumb-link"><a href="analysis-tokenizers.html">Tokenizers</a></span> » <span class="breadcrumb-node">Classic Tokenizer</span></div><div xmlns="" class="navheader"><span class="prev"><a href="analysis-uaxurlemail-tokenizer.html">
              « 
              UAX URL Email  Tokenizer</a>
           
        </span><span class="next">
           
          <a href="analysis-thai-tokenizer.html">Thai Tokenizer
               »
            </a></span></div><div class="section"><div class="titlepage"><div><div><h2 class="title"><a id="analysis-classic-tokenizer"></a>Classic Tokenizer<a xmlns="" href="https://github.com/elastic/elasticsearch/edit/5.x/docs/reference/analysis/tokenizers/classic-tokenizer.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h2></div></div></div><p>The <code class="literal">classic</code> tokenizer is a grammar based tokenizer that is good for English
language documents. This tokenizer has heuristics for special treatment of
acronyms, company names, email addresses, and internet host names. However,
these rules don’t always work, and the tokenizer doesn’t work well for most
languages other than English:</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
It splits words at most punctuation characters, removing punctuation. However, a
  dot that’s not followed by whitespace is considered part of a token.
</li><li class="listitem">
It splits words at hyphens, unless there’s a number in the token, in which case
  the whole token is interpreted as a product number and is not split.
</li><li class="listitem">
It recognizes email addresses and internet hostnames as one token.
</li></ul></div><h3><a id="_example_output_13"></a>Example output<a xmlns="" href="https://github.com/elastic/elasticsearch/edit/5.x/docs/reference/analysis/tokenizers/classic-tokenizer.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3><div xmlns="" class="pre_wrapper"><pre xmlns="http://www.w3.org/1999/xhtml" class="programlisting prettyprint lang-js">POST _analyze
{
  "tokenizer": "classic",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}</pre></div><div xmlns="" class="console_widget" data-snippet=":CONSOLE:"></div><p>The above sentence would produce the following terms:</p><div xmlns="" class="pre_wrapper"><pre xmlns="http://www.w3.org/1999/xhtml" class="programlisting prettyprint lang-text">[ The, 2, QUICK, Brown, Foxes, jumped, over, the, lazy, dog's, bone ]</pre></div><h3><a id="_configuration_14"></a>Configuration<a xmlns="" href="https://github.com/elastic/elasticsearch/edit/5.x/docs/reference/analysis/tokenizers/classic-tokenizer.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3><p>The <code class="literal">classic</code> tokenizer accepts the following parameters:</p><div class="horizontal"><table cellpadding="4px" border="0"><colgroup><col /><col /></colgroup><tbody valign="top"><tr><td valign="top">
<p>
<code class="literal">max_token_length</code>
</p>
</td><td valign="top">
<p>
    The maximum token length. If a token is seen that exceeds this length then
    it is split at <code class="literal">max_token_length</code> intervals. Defaults to <code class="literal">255</code>.
</p>
</td></tr></tbody></table></div><h3><a id="_example_configuration_8"></a>Example configuration<a xmlns="" href="https://github.com/elastic/elasticsearch/edit/5.x/docs/reference/analysis/tokenizers/classic-tokenizer.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3><p>In this example, we configure the <code class="literal">classic</code> tokenizer to have a
<code class="literal">max_token_length</code> of 5 (for demonstration purposes):</p><div xmlns="" class="pre_wrapper"><pre xmlns="http://www.w3.org/1999/xhtml" class="programlisting prettyprint lang-js">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "classic",
          "max_token_length": 5
        }
      }
    }
  }
}

POST my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}</pre></div><div xmlns="" class="console_widget" data-snippet=":CONSOLE:"></div><p>The above example produces the following terms:</p><div xmlns="" class="pre_wrapper"><pre xmlns="http://www.w3.org/1999/xhtml" class="programlisting prettyprint lang-text">[ The, 2, QUICK, Brown, Foxes, jumpe, d, over, the, lazy, dog's, bone ]</pre></div></div><div xmlns="" class="navfooter"><span class="prev"><a href="analysis-uaxurlemail-tokenizer.html">
              « 
              UAX URL Email  Tokenizer</a>
           
        </span><span class="next">
           
          <a href="analysis-thai-tokenizer.html">Thai Tokenizer
               »
            </a></span></div></body></html>