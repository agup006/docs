<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title xmlns="">Standard Tokenizer
        | Elasticsearch Reference [master]
      | Elastic
    </title><meta name="generator" content="DocBook XSL Stylesheets V1.78.1" /><link rel="home" href="index.html" title="Elasticsearch Reference [master]" /><link rel="up" href="analysis-tokenizers.html" title="Tokenizers" /><link rel="prev" href="analysis-tokenizers.html" title="Tokenizers" /><link rel="next" href="analysis-letter-tokenizer.html" title="Letter Tokenizer" /><meta xmlns="" name="description" content="Get started with the documentation for Elasticsearch, Kibana, Logstash, Beats, X-Pack, Elastic Cloud, Elasticsearch for Apache Hadoop, and our language clients." /><meta xmlns="" name="DC.type" content="Docs/Elasticsearch/Reference/master" /></head><body><div xmlns="" class="page_header">You are looking at preliminary documentation for a future release.
Not what you want? See the
<a href="../current/index.html">current release documentation</a>.
</div><div xmlns="" class="breadcrumbs"><span class="breadcrumb-link"><a href="index.html">Elasticsearch Reference
      [master]
    </a></span> » <span class="breadcrumb-link"><a href="analysis.html">Analysis</a></span> » <span class="breadcrumb-link"><a href="analysis-tokenizers.html">Tokenizers</a></span> » <span class="breadcrumb-node">Standard Tokenizer</span></div><div xmlns="" class="navheader"><span class="prev"><a href="analysis-tokenizers.html">
              « 
              Tokenizers</a>
           
        </span><span class="next">
           
          <a href="analysis-letter-tokenizer.html">Letter Tokenizer
               »
            </a></span></div><div class="section"><div class="titlepage"><div><div><h2 class="title"><a id="analysis-standard-tokenizer"></a>Standard Tokenizer<a xmlns="" href="https://github.com/elastic/elasticsearch/edit/master/docs/reference/analysis/tokenizers/standard-tokenizer.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h2></div></div></div><p>The <code class="literal">standard</code> tokenizer provides grammar based tokenization (based on the
Unicode Text Segmentation algorithm, as specified in
<a class="ulink" href="http://unicode.org/reports/tr29/" target="_top">Unicode Standard Annex #29</a>) and works well
for most languages.</p><h3><a id="_example_output_8"></a>Example output<a xmlns="" href="https://github.com/elastic/elasticsearch/edit/master/docs/reference/analysis/tokenizers/standard-tokenizer.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3><div xmlns="" class="pre_wrapper"><pre xmlns="http://www.w3.org/1999/xhtml" class="programlisting prettyprint lang-js">POST _analyze
{
  "tokenizer": "standard",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}</pre></div><div xmlns="" class="console_widget" data-snippet=":CONSOLE:"></div><p>The above sentence would produce the following terms:</p><div xmlns="" class="pre_wrapper"><pre xmlns="http://www.w3.org/1999/xhtml" class="programlisting prettyprint lang-text">[ The, 2, QUICK, Brown, Foxes, jumped, over, the, lazy, dog's, bone ]</pre></div><h3><a id="_configuration_9"></a>Configuration<a xmlns="" href="https://github.com/elastic/elasticsearch/edit/master/docs/reference/analysis/tokenizers/standard-tokenizer.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3><p>The <code class="literal">standard</code> tokenizer accepts the following parameters:</p><div class="horizontal"><table cellpadding="4px" border="0"><colgroup><col /><col /></colgroup><tbody valign="top"><tr><td valign="top">
<p>
<code class="literal">max_token_length</code>
</p>
</td><td valign="top">
<p>
    The maximum token length. If a token is seen that exceeds this length then
    it is split at <code class="literal">max_token_length</code> intervals. Defaults to <code class="literal">255</code>.
</p>
</td></tr></tbody></table></div><h3><a id="_example_configuration_6"></a>Example configuration<a xmlns="" href="https://github.com/elastic/elasticsearch/edit/master/docs/reference/analysis/tokenizers/standard-tokenizer.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3><p>In this example, we configure the <code class="literal">standard</code> tokenizer to have a
<code class="literal">max_token_length</code> of 5 (for demonstration purposes):</p><div xmlns="" class="pre_wrapper"><pre xmlns="http://www.w3.org/1999/xhtml" class="programlisting prettyprint lang-js">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "standard",
          "max_token_length": 5
        }
      }
    }
  }
}

POST my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}</pre></div><div xmlns="" class="console_widget" data-snippet=":CONSOLE:"></div><p>The above example produces the following terms:</p><div xmlns="" class="pre_wrapper"><pre xmlns="http://www.w3.org/1999/xhtml" class="programlisting prettyprint lang-text">[ The, 2, QUICK, Brown, Foxes, jumpe, d, over, the, lazy, dog's, bone ]</pre></div></div><div xmlns="" class="navfooter"><span class="prev"><a href="analysis-tokenizers.html">
              « 
              Tokenizers</a>
           
        </span><span class="next">
           
          <a href="analysis-letter-tokenizer.html">Letter Tokenizer
               »
            </a></span></div></body></html>