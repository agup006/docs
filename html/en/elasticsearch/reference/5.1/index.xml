<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE book PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN" "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd">
<?asciidoc-toc?>
<?asciidoc-numbered?>

<book lang="en">
<bookinfo>
    <title>Elasticsearch Reference</title>
</bookinfo>
<part id="getting-started">
<title>Getting Started <ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></title>
<partintro>
<simpara>Elasticsearch is a highly scalable open-source full-text search and analytics engine. It allows you to store, search, and analyze big volumes of data quickly and in near real time. It is generally used as the underlying engine/technology that powers applications that have complex search features and requirements.</simpara>
<simpara>Here are a few sample use-cases that Elasticsearch could be used for:</simpara>
<itemizedlist>
<listitem>
<simpara>
You run an online web store where you allow your customers to search for products that you sell. In this case, you can use Elasticsearch to store your entire product catalog and inventory and provide search and autocomplete suggestions for them.
</simpara>
</listitem>
<listitem>
<simpara>
You want to collect log or transaction data and you want to analyze and mine this data to look for trends, statistics, summarizations, or anomalies. In this case, you can use Logstash (part of the Elasticsearch/Logstash/Kibana stack) to collect, aggregate, and parse your data, and then have Logstash feed this data into Elasticsearch. Once the data is in Elasticsearch, you can run searches and aggregations to mine any information that is of interest to you.
</simpara>
</listitem>
<listitem>
<simpara>
You run a price alerting platform which allows price-savvy customers to specify a rule like "I am interested in buying a specific electronic gadget and I want to be notified if the price of gadget falls below $X from any vendor within the next month". In this case you can scrape vendor prices, push them into Elasticsearch and use its reverse-search (Percolator) capability to match price movements against customer queries and eventually push the alerts out to the customer once matches are found.
</simpara>
</listitem>
<listitem>
<simpara>
You have analytics/business-intelligence needs and want to quickly investigate, analyze, visualize, and ask ad-hoc questions on a lot of data (think millions or billions of records). In this case, you can use Elasticsearch to store your data and then use Kibana (part of the Elasticsearch/Logstash/Kibana stack) to build custom dashboards that can visualize aspects of your data that are important to you. Additionally, you can use the Elasticsearch aggregations functionality to perform complex business intelligence queries against your data.
</simpara>
</listitem>
</itemizedlist>
<simpara>For the rest of this tutorial, I will guide you through the process of getting Elasticsearch up and running, taking a peek inside it, and performing basic operations like indexing, searching, and modifying your data. At the end of this tutorial, you should have a good idea of what Elasticsearch is, how it works, and hopefully be inspired to see how you can use it to either build sophisticated search applications or to mine intelligence from your data.</simpara>
</partintro>
<chapter id="_basic_concepts">
<title>Basic Concepts<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></title>
<simpara>There are a few concepts that are core to Elasticsearch. Understanding these concepts from the outset will tremendously help ease the learning process.</simpara>
<bridgehead id="_near_realtime_nrt" renderas="sect2">Near Realtime (NRT)<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></bridgehead>
<simpara>Elasticsearch is a near real time search platform. What this means is there is a slight latency (normally one second) from the time you index a document until the time it becomes searchable.</simpara>
<bridgehead id="_cluster" renderas="sect2">Cluster<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></bridgehead>
<simpara>A cluster is a collection of one or more nodes (servers) that together holds your entire data and provides federated indexing and search capabilities across all nodes. A cluster is identified by a unique name which by default is "elasticsearch". This name is important because a node can only be part of a cluster if the node is set up to join the cluster by its name.</simpara>
<simpara>Make sure that you don&#8217;t reuse the same cluster names in different
environments, otherwise you might end up with nodes joining the wrong cluster.
For instance you could use <literal>logging-dev</literal>, <literal>logging-stage</literal>, and <literal>logging-prod</literal>
for the development, staging, and production clusters.</simpara>
<simpara>Note that it is valid and perfectly fine to have a cluster with only a single node in it. Furthermore, you may also have multiple independent clusters each with its own unique cluster name.</simpara>
<bridgehead id="_node" renderas="sect2">Node<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></bridgehead>
<simpara>A node is a single server that is part of your cluster, stores your data, and participates in the cluster&#8217;s indexing and search
capabilities. Just like a cluster, a node is identified by a name which by default is a random Universally Unique IDentifier (UUID) that is assigned to the node at startup. You can define any node name you want if you do not want the default.  This name is important for administration purposes where you want to identify which servers in your network correspond to which nodes in your Elasticsearch cluster.</simpara>
<simpara>A node can be configured to join a specific cluster by the cluster name. By default, each node is set up to join a cluster named <literal>elasticsearch</literal> which means that if you start up a number of nodes on your network and&#8212;assuming they can discover each other&#8212;they will all automatically form and join a single cluster named <literal>elasticsearch</literal>.</simpara>
<simpara>In a single cluster, you can have as many nodes as you want. Furthermore, if there are no other Elasticsearch nodes currently running on your network, starting a single node will by default form a new single-node cluster named <literal>elasticsearch</literal>.</simpara>
<bridgehead id="_index" renderas="sect2">Index<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></bridgehead>
<simpara>An index is a collection of documents that have somewhat similar characteristics. For example, you can have an index for customer data, another index for a product catalog, and yet another index for order data. An index is identified by a name (that must be all lowercase) and this name is used to refer to the index when performing indexing, search, update, and delete operations against the documents in it.</simpara>
<simpara>In a single cluster, you can define as many indexes as you want.</simpara>
<bridgehead id="_type" renderas="sect2">Type<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></bridgehead>
<simpara>Within an index, you can define one or more types. A type is a logical category/partition of your index whose semantics is completely up to you. In general, a type is defined for documents that have a set of common fields. For example, let&#8217;s assume you run a blogging platform and store all your data in a single index. In this index, you may define a type for user data, another type for blog data, and yet another type for comments data.</simpara>
<bridgehead id="_document" renderas="sect2">Document<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></bridgehead>
<simpara>A document is a basic unit of information that can be indexed. For example, you can have a document for a single customer, another document for a single product, and yet another for a single order. This document is expressed in <ulink url="http://json.org/">JSON</ulink> (JavaScript Object Notation) which is an ubiquitous internet data interchange format.</simpara>
<simpara>Within an index/type, you can store as many documents as you want. Note that although a document physically resides in an index, a document actually must be indexed/assigned to a type inside an index.</simpara>
<bridgehead id="_shards_amp_replicas" renderas="sect2">Shards &amp; Replicas<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></bridgehead>
<simpara>An index can potentially store a large amount of data that can exceed the hardware limits of a single node. For example, a single index of a billion documents taking up 1TB of disk space may not fit on the disk of a single node or may be too slow to serve search requests from a single node alone.</simpara>
<simpara>To solve this problem, Elasticsearch provides the ability to subdivide your index into multiple pieces called shards. When you create an index, you can simply define the number of shards that you want. Each shard is in itself a fully-functional and independent "index" that can be hosted on any node in the cluster.</simpara>
<simpara>Sharding is important for two primary reasons:</simpara>
<itemizedlist>
<listitem>
<simpara>
It allows you to horizontally split/scale your content volume
</simpara>
</listitem>
<listitem>
<simpara>
It allows you to distribute and parallelize operations across shards (potentially on multiple nodes) thus increasing performance/throughput
</simpara>
</listitem>
</itemizedlist>
<simpara>The mechanics of how a shard is distributed and also how its documents are aggregated back into search requests are completely managed by Elasticsearch and is transparent to you as the user.</simpara>
<simpara>In a network/cloud environment where failures can be expected anytime, it is very useful and highly recommended to have a failover mechanism in case a shard/node somehow goes offline or disappears for whatever reason. To this end, Elasticsearch allows you to make one or more copies of your index&#8217;s shards into what are called replica shards, or replicas for short.</simpara>
<simpara>Replication is important for two primary reasons:</simpara>
<itemizedlist>
<listitem>
<simpara>
It provides high availability in case a shard/node fails. For this reason, it is important to note that a replica shard is never allocated on the same node as the original/primary shard that it was copied from.
</simpara>
</listitem>
<listitem>
<simpara>
It allows you to scale out your search volume/throughput since searches can be executed on all replicas in parallel.
</simpara>
</listitem>
</itemizedlist>
<simpara>To summarize, each index can be split into multiple shards. An index can also be replicated zero (meaning no replicas) or more times. Once replicated, each index will have primary shards (the original shards that were replicated from) and replica shards (the copies of the primary shards).
The number of shards and replicas can be defined per index at the time the index is created. After the index is created, you may change the number of replicas dynamically anytime but you cannot change the number shards after-the-fact.</simpara>
<simpara>By default, each index in Elasticsearch is allocated 5 primary shards and 1 replica which means that if you have at least two nodes in your cluster, your index will have 5 primary shards and another 5 replica shards (1 complete replica) for a total of 10 shards per index.</simpara>
<note><simpara>Each Elasticsearch shard is a Lucene index.  There is a maximum number of documents you can have in a single Lucene index.  As of <ulink url="https://issues.apache.org/jira/browse/LUCENE-5843"><literal>LUCENE-5843</literal></ulink>, the limit is <literal>2,147,483,519</literal> (= Integer.MAX_VALUE - 128) documents.
You can monitor shard sizes using the <link linkend="cat-shards"><literal>_cat/shards</literal></link> api.</simpara></note>
<simpara>With that out of the way, let&#8217;s get started with the fun part&#8230;</simpara>
</chapter>
<chapter id="_installation">
<title>Installation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch requires at least Java 8. Specifically as of this writing, it is recommended that you use the Oracle JDK version 1.8.0_73. Java installation varies from platform to platform so we won&#8217;t go into those details here. Oracle&#8217;s recommended installation documentation can be found on <ulink url="http://docs.oracle.com/javase/8/docs/technotes/guides/install/install_overview.html">Oracle&#8217;s website</ulink>. Suffice to say, before you install Elasticsearch, please check your Java version first by running (and then install/upgrade accordingly if needed):</simpara>
<programlisting language="sh" linenumbering="unnumbered">java -version
echo $JAVA_HOME</programlisting>
<simpara>Once we have Java set up, we can then download and run Elasticsearch. The binaries are available from <ulink url="http://www.elastic.co/downloads"><literal>www.elastic.co/downloads</literal></ulink> along with all the releases that have been made in the past. For each release, you have a choice among a <literal>zip</literal> or <literal>tar</literal> archive, or a <literal>DEB</literal> or <literal>RPM</literal> package. For simplicity, let&#8217;s use the tar file.</simpara>
<simpara>Let&#8217;s download the Elasticsearch 5.1.1 tar as follows (Windows users should download the zip package):</simpara>
<programlisting language="sh" linenumbering="unnumbered">curl -L -O https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-5.1.1.tar.gz</programlisting>
<remark> NOTCONSOLE</remark>
<simpara>Then extract it as follows (Windows users should unzip the zip package):</simpara>
<programlisting language="sh" linenumbering="unnumbered">tar -xvf elasticsearch-5.1.1.tar.gz</programlisting>
<simpara>It will then create a bunch of files and folders in your current directory. We then go into the bin directory as follows:</simpara>
<programlisting language="sh" linenumbering="unnumbered">cd elasticsearch-5.1.1/bin</programlisting>
<simpara>And now we are ready to start our node and single cluster (Windows users should run the elasticsearch.bat file):</simpara>
<programlisting language="sh" linenumbering="unnumbered">./elasticsearch</programlisting>
<simpara>If everything goes well, you should see a bunch of messages that look like below:</simpara>
<programlisting language="sh" linenumbering="unnumbered">[2016-09-16T14:17:51,251][INFO ][o.e.n.Node               ] [] initializing ...
[2016-09-16T14:17:51,329][INFO ][o.e.e.NodeEnvironment    ] [6-bjhwl] using [1] data paths, mounts [[/ (/dev/sda1)]], net usable_space [317.7gb], net total_space [453.6gb], spins? [no], types [ext4]
[2016-09-16T14:17:51,330][INFO ][o.e.e.NodeEnvironment    ] [6-bjhwl] heap size [1.9gb], compressed ordinary object pointers [true]
[2016-09-16T14:17:51,333][INFO ][o.e.n.Node               ] [6-bjhwl] node name [6-bjhwl] derived from node ID; set [node.name] to override
[2016-09-16T14:17:51,334][INFO ][o.e.n.Node               ] [6-bjhwl] version[5.1.1], pid[21261], build[f5daa16/2016-09-16T09:12:24.346Z], OS[Linux/4.4.0-36-generic/amd64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_60/25.60-b23]
[2016-09-16T14:17:51,967][INFO ][o.e.p.PluginsService     ] [6-bjhwl] loaded module [aggs-matrix-stats]
[2016-09-16T14:17:51,967][INFO ][o.e.p.PluginsService     ] [6-bjhwl] loaded module [ingest-common]
[2016-09-16T14:17:51,967][INFO ][o.e.p.PluginsService     ] [6-bjhwl] loaded module [lang-expression]
[2016-09-16T14:17:51,967][INFO ][o.e.p.PluginsService     ] [6-bjhwl] loaded module [lang-groovy]
[2016-09-16T14:17:51,967][INFO ][o.e.p.PluginsService     ] [6-bjhwl] loaded module [lang-mustache]
[2016-09-16T14:17:51,967][INFO ][o.e.p.PluginsService     ] [6-bjhwl] loaded module [lang-painless]
[2016-09-16T14:17:51,967][INFO ][o.e.p.PluginsService     ] [6-bjhwl] loaded module [percolator]
[2016-09-16T14:17:51,968][INFO ][o.e.p.PluginsService     ] [6-bjhwl] loaded module [reindex]
[2016-09-16T14:17:51,968][INFO ][o.e.p.PluginsService     ] [6-bjhwl] loaded module [transport-netty3]
[2016-09-16T14:17:51,968][INFO ][o.e.p.PluginsService     ] [6-bjhwl] loaded module [transport-netty4]
[2016-09-16T14:17:51,968][INFO ][o.e.p.PluginsService     ] [6-bjhwl] loaded plugin [mapper-murmur3]
[2016-09-16T14:17:53,521][INFO ][o.e.n.Node               ] [6-bjhwl] initialized
[2016-09-16T14:17:53,521][INFO ][o.e.n.Node               ] [6-bjhwl] starting ...
[2016-09-16T14:17:53,671][INFO ][o.e.t.TransportService   ] [6-bjhwl] publish_address {192.168.8.112:9300}, bound_addresses {{192.168.8.112:9300}
[2016-09-16T14:17:53,676][WARN ][o.e.b.BootstrapCheck     ] [6-bjhwl] max virtual memory areas vm.max_map_count [65530] likely too low, increase to at least [262144]
[2016-09-16T14:17:56,731][INFO ][o.e.h.HttpServer         ] [6-bjhwl] publish_address {192.168.8.112:9200}, bound_addresses {[::1]:9200}, {192.168.8.112:9200}
[2016-09-16T14:17:56,732][INFO ][o.e.g.GatewayService     ] [6-bjhwl] recovered [0] indices into cluster_state
[2016-09-16T14:17:56,748][INFO ][o.e.n.Node               ] [6-bjhwl] started</programlisting>
<simpara>Without going too much into detail, we can see that our node named "6-bjhwl" (which will be a different set of characters in your case) has started and elected itself as a master in a single cluster. Don&#8217;t worry yet at the moment what master means. The main thing that is important here is that we have started one node within one cluster.</simpara>
<simpara>As mentioned previously, we can override either the cluster or node name. This can be done from the command line when starting Elasticsearch as follows:</simpara>
<programlisting language="sh" linenumbering="unnumbered">./elasticsearch -Ecluster.name=my_cluster_name -Enode.name=my_node_name</programlisting>
<simpara>Also note the line marked http with information about the HTTP address (<literal>192.168.8.112</literal>) and port (<literal>9200</literal>) that our node is reachable from. By default, Elasticsearch uses port <literal>9200</literal> to provide access to its REST API. This port is configurable if necessary.</simpara>
</chapter>
<chapter id="_exploring_your_cluster">
<title>Exploring Your Cluster<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></title>
<bridgehead id="_the_rest_api" renderas="sect2">The REST API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></bridgehead>
<simpara>Now that we have our node (and cluster) up and running, the next step is to understand how to communicate with it. Fortunately, Elasticsearch provides a very comprehensive and powerful REST API that you can use to interact with your cluster. Among the few things that can be done with the API are as follows:</simpara>
<itemizedlist>
<listitem>
<simpara>
Check your cluster, node, and index health, status, and statistics
</simpara>
</listitem>
<listitem>
<simpara>
Administer your cluster, node, and index data and metadata
</simpara>
</listitem>
<listitem>
<simpara>
Perform CRUD (Create, Read, Update, and Delete) and search operations against your indexes
</simpara>
</listitem>
<listitem>
<simpara>
Execute advanced search operations such as paging, sorting, filtering, scripting, aggregations, and many others
</simpara>
</listitem>
</itemizedlist>
<section id="_cluster_health">
<title>Cluster Health<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></title>
<simpara>Let&#8217;s start with a basic health check, which we can use to see how our cluster is doing. We&#8217;ll be using curl to do this but you can use any tool that allows you to make HTTP/REST calls. Let&#8217;s assume that we are still on the same node where we started Elasticsearch on and open another command shell window.</simpara>
<simpara>To check the cluster health, we will be using the <link linkend="cat"><literal>_cat</literal> API</link>. You can
run the command below in <ulink url="https://www.elastic.co/guide/en/kibana/master/console-kibana.html">Kibana&#8217;s Console</ulink>
by clicking "VIEW IN CONSOLE" or with <literal>curl</literal> by clicking the "COPY AS CURL"
link below and pasting it into a terminal.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/health?v</programlisting>
<remark> CONSOLE</remark>
<simpara>And the response:</simpara>
<programlisting language="txt" linenumbering="unnumbered">epoch      timestamp cluster       status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent
1475247709 17:01:49  elasticsearch green           1         1      0   0    0    0        0             0                  -                100.0%</programlisting>
<remark> TESTRESPONSE[s/1475247709 17:01:49  elasticsearch/\\d+ \\d+:\\d+:\\d+ docs_integTest/ _cat]</remark>
<simpara>We can see that our cluster named "elasticsearch" is up with a green status.</simpara>
<simpara>Whenever we ask for the cluster health, we either get green, yellow, or red. Green means everything is good (cluster is fully functional), yellow means all data is available but some replicas are not yet allocated (cluster is fully functional), and red means some data is not available for whatever reason. Note that even if a cluster is red, it still is partially functional (i.e. it will continue to serve search requests from the available shards) but you will likely need to fix it ASAP since you have missing data.</simpara>
<simpara>Also from the above response, we can see a total of 1 node and that we have 0 shards since we have no data in it yet. Note that since we are using the default cluster name (elasticsearch) and since Elasticsearch uses unicast network discovery by default to find other nodes on the same machine, it is possible that you could accidentally start up more than one node on your computer and have them all join a single cluster. In this scenario, you may see more than 1 node in the above response.</simpara>
<simpara>We can also get a list of nodes in our cluster as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/nodes?v</programlisting>
<remark> CONSOLE</remark>
<simpara>And the response:</simpara>
<programlisting language="txt" linenumbering="unnumbered">ip        heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name
127.0.0.1           10           5   5    4.46                        mdi      *      PB2SGZY</programlisting>
<remark> TESTRESPONSE[s/10           5   5    4.46/\\d+ \\d+ \\d+ (\\d+\\.\\d+)? (\\d+\\.\\d+)? (\\d+\.\\d+)?/]</remark>
<remark> TESTRESPONSE[s/[*]/[*]/ s/PB2SGZY/.+/ _cat]</remark>
<simpara>Here, we can see our one node named "PB2SGZY", which is the single node that is currently in our cluster.</simpara>
</section>
<section id="_list_all_indices">
<title>List All Indices<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></title>
<simpara>Now let&#8217;s take a peek at our indices:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/indices?v</programlisting>
<remark> CONSOLE</remark>
<simpara>And the response:</simpara>
<programlisting language="txt" linenumbering="unnumbered">health status index uuid pri rep docs.count docs.deleted store.size pri.store.size</programlisting>
<remark> TESTRESPONSE[_cat]</remark>
<simpara>Which simply means we have no indices yet in the cluster.</simpara>
</section>
<section id="_create_an_index">
<title>Create an Index<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></title>
<simpara>Now let&#8217;s create an index named "customer" and then list all the indexes again:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /customer?pretty
GET /_cat/indices?v</programlisting>
<remark> CONSOLE</remark>
<simpara>The first command creates the index named "customer" using the PUT verb. We simply append <literal>pretty</literal> to the end of the call to tell it to pretty-print the JSON response (if any).</simpara>
<simpara>And the response:</simpara>
<programlisting language="txt" linenumbering="unnumbered">health status index    uuid                   pri rep docs.count docs.deleted store.size pri.store.size
yellow open   customer 95SQ4TSUT7mWBT7VNHH67A   5   1          0            0       260b           260b</programlisting>
<remark> TESTRESPONSE[s/95SQ4TSUT7mWBT7VNHH67A/.+/ s/260b/\\d+b/ _cat]</remark>
<simpara>The results of the second command tells us that we now have 1 index named customer and it has 5 primary shards and 1 replica (the defaults) and it contains 0 documents in it.</simpara>
<simpara>You might also notice that the customer index has a yellow health tagged to it. Recall from our previous discussion that yellow means that some replicas are not (yet) allocated. The reason this happens for this index is because Elasticsearch by default created one replica for this index. Since we only have one node running at the moment, that one replica cannot yet be allocated (for high availability) until a later point in time when another node joins the cluster. Once that replica gets allocated onto a second node, the health status for this index will turn to green.</simpara>
</section>
<section id="_index_and_query_a_document">
<title>Index and Query a Document<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></title>
<simpara>Let&#8217;s now put something into our customer index. Remember previously that in order to index a document, we must tell Elasticsearch which type in the index it should go to.</simpara>
<simpara>Let&#8217;s index a simple customer document into the customer index, "external" type, with an ID of 1 as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /customer/external/1?pretty
{
  "name": "John Doe"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>And the response:</simpara>
<programlisting language="sh" linenumbering="unnumbered">{
  "_index" : "customer",
  "_type" : "external",
  "_id" : "1",
  "_version" : 1,
  "result" : "created",
  "_shards" : {
    "total" : 2,
    "successful" : 1,
    "failed" : 0
  },
  "created" : true
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>From the above, we can see that a new customer document was successfully created inside the customer index and the external type. The document also has an internal id of 1 which we specified at index time.</simpara>
<simpara>It is important to note that Elasticsearch does not require you to explicitly create an index first before you can index documents into it. In the previous example, Elasticsearch will automatically create the customer index if it didn&#8217;t already exist beforehand.</simpara>
<simpara>Let&#8217;s now retrieve that document that we just indexed:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /customer/external/1?pretty</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>And the response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "_index" : "customer",
  "_type" : "external",
  "_id" : "1",
  "_version" : 1,
  "found" : true,
  "_source" : { "name": "John Doe" }
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>Nothing out of the ordinary here other than a field, <literal>found</literal>, stating that we found a document with the requested ID 1 and another field, <literal>_source</literal>, which returns the full JSON document that we indexed from the previous step.</simpara>
</section>
<section id="_delete_an_index">
<title>Delete an Index<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></title>
<simpara>Now let&#8217;s delete the index that we just created and then list all the indexes again:</simpara>
<programlisting language="js" linenumbering="unnumbered">DELETE /customer?pretty
GET /_cat/indices?v</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>And the response:</simpara>
<programlisting language="txt" linenumbering="unnumbered">health status index uuid pri rep docs.count docs.deleted store.size pri.store.size</programlisting>
<remark> TESTRESPONSE[_cat]</remark>
<simpara>Which means that the index was deleted successfully and we are now back to where we started with nothing in our cluster.</simpara>
<simpara>Before we move on, let&#8217;s take a closer look again at some of the API commands that we have learned so far:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /customer
PUT /customer/external/1
{
  "name": "John Doe"
}
GET /customer/external/1
DELETE /customer</programlisting>
<remark> CONSOLE</remark>
<simpara>If we study the above commands carefully, we can actually see a pattern of how we access data in Elasticsearch. That pattern can be summarized as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">&lt;REST Verb&gt; /&lt;Index&gt;/&lt;Type&gt;/&lt;ID&gt;</programlisting>
<remark> NOTCONSOLE</remark>
<simpara>This REST access pattern is pervasive throughout all the API commands that if you can simply remember it, you will have a good head start at mastering Elasticsearch.</simpara>
</section>
</chapter>
<chapter id="_modifying_your_data">
<title>Modifying Your Data<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch provides data manipulation and search capabilities in near real time. By default, you can expect a one second delay (refresh interval) from the time you index/update/delete your data until the time that it appears in your search results. This is an important distinction from other platforms like SQL wherein data is immediately available after a transaction is completed.</simpara>
<bridgehead id="_indexing_replacing_documents" renderas="sect2">Indexing/Replacing Documents<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></bridgehead>
<simpara>We&#8217;ve previously seen how we can index a single document. Let&#8217;s recall that command again:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /customer/external/1?pretty
{
  "name": "John Doe"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Again, the above will index the specified document into the customer index, external type, with the ID of 1. If we then executed the above command again with a different (or same) document, Elasticsearch will replace (i.e. reindex) a new document on top of the existing one with the ID of 1:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /customer/external/1?pretty
{
  "name": "Jane Doe"
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>The above changes the name of the document with the ID of 1 from "John Doe" to "Jane Doe". If, on the other hand, we use a different ID, a new document will be indexed and the existing document(s) already in the index remains untouched.</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /customer/external/2?pretty
{
  "name": "Jane Doe"
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>The above indexes a new document with an ID of 2.</simpara>
<simpara>When indexing, the ID part is optional. If not specified, Elasticsearch will generate a random ID and then use it to index the document. The actual ID Elasticsearch generates (or whatever we specified explicitly in the previous examples) is returned as part of the index API call.</simpara>
<simpara>This example shows how to index a document without an explicit ID:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /customer/external?pretty
{
  "name": "Jane Doe"
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Note that in the above case, we are using the <literal>POST</literal> verb instead of PUT since we didn&#8217;t specify an ID.</simpara>
<section id="_updating_documents">
<title>Updating Documents<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></title>
<simpara>In addition to being able to index and replace documents, we can also update documents. Note though that Elasticsearch does not actually do in-place updates under the hood. Whenever we do an update, Elasticsearch deletes the old document and then indexes a new document with the update applied to it in one shot.</simpara>
<simpara>This example shows how to update our previous document (ID of 1) by changing the name field to "Jane Doe":</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /customer/external/1/_update?pretty
{
  "doc": { "name": "Jane Doe" }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>This example shows how to update our previous document (ID of 1) by changing the name field to "Jane Doe" and at the same time add an age field to it:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /customer/external/1/_update?pretty
{
  "doc": { "name": "Jane Doe", "age": 20 }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Updates can also be performed by using simple scripts. This example uses a script to increment the age by 5:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /customer/external/1/_update?pretty
{
  "script" : "ctx._source.age += 5"
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>In the above example, <literal>ctx._source</literal> refers to the current source document that is about to be updated.</simpara>
<simpara>Note that as of this writing, updates can only be performed on a single document at a time. In the future, Elasticsearch might provide the ability to update multiple documents given a query condition (like an <literal>SQL UPDATE-WHERE</literal> statement).</simpara>
</section>
<section id="_deleting_documents">
<title>Deleting Documents<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></title>
<simpara>Deleting a document is fairly straightforward. This example shows how to delete our previous customer with the ID of 2:</simpara>
<programlisting language="js" linenumbering="unnumbered">DELETE /customer/external/2?pretty</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>See the <xref linkend="docs-delete-by-query"/> to delete all documents matching a specific query.
It is worth noting that it is much more efficient to delete a whole index
instead of deleting all documents with the Delete By Query API.</simpara>
</section>
<section id="_batch_processing">
<title>Batch Processing<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></title>
<simpara>In addition to being able to index, update, and delete individual documents, Elasticsearch also provides the ability to perform any of the above operations in batches using the <link linkend="docs-bulk"><literal>_bulk</literal> API</link>. This functionality is important in that it provides a very efficient mechanism to do multiple operations as fast as possible with as few network roundtrips as possible.</simpara>
<simpara>As a quick example, the following call indexes two documents (ID 1 - John Doe and ID 2 - Jane Doe) in one bulk operation:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /customer/external/_bulk?pretty
{"index":{"_id":"1"}}
{"name": "John Doe" }
{"index":{"_id":"2"}}
{"name": "Jane Doe" }</programlisting>
<remark> CONSOLE</remark>
<simpara>This example updates the first document (ID of 1) and then deletes the second document (ID of 2) in one bulk operation:</simpara>
<programlisting language="sh" linenumbering="unnumbered">POST /customer/external/_bulk?pretty
{"update":{"_id":"1"}}
{"doc": { "name": "John Doe becomes Jane Doe" } }
{"delete":{"_id":"2"}}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Note above that for the delete action, there is no corresponding source document after it since deletes only require the ID of the document to be deleted.</simpara>
<simpara>The bulk API executes all the actions sequentially and in order. If a single action fails for whatever reason, it will continue to process the remainder of the actions after it. When the bulk API returns, it will provide a status for each action (in the same order it was sent in) so that you can check if a specific action failed or not.</simpara>
</section>
</chapter>
<chapter id="_exploring_your_data">
<title>Exploring Your Data<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></title>
<bridgehead id="_sample_dataset" renderas="sect2">Sample Dataset<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></bridgehead>
<simpara>Now that we&#8217;ve gotten a glimpse of the basics, let&#8217;s try to work on a more realistic dataset. I&#8217;ve prepared a sample of fictitious JSON documents of customer bank account information. Each document has the following schema:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "account_number": 0,
    "balance": 16623,
    "firstname": "Bradshaw",
    "lastname": "Mckenzie",
    "age": 29,
    "gender": "F",
    "address": "244 Columbus Place",
    "employer": "Euron",
    "email": "bradshawmckenzie@euron.com",
    "city": "Hobucken",
    "state": "CO"
}</programlisting>
<remark> NOTCONSOLE</remark>
<simpara>For the curious, I generated this data from <ulink url="http://www.json-generator.com/"><literal>www.json-generator.com/</literal></ulink> so please ignore the actual values and semantics of the data as these are all randomly generated.</simpara>
<bridgehead id="_loading_the_sample_dataset" renderas="sect2">Loading the Sample Dataset<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></bridgehead>
<simpara>You can download the sample dataset (accounts.json) from <ulink url="https://github.com/elastic/elasticsearch/blob/master/docs/src/test/resources/accounts.json?raw=true">here</ulink>. Extract it to our current directory and let&#8217;s load it into our cluster as follows:</simpara>
<programlisting language="sh" linenumbering="unnumbered">curl -XPOST 'localhost:9200/bank/account/_bulk?pretty&amp;refresh' --data-binary "@accounts.json"
curl 'localhost:9200/_cat/indices?v'</programlisting>
<remark> NOTCONSOLE</remark>
<simpara>And the response:</simpara>
<programlisting language="js" linenumbering="unnumbered">health status index uuid                   pri rep docs.count docs.deleted store.size pri.store.size
yellow open   bank  l7sSYV2cQXmu6_4rJWVIww   5   1       1000            0    128.6kb        128.6kb</programlisting>
<remark> TESTRESPONSE[s/128.6kb/\\d+(\\.\\d+)?[mk]?b/]</remark>
<remark> TESTRESPONSE[s/l7sSYV2cQXmu6_4rJWVIww/.+/ _cat]</remark>
<simpara>Which means that we just successfully bulk indexed 1000 documents into the bank index (under the account type).</simpara>
<section id="_the_search_api">
<title>The Search API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></title>
<simpara>Now let&#8217;s start with some simple searches. There are two basic ways to run searches: one is by sending search parameters through the <link linkend="search-uri-request">REST request URI</link> and the other by sending them through the <link linkend="search-request-body">REST request body</link>. The request body method allows you to be more expressive and also to define your searches in a more readable JSON format. We&#8217;ll try one example of the request URI method but for the remainder of this tutorial, we will exclusively be using the request body method.</simpara>
<simpara>The REST API for search is accessible from the <literal>_search</literal> endpoint. This example returns all documents in the bank index:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /bank/_search?q=*&amp;sort=account_number:asc</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Let&#8217;s first dissect the search call. We are searching (<literal>_search</literal> endpoint) in the bank index, and the <literal>q=*</literal> parameter instructs Elasticsearch to match all documents in the index. The <literal>pretty</literal> parameter, again, just tells Elasticsearch to return pretty-printed JSON results.</simpara>
<simpara>And the response (partially shown):</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "took" : 63,
  "timed_out" : false,
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "failed" : 0
  },
  "hits" : {
    "total" : 1000,
    "max_score" : null,
    "hits" : [ {
      "_index" : "bank",
      "_type" : "account",
      "_id" : "0",
      "sort": [0],
      "_score" : null,
      "_source" : {"account_number":0,"balance":16623,"firstname":"Bradshaw","lastname":"Mckenzie","age":29,"gender":"F","address":"244 Columbus Place","employer":"Euron","email":"bradshawmckenzie@euron.com","city":"Hobucken","state":"CO"}
    }, {
      "_index" : "bank",
      "_type" : "account",
      "_id" : "1",
      "sort": [1],
      "_score" : null,
      "_source" : {"account_number":1,"balance":39225,"firstname":"Amber","lastname":"Duke","age":32,"gender":"M","address":"880 Holmes Lane","employer":"Pyrami","email":"amberduke@pyrami.com","city":"Brogan","state":"IL"}
    }, ...
    ]
  }
}</programlisting>
<remark> TESTRESPONSE[s/"took" : 63/"took" : $body.took/]</remark>
<remark> TESTRESPONSE[s/\.\.\./$body.hits.hits.2, $body.hits.hits.3, $body.hits.hits.4, $body.hits.hits.5, $body.hits.hits.6, $body.hits.hits.7, $body.hits.hits.8, $body.hits.hits.9/]</remark>
<simpara>As for the response, we see the following parts:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>took</literal> – time in milliseconds for Elasticsearch to execute the search
</simpara>
</listitem>
<listitem>
<simpara>
<literal>timed_out</literal> – tells us if the search timed out or not
</simpara>
</listitem>
<listitem>
<simpara>
<literal>_shards</literal> – tells us how many shards were searched, as well as a count of the successful/failed searched shards
</simpara>
</listitem>
<listitem>
<simpara>
<literal>hits</literal> – search results
</simpara>
</listitem>
<listitem>
<simpara>
<literal>hits.total</literal> – total number of documents matching our search criteria
</simpara>
</listitem>
<listitem>
<simpara>
<literal>hits.hits</literal> – actual array of search results (defaults to first 10 documents)
</simpara>
</listitem>
<listitem>
<simpara>
<literal>sort</literal> - sort key for results (missing if sorting by score)
</simpara>
</listitem>
<listitem>
<simpara>
<literal>_score</literal> and <literal>max_score</literal> - ignore these fields for now
</simpara>
</listitem>
</itemizedlist>
<simpara>Here is the same exact search above using the alternative request body method:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /bank/_search
{
  "query": { "match_all": {} },
  "sort": [
    { "account_number": "asc" }
  ]
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>The difference here is that instead of passing <literal>q=*</literal> in the URI, we POST a JSON-style query request body to the <literal>_search</literal> API. We&#8217;ll discuss this JSON query in the next section.</simpara>
<simpara>It is important to understand that once you get your search results back, Elasticsearch is completely done with the request and does not maintain any kind of server-side resources or open cursors into your results. This is in stark contrast to many other platforms such as SQL wherein you may initially get a partial subset of your query results up-front and then you have to continuously go back to the server if you want to fetch (or page through) the rest of the results using some kind of stateful server-side cursor.</simpara>
</section>
<section id="_introducing_the_query_language">
<title>Introducing the Query Language<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch provides a JSON-style domain-specific language that you can use to execute queries. This is referred to as the <link linkend="query-dsl">Query DSL</link>. The query language is quite comprehensive and can be intimidating at first glance but the best way to actually learn it is to start with a few basic examples.</simpara>
<simpara>Going back to our last example, we executed this query:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /bank/_search
{
  "query": { "match_all": {} }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Dissecting the above, the <literal>query</literal> part tells us what our query definition is and the <literal>match_all</literal> part is simply the type of query that we want to run. The <literal>match_all</literal> query is simply a search for all documents in the specified index.</simpara>
<simpara>In addition to the <literal>query</literal> parameter, we also can pass other parameters to
influence the search results. In the example in the section above we passed in
<literal>sort</literal>, here we pass in <literal>size</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /bank/_search
{
  "query": { "match_all": {} },
  "size": 1
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Note that if <literal>size</literal> is not specified, it defaults to 10.</simpara>
<simpara>This example does a <literal>match_all</literal> and returns documents 11 through 20:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /bank/_search
{
  "query": { "match_all": {} },
  "from": 10,
  "size": 10
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>The <literal>from</literal> parameter (0-based) specifies which document index to start from and the <literal>size</literal> parameter specifies how many documents to return starting at the from parameter. This feature is useful when implementing paging of search results. Note that if <literal>from</literal> is not specified, it defaults to 0.</simpara>
<simpara>This example does a <literal>match_all</literal> and sorts the results by account balance in descending order and returns the top 10 (default size) documents.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /bank/_search
{
  "query": { "match_all": {} },
  "sort": { "balance": { "order": "desc" } }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
</section>
<section id="_executing_searches">
<title>Executing Searches<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></title>
<simpara>Now that we have seen a few of the basic search parameters, let&#8217;s dig in some more into the Query DSL. Let&#8217;s first take a look at the returned document fields. By default, the full JSON document is returned as part of all searches. This is referred to as the source (<literal>_source</literal> field in the search hits). If we don&#8217;t want the entire source document returned, we have the ability to request only a few fields from within source to be returned.</simpara>
<simpara>This example shows how to return two fields, <literal>account_number</literal> and <literal>balance</literal> (inside of <literal>_source</literal>), from the search:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /bank/_search
{
  "query": { "match_all": {} },
  "_source": ["account_number", "balance"]
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Note that the above example simply reduces the <literal>_source</literal> field. It will still only return one field named <literal>_source</literal> but within it, only the fields <literal>account_number</literal> and <literal>balance</literal> are included.</simpara>
<simpara>If you come from a SQL background, the above is somewhat similar in concept to the <literal>SQL SELECT FROM</literal> field list.</simpara>
<simpara>Now let&#8217;s move on to the query part. Previously, we&#8217;ve seen how the <literal>match_all</literal> query is used to match all documents. Let&#8217;s now introduce a new query called the <link linkend="query-dsl-match-query"><literal>match</literal> query</link>, which can be thought of as a basic fielded search query (i.e. a search done against a specific field or set of fields).</simpara>
<simpara>This example returns the account numbered 20:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /bank/_search
{
  "query": { "match": { "account_number": 20 } }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>This example returns all accounts containing the term "mill" in the address:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /bank/_search
{
  "query": { "match": { "address": "mill" } }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>This example returns all accounts containing the term "mill" or "lane" in the address:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /bank/_search
{
  "query": { "match": { "address": "mill lane" } }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>This example is a variant of <literal>match</literal> (<literal>match_phrase</literal>) that returns all accounts containing the phrase "mill lane" in the address:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /bank/_search
{
  "query": { "match_phrase": { "address": "mill lane" } }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Let&#8217;s now introduce the <link linkend="query-dsl-bool-query"><literal>bool</literal>(ean) query</link>. The <literal>bool</literal> query allows us to compose smaller queries into bigger queries using boolean logic.</simpara>
<simpara>This example composes two <literal>match</literal> queries and returns all accounts containing "mill" and "lane" in the address:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /bank/_search
{
  "query": {
    "bool": {
      "must": [
        { "match": { "address": "mill" } },
        { "match": { "address": "lane" } }
      ]
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>In the above example, the <literal>bool must</literal> clause specifies all the queries that must be true for a document to be considered a match.</simpara>
<simpara>In contrast, this example composes two <literal>match</literal> queries and returns all accounts containing "mill" or "lane" in the address:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /bank/_search
{
  "query": {
    "bool": {
      "should": [
        { "match": { "address": "mill" } },
        { "match": { "address": "lane" } }
      ]
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>In the above example, the <literal>bool should</literal> clause specifies a list of queries either of which must be true for a document to be considered a match.</simpara>
<simpara>This example composes two <literal>match</literal> queries and returns all accounts that contain neither "mill" nor "lane" in the address:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /bank/_search
{
  "query": {
    "bool": {
      "must_not": [
        { "match": { "address": "mill" } },
        { "match": { "address": "lane" } }
      ]
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>In the above example, the <literal>bool must_not</literal> clause specifies a list of queries none of which must be true for a document to be considered a match.</simpara>
<simpara>We can combine <literal>must</literal>, <literal>should</literal>, and <literal>must_not</literal> clauses simultaneously inside a <literal>bool</literal> query. Furthermore, we can compose <literal>bool</literal> queries inside any of these <literal>bool</literal> clauses to mimic any complex multi-level boolean logic.</simpara>
<simpara>This example returns all accounts of anybody who is 40 years old but don&#8217;t live in ID(aho):</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /bank/_search
{
  "query": {
    "bool": {
      "must": [
        { "match": { "age": "40" } }
      ],
      "must_not": [
        { "match": { "state": "ID" } }
      ]
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
</section>
<section id="_executing_filters">
<title>Executing Filters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></title>
<simpara>In the previous section, we skipped over a little detail called the document score (<literal>_score</literal> field in the search results). The score is a numeric value that is a relative measure of how well the document matches the search query that we specified. The higher the score, the more relevant the document is, the lower the score, the less relevant the document is.</simpara>
<simpara>But queries do not always need to produce scores, in particular when they are only used for "filtering" the document set. Elasticsearch detects these situations and automatically optimizes query execution in order not to compute useless scores.</simpara>
<simpara>The <link linkend="query-dsl-bool-query"><literal>bool</literal> query</link> that we introduced in the previous section also supports <literal>filter</literal> clauses which allow to use a query to restrict the documents that will be matched by other clauses, without changing how scores are computed. As an example, let&#8217;s introduce the <link linkend="query-dsl-range-query"><literal>range</literal> query</link>, which allows us to filter documents by a range of values. This is generally used for numeric or date filtering.</simpara>
<simpara>This example uses a bool query to return all accounts with balances between 20000 and 30000, inclusive. In other words, we want to find accounts with a balance that is greater than or equal to 20000 and less than or equal to 30000.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /bank/_search
{
  "query": {
    "bool": {
      "must": { "match_all": {} },
      "filter": {
        "range": {
          "balance": {
            "gte": 20000,
            "lte": 30000
          }
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Dissecting the above, the bool query contains a <literal>match_all</literal> query (the query part) and a <literal>range</literal> query (the filter part). We can substitute any other queries into the query and the filter parts. In the above case, the range query makes perfect sense since documents falling into the range all match "equally", i.e., no document is more relevant than another.</simpara>
<simpara>In addition to the <literal>match_all</literal>, <literal>match</literal>, <literal>bool</literal>, and <literal>range</literal> queries, there are a lot of other query types that are available and we won&#8217;t go into them here. Since we already have a basic understanding of how they work, it shouldn&#8217;t be too difficult to apply this knowledge in learning and experimenting with the other query types.</simpara>
</section>
<section id="_executing_aggregations">
<title>Executing Aggregations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></title>
<simpara>Aggregations provide the ability to group and extract statistics from your data. The easiest way to think about aggregations is by roughly equating it to the SQL GROUP BY and the SQL aggregate functions. In Elasticsearch, you have the ability to execute searches returning hits and at the same time return aggregated results separate from the hits all in one response. This is very powerful and efficient in the sense that you can run queries and multiple aggregations and get the results back of both (or either) operations in one shot avoiding network roundtrips using a concise and simplified API.</simpara>
<simpara>To start with, this example groups all the accounts by state, and then returns the top 10 (default) states sorted by count descending (also default):</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /bank/_search
{
  "size": 0,
  "aggs": {
    "group_by_state": {
      "terms": {
        "field": "state.keyword"
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>In SQL, the above aggregation is similar in concept to:</simpara>
<programlisting language="sh" linenumbering="unnumbered">SELECT state, COUNT(*) FROM bank GROUP BY state ORDER BY COUNT(*) DESC</programlisting>
<simpara>And the response (partially shown):</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "took": 29,
  "timed_out": false,
  "_shards": {
    "total": 5,
    "successful": 5,
    "failed": 0
  },
  "hits" : {
    "total" : 1000,
    "max_score" : 0.0,
    "hits" : [ ]
  },
  "aggregations" : {
    "group_by_state" : {
      "doc_count_error_upper_bound": 20,
      "sum_other_doc_count": 770,
      "buckets" : [ {
        "key" : "ID",
        "doc_count" : 27
      }, {
        "key" : "TX",
        "doc_count" : 27
      }, {
        "key" : "AL",
        "doc_count" : 25
      }, {
        "key" : "MD",
        "doc_count" : 25
      }, {
        "key" : "TN",
        "doc_count" : 23
      }, {
        "key" : "MA",
        "doc_count" : 21
      }, {
        "key" : "NC",
        "doc_count" : 21
      }, {
        "key" : "ND",
        "doc_count" : 21
      }, {
        "key" : "ME",
        "doc_count" : 20
      }, {
        "key" : "MO",
        "doc_count" : 20
      } ]
    }
  }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 29/"took": $body.took/]</remark>
<simpara>We can see that there are 27 accounts in <literal>ID</literal> (Idaho), followed by 27 accounts
in <literal>TX</literal> (Texas), followed by 25 accounts in <literal>AL</literal> (Alabama), and so forth.</simpara>
<simpara>Note that we set <literal>size=0</literal> to not show search hits because we only want to see the aggregation results in the response.</simpara>
<simpara>Building on the previous aggregation, this example calculates the average account balance by state (again only for the top 10 states sorted by count in descending order):</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /bank/_search
{
  "size": 0,
  "aggs": {
    "group_by_state": {
      "terms": {
        "field": "state.keyword"
      },
      "aggs": {
        "average_balance": {
          "avg": {
            "field": "balance"
          }
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Notice how we nested the <literal>average_balance</literal> aggregation inside the <literal>group_by_state</literal> aggregation. This is a common pattern for all the aggregations. You can nest aggregations inside aggregations arbitrarily to extract pivoted summarizations that you require from your data.</simpara>
<simpara>Building on the previous aggregation, let&#8217;s now sort on the average balance in descending order:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /bank/_search
{
  "size": 0,
  "aggs": {
    "group_by_state": {
      "terms": {
        "field": "state.keyword",
        "order": {
          "average_balance": "desc"
        }
      },
      "aggs": {
        "average_balance": {
          "avg": {
            "field": "balance"
          }
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>This example demonstrates how we can group by age brackets (ages 20-29, 30-39, and 40-49), then by gender, and then finally get the average account balance, per age bracket, per gender:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /bank/_search
{
  "size": 0,
  "aggs": {
    "group_by_age": {
      "range": {
        "field": "age",
        "ranges": [
          {
            "from": 20,
            "to": 30
          },
          {
            "from": 30,
            "to": 40
          },
          {
            "from": 40,
            "to": 50
          }
        ]
      },
      "aggs": {
        "group_by_gender": {
          "terms": {
            "field": "gender.keyword"
          },
          "aggs": {
            "average_balance": {
              "avg": {
                "field": "balance"
              }
            }
          }
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>There are a many other aggregations capabilities that we won&#8217;t go into detail here. The <link linkend="search-aggregations">aggregations reference guide</link> is a great starting point if you want to do further experimentation.</simpara>
</section>
</chapter>
<chapter id="_conclusion">
<title>Conclusion<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/getting-started.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch is both a simple and complex product. We&#8217;ve so far learned the basics of what it is, how to look inside of it, and how to work with it using some of the REST APIs. I hope that this tutorial has given you a better understanding of what Elasticsearch is and more importantly, inspired you to further experiment with the rest of its great features!</simpara>
</chapter>
</part>
<part id="setup">
<title>Setup Elasticsearch <ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup.asciidoc">Edit me</ulink></title>
<partintro>
<simpara>This section includes information on how to setup Elasticsearch and get it
running, including:</simpara>
<itemizedlist>
<listitem>
<simpara>
Downloading
</simpara>
</listitem>
<listitem>
<simpara>
Installing
</simpara>
</listitem>
<listitem>
<simpara>
Starting
</simpara>
</listitem>
<listitem>
<simpara>
Configuring
</simpara>
</listitem>
</itemizedlist>
<bridgehead id="supported-platforms" renderas="sect1">Supported platforms<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup.asciidoc">Edit me</ulink></bridgehead>
<simpara>The matrix of officially supported operating systems and JVMs is available here:
<ulink url="/support/matrix">Support Matrix</ulink>.  Elasticsearch is tested on the listed
platforms, but it is possible that it will work on other platforms too.</simpara>
<bridgehead id="jvm-version" renderas="sect1">Java (JVM) Version<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup.asciidoc">Edit me</ulink></bridgehead>
<simpara>Elasticsearch is built using Java, and requires at least
<ulink url="http://www.oracle.com/technetwork/java/javase/downloads/index.html">Java 8</ulink> in
order to run. Only Oracle&#8217;s Java and the OpenJDK are supported. The same JVM
version should be used on all Elasticsearch nodes and clients.</simpara>
<simpara>We recommend installing Java version <emphasis role="strong">1.8.0_73 or later</emphasis>. Elasticsearch will
refuse to start if a known-bad version of Java is used.</simpara>
<simpara>The version of Java that Elasticsearch will use can be configured by setting
the <literal>JAVA_HOME</literal> environment variable.</simpara>
<note><simpara>Elasticsearch ships with default configuration for running Elasticsearch on 64-bit server JVMs. If you are using a 32-bit client JVM,
you must remove <literal>-server</literal> from <link linkend="jvm-options">jvm.options</link> and if you are using any 32-bit JVM you should reconfigure the thread stack size
from <literal>-Xss1m</literal> to <literal>-Xss320k</literal>.</simpara></note>
</partintro>
<chapter id="install-elasticsearch">
<title>Installing Elasticsearch<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch is provided in the following package formats:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>zip</literal>/<literal>tar.gz</literal>
</simpara>
</entry>
<entry>
<simpara>
The <literal>zip</literal> and <literal>tar.gz</literal> packages are suitable for installation on any system
and are the easiest choice for getting started with Elasticsearch.
</simpara>
<simpara><xref linkend="zip-targz"/> or <xref linkend="windows"/></simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>deb</literal>
</simpara>
</entry>
<entry>
<simpara>
The <literal>deb</literal> package is suitable for Debian, Ubuntu, and other Debian-based
systems.  Debian packages may be downloaded from the Elasticsearch website or
from our Debian repository.
</simpara>
<simpara><xref linkend="deb"/></simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>rpm</literal>
</simpara>
</entry>
<entry>
<simpara>
The <literal>rpm</literal> package is suitable for installation on Red Hat, Centos, SLES,
OpenSuSE and other RPM-based systems.  RPMs may be downloaded from the
Elasticsearch website or from our RPM repository.
</simpara>
<simpara><xref linkend="rpm"/></simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>docker</literal>
</simpara>
</entry>
<entry>
<simpara>
An image is available for running Elasticsearch as a Docker container. It ships with <ulink url="https://www.elastic.co/guide/en/x-pack/current/index.html">X-Pack</ulink> pre-installed and may be downloaded from the Elastic Docker Registry.
</simpara>
<simpara><xref linkend="docker"/></simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="config-mgmt-tools" renderas="sect2">Configuration Management Tools<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install.asciidoc">Edit me</ulink></bridgehead>
<simpara>We also provide the following configuration management tools to help with
large deployments:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
Puppet
</simpara>
</entry>
<entry>
<simpara>
<ulink url="https://github.com/elastic/puppet-elasticsearch">puppet-elasticsearch</ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Chef
</simpara>
</entry>
<entry>
<simpara>
<ulink url="https://github.com/elastic/cookbook-elasticsearch">cookbook-elasticsearch</ulink>
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<section id="zip-targz">
<title>Install Elasticsearch with <literal>.zip</literal> or <literal>.tar.gz</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/zip-targz.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch is provided as a <literal>.zip</literal> and as a <literal>.tar.gz</literal> package.  These
packages can be used to install Elasticsearch on any system and are the
easiest package format to use when trying out Elasticsearch.</simpara>
<simpara>The latest stable version of Elasticsearch can be found on the
<ulink url="/downloads/elasticsearch">Download Elasticsearch</ulink> page.
Other versions can be found on the
<ulink url="/downloads/past-releases">Past Releases page</ulink>.</simpara>
<note><simpara>Elasticsearch requires Java 8 or later. Use the
<ulink url="http://www.oracle.com/technetwork/java/javase/downloads/index.html">official Oracle distribution</ulink>
or an open-source distribution such as <ulink url="http://openjdk.java.net">OpenJDK</ulink>.</simpara></note>
<section id="install-zip">
<title>Download and install the <literal>.zip</literal> package<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/zip-targz.asciidoc">Edit me</ulink></title>
<simpara>Version 5.1.1 of Elasticsearch has not yet been released.</simpara>
</section>
<section id="install-targz">
<title>Download and install the <literal>.tar.gz</literal> package<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/zip-targz.asciidoc">Edit me</ulink></title>
<simpara>Version 5.1.1 of Elasticsearch has not yet been released.</simpara>
</section>
<section id="zip-targz-running">
<title>Running Elasticsearch from the command line<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/zip-targz.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch can be started from the command line as follows:</simpara>
<programlisting language="sh" linenumbering="unnumbered">./bin/elasticsearch</programlisting>
<simpara>By default, Elasticsearch runs in the foreground, prints its logs to the
standard output (<literal>stdout</literal>), and can be stopped by pressing <literal>Ctrl-C</literal>.</simpara>
</section>
<section id="_checking_that_elasticsearch_is_running">
<title>Checking that Elasticsearch is running<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/check-running.asciidoc">Edit me</ulink></title>
<simpara>You can test that your Elasticsearch node is running by sending an HTTP
request to port <literal>9200</literal> on <literal>localhost</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /</programlisting>
<remark> CONSOLE</remark>
<simpara>which should give you a response something like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "name" : "Cp8oag6",
  "cluster_name" : "elasticsearch",
  "cluster_uuid" : "AT69_T_DTp-1qgIJlatQqA",
  "version" : {
    "number" : "5.1.1",
    "build_hash" : "f27399d",
    "build_date" : "2016-03-30T09:51:41.449Z",
    "build_snapshot" : false,
    "lucene_version" : "6.3.0"
  },
  "tagline" : "You Know, for Search"
}</programlisting>
<remark> TESTRESPONSE[s/"name" : "Cp8oag6",/"name" : "$body.name",/]</remark>
<remark> TESTRESPONSE[s/"cluster_name" : "elasticsearch",/"cluster_name" : "$body.cluster_name",/]</remark>
<remark> TESTRESPONSE[s/"cluster_uuid" : "AT69_T_DTp-1qgIJlatQqA",/"cluster_uuid" : "$body.cluster_uuid",/]</remark>
<remark> TESTRESPONSE[s/"build_hash" : "f27399d",/"build_hash" : "$body.version.build_hash",/]</remark>
<remark> TESTRESPONSE[s/"build_date" : "2016-03-30T09:51:41.449Z",/"build_date" : $body.version.build_date,/]</remark>
<remark> TESTRESPONSE[s/"build_snapshot" : false,/"build_snapshot" : $body.version.build_snapshot,/]</remark>
<remark> So much s/// but at least we test that the layout is close to matching....</remark>
<simpara>Log printing to <literal>stdout</literal> can be disabled using the <literal>-q</literal> or <literal>--quiet</literal>
option on the command line.</simpara>
</section>
<section id="setup-installation-daemon">
<title>Running as a daemon<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/zip-targz.asciidoc">Edit me</ulink></title>
<simpara>To run Elasticsearch as a daemon, specify <literal>-d</literal> on the command line, and record
the process ID in a file using the <literal>-p</literal> option:</simpara>
<programlisting language="sh" linenumbering="unnumbered">./bin/elasticsearch -d -p pid</programlisting>
<simpara>Log messages can be found in the <literal>$ES_HOME/logs/</literal> directory.</simpara>
<simpara>To shut down Elasticsearch, kill the process ID recorded in the <literal>pid</literal> file:</simpara>
<programlisting language="sh" linenumbering="unnumbered">kill `cat pid`</programlisting>
<note><simpara>The startup scripts provided in the <link linkend="rpm">RPM</link> and <link linkend="deb">Debian</link>
packages take care of starting and stopping the Elasticsearch process for you.</simpara></note>
</section>
<section id="zip-targz-configuring">
<title>Configuring Elasticsearch on the command line<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/zip-targz.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch loads its configuration from the <literal>$ES_HOME/config/elasticsearch.yml</literal>
file by default.  The format of this config file is explained in
<xref linkend="settings"/>.</simpara>
<simpara>Any settings that can be specified in the config file can also be specified on
the command line, using the <literal>-E</literal> syntax as follows:</simpara>
<programlisting language="sh" linenumbering="unnumbered">./bin/elasticsearch -d -Ecluster.name=my_cluster -Enode.name=node_1</programlisting>
<tip><simpara>Typically, any cluster-wide settings (like <literal>cluster.name</literal>) should be
added to the <literal>elasticsearch.yml</literal> config file, while any node-specific settings
such as <literal>node.name</literal> could be specified on the command line.</simpara></tip>
</section>
<section id="zip-targz-layout">
<title>Directory layout of <literal>.zip</literal> and <literal>.tar.gz</literal> archives<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/zip-targz.asciidoc">Edit me</ulink></title>
<simpara>The <literal>.zip</literal> and <literal>.tar.gz</literal> packages are entirely self-contained. All files and
directories are, by default, contained within <literal>$ES_HOME</literal>&#8201;&#8212;&#8201;the directory
created when unpacking the archive.</simpara>
<simpara>This is very convenient because you don&#8217;t have to create any directories to
start using Elasticsearch, and uninstalling Elasticsearch is as easy as
removing the <literal>$ES_HOME</literal> directory.  However, it is advisable to change the
default locations of the config directory, the data directory, and the logs
directory so that you do not delete important data later on.</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"> Type </entry>
<entry align="left" valign="top"> Description </entry>
<entry align="left" valign="top"> Default Location </entry>
<entry align="left" valign="top"> Setting</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">home</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Elasticsearch home directory or <literal>$ES_HOME</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Directory created by unpacking the archive</simpara></entry>
<entry align="left" valign="top"><simpara><literal></literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">bin</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Binary scripts including <literal>elasticsearch</literal> to start a node
    and <literal>elasticsearch-plugin</literal> to install plugins</simpara></entry>
<entry align="left" valign="top"><simpara><literal>$ES_HOME/bin</literal></simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">conf</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Configuration files including <literal>elasticsearch.yml</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>$ES_HOME/config</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>path.conf</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">data</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>The location of the data files of each index / shard allocated
    on the node. Can hold multiple locations.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>$ES_HOME/data</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>path.data</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">logs</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Log files location.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>$ES_HOME/logs</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>path.logs</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">plugins</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Plugin files location. Each plugin will be contained in a subdirectory.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>$ES_HOME/plugins</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal></literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">repo</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Shared file system repository locations. Can hold multiple locations. A file system repository can be placed in to any subdirectory of any directory specified here.</simpara></entry>
<entry align="left" valign="top"><simpara>Not configured</simpara></entry>
<entry align="left" valign="top"><simpara><literal>path.repo</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">script</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Location of script files.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>$ES_HOME/scripts</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>path.scripts</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section id="_next_steps" role="exclude">
<title>Next steps<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/next-steps.asciidoc">Edit me</ulink></title>
<simpara>You now have a test Elasticsearch environment set up.  Before you start
serious development or go into production with Elasticsearch, you will need to
do some additional setup:</simpara>
<itemizedlist>
<listitem>
<simpara>
Learn how to <link linkend="settings">configure Elasticsearch</link>.
</simpara>
</listitem>
<listitem>
<simpara>
Configure <link linkend="important-settings">important Elasticsearch settings</link>.
</simpara>
</listitem>
<listitem>
<simpara>
Configure <link linkend="system-config">important system settings</link>.
</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section id="deb">
<title>Install Elasticsearch with Debian Package<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/deb.asciidoc">Edit me</ulink></title>
<simpara>The Debian package for Elasticsearch can be <link linkend="install-rpm">downloaded from our website</link>
or from our  <link linkend="deb-repo">APT repository</link>. It can be used to install
Elasticsearch on any Debian-based system such as Debian and Ubuntu.</simpara>
<simpara>The latest stable version of Elasticsearch can be found on the
<ulink url="/downloads/elasticsearch">Download Elasticsearch</ulink> page. Other versions can
be found on the <ulink url="/downloads/past-releases">Past Releases page</ulink>.</simpara>
<note><simpara>Elasticsearch requires Java 8 or later. Use the
<ulink url="http://www.oracle.com/technetwork/java/javase/downloads/index.html">official Oracle distribution</ulink>
or an open-source distribution such as <ulink url="http://openjdk.java.net">OpenJDK</ulink>.</simpara></note>
<section id="deb-key">
<title>Import the Elasticsearch PGP Key<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/deb.asciidoc">Edit me</ulink></title>
<simpara>We sign all of our packages with the Elasticsearch Signing Key (PGP key
<ulink url="https://pgp.mit.edu/pks/lookup?op=vindex&amp;search=0xD27D666CD88E42B4">D88E42B4</ulink>,
available from <ulink url="https://pgp.mit.edu">https://pgp.mit.edu</ulink>) with fingerprint:</simpara>
<literallayout class="monospaced">4609 5ACC 8548 582C 1A26 99A9 D27D 666C D88E 42B4</literallayout>
<simpara>Download and install the public signing key:</simpara>
<programlisting language="sh" linenumbering="unnumbered">wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -</programlisting>
</section>
<section id="deb-repo">
<title>Installing from the APT repository<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/deb.asciidoc">Edit me</ulink></title>
<simpara>Version 5.1.1 of Elasticsearch has not yet been released.</simpara>
<note><simpara>On systemd-based distributions, the installation scripts will attempt to set kernel parameters (e.g.,
<literal>vm.max_map_count</literal>); you can skip this by setting the environment variable <literal>ES_SKIP_SET_KERNEL_PARAMETERS</literal> to <literal>true</literal>.</simpara></note>
</section>
<section id="install-deb">
<title>Download and install the Debian package manually<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/deb.asciidoc">Edit me</ulink></title>
<simpara>Version 5.1.1 of Elasticsearch has not yet been released.</simpara>
</section>
<section id="_sysv_literal_init_literal_vs_literal_systemd_literal">
<title>SysV <literal>init</literal> vs <literal>systemd</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/init-systemd.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch is not started automatically after installation. How to start
and stop Elasticsearch depends on whether your system uses SysV <literal>init</literal> or
<literal>systemd</literal> (used by newer distributions).  You can tell which is being used by
running this command:</simpara>
<programlisting language="sh" linenumbering="unnumbered">ps -p 1</programlisting>
</section>
<section id="deb-running-init">
<title>Running Elasticsearch with SysV <literal>init</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/deb.asciidoc">Edit me</ulink></title>
<simpara>Use the <literal>update-rc.d</literal> command to configure Elasticsearch to start automatically
when the system boots up:</simpara>
<programlisting language="sh" linenumbering="unnumbered">sudo update-rc.d elasticsearch defaults 95 10</programlisting>
<simpara>Elasticsearch can be started and stopped using the <literal>service</literal> command:</simpara>
<programlisting language="sh" linenumbering="unnumbered">sudo -i service elasticsearch start
sudo -i service elasticsearch stop</programlisting>
<simpara>If Elasticsearch fails to start for any reason, it will print the reason for
failure to STDOUT. Log files can be found in <literal>/var/log/elasticsearch/</literal>.</simpara>
</section>
<section id="deb-running-systemd">
<title>Running Elasticsearch with <literal>systemd</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/systemd.asciidoc">Edit me</ulink></title>
<simpara>To configure Elasticsearch to start automatically when the system boots up,
run the following commands:</simpara>
<programlisting language="sh" linenumbering="unnumbered">sudo /bin/systemctl daemon-reload
sudo /bin/systemctl enable elasticsearch.service</programlisting>
<simpara>Elasticsearch can be started and stopped as follows:</simpara>
<programlisting language="sh" linenumbering="unnumbered">sudo systemctl start elasticsearch.service
sudo systemctl stop elasticsearch.service</programlisting>
<simpara>These commands provide no feedback as to whether Elasticsearch was started
successfully or not. Instead, this information will be written in the log
files located in <literal>/var/log/elasticsearch/</literal>.</simpara>
<simpara>By default the Elasticsearch service doesn&#8217;t log information in the <literal>systemd</literal>
journal. To enable <literal>journalctl</literal> logging, the <literal>--quiet</literal> option must be removed
 from the <literal>ExecStart</literal> command line in the <literal>elasticsearch.service</literal> file.</simpara>
<simpara>When <literal>systemd</literal> logging is enabled, the logging information are available using
the <literal>journalctl</literal> commands:</simpara>
<simpara>To tail the journal:</simpara>
<programlisting language="sh" linenumbering="unnumbered">sudo journalctl -f</programlisting>
<simpara>To list journal entries for the elasticsearch service:</simpara>
<programlisting language="sh" linenumbering="unnumbered">sudo journalctl --unit elasticsearch</programlisting>
<simpara>To list journal entries for the elasticsearch service starting from a given time:</simpara>
<programlisting language="sh" linenumbering="unnumbered">sudo journalctl --unit elasticsearch --since  "2016-10-30 18:17:16"</programlisting>
<simpara>Check <literal>man journalctl</literal> or <ulink url="https://www.freedesktop.org/software/systemd/man/journalctl.html">https://www.freedesktop.org/software/systemd/man/journalctl.html</ulink> for
more command line options.</simpara>
</section>
<section id="deb-check-running">
<title>Checking that Elasticsearch is running<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/check-running.asciidoc">Edit me</ulink></title>
<simpara>You can test that your Elasticsearch node is running by sending an HTTP
request to port <literal>9200</literal> on <literal>localhost</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /</programlisting>
<remark> CONSOLE</remark>
<simpara>which should give you a response something like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "name" : "Cp8oag6",
  "cluster_name" : "elasticsearch",
  "cluster_uuid" : "AT69_T_DTp-1qgIJlatQqA",
  "version" : {
    "number" : "5.1.1",
    "build_hash" : "f27399d",
    "build_date" : "2016-03-30T09:51:41.449Z",
    "build_snapshot" : false,
    "lucene_version" : "6.3.0"
  },
  "tagline" : "You Know, for Search"
}</programlisting>
<remark> TESTRESPONSE[s/"name" : "Cp8oag6",/"name" : "$body.name",/]</remark>
<remark> TESTRESPONSE[s/"cluster_name" : "elasticsearch",/"cluster_name" : "$body.cluster_name",/]</remark>
<remark> TESTRESPONSE[s/"cluster_uuid" : "AT69_T_DTp-1qgIJlatQqA",/"cluster_uuid" : "$body.cluster_uuid",/]</remark>
<remark> TESTRESPONSE[s/"build_hash" : "f27399d",/"build_hash" : "$body.version.build_hash",/]</remark>
<remark> TESTRESPONSE[s/"build_date" : "2016-03-30T09:51:41.449Z",/"build_date" : $body.version.build_date,/]</remark>
<remark> TESTRESPONSE[s/"build_snapshot" : false,/"build_snapshot" : $body.version.build_snapshot,/]</remark>
<remark> So much s/// but at least we test that the layout is close to matching....</remark>
</section>
<section id="deb-configuring">
<title>Configuring Elasticsearch<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/deb.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch loads its configuration from the <literal>/etc/elasticsearch/elasticsearch.yml</literal>
file by default.  The format of this config file is explained in
<xref linkend="settings"/>.</simpara>
<simpara>The Debian package also has a system configuration file (<literal>/etc/default/elasticsearch</literal>),
which allows you to set the following parameters:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>ES_USER</literal>
</simpara>
</entry>
<entry>
<simpara>
  The user to run as, defaults to <literal>elasticsearch</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>ES_GROUP</literal>
</simpara>
</entry>
<entry>
<simpara>
  The group to run as, defaults to <literal>elasticsearch</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>JAVA_HOME</literal>
</simpara>
</entry>
<entry>
<simpara>
  Set a custom Java path to be used.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>MAX_OPEN_FILES</literal>
</simpara>
</entry>
<entry>
<simpara>
    Maximum number of open files, defaults to <literal>65536</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>MAX_LOCKED_MEMORY</literal>
</simpara>
</entry>
<entry>
<simpara>
    Maximum locked memory size. Set to <literal>unlimited</literal> if you use the
    <literal>bootstrap.memory_lock</literal> option in elasticsearch.yml.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>MAX_MAP_COUNT</literal>
</simpara>
</entry>
<entry>
<simpara>
    Maximum number of memory map areas a process may have. If you use <literal>mmapfs</literal>
    as index store type, make sure this is set to a high value. For more
    information, check the
    <ulink url="https://github.com/torvalds/linux/blob/master/Documentation/sysctl/vm.txt">linux kernel documentation</ulink>
    about <literal>max_map_count</literal>. This is set via <literal>sysctl</literal> before starting
    elasticsearch. Defaults to <literal>262144</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>LOG_DIR</literal>
</simpara>
</entry>
<entry>
<simpara>
    Log directory, defaults to <literal>/var/log/elasticsearch</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>DATA_DIR</literal>
</simpara>
</entry>
<entry>
<simpara>
    Data directory, defaults to <literal>/var/lib/elasticsearch</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>CONF_DIR</literal>
</simpara>
</entry>
<entry>
<simpara>
    Configuration file directory (which needs to include <literal>elasticsearch.yml</literal>
    and <literal>log4j2.properties</literal> files), defaults to <literal>/etc/elasticsearch</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>ES_JAVA_OPTS</literal>
</simpara>
</entry>
<entry>
<simpara>
    Any additional JVM system properties you may want to apply.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>RESTART_ON_UPGRADE</literal>
</simpara>
</entry>
<entry>
<simpara>
    Configure restart on package upgrade, defaults to <literal>false</literal>. This means you
    will have to restart your elasticsearch instance after installing a
    package manually. The reason for this is to ensure, that upgrades in a
    cluster do not result in a continuous shard reallocation resulting in high
    network traffic and reducing the response times of your cluster.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<note><simpara>Distributions that use <literal>systemd</literal> require that system resource limits be
configured via <literal>systemd</literal> rather than via the <literal>/etc/sysconfig/elasticsearch</literal>
file.  See <xref linkend="systemd"/> for more information.</simpara></note>
</section>
<section id="deb-layout">
<title>Directory layout of Debian package<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/deb.asciidoc">Edit me</ulink></title>
<simpara>The Debian package places config files, logs, and the data directory in the appropriate
locations for a Debian-based system:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"> Type </entry>
<entry align="left" valign="top"> Description </entry>
<entry align="left" valign="top"> Default Location </entry>
<entry align="left" valign="top"> Setting</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">home</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Elasticsearch home directory or <literal>$ES_HOME</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>/usr/share/elasticsearch</literal></simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">bin</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Binary scripts including <literal>elasticsearch</literal> to start a node
    and <literal>elasticsearch-plugin</literal> to install plugins</simpara></entry>
<entry align="left" valign="top"><simpara><literal>/usr/share/elasticsearch/bin</literal></simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">conf</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Configuration files including <literal>elasticsearch.yml</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>/etc/elasticsearch</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>path.conf</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">conf</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Environment variables including heap size, file descriptors.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>/etc/default/elasticsearch</literal></simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">data</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>The location of the data files of each index / shard allocated
    on the node. Can hold multiple locations.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>/var/lib/elasticsearch</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>path.data</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">logs</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Log files location.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>/var/log/elasticsearch</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>path.logs</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">plugins</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Plugin files location. Each plugin will be contained in a subdirectory.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>/usr/share/elasticsearch/plugins</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal></literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">repo</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Shared file system repository locations. Can hold multiple locations. A file system repository can be placed in to any subdirectory of any directory specified here.</simpara></entry>
<entry align="left" valign="top"><simpara>Not configured</simpara></entry>
<entry align="left" valign="top"><simpara><literal>path.repo</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">script</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Location of script files.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>/etc/elasticsearch/scripts</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>path.scripts</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section id="_next_steps_2" role="exclude">
<title>Next steps<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/next-steps.asciidoc">Edit me</ulink></title>
<simpara>You now have a test Elasticsearch environment set up.  Before you start
serious development or go into production with Elasticsearch, you will need to
do some additional setup:</simpara>
<itemizedlist>
<listitem>
<simpara>
Learn how to <link linkend="settings">configure Elasticsearch</link>.
</simpara>
</listitem>
<listitem>
<simpara>
Configure <link linkend="important-settings">important Elasticsearch settings</link>.
</simpara>
</listitem>
<listitem>
<simpara>
Configure <link linkend="system-config">important system settings</link>.
</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section id="rpm">
<title>Install Elasticsearch with RPM<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/rpm.asciidoc">Edit me</ulink></title>
<simpara>The RPM for Elasticsearch can be <link linkend="install-rpm">downloaded from our website</link>
or from our  <link linkend="rpm-repo">RPM repository</link>. It can be used to install
Elasticsearch on any RPM-based system such as OpenSuSE, SLES, Centos, Red Hat,
and Oracle Enterprise.</simpara>
<note><simpara>RPM install is not supported on distributions with old versions of RPM,
such as SLES 11 and CentOS 5.  Please see <xref linkend="zip-targz"/> instead.</simpara></note>
<simpara>The latest stable version of Elasticsearch can be found on the
<ulink url="/downloads/elasticsearch">Download Elasticsearch</ulink> page. Other versions can
be found on the <ulink url="/downloads/past-releases">Past Releases page</ulink>.</simpara>
<note><simpara>Elasticsearch requires Java 8 or later. Use the
<ulink url="http://www.oracle.com/technetwork/java/javase/downloads/index.html">official Oracle distribution</ulink>
or an open-source distribution such as <ulink url="http://openjdk.java.net">OpenJDK</ulink>.</simpara></note>
<section id="rpm-key">
<title>Import the Elasticsearch PGP Key<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/rpm.asciidoc">Edit me</ulink></title>
<simpara>We sign all of our packages with the Elasticsearch Signing Key (PGP key
<ulink url="https://pgp.mit.edu/pks/lookup?op=vindex&amp;search=0xD27D666CD88E42B4">D88E42B4</ulink>,
available from <ulink url="https://pgp.mit.edu">https://pgp.mit.edu</ulink>) with fingerprint:</simpara>
<literallayout class="monospaced">4609 5ACC 8548 582C 1A26 99A9 D27D 666C D88E 42B4</literallayout>
<simpara>Download and install the public signing key:</simpara>
<programlisting language="sh" linenumbering="unnumbered">rpm --import https://artifacts.elastic.co/GPG-KEY-elasticsearch</programlisting>
</section>
<section id="rpm-repo">
<title>Installing from the RPM repository<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/rpm.asciidoc">Edit me</ulink></title>
<simpara>Version 5.1.1 of Elasticsearch has not yet been released.</simpara>
</section>
<section id="install-rpm">
<title>Download and install the RPM manually<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/rpm.asciidoc">Edit me</ulink></title>
<simpara>Version 5.1.1 of Elasticsearch has not yet been released.</simpara>
<note><simpara>On systemd-based distributions, the installation scripts will attempt to set kernel parameters (e.g.,
<literal>vm.max_map_count</literal>); you can skip this by setting the environment variable <literal>ES_SKIP_SET_KERNEL_PARAMETERS</literal> to <literal>true</literal>.</simpara></note>
</section>
<section id="_sysv_literal_init_literal_vs_literal_systemd_literal_2">
<title>SysV <literal>init</literal> vs <literal>systemd</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/init-systemd.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch is not started automatically after installation. How to start
and stop Elasticsearch depends on whether your system uses SysV <literal>init</literal> or
<literal>systemd</literal> (used by newer distributions).  You can tell which is being used by
running this command:</simpara>
<programlisting language="sh" linenumbering="unnumbered">ps -p 1</programlisting>
</section>
<section id="rpm-running-init">
<title>Running Elasticsearch with SysV <literal>init</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/rpm.asciidoc">Edit me</ulink></title>
<simpara>Use the <literal>chkconfig</literal> command to configure Elasticsearch to start automatically
when the system boots up:</simpara>
<programlisting language="sh" linenumbering="unnumbered">sudo chkconfig --add elasticsearch</programlisting>
<simpara>Elasticsearch can be started and stopped using the <literal>service</literal> command:</simpara>
<programlisting language="sh" linenumbering="unnumbered">sudo -i service elasticsearch start
sudo -i service elasticsearch stop</programlisting>
<simpara>If Elasticsearch fails to start for any reason, it will print the reason for
failure to STDOUT. Log files can be found in <literal>/var/log/elasticsearch/</literal>.</simpara>
</section>
<section id="rpm-running-systemd">
<title>Running Elasticsearch with <literal>systemd</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/systemd.asciidoc">Edit me</ulink></title>
<simpara>To configure Elasticsearch to start automatically when the system boots up,
run the following commands:</simpara>
<programlisting language="sh" linenumbering="unnumbered">sudo /bin/systemctl daemon-reload
sudo /bin/systemctl enable elasticsearch.service</programlisting>
<simpara>Elasticsearch can be started and stopped as follows:</simpara>
<programlisting language="sh" linenumbering="unnumbered">sudo systemctl start elasticsearch.service
sudo systemctl stop elasticsearch.service</programlisting>
<simpara>These commands provide no feedback as to whether Elasticsearch was started
successfully or not. Instead, this information will be written in the log
files located in <literal>/var/log/elasticsearch/</literal>.</simpara>
<simpara>By default the Elasticsearch service doesn&#8217;t log information in the <literal>systemd</literal>
journal. To enable <literal>journalctl</literal> logging, the <literal>--quiet</literal> option must be removed
 from the <literal>ExecStart</literal> command line in the <literal>elasticsearch.service</literal> file.</simpara>
<simpara>When <literal>systemd</literal> logging is enabled, the logging information are available using
the <literal>journalctl</literal> commands:</simpara>
<simpara>To tail the journal:</simpara>
<programlisting language="sh" linenumbering="unnumbered">sudo journalctl -f</programlisting>
<simpara>To list journal entries for the elasticsearch service:</simpara>
<programlisting language="sh" linenumbering="unnumbered">sudo journalctl --unit elasticsearch</programlisting>
<simpara>To list journal entries for the elasticsearch service starting from a given time:</simpara>
<programlisting language="sh" linenumbering="unnumbered">sudo journalctl --unit elasticsearch --since  "2016-10-30 18:17:16"</programlisting>
<simpara>Check <literal>man journalctl</literal> or <ulink url="https://www.freedesktop.org/software/systemd/man/journalctl.html">https://www.freedesktop.org/software/systemd/man/journalctl.html</ulink> for
more command line options.</simpara>
</section>
<section id="rpm-check-running">
<title>Checking that Elasticsearch is running<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/check-running.asciidoc">Edit me</ulink></title>
<simpara>You can test that your Elasticsearch node is running by sending an HTTP
request to port <literal>9200</literal> on <literal>localhost</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /</programlisting>
<remark> CONSOLE</remark>
<simpara>which should give you a response something like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "name" : "Cp8oag6",
  "cluster_name" : "elasticsearch",
  "cluster_uuid" : "AT69_T_DTp-1qgIJlatQqA",
  "version" : {
    "number" : "5.1.1",
    "build_hash" : "f27399d",
    "build_date" : "2016-03-30T09:51:41.449Z",
    "build_snapshot" : false,
    "lucene_version" : "6.3.0"
  },
  "tagline" : "You Know, for Search"
}</programlisting>
<remark> TESTRESPONSE[s/"name" : "Cp8oag6",/"name" : "$body.name",/]</remark>
<remark> TESTRESPONSE[s/"cluster_name" : "elasticsearch",/"cluster_name" : "$body.cluster_name",/]</remark>
<remark> TESTRESPONSE[s/"cluster_uuid" : "AT69_T_DTp-1qgIJlatQqA",/"cluster_uuid" : "$body.cluster_uuid",/]</remark>
<remark> TESTRESPONSE[s/"build_hash" : "f27399d",/"build_hash" : "$body.version.build_hash",/]</remark>
<remark> TESTRESPONSE[s/"build_date" : "2016-03-30T09:51:41.449Z",/"build_date" : $body.version.build_date,/]</remark>
<remark> TESTRESPONSE[s/"build_snapshot" : false,/"build_snapshot" : $body.version.build_snapshot,/]</remark>
<remark> So much s/// but at least we test that the layout is close to matching....</remark>
</section>
<section id="rpm-configuring">
<title>Configuring Elasticsearch<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/rpm.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch loads its configuration from the <literal>/etc/elasticsearch/elasticsearch.yml</literal>
file by default.  The format of this config file is explained in
<xref linkend="settings"/>.</simpara>
<simpara>The RPM also has a system configuration file (<literal>/etc/sysconfig/elasticsearch</literal>),
which allows you to set the following parameters:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>ES_USER</literal>
</simpara>
</entry>
<entry>
<simpara>
  The user to run as, defaults to <literal>elasticsearch</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>ES_GROUP</literal>
</simpara>
</entry>
<entry>
<simpara>
  The group to run as, defaults to <literal>elasticsearch</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>JAVA_HOME</literal>
</simpara>
</entry>
<entry>
<simpara>
  Set a custom Java path to be used.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>MAX_OPEN_FILES</literal>
</simpara>
</entry>
<entry>
<simpara>
    Maximum number of open files, defaults to <literal>65536</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>MAX_LOCKED_MEMORY</literal>
</simpara>
</entry>
<entry>
<simpara>
    Maximum locked memory size. Set to <literal>unlimited</literal> if you use the
    <literal>bootstrap.memory_lock</literal> option in elasticsearch.yml.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>MAX_MAP_COUNT</literal>
</simpara>
</entry>
<entry>
<simpara>
    Maximum number of memory map areas a process may have. If you use <literal>mmapfs</literal>
    as index store type, make sure this is set to a high value. For more
    information, check the
    <ulink url="https://github.com/torvalds/linux/blob/master/Documentation/sysctl/vm.txt">linux kernel documentation</ulink>
    about <literal>max_map_count</literal>. This is set via <literal>sysctl</literal> before starting
    elasticsearch. Defaults to <literal>262144</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>LOG_DIR</literal>
</simpara>
</entry>
<entry>
<simpara>
    Log directory, defaults to <literal>/var/log/elasticsearch</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>DATA_DIR</literal>
</simpara>
</entry>
<entry>
<simpara>
    Data directory, defaults to <literal>/var/lib/elasticsearch</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>CONF_DIR</literal>
</simpara>
</entry>
<entry>
<simpara>
    Configuration file directory (which needs to include <literal>elasticsearch.yml</literal>
    and <literal>log4j2.properties</literal> files), defaults to <literal>/etc/elasticsearch</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>ES_JAVA_OPTS</literal>
</simpara>
</entry>
<entry>
<simpara>
    Any additional JVM system properties you may want to apply.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>RESTART_ON_UPGRADE</literal>
</simpara>
</entry>
<entry>
<simpara>
    Configure restart on package upgrade, defaults to <literal>false</literal>. This means you
    will have to restart your elasticsearch instance after installing a
    package manually. The reason for this is to ensure, that upgrades in a
    cluster do not result in a continuous shard reallocation resulting in high
    network traffic and reducing the response times of your cluster.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<note><simpara>Distributions that use <literal>systemd</literal> require that system resource limits be
configured via <literal>systemd</literal> rather than via the <literal>/etc/sysconfig/elasticsearch</literal>
file.  See <xref linkend="systemd"/> for more information.</simpara></note>
</section>
<section id="rpm-layout">
<title>Directory layout of RPM<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/rpm.asciidoc">Edit me</ulink></title>
<simpara>The RPM places config files, logs, and the data directory in the appropriate
locations for an RPM-based system:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"> Type </entry>
<entry align="left" valign="top"> Description </entry>
<entry align="left" valign="top"> Default Location </entry>
<entry align="left" valign="top"> Setting</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">home</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Elasticsearch home directory or <literal>$ES_HOME</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>/usr/share/elasticsearch</literal></simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">bin</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Binary scripts including <literal>elasticsearch</literal> to start a node
    and <literal>elasticsearch-plugin</literal> to install plugins</simpara></entry>
<entry align="left" valign="top"><simpara><literal>/usr/share/elasticsearch/bin</literal></simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">conf</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Configuration files including <literal>elasticsearch.yml</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>/etc/elasticsearch</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>path.conf</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">conf</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Environment variables including heap size, file descriptors.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>/etc/sysconfig/elasticsearch</literal></simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">data</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>The location of the data files of each index / shard allocated
    on the node. Can hold multiple locations.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>/var/lib/elasticsearch</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>path.data</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">logs</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Log files location.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>/var/log/elasticsearch</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>path.logs</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">plugins</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Plugin files location. Each plugin will be contained in a subdirectory.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>/usr/share/elasticsearch/plugins</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal></literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">repo</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Shared file system repository locations. Can hold multiple locations. A file system repository can be placed in to any subdirectory of any directory specified here.</simpara></entry>
<entry align="left" valign="top"><simpara>Not configured</simpara></entry>
<entry align="left" valign="top"><simpara><literal>path.repo</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">script</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Location of script files.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>/etc/elasticsearch/scripts</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>path.scripts</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section id="_next_steps_3" role="exclude">
<title>Next steps<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/next-steps.asciidoc">Edit me</ulink></title>
<simpara>You now have a test Elasticsearch environment set up.  Before you start
serious development or go into production with Elasticsearch, you will need to
do some additional setup:</simpara>
<itemizedlist>
<listitem>
<simpara>
Learn how to <link linkend="settings">configure Elasticsearch</link>.
</simpara>
</listitem>
<listitem>
<simpara>
Configure <link linkend="important-settings">important Elasticsearch settings</link>.
</simpara>
</listitem>
<listitem>
<simpara>
Configure <link linkend="system-config">important system settings</link>.
</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section id="windows">
<title>Install Elasticsearch on Windows<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/windows.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch can be installed on Windows using the <literal>.zip</literal> package.  This
comes with a <literal>elasticsearch-service.bat</literal> command which will setup Elasticsearch to run as a
service.</simpara>
<simpara>The latest stable version of Elasticsearch can be found on the
<ulink url="/downloads/elasticsearch">Download Elasticsearch</ulink> page.
Other versions can be found on the
<ulink url="/downloads/past-releases">Past Releases page</ulink>.</simpara>
<note><simpara>Elasticsearch requires Java 8 or later. Use the
<ulink url="http://www.oracle.com/technetwork/java/javase/downloads/index.html">official Oracle distribution</ulink>
or an open-source distribution such as <ulink url="http://openjdk.java.net">OpenJDK</ulink>.</simpara></note>
<section id="install-windows">
<title>Download and install the <literal>.zip</literal> package<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/windows.asciidoc">Edit me</ulink></title>
<simpara>Version 5.1.1 of Elasticsearch has not yet been released.</simpara>
</section>
<section id="windows-running">
<title>Running Elasticsearch from the command line<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/windows.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch can be started from the command line as follows:</simpara>
<programlisting language="sh" linenumbering="unnumbered">.\bin\elasticsearch</programlisting>
<simpara>By default, Elasticsearch runs in the foreground, prints its logs to <literal>STDOUT</literal>,
and can be stopped by pressing <literal>Ctrl-C</literal>.</simpara>
</section>
<section id="windows-configuring">
<title>Configuring Elasticsearch on the command line<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/windows.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch loads its configuration from the <literal>%ES_HOME%/config/elasticsearch.yml</literal>
file by default.  The format of this config file is explained in
<xref linkend="settings"/>.</simpara>
<simpara>Any settings that can be specified in the config file can also be specified on
the command line, using the <literal>-E</literal> syntax as follows:</simpara>
<programlisting language="sh" linenumbering="unnumbered">./bin/elasticsearch -Ecluster.name=my_cluster -Enode.name=node_1</programlisting>
<note><simpara>Values that contain spaces must be surrounded with quotes.  For instance <literal>-Epath.logs="C:\My Logs\logs"</literal>.</simpara></note>
<tip><simpara>Typically, any cluster-wide settings (like <literal>cluster.name</literal>) should be
added to the <literal>elasticsearch.yml</literal> config file, while any node-specific settings
such as <literal>node.name</literal> could be specified on the command line.</simpara></tip>
</section>
<section id="_checking_that_elasticsearch_is_running_2">
<title>Checking that Elasticsearch is running<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/check-running.asciidoc">Edit me</ulink></title>
<simpara>You can test that your Elasticsearch node is running by sending an HTTP
request to port <literal>9200</literal> on <literal>localhost</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /</programlisting>
<remark> CONSOLE</remark>
<simpara>which should give you a response something like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "name" : "Cp8oag6",
  "cluster_name" : "elasticsearch",
  "cluster_uuid" : "AT69_T_DTp-1qgIJlatQqA",
  "version" : {
    "number" : "5.1.1",
    "build_hash" : "f27399d",
    "build_date" : "2016-03-30T09:51:41.449Z",
    "build_snapshot" : false,
    "lucene_version" : "6.3.0"
  },
  "tagline" : "You Know, for Search"
}</programlisting>
<remark> TESTRESPONSE[s/"name" : "Cp8oag6",/"name" : "$body.name",/]</remark>
<remark> TESTRESPONSE[s/"cluster_name" : "elasticsearch",/"cluster_name" : "$body.cluster_name",/]</remark>
<remark> TESTRESPONSE[s/"cluster_uuid" : "AT69_T_DTp-1qgIJlatQqA",/"cluster_uuid" : "$body.cluster_uuid",/]</remark>
<remark> TESTRESPONSE[s/"build_hash" : "f27399d",/"build_hash" : "$body.version.build_hash",/]</remark>
<remark> TESTRESPONSE[s/"build_date" : "2016-03-30T09:51:41.449Z",/"build_date" : $body.version.build_date,/]</remark>
<remark> TESTRESPONSE[s/"build_snapshot" : false,/"build_snapshot" : $body.version.build_snapshot,/]</remark>
<remark> So much s/// but at least we test that the layout is close to matching....</remark>
</section>
<section id="windows-service">
<title>Installing Elasticsearch as a Service on Windows<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/windows.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch can be installed as a service to run in the background or start
automatically at boot time without any user interaction. This can be achieved
through the <literal>elasticsearch-service.bat</literal> script in the <literal>bin\</literal> folder which allows one to
install, remove, manage or configure the service and potentially start and
stop the service, all from the command-line.</simpara>
<programlisting language="sh" linenumbering="unnumbered">c:\elasticsearch-5.1.1\bin&gt;elasticsearch-service

Usage: elasticsearch-service.bat install|remove|start|stop|manager [SERVICE_ID]</programlisting>
<simpara>The script requires one parameter (the command to execute) followed by an
optional one indicating the service id (useful when installing multiple
Elasticsearch services).</simpara>
<simpara>The commands available are:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>install</literal>
</simpara>
</entry>
<entry>
<simpara>
Install Elasticsearch as a service
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>remove</literal>
</simpara>
</entry>
<entry>
<simpara>
Remove the installed Elasticsearch service (and stop the service if started)
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>start</literal>
</simpara>
</entry>
<entry>
<simpara>
Start the Elasticsearch service (if installed)
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>stop</literal>
</simpara>
</entry>
<entry>
<simpara>
Stop the Elasticsearch service (if started)
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>manager</literal>
</simpara>
</entry>
<entry>
<simpara>
Start a GUI for managing the installed service
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>Based on the architecture of the available JDK/JRE (set through <literal>JAVA_HOME</literal>),
the appropriate 64-bit(x64) or 32-bit(x86) service will be installed. This
information is made available during install:</simpara>
<programlisting language="sh" linenumbering="unnumbered">c:\elasticsearch-5.1.1\bin&gt;elasticsearch-service install
Installing service      :  "elasticsearch-service-x64"
Using JAVA_HOME (64-bit):  "c:\jvm\jdk1.8"
The service 'elasticsearch-service-x64' has been installed.</programlisting>
<note><simpara>While a JRE can be used for the Elasticsearch service, due to its use of a client VM (as opposed to a server JVM which offers better performance for long-running applications) its usage is discouraged and a warning will be issued.</simpara></note>
<note><simpara>Upgrading (or downgrading) JVM versions does not require the service to be reinstalled. However, upgrading across JVM types (e.g. JRE versus SE) is not supported, and does require the service to be reinstalled.</simpara></note>
<bridgehead id="windows-service-settings" renderas="sect2">Customizing service settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/windows.asciidoc">Edit me</ulink></bridgehead>
<simpara>The Elasticsearch service can be configured prior to installation by setting the the following environment variables (either using the <ulink url="https://technet.microsoft.com/en-us/library/cc754250(v=ws.10).aspx">set command</ulink> from the command line, or through the <literal>System Properties-&gt;Environment Variables</literal> GUI).</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>SERVICE_ID</literal>
</simpara>
</entry>
<entry>
<simpara>
  A unique identifier for the service.  Useful if installing multiple instances on the same machine.  Defaults to <literal>elasticsearch-service-x86</literal> (on 32-bit Windows) or <literal>elasticsearch-service-x64</literal> (on 64-bit Windows).
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>SERVICE_USERNAME</literal>
</simpara>
</entry>
<entry>
<simpara>
  The user to run as, defaults to the local system account.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>SERVICE_PASSWORD</literal>
</simpara>
</entry>
<entry>
<simpara>
  The password for the user specified in <literal>%SERVICE_USERNAME%</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>SERVICE_DISPLAY_NAME</literal>
</simpara>
</entry>
<entry>
<simpara>
  The name of the service.  Defaults to <literal>Elasticsearch &lt;version&gt; %SERVICE_ID%</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>SERVICE_DESCRIPTION</literal>
</simpara>
</entry>
<entry>
<simpara>
  The description of the service.  Defaults to <literal>Elasticsearch &lt;version&gt; Windows Service - https://elastic.co</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>JAVA_HOME</literal>
</simpara>
</entry>
<entry>
<simpara>
  The installation directory of the desired JVM to run the service under.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>LOG_DIR</literal>
</simpara>
</entry>
<entry>
<simpara>
    Log directory, defaults to <literal>%ES_HOME%\logs</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>DATA_DIR</literal>
</simpara>
</entry>
<entry>
<simpara>
    Data directory, defaults to <literal>%ES_HOME%\data</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>CONF_DIR</literal>
</simpara>
</entry>
<entry>
<simpara>
    Configuration file directory (which needs to include <literal>elasticsearch.yml</literal>
    and <literal>log4j2.properties</literal> files), defaults to <literal>%ES_HOME%\conf</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>ES_JAVA_OPTS</literal>
</simpara>
</entry>
<entry>
<simpara>
    Any additional JVM system properties you may want to apply.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>ES_START_TYPE</literal>
</simpara>
</entry>
<entry>
<simpara>
    Startup mode for the service.  Can be either <literal>auto</literal> or <literal>manual</literal> (default).
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>ES_STOP_TIMEOUT</literal> 
</simpara>
</entry>
<entry>
<simpara>
  The timeout in seconds that procrun waits for service to exit gracefully.  Defaults to <literal>0</literal>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<note><simpara>At its core, <literal>elasticsearch-service.bat</literal> relies on <ulink url="http://commons.apache.org/proper/commons-daemon/">Apache Commons Daemon</ulink> project
to install the service. Environment variables set prior to the service installation are copied and will be used during the service lifecycle. This means any changes made to them after the installation will not be picked up unless the service is reinstalled.</simpara></note>
<note><simpara>On Windows, the <link linkend="heap-size">heap size</link> can be configured as for
any other Elasticsearch installation when running Elasticsearch from the
command line, or when installing Elasticsearch as a service for the
first time. To adjust the heap size for an already installed service,
use the service manager: <literal>bin\elasticsearch-service.bat manager</literal>.</simpara></note>
<variablelist>
<varlistentry>
<term>
Using the Manager GUI
</term>
<listitem>
<simpara>
It is also possible to configure the service after it&#8217;s been installed using the manager GUI (<literal>elasticsearch-service-mgr.exe</literal>), which offers insight into the installed service, including its status, startup type, JVM, start and stop settings amongst other things.  Simply invoking <literal>elasticsearch-service.bat manager</literal> from the command-line will open up the manager window:
</simpara>
</listitem>
</varlistentry>
</variablelist>
<informalfigure>
<mediaobject>
  <imageobject>
  <imagedata fileref="images/service-manager-win.png" align="center"/>
  </imageobject>
  <textobject><phrase>Windows Service Manager GUI</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>Most changes (like JVM settings) made through the manager GUI will require a restart of the service in order to take affect.</simpara>
</section>
<section id="windows-layout">
<title>Directory layout of <literal>.zip</literal> archive<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/windows.asciidoc">Edit me</ulink></title>
<simpara>The <literal>.zip</literal> package is entirely self-contained. All files and directories are,
by default, contained within <literal>%ES_HOME%</literal>&#8201;&#8212;&#8201;the directory created when
unpacking the archive.</simpara>
<simpara>This is very convenient because you don&#8217;t have to create any directories to
start using Elasticsearch, and uninstalling Elasticsearch is as easy as
removing the <literal>%ES_HOME%</literal> directory.  However, it is advisable to change the
default locations of the config directory, the data directory, and the logs
directory so that you do not delete important data later on.</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"> Type </entry>
<entry align="left" valign="top"> Description </entry>
<entry align="left" valign="top"> Default Location </entry>
<entry align="left" valign="top"> Setting</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">home</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Elasticsearch home directory or <literal>%ES_HOME%</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Directory created by unpacking the archive</simpara></entry>
<entry align="left" valign="top"><simpara><literal></literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">bin</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Binary scripts including <literal>elasticsearch</literal> to start a node
    and <literal>elasticsearch-plugin</literal> to install plugins</simpara></entry>
<entry align="left" valign="top"><simpara><literal>%ES_HOME%\bin</literal></simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">conf</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Configuration files including <literal>elasticsearch.yml</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>%ES_HOME%\config</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>path.conf</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">data</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>The location of the data files of each index / shard allocated
    on the node. Can hold multiple locations.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>%ES_HOME%\data</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>path.data</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">logs</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Log files location.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>%ES_HOME%\logs</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>path.logs</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">plugins</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Plugin files location. Each plugin will be contained in a subdirectory.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>%ES_HOME%\plugins</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal></literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">repo</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Shared file system repository locations. Can hold multiple locations. A file system repository can be placed in to any subdirectory of any directory specified here.</simpara></entry>
<entry align="left" valign="top"><simpara>Not configured</simpara></entry>
<entry align="left" valign="top"><simpara><literal>path.repo</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><emphasis role="strong">script</emphasis></simpara></entry>
<entry align="left" valign="top"><simpara>Location of script files.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>%ES_HOME%\scripts</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>path.scripts</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section id="_next_steps_4" role="exclude">
<title>Next steps<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/next-steps.asciidoc">Edit me</ulink></title>
<simpara>You now have a test Elasticsearch environment set up.  Before you start
serious development or go into production with Elasticsearch, you will need to
do some additional setup:</simpara>
<itemizedlist>
<listitem>
<simpara>
Learn how to <link linkend="settings">configure Elasticsearch</link>.
</simpara>
</listitem>
<listitem>
<simpara>
Configure <link linkend="important-settings">important Elasticsearch settings</link>.
</simpara>
</listitem>
<listitem>
<simpara>
Configure <link linkend="system-config">important system settings</link>.
</simpara>
</listitem>
</itemizedlist>
</section>
</section>
<section id="docker">
<title>Install Elasticsearch with Docker<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/docker.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch is also available as a Docker image.
The image is built with <ulink url="https://www.elastic.co/guide/en/x-pack/5.0/index.html">X-Pack</ulink>.</simpara>
<section id="_security_note">
<title>Security note<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/docker.asciidoc">Edit me</ulink></title>
<note><simpara><ulink url="https://www.elastic.co/guide/en/x-pack/5.0/index.html">X-Pack</ulink> is preinstalled in this image.
Please take a few minutes to familiarize yourself with <ulink url="https://www.elastic.co/guide/en/x-pack/5.0/security-getting-started.html">X-Pack Security</ulink> and how to change default passwords. The default password for the <literal>elastic</literal> user is <literal>changeme</literal>.</simpara></note>
<note><simpara>X-Pack includes a trial license for 30 days. After that, you can obtain one of the <ulink url="https://www.elastic.co/subscriptions">available subscriptions</ulink> or <ulink url="https://www.elastic.co/guide/en/x-pack/5.0/security-settings.html">disable Security</ulink>. The Basic license is free and includes the <ulink url="https://www.elastic.co/products/x-pack/monitoring">Monitoring</ulink> extension.</simpara></note>
<simpara>Obtaining Elasticsearch for Docker is as simple as issuing a <literal>docker pull</literal> command against the Elastic Docker registry.</simpara>
<warning><simpara>Version 5.1.1 of Elasticsearch has not yet been released, so no Docker image is currently available for this version.</simpara></warning>
</section>
<section id="docker-cli-run">
<title>Running Elasticsearch from the command line<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/docker.asciidoc">Edit me</ulink></title>
<section id="docker-cli-run-dev-mode">
<title>Development mode<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/docker.asciidoc">Edit me</ulink></title>
<warning><simpara>Version 5.1.1 of the Elasticsearch Docker image has not yet been released.</simpara></warning>
</section>
<section id="docker-cli-run-prod-mode">
<title>Production mode<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/docker.asciidoc">Edit me</ulink></title>
<important id="docker-prod-prerequisites">
<simpara>The <literal>vm_max_map_count</literal> kernel setting needs to be set to at least <literal>262144</literal> for production use.
Depending on your platform:</simpara>
<itemizedlist>
<listitem>
<simpara>
Linux
</simpara>
<simpara>The <literal>vm_map_max_count</literal> setting should be set permanently in /etc/sysctl.conf:</simpara>
<programlisting language="sh" linenumbering="unnumbered">$ grep vm.max_map_count /etc/sysctl.conf
vm.max_map_count=262144</programlisting>
<simpara>To apply the setting on a live system type: <literal>sysctl -w vm.max_map_count=262144</literal></simpara>
</listitem>
<listitem>
<simpara>
OSX with <ulink url="https://docs.docker.com/engine/installation/mac/#/docker-for-mac">Docker for Mac</ulink>
</simpara>
<simpara>The <literal>vm_max_map_count</literal> setting must be set within the xhyve virtual machine:</simpara>
<programlisting language="sh" linenumbering="unnumbered">$ screen ~/Library/Containers/com.docker.docker/Data/com.docker.driver.amd64-linux/tty</programlisting>
<simpara>Log in with <emphasis>root</emphasis> and no password.
Then configure the <literal>sysctl</literal> setting as you would for Linux:</simpara>
<programlisting language="sh" linenumbering="unnumbered">sysctl -w vm.max_map_count=262144</programlisting>
</listitem>
<listitem>
<simpara>
OSX with <ulink url="https://docs.docker.com/engine/installation/mac/#docker-toolbox">Docker Toolbox</ulink>
</simpara>
<simpara>The <literal>vm_max_map_count</literal> setting must be set via docker-machine:</simpara>
<programlisting language="sh" linenumbering="unnumbered">docker-machine ssh
sudo sysctl -w vm.max_map_count=262144</programlisting>
</listitem>
</itemizedlist>
</important>
<simpara>The following example brings up a cluster comprising two Elasticsearch nodes.
To bring up the cluster, use the <link linkend="docker-prod-cluster-composefile"><literal>docker-compose.yml</literal></link> and just type:</simpara>
<warning><simpara>Version 5.1.1 of the Elasticsearch Docker image has not yet been released, so a <literal>docker-compose.yml</literal> is not available for this version.</simpara></warning>
<note><simpara><literal>docker-compose</literal> is not pre-installed with Docker on Linux.
Instructions for installing it can be found on the <ulink url="https://docs.docker.com/compose/install/#install-using-pip">docker-compose webpage</ulink>.</simpara></note>
<simpara>The node <literal>elasticsearch1</literal> listens on <literal>localhost:9200</literal> while <literal>elasticsearch2</literal> talks to <literal>elasticsearch1</literal> over a Docker network.</simpara>
<simpara>This example also uses <ulink url="https://docs.docker.com/engine/tutorials/dockervolumes">Docker named volumes</ulink>, called <literal>esdata1</literal> and <literal>esdata2</literal> which will be created if not already present.</simpara>
<simpara id="docker-prod-cluster-composefile"><literal>docker-compose.yml</literal>:</simpara>
<warning><simpara>Version 5.1.1 of the Elasticsearch Docker image has not yet been released, so a <literal>docker-compose.yml</literal> is not available for this version.</simpara></warning>
<simpara>To stop the cluster, type <literal>docker-compose down</literal>. Data volumes will persist, so it&#8217;s possible to start the cluster again with the same data using <literal>docker-compose up</literal>.
To destroy the cluster <emphasis role="strong">and the data volumes</emphasis> just type <literal>docker-compose down -v</literal>.</simpara>
</section>
<section id="_inspect_status_of_cluster">
<title>Inspect status of cluster:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/docker.asciidoc">Edit me</ulink></title>
<programlisting language="sh" linenumbering="unnumbered">curl -u elastic http://127.0.0.1:9200/_cat/health
Enter host password for user 'elastic':
1472225929 15:38:49 docker-cluster green 2 2 4 2 0 0 0 0 - 100.0%</programlisting>
<remark> NOTCONSOLE</remark>
<remark> This is demonstrating curl. Console will prompt you for a username and</remark>
<remark> password so no need to demonstrate that. Converting this would not show the</remark>
<remark> important `-u elastic` parameters for `curl`.</remark>
<simpara>Log messages go to the console and are handled by the configured Docker logging driver. By default you can access logs with <literal>docker logs</literal>.</simpara>
</section>
</section>
<section id="docker-configuration-methods">
<title>Configuring Elasticsearch with Docker<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/docker.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch loads its configuration from files under <literal>/usr/share/elasticsearch/config/</literal>. These configuration files are documented in <xref linkend="settings"/> and <xref linkend="jvm-options"/>.</simpara>
<simpara>The image offers several methods for configuring Elasticsearch settings with the conventional approach being to provide customized files, i.e. <literal>elasticsearch.yml</literal>, but it&#8217;s also possible to use environment variables to set options:</simpara>
<section id="_a_present_the_parameters_via_docker_environment_variables">
<title>A. Present the parameters via Docker environment variables<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/docker.asciidoc">Edit me</ulink></title>
<simpara>For example, to define the cluster name with <literal>docker run</literal> you can pass <literal>-e "cluster.name=mynewclustername"</literal>. Double quotes are required.</simpara>
<note><simpara>There is a difference between defining <link linkend="_setting_default_settings">default settings</link> and normal settings. The former are prefixed with <literal>default.</literal> and cannot override normal settings, if defined.</simpara></note>
</section>
<section id="_b_bind_mounted_configuration">
<title>B. Bind-mounted configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/docker.asciidoc">Edit me</ulink></title>
<simpara>Create your custom config file and mount this over the image&#8217;s corresponding file.
For example, bind-mounting a <literal>custom_elasticsearch.yml</literal> with <literal>docker run</literal> can be accomplished with the parameter:</simpara>
<programlisting language="sh" linenumbering="unnumbered">-v full_path_to/custom_elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml</programlisting>
<important><simpara><literal>custom_elasticsearch.yml</literal> should be readable by uid:gid <literal>1000:1000</literal></simpara></important>
</section>
<section id="_c_customized_image">
<title>C. Customized image<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/docker.asciidoc">Edit me</ulink></title>
<simpara>In some environments, it may make more sense to prepare a custom image containing your configuration. A <literal>Dockerfile</literal> to achieve this may be as simple as:</simpara>
<programlisting language="sh" linenumbering="unnumbered">FROM docker.elastic.co/elasticsearch/elasticsearch:5.1.1
ADD elasticsearch.yml /usr/share/elasticsearch/config/
USER root
chown elasticsearch:elasticsearch config/elasticsearch.yml
USER elasticsearch</programlisting>
<simpara>You could then build and try the image with something like:</simpara>
<programlisting language="sh" linenumbering="unnumbered">docker build --tag=elasticsearch-custom .
docker run -ti -v /usr/share/elasticsearch/data elasticsearch-custom</programlisting>
</section>
<section id="_d_override_the_image_8217_s_default_ulink_url_https_docs_docker_com_engine_reference_run_cmd_default_command_or_options_cmd_ulink">
<title>D. Override the image&#8217;s default <ulink url="https://docs.docker.com/engine/reference/run/#cmd-default-command-or-options">CMD</ulink><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/docker.asciidoc">Edit me</ulink></title>
<simpara>Options can be passed as command-line options to the Elasticsearch process by
overriding the default command for the image. For example:</simpara>
<programlisting language="sh" linenumbering="unnumbered">docker run &lt;various parameters&gt; bin/elasticsearch -Ecluster.name=mynewclustername</programlisting>
</section>
</section>
<section id="_notes_for_production_use_and_defaults">
<title>Notes for production use and defaults<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/docker.asciidoc">Edit me</ulink></title>
<simpara>We have collected a number of best practices for production use.</simpara>
<note><simpara>Any Docker parameters mentioned below assume the use of <literal>docker run</literal>.</simpara></note>
<orderedlist numeration="arabic">
<listitem>
<simpara>
It is important to correctly set capabilities and ulimits via the Docker CLI. As seen earlier in the example <link linkend="docker-prod-cluster-composefile">docker-compose.yml</link>, the following options are required:
</simpara>
<literallayout class="monospaced">--cap-add=IPC_LOCK --ulimit memlock=-1:-1 --ulimit nofile=65536:65536</literallayout>
</listitem>
<listitem>
<simpara>
Ensure <literal>bootstrap.memory_lock</literal> is set to <literal>true</literal> as explained in "<link linkend="setup-configuration-memory">Disable swapping</link>".
</simpara>
<simpara>This can be achieved through any of the <link linkend="docker-configuration-methods">configuration methods</link>, e.g. by setting the appropriate environments variable with <literal>-e "bootstrap.memory_lock=true"</literal>.</simpara>
</listitem>
<listitem>
<simpara>
The image <ulink url="https://docs.docker.com/engine/reference/builder/#/expose">exposes</ulink> TCP ports 9200 and 9300. For clusters it is recommended to randomize the published ports with <literal>--publish-all</literal>, unless you are pinning one container per host.
</simpara>
</listitem>
<listitem>
<simpara>
Use the <literal>ES_JAVA_OPTS</literal> environment variable to set heap size, e.g. to use 16GB use <literal>-e ES_JAVA_OPTS="-Xms16g -Xmx16g"</literal> with <literal>docker run</literal>. It is also recommended to set a <ulink url="https://docs.docker.com/engine/reference/run/#user-memory-constraints">memory limit</ulink> for the container.
</simpara>
</listitem>
<listitem>
<simpara>
Pin your deployments to a specific version of the Elasticsearch Docker image, e.g. <literal>docker.elastic.co/elasticsearch/elasticsearch:5.1.1</literal>.
</simpara>
</listitem>
<listitem>
<simpara>
Always use a volume bound on <literal>/usr/share/elasticsearch/data</literal>, as shown in the <link linkend="docker-cli-run-prod-mode">production example</link>, for the following reasons:
</simpara>
<orderedlist numeration="loweralpha">
<listitem>
<simpara>
The data of your elasticsearch node won&#8217;t be lost if the container is killed
</simpara>
</listitem>
<listitem>
<simpara>
Elasticsearch is I/O sensitive and the Docker storage driver is not ideal for fast I/O
</simpara>
</listitem>
<listitem>
<simpara>
It allows the use of advanced <ulink url="https://docs.docker.com/engine/extend/plugins/#volume-plugins">Docker volume plugins</ulink>
</simpara>
</listitem>
</orderedlist>
</listitem>
<listitem>
<simpara>
If you are using the devicemapper storage driver (default on at least RedHat (rpm) based distributions) make sure you are not using the default <literal>loop-lvm</literal> mode. Configure docker-engine to use <ulink url="https://docs.docker.com/engine/userguide/storagedriver/device-mapper-driver/#configure-docker-with-devicemapper">direct-lvm</ulink> instead.
</simpara>
</listitem>
<listitem>
<simpara>
Consider centralizing your logs by using a different <ulink url="https://docs.docker.com/engine/admin/logging/overview/">logging driver</ulink>. Also note that the default json-file logging driver is not ideally suited for production use.
</simpara>
</listitem>
</orderedlist>
</section>
<section id="_next_steps_5" role="exclude">
<title>Next steps<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/install/next-steps.asciidoc">Edit me</ulink></title>
<simpara>You now have a test Elasticsearch environment set up.  Before you start
serious development or go into production with Elasticsearch, you will need to
do some additional setup:</simpara>
<itemizedlist>
<listitem>
<simpara>
Learn how to <link linkend="settings">configure Elasticsearch</link>.
</simpara>
</listitem>
<listitem>
<simpara>
Configure <link linkend="important-settings">important Elasticsearch settings</link>.
</simpara>
</listitem>
<listitem>
<simpara>
Configure <link linkend="system-config">important system settings</link>.
</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</chapter>
<chapter id="settings">
<title>Configuring Elasticsearch<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/configuration.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch ships with good defaults and requires very little configuration.
Most settings can be changed on a running cluster using the
<xref linkend="cluster-update-settings"/> API.</simpara>
<simpara>The configuration files should contain settings which are node-specific (such
as <literal>node.name</literal> and paths), or settings which a node requires in order to be
able to join a cluster, such as <literal>cluster.name</literal> and <literal>network.host</literal>.</simpara>
<bridgehead id="_config_file_location" renderas="sect2">Config file location<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/configuration.asciidoc">Edit me</ulink></bridgehead>
<simpara>Elasticsearch has two configuration files:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>elasticsearch.yml</literal> for configuring Elasticsearch, and
</simpara>
</listitem>
<listitem>
<simpara>
<literal>log4j2.properties</literal> for configuring Elasticsearch logging.
</simpara>
</listitem>
</itemizedlist>
<simpara>These files are located in the config directory, whose location defaults to
<literal>$ES_HOME/config/</literal>.  The Debian and RPM packages set the config directory
location to <literal>/etc/elasticsearch/</literal>.</simpara>
<simpara>The location of the config directory can be changed with the <literal>path.conf</literal>
setting, as follows:</simpara>
<programlisting language="sh" linenumbering="unnumbered">./bin/elasticsearch -Epath.conf=/path/to/my/config/</programlisting>
<bridgehead id="_config_file_format" renderas="sect2">Config file format<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/configuration.asciidoc">Edit me</ulink></bridgehead>
<simpara>The configuration format is <ulink url="http://www.yaml.org/">YAML</ulink>. Here is an
example of changing the path of the data and logs directories:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">path:
    data: /var/lib/elasticsearch
    logs: /var/log/elasticsearch</programlisting>
<simpara>Settings can also be flattened as follows:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">path.data: /var/lib/elasticsearch
path.logs: /var/log/elasticsearch</programlisting>
<bridgehead id="_environment_variable_subsitution" renderas="sect2">Environment variable subsitution<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/configuration.asciidoc">Edit me</ulink></bridgehead>
<simpara>Environment variables referenced with the <literal>${...}</literal> notation within the
configuration file will be replaced with the value of the environment
variable, for instance:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">node.name:    ${HOSTNAME}
network.host: ${ES_NETWORK_HOST}</programlisting>
<bridgehead id="_prompting_for_settings" renderas="sect2">Prompting for settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/configuration.asciidoc">Edit me</ulink></bridgehead>
<simpara>For settings that you do not wish to store in the configuration file, you can
use the value <literal>${prompt.text}</literal> or <literal>${prompt.secret}</literal> and start Elasticsearch
in the foreground. <literal>${prompt.secret}</literal> has echoing disabled so that the value
entered will not be shown in your terminal; <literal>${prompt.text}</literal> will allow you to
see the value as you type it in. For example:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">node:
  name: ${prompt.text}</programlisting>
<simpara>When starting Elasticsearch, you will be prompted to enter the actual value
like so:</simpara>
<programlisting language="sh" linenumbering="unnumbered">Enter value for [node.name]:</programlisting>
<note><simpara>Elasticsearch will not start if <literal>${prompt.text}</literal> or <literal>${prompt.secret}</literal>
is used in the settings and the process is run as a service or in the background.</simpara></note>
<bridgehead id="_setting_default_settings" renderas="sect2">Setting default settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/configuration.asciidoc">Edit me</ulink></bridgehead>
<simpara>New default settings may be specified on the command line using the
<literal>default.</literal> prefix.  This will specify a value that will be used by
default unless another value is specified in the config file.</simpara>
<simpara>For instance, if Elasticsearch is started as follows:</simpara>
<programlisting language="sh" linenumbering="unnumbered">./bin/elasticsearch -Edefault.node.name=My_Node</programlisting>
<simpara>the value for <literal>node.name</literal> will be <literal>My_Node</literal>, unless it is overwritten on the
command line with <literal>es.node.name</literal> or in the config file with <literal>node.name</literal>.</simpara>
<bridgehead id="logging" renderas="sect1">Logging configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/configuration.asciidoc">Edit me</ulink></bridgehead>
<simpara>Elasticsearch uses <ulink url="http://logging.apache.org/log4j/2.x/">Log4j 2</ulink> for
logging. Log4j 2 can be configured using the log4j2.properties
file. Elasticsearch exposes a single property <literal>${sys:es.logs}</literal> that can be
referenced in the configuration file to determine the location of the log files;
this will resolve to a prefix for the Elasticsearch log file at runtime.</simpara>
<simpara>For example, if your log directory (<literal>path.logs</literal>) is <literal>/var/log/elasticsearch</literal> and
your cluster is named <literal>production</literal> then <literal>${sys:es.logs}</literal> will resolve to
<literal>/var/log/elasticsearch/production</literal>.</simpara>
<programlisting language="properties" linenumbering="unnumbered">appender.rolling.type = RollingFile <co id="CO1-1"/>
appender.rolling.name = rolling
appender.rolling.fileName = ${sys:es.logs}.log <co id="CO1-2"/>
appender.rolling.layout.type = PatternLayout
appender.rolling.layout.pattern = [%d{ISO8601}][%-5p][%-25c] %.10000m%n
appender.rolling.filePattern = ${sys:es.logs}-%d{yyyy-MM-dd}.log <co id="CO1-3"/>
appender.rolling.policies.type = Policies
appender.rolling.policies.time.type = TimeBasedTriggeringPolicy <co id="CO1-4"/>
appender.rolling.policies.time.interval = 1 <co id="CO1-5"/>
appender.rolling.policies.time.modulate = true <co id="CO1-6"/></programlisting>
<calloutlist>
<callout arearefs="CO1-1">
<para>
Configure the <literal>RollingFile</literal> appender
</para>
</callout>
<callout arearefs="CO1-2">
<para>
Log to <literal>/var/log/elasticsearch/production.log</literal>
</para>
</callout>
<callout arearefs="CO1-3">
<para>
Roll logs to <literal>/var/log/elasticsearch/production-yyyy-MM-dd.log</literal>
</para>
</callout>
<callout arearefs="CO1-4">
<para>
Using a time-based roll policy
</para>
</callout>
<callout arearefs="CO1-5">
<para>
Roll logs on a daily basis
</para>
</callout>
<callout arearefs="CO1-6">
<para>
Align rolls on the day boundary (as opposed to rolling every twenty-four
    hours)
</para>
</callout>
</calloutlist>
<simpara>If you append <literal>.gz</literal> or <literal>.zip</literal> to <literal>appender.rolling.filePattern</literal>, then the logs
will be compressed as they are rolled.</simpara>
<simpara>Multiple configuration files can be loaded (in which case they will get merged)
as long as they are named <literal>log4j2.properties</literal> and have the Elasticsearch config
directory as an ancestor; this is useful for plugins that expose additional
loggers. The logger section contains the java packages and their corresponding
log level. The appender section contains the destinations for the logs.
Extensive information on how to customize logging and all the supported
appenders can be found on the
<ulink url="http://logging.apache.org/log4j/2.x/manual/configuration.html">Log4j
documentation</ulink>.</simpara>
<bridgehead id="deprecation-logging" renderas="sect2">Deprecation logging<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/configuration.asciidoc">Edit me</ulink></bridgehead>
<simpara>In addition to regular logging, Elasticsearch allows you to enable logging
of deprecated actions. For example this allows you to determine early, if
you need to migrate certain functionality in the future. By default,
deprecation logging is enabled at the WARN level, the level at which all
deprecation log messages will be emitted.</simpara>
<programlisting language="properties" linenumbering="unnumbered">logger.deprecation.level = warn</programlisting>
<simpara>This will create a daily rolling deprecation log file in your log directory.
Check this file regularly, especially when you intend to upgrade to a new
major version.</simpara>
<simpara>The default logging configuration has set the roll policy for the deprecation
logs to roll and compress after 1 GB, and to preserve a maximum of five log
files (four rolled logs, and the active log).</simpara>
<simpara>You can disable it in the <literal>config/log4j2.properties</literal> file by setting the deprecation
log level to <literal>error</literal>.</simpara>
</chapter>
<chapter id="important-settings">
<title>Important Elasticsearch configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/important-settings.asciidoc">Edit me</ulink></title>
<simpara>While Elasticsearch requires very little configuration, there are a number of
settings which need to be configured manually and should definitely be
configured before going into production.</simpara>
<itemizedlist>
<listitem>
<simpara>
<link linkend="path-settings"><literal>path.data</literal> and <literal>path.logs</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="cluster.name"><literal>cluster.name</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="node.name"><literal>node.name</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="bootstrap.memory_lock"><literal>bootstrap.memory_lock</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="network.host"><literal>network.host</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="unicast.hosts"><literal>discovery.zen.ping.unicast.hosts</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="minimum_master_nodes"><literal>discovery.zen.minimum_master_nodes</literal></link>
</simpara>
</listitem>
</itemizedlist>
<bridgehead id="path-settings" renderas="sect2"><literal>path.data</literal> and <literal>path.logs</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/important-settings.asciidoc">Edit me</ulink></bridgehead>
<simpara>If you are using the <literal>.zip</literal> or <literal>.tar.gz</literal> archives, the <literal>data</literal> and <literal>logs</literal>
directories are sub-folders of <literal>$ES_HOME</literal>.  If these important folders are
left in their default locations, there is a high risk of them being deleted
while  upgrading Elasticsearch to a new version.</simpara>
<simpara>In production use, you will almost certainly want to change the locations of
the data and log folder:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">path:
  logs: /var/log/elasticsearch
  data: /var/data/elasticsearch</programlisting>
<simpara>The RPM and Debian distributions already use custom paths for <literal>data</literal> and
<literal>logs</literal>.</simpara>
<simpara>The <literal>path.data</literal> settings can be set to multiple paths, in which case all paths
will be used to store data (although the files belonging to a single shard
will all be stored on the same data path):</simpara>
<programlisting language="yaml" linenumbering="unnumbered">path:
  data:
    - /mnt/elasticsearch_1
    - /mnt/elasticsearch_2
    - /mnt/elasticsearch_3</programlisting>
<bridgehead id="cluster.name" renderas="sect2"><literal>cluster.name</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/important-settings.asciidoc">Edit me</ulink></bridgehead>
<simpara>A node can only join a cluster when it shares its <literal>cluster.name</literal> with all the
other nodes in the cluster. The default name is <literal>elasticsearch</literal>, but you
should change it to an appropriate name which describes the purpose of the
cluster.</simpara>
<programlisting language="yaml" linenumbering="unnumbered">cluster.name: logging-prod</programlisting>
<simpara>Make sure that you don&#8217;t reuse the same cluster names in different
environments, otherwise you might end up with nodes joining the wrong cluster.</simpara>
<bridgehead id="node.name" renderas="sect2"><literal>node.name</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/important-settings.asciidoc">Edit me</ulink></bridgehead>
<simpara>By default, Elasticsearch will take the 7 first character of the randomly generated uuid used as the node id.
Note that the node id is persisted and does not change when a node restarts and therefore the default node name
will also not change.</simpara>
<simpara>It is worth configuring a more meaningful name which will also have the
advantage of persisting after restarting the node:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">node.name: prod-data-2</programlisting>
<simpara>The <literal>node.name</literal> can also be set to the server&#8217;s HOSTNAME as follows:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">node.name: ${HOSTNAME}</programlisting>
<bridgehead id="bootstrap.memory_lock" renderas="sect2"><literal>bootstrap.memory_lock</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/important-settings.asciidoc">Edit me</ulink></bridgehead>
<simpara>It is vitally important to the health of your node that none of the JVM is
ever swapped out to disk.  One way of achieving that is set the
<literal>bootstrap.memory_lock</literal> setting to <literal>true</literal>.</simpara>
<simpara>For this setting to have effect, other system settings need to be configured
first. See <xref linkend="mlockall"/> for more details about how to set up memory locking
correctly.</simpara>
<bridgehead id="network.host" renderas="sect2"><literal>network.host</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/important-settings.asciidoc">Edit me</ulink></bridgehead>
<simpara>By default, Elasticsearch binds to loopback addresses only&#8201;&#8212;&#8201;e.g. <literal>127.0.0.1</literal>
and <literal>[::1]</literal>. This is sufficient to run a single development node on a server.</simpara>
<tip><simpara>In fact, more than one node can be started from the same <literal>$ES_HOME</literal> location
on a single node.  This can be useful for testing Elasticsearch&#8217;s ability to
form clusters, but it is not a configuration recommended for production.</simpara></tip>
<simpara>In order to communicate and to form a cluster with nodes on other servers,
your node will need to bind to a non-loopback address.  While there are many
<link linkend="modules-network">network settings</link>, usually all you need to configure is
<literal>network.host</literal>:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">network.host: 192.168.1.10</programlisting>
<simpara>The <literal>network.host</literal> setting also understands some special values such as
<literal>_local_</literal>, <literal>_site_</literal>, <literal>_global_</literal> and modifiers like <literal>:ip4</literal> and <literal>:ip6</literal>, details
of which can be found in <xref linkend="network-interface-values"/>.</simpara>
<important><simpara>As soon you provide a custom setting for <literal>network.host</literal>,
Elasticsearch assumes that you are moving from development mode to production
mode, and upgrades a number of system startup checks from warnings to
exceptions.  See <xref linkend="dev-vs-prod"/> for more information.</simpara></important>
<bridgehead id="unicast.hosts" renderas="sect2"><literal>discovery.zen.ping.unicast.hosts</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/important-settings.asciidoc">Edit me</ulink></bridgehead>
<simpara>Out of the box, without any network configuration, Elasticsearch will bind to
the available loopback addresses and will scan ports 9300 to 9305 to try to
connect to other nodes running on the same server. This provides an auto-
clustering experience without having to do any configuration.</simpara>
<simpara>When the moment comes to form a cluster with nodes on other servers, you have
to provide a seed list of other nodes in the cluster that are likely to be
live and contactable.  This can be specified as follows:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">discovery.zen.ping.unicast.hosts:
   - 192.168.1.10:9300
   - 192.168.1.11 <co id="CO2-1"/>
   - seeds.mydomain.com <co id="CO2-2"/></programlisting>
<calloutlist>
<callout arearefs="CO2-1">
<para>
The port will default to 9300 if not specified.
</para>
</callout>
<callout arearefs="CO2-2">
<para>
A hostname that resolves to multiple IP addresses will try all resolved addresses.
</para>
</callout>
</calloutlist>
<bridgehead id="minimum_master_nodes" renderas="sect2"><literal>discovery.zen.minimum_master_nodes</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/important-settings.asciidoc">Edit me</ulink></bridgehead>
<simpara>To prevent data loss, it is vital to configure the
<literal>discovery.zen.minimum_master_nodes</literal> setting so that each master-eligible node
knows the <emphasis>minimum number of master-eligible nodes</emphasis> that must be visible in
order to form a cluster.</simpara>
<simpara>Without this setting, a cluster that suffers a network failure is at risk of
having the cluster split into two independent clusters&#8201;&#8212;&#8201;a split brain&#8201;&#8212;&#8201;which will lead to data loss. A more detailed explanation is provided
in <xref linkend="split-brain"/>.</simpara>
<simpara>To avoid a split brain, this setting should be set to a <emphasis>quorum</emphasis> of master-
eligible nodes:</simpara>
<literallayout class="monospaced">(master_eligible_nodes / 2) + 1</literallayout>
<simpara>In other words, if there are three master-eligible nodes, then minimum master
nodes should be set to <literal>(3 / 2) + 1</literal> or <literal>2</literal>:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">discovery.zen.minimum_master_nodes: 2</programlisting>
</chapter>
<chapter id="bootstrap-checks">
<title>Bootstrap Checks<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/bootstrap-checks.asciidoc">Edit me</ulink></title>
<simpara>Collectively, we have a lot of experience with users suffering
unexpected issues because they have not configured
<link linkend="important-settings">important settings</link>. In previous versions of
Elasticsearch, misconfiguration of some of these settings were logged
as warnings. Understandably, users sometimes miss these log messages.
To ensure that these settings receive the attention that they deserve,
Elasticsearch has bootstrap checks upon startup.</simpara>
<simpara>These bootstrap checks inspect a variety of Elasticsearch and system
settings and compare them to values that are safe for the operation of
Elasticsearch. If Elasticsearch is in development mode, any bootstrap
checks that fail appear as warnings in the Elasticsearch log. If
Elasticsearch is in production mode, any bootstrap checks that fail will
cause Elasticsearch to refuse to start.</simpara>
<simpara>There are some bootstrap checks that are always enforced to prevent
Elasticsearch from running with incompatible settings. These checks are
documented individually.</simpara>
<bridgehead id="_development_vs_production_mode" renderas="sect2">Development vs. production mode<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/bootstrap-checks.asciidoc">Edit me</ulink></bridgehead>
<simpara>By default, Elasticsearch binds to <literal>localhost</literal> for <link linkend="modules-http">HTTP</link>
and <link linkend="modules-transport">transport (internal)</link> communication. This is
fine for downloading and playing with Elasticsearch, and everyday
development but it&#8217;s useless for production systems. To form a cluster,
Elasticsearch instances must be reachable via transport communication so
they must bind transport to an external interface. Thus, we consider an
Elaticsearch instance to be in development mode if it does not bind
transport to an external interface (the default), and is otherwise in
production mode if it does bind transport to an external interface. Note
that HTTP can be configured independently of transport via
<link linkend="modules-http"><literal>http.host</literal></link> and <link linkend="modules-transport"><literal>transport.host</literal></link>;
this can be useful for configuring a single instance to be reachable via
HTTP for testing purposes without triggering production mode.</simpara>
<section id="_heap_size_check">
<title>Heap size check<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/bootstrap-checks.asciidoc">Edit me</ulink></title>
<simpara>If a JVM is started with unequal initial and max heap size, it can be
prone to pauses as the JVM heap is resized during system usage. To avoid
these resize pauses, it&#8217;s best to start the JVM with the initial heap
size equal to the maximum heap size. Additionally, if
<link linkend="bootstrap.memory_lock"><literal>bootstrap.memory_lock</literal></link> is enabled, the JVM will
lock the initial size of the heap on startup. If the initial heap size
is not equal to the maximum heap size, after a resize it will not be the
case that all of the JVM heap is locked in memory. To pass the heap size
check, you must configure the <link linkend="heap-size">heap size</link>.</simpara>
</section>
<section id="_file_descriptor_check">
<title>File descriptor check<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/bootstrap-checks.asciidoc">Edit me</ulink></title>
<simpara>File descriptors are a Unix construct for tracking open "files". In Unix
though, <ulink url="https://en.wikipedia.org/wiki/Everything_is_a_file">everything is
a file</ulink>. For example, "files" could be a physical file, a virtual file
(e.g., <literal>/proc/loadavg</literal>), or network sockets. Elasticsearch requires
lots of file descriptors (e.g., every shard is composed of multiple
segments and other files, plus connections to other nodes, etc.). This
bootstrap check is enforced on OS X and Linux. To pass the file
descriptor check, you might have to configure <link linkend="file-descriptors">file descriptors</link>.</simpara>
</section>
<section id="_memory_lock_check">
<title>Memory lock check<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/bootstrap-checks.asciidoc">Edit me</ulink></title>
<simpara>When the JVM does a major garbage collection it touches every page of
the heap. If any of those pages are swapped out to disk they will have
to be swapped back in to memory. That causes lots of disk thrashing that
Elasticsearch would much rather use to service requests. There are
several ways to configure a system to disallow swapping. One way is by
requesting the JVM to lock the heap in memory through <literal>mlockall</literal> (Unix)
or virtual lock (Windows). This is done via the Elasticsearch setting
<link linkend="bootstrap.memory_lock"><literal>bootstrap.memory_lock</literal></link>. However, there are cases
where this setting can be passed to Elasticsearch but Elasticsearch is
not able to lock the heap (e.g., if the <literal>elasticsearch</literal> user does not
have <literal>memlock unlimited</literal>). The memory lock check verifies that <emphasis role="strong">if</emphasis> the
<literal>bootstrap.memory_lock</literal> setting is enabled, that the JVM was successfully
able to lock the heap. To pass the memory lock check, you might have to
configure <link linkend="mlockall"><literal>mlockall</literal></link>.</simpara>
</section>
<section id="_maximum_number_of_threads_check">
<title>Maximum number of threads check<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/bootstrap-checks.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch executes requests by breaking the request down into stages
and handing those stages off to different thread pool executors. There
are different <link linkend="modules-threadpool">thread pool executors</link> for a variety
of tasks within Elasticsearch. Thus, Elasticsearch needs the ability to
create a lot of threads. The maximum number of threads check ensures
that the Elasticsearch process has the rights to create enough threads
under normal use. This check is enforced only on Linux. If you are on
Linux, to pass the maximum number of threads check, you must configure
your system to allow the Elasticsearch process the ability to create at
least 2048 threads. This can be done via <literal>/etc/security/limits.conf</literal>
using the <literal>nproc</literal> setting (note that you might have to increase the
limits for the <literal>root</literal> user too).</simpara>
</section>
<section id="max-size-virtual-memory-check">
<title>Maximum size virtual memory check<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/bootstrap-checks.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch and Lucene use <literal>mmap</literal> to great effect to map portions of
an index into the Elasticsearch address space. This keeps certain index
data off the JVM heap but in memory for blazing fast access. For this to
be effective, the Elasticsearch should have unlimited address space. The
maximum size virtual memory check enforces that the Elasticsearch
process has unlimited address space and is enforced only on Linux. To
pass the maximum size virtual memory check, you must configure your
system to allow the Elasticsearch process the ability to have unlimited
address space. This can be done via <literal>/etc/security/limits.conf</literal> using
the <literal>as</literal> setting to <literal>unlimited</literal> (note that you might have to increase
the limits for the <literal>root</literal> user too).</simpara>
</section>
<section id="_maximum_map_count_check">
<title>Maximum map count check<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/bootstrap-checks.asciidoc">Edit me</ulink></title>
<simpara>Continuing from the previous <link linkend="max-size-virtual-memory-check">point</link>, to
use <literal>mmap</literal> effectively, Elasticsearch also requires the ability to
create many memory-mapped areas. The maximum map count check checks that
the kernel allows a process to have at least 262,144 memory-mapped areas
and is enforced on Linux only. To pass the maximum map count check, you
must configure <literal>vm.max_map_count</literal> via <literal>sysctl</literal> to be at least <literal>262144</literal>.</simpara>
</section>
<section id="_client_jvm_check">
<title>Client JVM check<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/bootstrap-checks.asciidoc">Edit me</ulink></title>
<simpara>There are two different JVMs provided by OpenJDK-derived JVMs: the
client JVM and the server JVM. These JVMs use different compilers for
producing executable machine code from Java bytecode. The client JVM is
tuned for startup time and memory footprint while the server JVM is
tuned for maximizing performance. The difference in performance between
the two VMs can be substantial. The client JVM check ensures that
Elasticsearch is not running inside the client JVM. To pass the client
JVM check, you must start Elasticsearch with the server VM. On modern
systems and operating systems, the server VM is the
default. Additionally, Elasticsearch is configured by default to force
the server VM.</simpara>
</section>
<section id="_use_serial_collector_check">
<title>Use serial collector check<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/bootstrap-checks.asciidoc">Edit me</ulink></title>
<simpara>There are various garbage collectors for the OpenJDK-derived JVMs targeting
different workloads. The serial collector in particular is best suited for
single logical CPU machines or extremely small heaps, neither of which are
suitable for running Elasticsearch. Using the serial collector with
Elasticsearch can be devastating for performance. The serial collector check
ensures that Elasticsearch is not configured to run with the serial
collector. To pass the serial collector check, you must not start Elasticsearch
with the serial collector (whether it&#8217;s from the defaults for the JVM that
you&#8217;re using, or you&#8217;ve explicitly specified it with <literal>-XX:+UseSerialGC</literal>). Note
that the default JVM configuration that ship with Elasticsearch configures
Elasticsearch to use the CMS collector.</simpara>
</section>
<section id="_onerror_and_onoutofmemoryerror_checks">
<title>OnError and OnOutOfMemoryError checks<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/bootstrap-checks.asciidoc">Edit me</ulink></title>
<simpara>The JVM options <literal>OnError</literal> and <literal>OnOutOfMemoryError</literal> enable executing
arbitrary commands if the JVM encounters a fatal error (<literal>OnError</literal>) or an
<literal>OutOfMemoryError</literal> (<literal>OnOutOfMemoryError</literal>). However, by default,
Elasticsearch system call filters (seccomp) are enabled and these
filters prevent forking. Thus, using <literal>OnError</literal> or <literal>OnOutOfMemoryError</literal>
and system call filters are incompatible. The <literal>OnError</literal> and
<literal>OnOutOfMemoryError</literal> checks prevent Elasticsearch from starting if
either of these JVM options are used and system call filters are
enabled. This check is always enforced. To pass this check do not enable
<literal>OnError</literal> nor <literal>OnOutOfMemoryError</literal>; instead, upgrade to Java 8u92 and
use the JVM flag <literal>ExitOnOutOfMemoryError</literal>. While this does not have the
full capabilities of <literal>OnError</literal> nor <literal>OnOutOfMemoryError</literal>, arbitrary
forking will not be supported with seccomp enabled.</simpara>
</section>
<section id="_g1gc_check">
<title>G1GC check<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/bootstrap-checks.asciidoc">Edit me</ulink></title>
<simpara>Early versions of the HotSpot JVM that shipped with JDK 8 are known to have
issues that can lead to index corruption when the G1GC collector is enabled.
The versions impacted are those earlier than the version of HotSpot that
shipped with JDK 8u40. The G1GC check detects these early versions of the
HotSpot JVM.</simpara>
</section>
</chapter>
<chapter id="system-config">
<title>Important System Configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/sysconfig.asciidoc">Edit me</ulink></title>
<simpara>Ideally, Elasticsearch should run alone on a server and use all of the
resources available to it.  In order to do so, you need to configure your
operating system to allow the user running Elasticsearch to access more
resources than allowed by default.</simpara>
<simpara>The following settings <emphasis role="strong">must</emphasis> be addressed before going to production:</simpara>
<itemizedlist>
<listitem>
<simpara>
<link linkend="heap-size">Set JVM heap size</link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="setup-configuration-memory">Disable swapping</link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="file-descriptors">Increase file descriptors</link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="vm-max-map-count">Ensure sufficient virtual memory</link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="max-number-of-threads">Ensure sufficient threads</link>
</simpara>
</listitem>
</itemizedlist>
<bridgehead id="dev-vs-prod" renderas="sect2">Development mode vs production mode<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/sysconfig.asciidoc">Edit me</ulink></bridgehead>
<simpara>By default, Elasticsearch assumes that you are working in development mode.
If any of the above settings are not configured correctly, a warning will be
written to the log file, but you will be able to start and run your
Elasticsearch node.</simpara>
<simpara>As soon as you configure a network setting like <literal>network.host</literal>, Elasticsearch
assumes that you are moving to production and will upgrade the above warnings
to exceptions.  These exceptions will prevent your Elasticsearch node from
starting.  This is an important safety measure to ensure that you will not
lose data because of a malconfigured server.</simpara>
<section id="setting-system-settings">
<title>Configuring system settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/sysconfig/configuring.asciidoc">Edit me</ulink></title>
<simpara>Where to configure systems settings depends on which package you have used to
install Elasticsearch, and which operating system you are using.</simpara>
<simpara>When using the <literal>.zip</literal> or <literal>.tar.gz</literal> packages, system settings can be configured:</simpara>
<itemizedlist>
<listitem>
<simpara>
temporarily with <link linkend="ulimit"><literal>ulimit</literal></link>, or
</simpara>
</listitem>
<listitem>
<simpara>
permanently in <link linkend="limits.conf"><literal>/etc/security/limits.conf</literal></link>.
</simpara>
</listitem>
</itemizedlist>
<simpara>When using the RPM or Debian packages, most system settings are set in the
<link linkend="sysconfig">system configuration file</link>. However, systems which use systemd
require that system limits are specified in a
<link linkend="systemd">systemd configuration file</link>.</simpara>
<section id="ulimit">
<title><literal>ulimit</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/sysconfig/configuring.asciidoc">Edit me</ulink></title>
<simpara>On Linux systems, <literal>ulimit</literal> can be used to change resource limits on a
temporary basis. Limits usually need to be set as <literal>root</literal> before switching to
the user that will run Elasticsearch.  For example, to set the number of
open file handles (<literal>ulimit -n</literal>) to 65,536, you can do the following:</simpara>
<programlisting language="sh" linenumbering="unnumbered">sudo su  <co id="CO3-1"/>
ulimit -n 65536 <co id="CO3-2"/>
su elasticsearch <co id="CO3-3"/></programlisting>
<calloutlist>
<callout arearefs="CO3-1">
<para>
Become <literal>root</literal>.
</para>
</callout>
<callout arearefs="CO3-2">
<para>
Change the max number of open files.
</para>
</callout>
<callout arearefs="CO3-3">
<para>
Become the <literal>elasticsearch</literal> user in order to start Elasticsearch.
</para>
</callout>
</calloutlist>
<simpara>The new limit is only applied during the current session.</simpara>
<simpara>You can consult all currently applied limits with <literal>ulimit -a</literal>.</simpara>
</section>
<section id="limits.conf">
<title><literal>/etc/security/limits.conf</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/sysconfig/configuring.asciidoc">Edit me</ulink></title>
<simpara>On Linux systems, persistent limits can be set for a particular user by
editing the <literal>/etc/security/limits.conf</literal> file. To set the maximum number of
open files for the <literal>elasticsearch</literal> user to 65,536, add the following line to
the <literal>limits.conf</literal> file:</simpara>
<programlisting language="sh" linenumbering="unnumbered">elasticsearch  -  nofile  65536</programlisting>
<simpara>This change will only take effect the next time the <literal>elasticsearch</literal> user opens
a new session.</simpara>
<note>
<title>Ubuntu and <literal>limits.conf</literal></title>
<simpara>Ubuntu ignores the <literal>limits.conf</literal> file for processes started by <literal>init.d</literal>.  To
enable the <literal>limits.conf</literal> file, edit <literal>/etc/pam.d/su</literal> and uncomment the
following line:</simpara>
<programlisting language="sh" linenumbering="unnumbered"># session    required   pam_limits.so</programlisting>
</note>
</section>
<section id="sysconfig">
<title>Sysconfig file<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/sysconfig/configuring.asciidoc">Edit me</ulink></title>
<simpara>When using the RPM or Debian packages, system settings and environment
variables can be specified in the system configuration file, which is located
in:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
RPM
</simpara>
</entry>
<entry>
<simpara>
<literal>/etc/sysconfig/elasticsearch</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Debian
</simpara>
</entry>
<entry>
<simpara>
<literal>/etc/default/elasticsearch</literal>
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>However, for systems which uses <literal>systemd</literal>, system limits need to be specified
via <link linkend="systemd">systemd</link>.</simpara>
</section>
<section id="systemd">
<title>Systemd configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/sysconfig/configuring.asciidoc">Edit me</ulink></title>
<simpara>When using the RPM or Debian packages on systems that use
<ulink url="https://en.wikipedia.org/wiki/Systemd">systemd</ulink>, system limits must be
specified via systemd.</simpara>
<simpara>The systemd service file (<literal>/usr/lib/systemd/system/elasticsearch.service</literal>)
contains the limits that are applied by default.</simpara>
<simpara>To override these, add a file called
<literal>/etc/systemd/system/elasticsearch.service.d/elasticsearch.conf</literal> and specify
any changes in that file, such as:</simpara>
<programlisting language="sh" linenumbering="unnumbered">LimitMEMLOCK=infinity</programlisting>
</section>
<section id="jvm-options">
<title>Setting JVM options<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/sysconfig/configuring.asciidoc">Edit me</ulink></title>
<simpara>The preferred method of setting Java Virtual Machine options (including
system properties and JVM flags) is via the <literal>jvm.options</literal> configuration
file. The default location of this file is <literal>config/jvm.options</literal> (when
installing from the tar or zip distributions) and
<literal>/etc/elasticsearch/jvm.options</literal> (when installing from the Debian or RPM
packages). This file contains a line-delimited list of JVM arguments,
which must begin with <literal>-</literal>. You can add custom JVM flags to this file and
check this configuration into your version control system.</simpara>
<simpara>An alternative mechanism for setting Java Virtual Machine options is
via the <literal>ES_JAVA_OPTS</literal> environment variable. For instance:</simpara>
<programlisting language="sh" linenumbering="unnumbered">export ES_JAVA_OPTS="$ES_JAVA_OPTS -Djava.io.tmpdir=/path/to/temp/dir"
./bin/elasticsearch</programlisting>
<simpara>When using the RPM or Debian packages, <literal>ES_JAVA_OPTS</literal> can be specified in the
<link linkend="sysconfig">system configuration file</link>.</simpara>
</section>
</section>
<section id="heap-size">
<title>Set JVM heap size via jvm.options<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/sysconfig/heap_size.asciidoc">Edit me</ulink></title>
<simpara>By default, Elasticsearch tells the JVM to use a heap with a minimum
and maximum size of 2 GB. When moving to production, it is
important to configure heap size to ensure that Elasticsearch has enough
heap available.</simpara>
<simpara>Elasticsearch will assign the entire heap specified in <link linkend="jvm-options">jvm.options</link>
via the Xms (minimum heap size) and Xmx (maximum heap size) settings.</simpara>
<simpara>The value for these setting depends on the amount of RAM available on
your server. Good rules of thumb are:</simpara>
<itemizedlist>
<listitem>
<simpara>
Set the minimum heap size (Xms) and maximum heap size (Xmx) to be
  equal to each other.
</simpara>
</listitem>
<listitem>
<simpara>
The more heap available to Elasticsearch, the more memory it can use for
  caching. But note that too much heap can subject you to long garbage
  collection pauses.
</simpara>
</listitem>
<listitem>
<simpara>
Set Xmx to no more than 50% of your physical RAM, to ensure that there
  is enough physical RAM left for kernel file system caches.
</simpara>
</listitem>
<listitem>
<simpara>
Don’t set Xmx to above the cutoff that the JVM uses for compressed
  object pointers (compressed oops); the exact cutoff varies but is
  near 32 GB. You can verify that you are under the limit by looking
  for a line in the logs like the following:
</simpara>
<literallayout class="monospaced">heap size [1.9gb], compressed ordinary object pointers [true]</literallayout>
</listitem>
<listitem>
<simpara>
Even better, try to stay below the threshold for zero-based
  compressed oops; the exact cutoff varies but 26 GB is safe on most
  systems, but can be as large as 30 GB on some systems. You can verify
  that you are under the limit by starting Elasticsearch with the JVM
  options <literal>-XX:+UnlockDiagnosticVMOptions -XX:+PrintCompressedOopsMode</literal>
  and looking for a line like the following:
</simpara>
<literallayout class="monospaced">heap address: 0x000000011be00000, size: 27648 MB, zero based Compressed Oops</literallayout>
<simpara>showing that zero-based compressed oops are enabled instead of</simpara>
<literallayout class="monospaced">heap address: 0x0000000118400000, size: 28672 MB, Compressed Oops with base: 0x00000001183ff000</literallayout>
</listitem>
</itemizedlist>
<simpara>Here are examples of how to set the heap size via the jvm.options file:</simpara>
<programlisting language="txt" linenumbering="unnumbered">-Xms2g <co id="CO4-1"/>
-Xmx2g <co id="CO4-2"/></programlisting>
<calloutlist>
<callout arearefs="CO4-1">
<para>
Set the minimum heap size to 2g.
</para>
</callout>
<callout arearefs="CO4-2">
<para>
Set the maximum heap size to 2g.
</para>
</callout>
</calloutlist>
<simpara>It is also possible to set the heap size via an environment variable.
This can be done by commenting out the <literal>Xms</literal> and <literal>Xmx</literal> settings
in the jvm.options file and setting these values via <literal>ES_JAVA_OPTS</literal>:</simpara>
<programlisting language="sh" linenumbering="unnumbered">ES_JAVA_OPTS="-Xms2g -Xmx2g" ./bin/elasticsearch <co id="CO5-1"/>
ES_JAVA_OPTS="-Xms4000m -Xmx4000m" ./bin/elasticsearch <co id="CO5-2"/></programlisting>
<calloutlist>
<callout arearefs="CO5-1">
<para>
Set the minimum and maximum heap size to 2 GB.
</para>
</callout>
<callout arearefs="CO5-2">
<para>
Set the minimum and maximum heap size to 4000 MB.
</para>
</callout>
</calloutlist>
<note><simpara>Configuring the heap for the <link linkend="windows-service">Windows service</link>
is different than the above. The values initially populated for the
Windows service can be configured as above but are different after the
service has been installed. Consult the
<link linkend="windows-service">Windows service documentation</link> for additional
details.</simpara></note>
</section>
<section id="setup-configuration-memory">
<title>Disable swapping<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/sysconfig/swap.asciidoc">Edit me</ulink></title>
<simpara>Most operating systems try to use as much memory as possible for file system
caches and eagerly swap out unused application memory. This can result in
parts of the JVM heap being swapped out to disk.</simpara>
<simpara>Swapping is very bad for performance and for node stability and should be
avoided at all costs. It can cause garbage collections to last for <emphasis role="strong">minutes</emphasis>
instead of milliseconds and can cause nodes to respond slowly or even to
disconnect from the cluster.</simpara>
<simpara>There are three approaches to disabling swapping:</simpara>
<section id="mlockall">
<title>Enable <literal>bootstrap.memory_lock</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/sysconfig/swap.asciidoc">Edit me</ulink></title>
<simpara>The first option is to use
<ulink url="http://opengroup.org/onlinepubs/007908799/xsh/mlockall.html">mlockall</ulink> on Linux/Unix systems, or <ulink url="https://msdn.microsoft.com/en-us/library/windows/desktop/aa366895%28v=vs.85%29.aspx">VirtualLock</ulink> on Windows, to
try to lock the process address space into RAM, preventing any Elasticsearch
memory from being swapped out.  This can be done, by adding this line
to the <literal>config/elasticsearch.yml</literal> file:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">bootstrap.memory_lock: true</programlisting>
<warning><simpara><literal>mlockall</literal> might cause the JVM or shell session to exit if it tries
to allocate more memory than is available!</simpara></warning>
<simpara>After starting Elasticsearch, you can see whether this setting was applied
successfully by checking the value of <literal>mlockall</literal> in the output from this
request:</simpara>
<programlisting language="sh" linenumbering="unnumbered">GET _nodes?filter_path=**.mlockall</programlisting>
<remark> CONSOLE</remark>
<simpara>If you see that <literal>mlockall</literal> is <literal>false</literal>, then it means that the <literal>mlockall</literal>
request has failed.  You will also see a line with more information in the
logs with the words <literal>Unable to lock JVM Memory</literal>.</simpara>
<simpara>The most probable reason, on Linux/Unix systems, is that the user running
Elasticsearch doesn&#8217;t have permission to lock memory.  This can be granted as follows:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>.zip</literal> and <literal>.tar.gz</literal>
</term>
<listitem>
<simpara>
  Set <link linkend="ulimit"><literal>ulimit -l unlimited</literal></link> as root before starting Elasticsearch,
  or set <literal>memlock</literal> to <literal>unlimited</literal> in
  <link linkend="limits.conf"><literal>/etc/security/limits.conf</literal></link>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
RPM and Debian
</term>
<listitem>
<simpara>
  Set <literal>MAX_LOCKED_MEMORY</literal> to <literal>unlimited</literal> in the
  <link linkend="sysconfig">system configuration file</link> (or see below for systems using <literal>systemd</literal>).
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Systems using <literal>systemd</literal>
</term>
<listitem>
<simpara>
  Set <literal>LimitMEMLOCK</literal> to <literal>infinity</literal> in the <link linkend="systemd">systemd configuration</link>.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>Another possible reason why <literal>mlockall</literal> can fail is that the temporary directory
(usually <literal>/tmp</literal>) is mounted with the <literal>noexec</literal> option. This can be solved by
specifying a new temp directory using the <literal>ES_JAVA_OPTS</literal> environment variable:</simpara>
<programlisting language="sh" linenumbering="unnumbered">export ES_JAVA_OPTS="$ES_JAVA_OPTS -Djava.io.tmpdir=/path/to/temp/dir"
./bin/elasticsearch</programlisting>
<simpara>or setting this JVM flag in the jvm.options configuration file.</simpara>
</section>
<section id="disable-swap-files">
<title>Disable all swap files<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/sysconfig/swap.asciidoc">Edit me</ulink></title>
<simpara>The second option is to completely disable swap. Usually Elasticsearch
is the only service running on a box, and its memory usage is controlled
by the JVM options.  There should be no need to have swap enabled.</simpara>
<simpara>On Linux systems, you can disable swap temporarily
by running: <literal>sudo swapoff -a</literal>. To disable it permanently, you will need
to edit the <literal>/etc/fstab</literal> file and comment out any lines that contain the
word <literal>swap</literal>.</simpara>
<simpara>On Windows, the equivalent can be achieved by disabling the paging file entirely
via <literal>System Properties → Advanced → Performance → Advanced → Virtual memory</literal>.</simpara>
</section>
<section id="swappiness">
<title>Configure <literal>swappiness</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/sysconfig/swap.asciidoc">Edit me</ulink></title>
<simpara>The second option available on Linux systems is to ensure that the sysctl value
<literal>vm.swappiness</literal> is set to <literal>1</literal>. This reduces the kernel&#8217;s tendency to swap and
should not lead to swapping under normal circumstances, while still allowing
the whole system to swap in emergency conditions.</simpara>
</section>
</section>
<section id="file-descriptors">
<title>File Descriptors<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/sysconfig/file-descriptors.asciidoc">Edit me</ulink></title>
<note><simpara>This is only relevant for Linux and macOS and can be safely ignored if running
Elasticsearch on Windows. On Windows that JVM uses an
<ulink url="https://msdn.microsoft.com/en-us/library/windows/desktop/aa363858(v=vs.85).aspx">API</ulink>
limited only by available resources.</simpara></note>
<simpara>Elasticsearch uses a lot of file descriptors or file handles.  Running out of
file descriptors can be disastrous and will most probably lead to data loss.
Make sure to increase the limit on the number of open files descriptors for
the user running Elasticsearch to 65,536 or higher.</simpara>
<simpara>For the <literal>.zip</literal> and <literal>.tar.gz</literal> packages, set <link linkend="ulimit"><literal>ulimit -n 65536</literal></link> as
root before starting Elasticsearch,   or set <literal>nofile</literal> to <literal>65536</literal> in
<link linkend="limits.conf"><literal>/etc/security/limits.conf</literal></link>.</simpara>
<simpara>RPM and Debian packages already default the maximum number of file
descriptors to 65536 and do not require further configuration.</simpara>
<simpara>You can check the <literal>max_file_descriptors</literal> configured for each node
using the <xref linkend="cluster-nodes-stats"/> API, with:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _nodes/stats/process?filter_path=**.max_file_descriptors</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="vm-max-map-count">
<title>Virtual memory<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/sysconfig/virtual-memory.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch uses a <link linkend="default_fs"><literal>hybrid mmapfs / niofs</literal></link> directory by
default to store its indices.  The default operating system limits on mmap
counts is likely to be too low, which may result in out of memory exceptions.</simpara>
<simpara>On Linux, you can increase the limits by running the following command as
<literal>root</literal>:</simpara>
<programlisting language="sh" linenumbering="unnumbered">sysctl -w vm.max_map_count=262144</programlisting>
<simpara>To set this value permanently, update the <literal>vm.max_map_count</literal> setting in
<literal>/etc/sysctl.conf</literal>.  To verify after rebooting, run <literal>sysctl vm.max_map_count</literal>.</simpara>
<simpara>The RPM and Debian packages will configure this setting automatically.  No
further configuration is required.</simpara>
</section>
<section id="max-number-of-threads">
<title>Number of threads<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/sysconfig/threads.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch uses a number of thread pools for different types of operations.
It is important that it is able to create new threads whenever needed.   Make
sure that the number of threads that the Elasticsearch user can create is at
least 2048.</simpara>
<simpara>This can be done by setting <link linkend="ulimit"><literal>ulimit -u 2048</literal></link> as root before
starting Elasticsearch, or by setting <literal>nproc</literal> to <literal>2048</literal> in
<link linkend="limits.conf"><literal>/etc/security/limits.conf</literal></link>.</simpara>
</section>
</chapter>
<chapter id="setup-upgrade">
<title>Upgrading Elasticsearch<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/upgrade.asciidoc">Edit me</ulink></title>
<important>
<simpara>Before upgrading Elasticsearch:</simpara>
<itemizedlist>
<listitem>
<simpara>
Consult the <link linkend="breaking-changes">breaking changes</link> docs.
</simpara>
</listitem>
<listitem>
<simpara>
Use the <ulink url="https://github.com/elastic/elasticsearch-migration/">Elasticsearch Migration Plugin</ulink>
  to detect potential issues before upgrading.
</simpara>
</listitem>
<listitem>
<simpara>
Test upgrades in a dev environment before upgrading your production cluster.
</simpara>
</listitem>
<listitem>
<simpara>
Always <link linkend="modules-snapshots">back up your data</link> before upgrading.
  You <emphasis role="strong">cannot roll back</emphasis> to an earlier version unless you have a backup of your data.
</simpara>
</listitem>
<listitem>
<simpara>
If you are using custom plugins, check that a compatible version is available.
</simpara>
</listitem>
</itemizedlist>
</important>
<simpara>Elasticsearch can usually be upgraded using a rolling upgrade process,
resulting in no interruption of service.  This section details how to perform
both rolling upgrades and upgrades with full cluster restarts.</simpara>
<simpara>To determine whether a rolling upgrade is supported for your release, please
consult this table:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="3">
<colspec colname="col_1" colwidth="20*"/>
<colspec colname="col_2" colwidth="20*"/>
<colspec colname="col_3" colwidth="60*"/>
<thead>
<row>
<entry align="left" valign="top">Upgrade From   </entry>
<entry align="left" valign="top">Upgrade To     </entry>
<entry align="left" valign="top">Supported Upgrade Type</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>1.x</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>5.x</literal></simpara></entry>
<entry align="left" valign="top"><simpara><link linkend="reindex-upgrade">Reindex to upgrade</link></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>2.x</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>2.y</literal></simpara></entry>
<entry align="left" valign="top"><simpara><link linkend="rolling-upgrades">Rolling upgrade</link> (where <literal>y &gt; x</literal>)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>2.x</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>5.x</literal></simpara></entry>
<entry align="left" valign="top"><simpara><link linkend="restart-upgrade">Full cluster restart</link></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>5.0.0 pre GA</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>5.x</literal></simpara></entry>
<entry align="left" valign="top"><simpara><link linkend="restart-upgrade">Full cluster restart</link></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>5.x</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>5.y</literal></simpara></entry>
<entry align="left" valign="top"><simpara><link linkend="rolling-upgrades">Rolling upgrade</link> (where <literal>y &gt; x</literal>)</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<important>
<title>Indices created in Elasticsearch 1.x or before</title>
<simpara>Elasticsearch is able to read indices created in the <emphasis role="strong">previous major version
only</emphasis>.  For instance, Elasticsearch 5.x can use indices created in
Elasticsearch 2.x, but not those created in Elasticsearch 1.x or before.</simpara>
<simpara>This condition also applies to indices backed up with
<link linkend="modules-snapshots">snapshot and restore</link>.  If an index was originally
created in 1.x, it cannot be restored into a 5.x cluster even if the
snapshot was made by a 2.x cluster.</simpara>
<simpara>Elasticsearch 5.x nodes will fail to start in the presence of too old indices.</simpara>
<simpara>See <xref linkend="reindex-upgrade"/> for more information about how to upgrade old indices.</simpara>
</important>
<section id="rolling-upgrades">
<title>Rolling upgrades<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/rolling_upgrade.asciidoc">Edit me</ulink></title>
<simpara>A rolling upgrade allows the Elasticsearch cluster to be upgraded one node at
a time, with no downtime for end users.  Running multiple versions of
Elasticsearch in the same cluster for any length of time beyond that required
for an upgrade is not supported, as shards will not be replicated from the
more recent version to the older version.</simpara>
<simpara>Consult this <link linkend="setup-upgrade">table</link> to verify that rolling upgrades are
supported for your version of Elasticsearch.</simpara>
<simpara>To perform a rolling upgrade:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>
<emphasis role="strong">Disable shard allocation</emphasis>
</simpara>
<simpara>When you shut down a node, the allocation process will wait for one minute
before starting to replicate the shards that were on that node to other nodes
in the cluster, causing a lot of wasted I/O.  This can be avoided by disabling
allocation before shutting down a node:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT _cluster/settings
{
  "transient": {
    "cluster.routing.allocation.enable": "none"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[skip:indexes don't assign]</remark>
</listitem>
<listitem>
<simpara>
<emphasis role="strong">Stop non-essential indexing and perform a synced flush (Optional)</emphasis>
</simpara>
<simpara>You may happily continue indexing during the upgrade.  However, shard recovery
will be much faster if you temporarily stop non-essential indexing and issue a
<link linkend="indices-synced-flush">synced-flush</link> request:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _flush/synced</programlisting>
<remark> CONSOLE</remark>
<simpara>A synced flush request is a &#8220;best effort&#8221; operation. It will fail if there
are any pending indexing operations, but it is safe to reissue the request
multiple times if necessary.</simpara>
</listitem>
<listitem>
<simpara>
<anchor id="upgrade-node" xreflabel="[upgrade-node]"/> <emphasis role="strong">Stop and upgrade a single node</emphasis>
</simpara>
<simpara>Shut down one of the nodes in the cluster <emphasis role="strong">before</emphasis> starting the upgrade.</simpara>
<tip>
<simpara>When using the zip or tarball packages, the <literal>config</literal>, <literal>data</literal>, <literal>logs</literal> and
<literal>plugins</literal> directories are placed within the Elasticsearch home directory by
default.</simpara>
<simpara>It is a good idea to place these directories in a different location so that
there is no chance of deleting them when upgrading Elasticsearch.  These
custom paths can be <link linkend="path-settings">configured</link> with the <literal>path.conf</literal>,
<literal>path.logs</literal>, and <literal>path.data</literal> settings.</simpara>
<simpara>The <link linkend="deb">Debian</link> and <link linkend="rpm">RPM</link> packages place these directories in the
appropriate place for each operating system.</simpara>
</tip>
<simpara>To upgrade using a <link linkend="deb">Debian</link> or <link linkend="rpm">RPM</link> package:</simpara>
<itemizedlist>
<listitem>
<simpara>
Use <literal>rpm</literal> or <literal>dpkg</literal> to install the new package.  All files should be
    placed in their proper locations, and config files should not be
    overwritten.
</simpara>
</listitem>
</itemizedlist>
<simpara>To upgrade using a zip or compressed tarball:</simpara>
<itemizedlist>
<listitem>
<simpara>
Extract the zip or tarball to a new directory, to be sure that you don&#8217;t
    overwrite the <literal>config</literal> or <literal>data</literal> directories.
</simpara>
</listitem>
<listitem>
<simpara>
Either copy the files in the <literal>config</literal> directory from your old installation
    to your new installation, or use the <literal>-E path.conf=</literal> option on the command
    line to point to an external config directory.
</simpara>
</listitem>
<listitem>
<simpara>
Either copy the files in the <literal>data</literal> directory from your old installation
    to your new installation, or configure the location of the data directory
    in the <literal>config/elasticsearch.yml</literal> file, with the <literal>path.data</literal> setting.
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
<emphasis role="strong">Upgrade any plugins</emphasis>
</simpara>
<simpara>Elasticsearch plugins must be upgraded when upgrading a node.  Use the
<literal>elasticsearch-plugin</literal> script to install the correct version of any plugins
that you need.</simpara>
</listitem>
<listitem>
<simpara>
<emphasis role="strong">Start the upgraded node</emphasis>
</simpara>
<simpara>Start the now upgraded node and confirm that it joins the cluster by checking
the log file or by checking the output of this request:</simpara>
<programlisting language="sh" linenumbering="unnumbered">GET _cat/nodes</programlisting>
<remark> CONSOLE</remark>
</listitem>
<listitem>
<simpara>
<emphasis role="strong">Reenable shard allocation</emphasis>
</simpara>
<simpara>Once the node has joined the cluster, reenable shard allocation to start using
the node:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT _cluster/settings
{
  "transient": {
    "cluster.routing.allocation.enable": "all"
  }
}</programlisting>
<remark> CONSOLE</remark>
</listitem>
<listitem>
<simpara>
<emphasis role="strong">Wait for the node to recover</emphasis>
</simpara>
<simpara>You should wait for the cluster to finish shard allocation before upgrading
the next node.  You can check on progress with the <link linkend="cat-health"><literal>_cat/health</literal></link>
request:</simpara>
<programlisting language="sh" linenumbering="unnumbered">GET _cat/health</programlisting>
<remark> CONSOLE</remark>
<simpara>Wait for the <literal>status</literal> column to move from <literal>yellow</literal> to <literal>green</literal>.  Status <literal>green</literal>
means that all primary and replica shards have been allocated.</simpara>
<important>
<simpara>During a rolling upgrade, primary shards assigned to a node with the higher
version will never have their replicas assigned to a node with the lower
version, because the newer version may have a different data format which is
not understood by the older version.</simpara>
<simpara>If it is not possible to assign the replica shards to another node with the
higher version&#8201;&#8212;&#8201;e.g. if there is only one node with the higher version in
the cluster&#8201;&#8212;&#8201;then the replica shards will remain unassigned and the
cluster health will remain status <literal>yellow</literal>.</simpara>
<simpara>In this case, check that there are no initializing or relocating shards (the
<literal>init</literal> and <literal>relo</literal> columns) before proceding.</simpara>
<simpara>As soon as another node is upgraded, the replicas should be assigned and the
cluster health will reach status <literal>green</literal>.</simpara>
</important>
<simpara>Shards that have not been <link linkend="indices-synced-flush">sync-flushed</link> may take some time to
recover.  The recovery status of individual shards can be monitored with the
<link linkend="cat-recovery"><literal>_cat/recovery</literal></link> request:</simpara>
<programlisting language="sh" linenumbering="unnumbered">GET _cat/recovery</programlisting>
<remark> CONSOLE</remark>
<simpara>If you stopped indexing, then it is safe to resume indexing as soon as
recovery has completed.</simpara>
</listitem>
<listitem>
<simpara>
<emphasis role="strong">Repeat</emphasis>
</simpara>
<simpara>When the cluster is stable and the node has recovered, repeat the above steps
for all remaining nodes.</simpara>
</listitem>
</orderedlist>
</section>
<section id="restart-upgrade">
<title>Full cluster restart upgrade<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/cluster_restart.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch requires a full cluster restart when upgrading across major
versions.  Rolling upgrades are not supported across major versions. Consult
this <link linkend="setup-upgrade">table</link> to verify that a full cluster restart is
required.</simpara>
<simpara>The process to perform an upgrade with a full cluster restart is as follows:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>
<emphasis role="strong">Disable shard allocation</emphasis>
</simpara>
<simpara>When you shut down a node, the allocation process will immediately try to
replicate the shards that were on that node to other nodes in the cluster,
causing a lot of wasted I/O.  This can be avoided by disabling allocation
before shutting down a node:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT _cluster/settings
{
  "persistent": {
    "cluster.routing.allocation.enable": "none"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[skip:indexes don't assign]</remark>
</listitem>
<listitem>
<simpara>
<emphasis role="strong">Perform a synced flush</emphasis>
</simpara>
<simpara>Shard recovery will be much faster if you stop indexing and issue a
<link linkend="indices-synced-flush">synced-flush</link> request:</simpara>
<programlisting language="sh" linenumbering="unnumbered">POST _flush/synced</programlisting>
<remark> CONSOLE</remark>
<simpara>A synced flush request is a &#8220;best effort&#8221; operation. It will fail if there
are any pending indexing operations, but it is safe to reissue the request
multiple times if necessary.</simpara>
</listitem>
<listitem>
<simpara>
<emphasis role="strong">Shutdown and upgrade all nodes</emphasis>
</simpara>
<simpara>Stop all Elasticsearch services on all nodes in the cluster. Each node can be
upgraded following the same procedure described in <xref linkend="upgrade-node"/>.</simpara>
</listitem>
<listitem>
<simpara>
<emphasis role="strong">Upgrade any plugins</emphasis>
</simpara>
<simpara>Elasticsearch plugins must be upgraded when upgrading a node.  Use the
<literal>elasticsearch-plugin</literal> script to install the correct version of any plugins
that you need.</simpara>
</listitem>
<listitem>
<simpara>
<emphasis role="strong">Start the cluster</emphasis>
</simpara>
<simpara>If you have dedicated master nodes&#8201;&#8212;&#8201;nodes with <literal>node.master</literal> set to
<literal>true</literal>(the default) and <literal>node.data</literal> set to <literal>false</literal>&#8201;&#8212;&#8201; then it is a good idea
to start them first.  Wait for them to form a cluster and to elect a master
before proceeding with the data nodes. You can check progress by looking at the
logs.</simpara>
<simpara>As soon as the <link linkend="master-election">minimum number of master-eligible nodes</link>
have discovered each other, they will form a cluster and elect a master.  From
that point on, the <link linkend="cat-health"><literal>_cat/health</literal></link> and <link linkend="cat-nodes"><literal>_cat/nodes</literal></link>
APIs can be used to monitor nodes joining the cluster:</simpara>
<programlisting language="sh" linenumbering="unnumbered">GET _cat/health

GET _cat/nodes</programlisting>
<remark> CONSOLE</remark>
<simpara>Use these APIs to check that all nodes have successfully joined the cluster.</simpara>
</listitem>
<listitem>
<simpara>
<emphasis role="strong">Wait for yellow</emphasis>
</simpara>
<simpara>As soon as each node has joined the cluster, it will start to recover any
primary shards that are stored locally.  Initially, the
<link linkend="cat-health"><literal>_cat/health</literal></link> request will report a <literal>status</literal> of <literal>red</literal>, meaning
that not all primary shards have been allocated.</simpara>
<simpara>Once each node has recovered its local shards, the <literal>status</literal> will become
<literal>yellow</literal>, meaning all primary shards have been recovered, but not all replica
shards are allocated.  This is to be expected because allocation is still
disabled.</simpara>
</listitem>
<listitem>
<simpara>
<emphasis role="strong">Reenable allocation</emphasis>
</simpara>
<simpara>Delaying the allocation of replicas until all nodes have joined the cluster
allows the master to allocate replicas to nodes which already have local shard
copies.   At this point, with all the nodes in the cluster, it is safe to
reenable shard allocation:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT _cluster/settings
{
  "persistent": {
    "cluster.routing.allocation.enable": "all"
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The cluster will now start allocating replica shards to all data nodes. At this
point it is safe to resume indexing and searching, but your cluster will
recover more quickly if you can delay indexing and searching until all shards
have recovered.</simpara>
<simpara>You can monitor progress with the <link linkend="cat-health"><literal>_cat/health</literal></link> and
<link linkend="cat-recovery"><literal>_cat/recovery</literal></link> APIs:</simpara>
<programlisting language="sh" linenumbering="unnumbered">GET _cat/health

GET _cat/recovery</programlisting>
<remark> CONSOLE</remark>
<simpara>Once the <literal>status</literal> column in the <literal>_cat/health</literal> output has reached <literal>green</literal>, all
primary and replica shards have been successfully allocated.</simpara>
</listitem>
</orderedlist>
</section>
<section id="reindex-upgrade">
<title>Reindex to upgrade<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/reindex_upgrade.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch is able to use indices created in the previous major version
only.  For instance, Elasticsearch 5.x can use indices created in
Elasticsearch 2.x, but not those created in Elasticsearch 1.x or before.</simpara>
<note><simpara>Elasticsearch 5.x nodes will fail to start in the presence of too old indices.</simpara></note>
<simpara>If you are running an Elasticsearch 2.x cluster which contains indices that
were created before 2.x, you will either need to delete those old indices or
to reindex them before upgrading to 5.x.  See <xref linkend="reindex-upgrade-inplace"/>.</simpara>
<simpara>If you are running an Elasticsearch 1.x cluster, you have two options:</simpara>
<itemizedlist>
<listitem>
<simpara>
First upgrade to Elasticsearch 2.4.x, reindex the old indices, then upgrade
  to 5.x. See <xref linkend="reindex-upgrade-inplace"/>.
</simpara>
</listitem>
<listitem>
<simpara>
Create a new 5.x cluster and use reindex-from-remote to import indices
  directly from the 1.x cluster. See <xref linkend="reindex-upgrade-remote"/>.
</simpara>
</listitem>
</itemizedlist>
<sidebar>
<title>Time-based indices and retention periods</title>
<simpara>For many use cases with time-based indices, you will not need to worry about
carrying old 1.x indices with you to 5.x.  Data in time-based indices usually
becomes less interesting as time passes. Old indices can be deleted once they
fall outside of your retention period.</simpara>
<simpara>Users in this position can continue to use 2.x until all old 1.x indices have
been deleted, then upgrade to 5.x directly.</simpara>
</sidebar>
<section id="reindex-upgrade-inplace">
<title>Reindex in place<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/reindex_upgrade.asciidoc">Edit me</ulink></title>
<simpara>The easiest way to reindex old (1.x) indices in place is to use the
<ulink url="https://github.com/elastic/elasticsearch-migration/tree/2.x">Elasticsearch
Migration Plugin</ulink>.  You will need to upgrade to Elasticsearch 2.3.x or 2.4.x
first.</simpara>
<simpara>The reindex utility provided in the migration plugin does the following:</simpara>
<itemizedlist>
<listitem>
<simpara>
Creates a new index with the Elasticsearch version appended to the old index
  name (e.g. <literal>my_index-2.4.1</literal>), copying the mappings and settings from the old
  index.  Refresh is disabled on the new index and the number of replicas is
  set to <literal>0</literal> for efficient reindexing.
</simpara>
</listitem>
<listitem>
<simpara>
Sets the old index to read only to ensure that no data is written to the
  old index.
</simpara>
</listitem>
<listitem>
<simpara>
Reindexes all documents from the old index to the new index.
</simpara>
</listitem>
<listitem>
<simpara>
Resets the <literal>refresh_interval</literal> and <literal>number_of_replicas</literal> to the values
  used in the old index, and waits for the index to become green.
</simpara>
</listitem>
<listitem>
<simpara>
Adds any aliases that existed on the old index to the new index.
</simpara>
</listitem>
<listitem>
<simpara>
Deletes the old index.
</simpara>
</listitem>
<listitem>
<simpara>
Adds an alias to the new index with the old index name, e.g. alias
  <literal>my_index</literal> points to index <literal>my_index-2.4.1</literal>.
</simpara>
</listitem>
</itemizedlist>
<simpara>At the end of this process, you will have a new 2.x index which can be used
by an Elasticsearch 5.x cluster.</simpara>
</section>
<section id="reindex-upgrade-remote">
<title>Upgrading with reindex-from-remote<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/reindex_upgrade.asciidoc">Edit me</ulink></title>
<simpara>If you are running a 1.x cluster and would like to migrate directly to 5.x
without first migrating to 2.x, you can do so using
<link linkend="reindex-from-remote">reindex-from-remote</link>.</simpara>
<warning>
<simpara>Elasticsearch includes backwards compatibility code that allows indices from
the previous major version to be upgraded to the current major version.  By
moving directly from Elasticsearch 1.x to 5.x, you will have to solve any
backwards compatibility issues yourself.</simpara>
</warning>
<simpara>You will need to set up a 5.x cluster alongside your existing 1.x cluster.
The 5.x cluster needs to have access to the REST API of the 1.x cluster.</simpara>
<simpara>For each 1.x index that you want to transfer to the 5.x cluster, you will need
to:</simpara>
<itemizedlist>
<listitem>
<simpara>
Create a new index in 5.x with the appropriate mappings and settings.  Set
  the <literal>refresh_interval</literal> to <literal>-1</literal> and set <literal>number_of_replicas</literal> to <literal>0</literal> for
  faster reindexing.
</simpara>
</listitem>
<listitem>
<simpara>
Use <link linkend="reindex-from-remote">reindex-from-remote</link> to pull documents from the
  1.x index into the new 5.x index.
</simpara>
</listitem>
<listitem>
<simpara>
If you run the reindex job in the background (with <literal>wait_for_completion</literal> set
  to <literal>false</literal>), the reindex request will return a <literal>task_id</literal> which can be used to
  monitor progress of the reindex job in the <link linkend="tasks">task API</link>:
  <literal>GET _tasks/TASK_ID</literal>.
</simpara>
</listitem>
<listitem>
<simpara>
Once reindex has completed, set the <literal>refresh_interval</literal> and
  <literal>number_of_replicas</literal> to the desired values (the defaults are <literal>30s</literal> and <literal>1</literal>
  respectively).
</simpara>
</listitem>
<listitem>
<simpara>
Once the new index has finished replication, you can delete the old index.
</simpara>
</listitem>
</itemizedlist>
<simpara>The 5.x cluster can start out small, and you can gradually move nodes from the
1.x cluster to the 5.x cluster as you migrate indices across.</simpara>
</section>
</section>
</chapter>
<chapter id="stopping-elasticsearch">
<title>Stopping Elasticsearch<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/stopping.asciidoc">Edit me</ulink></title>
<simpara>An orderly shutdown of Elasticsearch ensures that Elasticsearch has a chance to cleanup and close
outstanding resources. For example, a node that is shutdown in an orderly fashion will remove itself
from the cluster, sync translogs to disk, and perform other related cleanup activities. You can help
ensure an orderly shutdown by properly stopping Elasticsearch.</simpara>
<simpara>If you&#8217;re running Elasticsearch as a service, you can stop Elasticsearch via the service management
functionality provided by your installation.</simpara>
<simpara>If you&#8217;re running Elasticsearch directly, you can stop Elasticsearch by sending control-C if you&#8217;re
running Elasticsearch in the console, or by sending <literal>SIGTERM</literal> to the Elasticsearch process on a
POSIX system. You can obtain the PID to send the signal to via various tools (e.g., <literal>ps</literal> or <literal>jps</literal>):</simpara>
<programlisting language="sh" linenumbering="unnumbered">$ jps | grep Elasticsearch
14542 Elasticsearch</programlisting>
<simpara>From the Elasticsearch startup logs:</simpara>
<programlisting language="sh" linenumbering="unnumbered">[2016-07-07 12:26:18,908][INFO ][node                     ] [I8hydUG] version[5.0.0-alpha4], pid[15399], build[3f5b994/2016-06-27T16:23:46.861Z], OS[Mac OS X/10.11.5/x86_64], JVM[Oracle Corporation/Java HotSpot(TM) 64-Bit Server VM/1.8.0_92/25.92-b14]</programlisting>
<simpara>Or by specifying a location to write a PID file to on startup (<literal>-p &lt;path&gt;</literal>):</simpara>
<programlisting language="sh" linenumbering="unnumbered">$ ./bin/elasticsearch -p /tmp/elasticsearch-pid -d
$ cat /tmp/elasticsearch-pid &amp;&amp; echo
15516
$ kill -SIGTERM 15516</programlisting>
<bridgehead id="_stopping_on_fatal_errors" renderas="sect2">Stopping on Fatal Errors<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/setup/stopping.asciidoc">Edit me</ulink></bridgehead>
<simpara>During the life of the Elasticsearch virtual machine, certain fatal errors could arise that put the
virtual machine in a questionable state. Such fatal errors include out of memory errors, internal
errors in virtual machine, and serious I/O errors.</simpara>
<simpara>When Elasticsearch detects that the virtual machine has encountered such a fatal error Elasticsearch
will attempt to log the error and then will halt the virtual machine. When Elasticsearch initiates
such a shutdown, it does not go through an orderly shutdown as described above. The Elasticsearch
process will also return with a special status code indicating the nature of the error.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
JVM internal error
</simpara>
</entry>
<entry>
<simpara>
128
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Out of memory error
</simpara>
</entry>
<entry>
<simpara>
127
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Stack overflow error
</simpara>
</entry>
<entry>
<simpara>
126
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Unknown virtual machine error
</simpara>
</entry>
<entry>
<simpara>
125
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Serious I/O error
</simpara>
</entry>
<entry>
<simpara>
124
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Unknown fatal error
</simpara>
</entry>
<entry>
<simpara>
1
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</chapter>
</part>
<part id="breaking-changes">
<title>Breaking changes <ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/index.asciidoc">Edit me</ulink></title>
<partintro>
<simpara>This section discusses the changes that you need to be aware of when migrating
your application from one version of Elasticsearch to another.</simpara>
<simpara>As a general rule:</simpara>
<itemizedlist>
<listitem>
<simpara>
Migration between minor versions&#8201;&#8212;&#8201;e.g. <literal>5.x</literal> to <literal>5.y</literal>&#8201;&#8212;&#8201;can be
  performed by <link linkend="rolling-upgrades">upgrading one node at a time</link>.
</simpara>
</listitem>
<listitem>
<simpara>
Migration between consecutive major versions&#8201;&#8212;&#8201;e.g. <literal>2.x</literal> to <literal>5.x</literal>&#8201;&#8212;&#8201;  requires a <link linkend="restart-upgrade">full cluster restart</link>.
</simpara>
</listitem>
<listitem>
<simpara>
Migration between non-consecutive major versions&#8201;&#8212;&#8201;e.g. <literal>1.x</literal> to <literal>5.x</literal>&#8201;&#8212;&#8201;  is not supported.
</simpara>
</listitem>
</itemizedlist>
<simpara>See <xref linkend="setup-upgrade"/> for more info.</simpara>
</partintro>
<chapter id="breaking-changes-5.1">
<title>Breaking changes in 5.1<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_1.asciidoc">Edit me</ulink></title>
<bridgehead id="breaking_51_index_api_changes" renderas="sect2">Indices API changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_1.asciidoc">Edit me</ulink></bridgehead>
<bridgehead id="_alias_names_are_validated_against_most_of_the_rules_for_index_names" renderas="sect3">Alias names are validated against (most of) the rules for index names<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_1.asciidoc">Edit me</ulink></bridgehead>
<simpara>Alias names are now validated against almost the same set of rules that validate
index names. The only difference is that aliases are allowed to have uppercase
characters. That means that aliases may not:</simpara>
<itemizedlist>
<listitem>
<simpara>
Start with <literal>_</literal>, <literal>-</literal>, or <literal>+</literal>
</simpara>
</listitem>
<listitem>
<simpara>
Contain <literal>#</literal>, <literal>\</literal>, <literal>/</literal>, <literal>*</literal>, <literal>?</literal>, <literal>"</literal>, <literal>&lt;</literal>, <literal>&gt;</literal>, <literal>|</literal>, ` <literal>, `,</literal>
</simpara>
</listitem>
<listitem>
<simpara>
Be longer than 100 UTF-8 encoded bytes
</simpara>
</listitem>
<listitem>
<simpara>
Be exactly <literal>.</literal> or <literal>..</literal>
</simpara>
</listitem>
</itemizedlist>
<simpara>Aliases created in versions before 5.1.0 are still supported but no new aliases
can be added that violate those rules. Since modifying an alias in elasticsearch
is removing it and recreating it atomically using the <literal>_aliases</literal> API, modifying
aliases with invalid names is also no longer supported.</simpara>
<bridgehead id="breaking_51_java_api_changes" renderas="sect2">Java API changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_1.asciidoc">Edit me</ulink></bridgehead>
<bridgehead id="_log4j_dependency_has_been_upgraded" renderas="sect3">Log4j dependency has been upgraded<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_1.asciidoc">Edit me</ulink></bridgehead>
<simpara>The Log4j dependency has been upgraded from version 2.6.2 to version 2.7. If you&#8217;re using the transport client in your
application, you should update your Log4j dependencies accordingly.</simpara>
<bridgehead id="breaking_51_plugin_api" renderas="sect2">Plugin API changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_1.asciidoc">Edit me</ulink></bridgehead>
<bridgehead id="_unicasthostsprovider_now_pull_based" renderas="sect3">UnicastHostsProvider now pull based<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_1.asciidoc">Edit me</ulink></bridgehead>
<simpara>Plugging in a <literal>UnicastHostsProvider</literal> for zen discovery is now pull based. Implement a <literal>DiscoveryPlugin</literal> and override the <literal>getZenHostsProviders</literal> method. Selecting a hosts provider is also now done with a separate setting, <literal>discovery.zen.hosts_provider</literal>.</simpara>
<bridgehead id="_zenping_and_masterelectservice_pluggability_removed" renderas="sect3">ZenPing and MasterElectService pluggability removed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_1.asciidoc">Edit me</ulink></bridgehead>
<simpara>These classes are no longer pluggable. Either implement your own discovery, or extend from ZenDiscovery and customize as necessary.</simpara>
<bridgehead id="_onmodule_support_removed" renderas="sect3">onModule support removed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_1.asciidoc">Edit me</ulink></bridgehead>
<simpara>Plugins could formerly implement methods of the name <literal>onModule</literal> which took a single
Guice module. All the uses of onModule for plugging in custom behavior have now been
converted to pull based plugins, and hooks for onModule have been removed.</simpara>
<bridgehead id="breaking_51_other_api_changes" renderas="sect2">Other API changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_1.asciidoc">Edit me</ulink></bridgehead>
<bridgehead id="_indices_stats_and_node_stats_api_unrecognized_metrics" renderas="sect3">Indices stats and node stats API unrecognized metrics<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_1.asciidoc">Edit me</ulink></bridgehead>
<simpara>The indices stats and node stats APIs allow querying Elasticsearch for a variety of metrics. Previous versions of
Elasticsearch would silently accept unrecognized metrics (e.g., typos like "transprot"). In 5.1.0, this is no longer
the case; unrecognized metrics will cause the request to fail. There is one exception to this which is the percolate
metric which was removed in 5.0.0 but requests for these will only produce a warning in the 5.x series starting with
5.1.0 and will fail like any other unrecognized metric in 6.0.0.</simpara>
</chapter>
<chapter id="breaking-changes-5.0">
<title>Breaking changes in 5.0<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0.asciidoc">Edit me</ulink></title>
<simpara>This section discusses the changes that you need to be aware of when migrating
your application to Elasticsearch 5.0.</simpara>
<bridgehead id="migration-plugin" renderas="sect2">Migration Plugin<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <ulink url="https://github.com/elastic/elasticsearch-migration/blob/2.x/README.asciidoc"><literal>elasticsearch-migration</literal> plugin</ulink>
(compatible with Elasticsearch 2.3.0 and above) will help you to find issues
that need to be addressed when upgrading to Elasticsearch 5.0.</simpara>
<bridgehead id="_indices_created_before_5_0" renderas="sect2">Indices created before 5.0<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0.asciidoc">Edit me</ulink></bridgehead>
<simpara>Elasticsearch 5.0 can read indices created in version 2.0 or above.  An
Elasticsearch 5.0 node will not start in the presence of indices created in a
version of Elasticsearch before 2.0.</simpara>
<important>
<title>Reindex indices from Elasticseach 1.x or before</title>
<simpara>Indices created in Elasticsearch 1.x or before will need to be reindexed with
Elasticsearch 2.x in order to be readable by Elasticsearch 5.x. It is not
sufficient to use the <literal>upgrade</literal> API.  See <xref linkend="reindex-upgrade"/> for more details.</simpara>
</important>
<simpara>The first time Elasticsearch 5.0 starts, it will automatically rename index
folders to use the index UUID instead of the index name. If you are using
<link linkend="indices-shadow-replicas">shadow replicas</link> with shared data folders, first
start a single node with access to all data folders, and let it rename all
index folders before starting other nodes in the cluster.</simpara>
<bridgehead id="_also_see" renderas="sect2">Also see:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0.asciidoc">Edit me</ulink></bridgehead>
<itemizedlist>
<listitem>
<simpara>
<xref linkend="breaking_50_search_changes"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="breaking_50_mapping_changes"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="breaking_50_percolator"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="breaking_50_suggester"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="breaking_50_index_apis"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="breaking_50_document_api_changes"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="breaking_50_settings_changes"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="breaking_50_allocation"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="breaking_50_http_changes"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="breaking_50_rest_api_changes"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="breaking_50_cat_api"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="breaking_50_java_api_changes"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="breaking_50_packaging"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="breaking_50_plugins"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="breaking_50_fs"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="breaking_50_aggregations_changes"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="breaking_50_scripting"/>
</simpara>
</listitem>
</itemizedlist>
<section id="breaking_50_search_changes">
<title>Search and Query DSL changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/search.asciidoc">Edit me</ulink></title>
<section id="_literal_search_type_literal">
<title><literal>search_type</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/search.asciidoc">Edit me</ulink></title>
<section id="_literal_search_type_count_literal_removed">
<title><literal>search_type=count</literal> removed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/search.asciidoc">Edit me</ulink></title>
<simpara>The <literal>count</literal> search type was deprecated since version 2.0.0 and is now removed.
In order to get the same benefits, you just need to set the value of the <literal>size</literal>
parameter to <literal>0</literal>.</simpara>
<simpara>For instance, the following request:</simpara>
<programlisting language="sh" linenumbering="unnumbered">GET /my_index/_search?search_type=count
{
  "aggs": {
    "my_terms": {
       "terms": {
         "field": "foo"
       }
     }
  }
}</programlisting>
<simpara>can be replaced with:</simpara>
<programlisting language="sh" linenumbering="unnumbered">GET /my_index/_search
{
  "size": 0,
  "aggs": {
    "my_terms": {
       "terms": {
         "field": "foo"
       }
     }
  }
}</programlisting>
</section>
<section id="_literal_search_type_scan_literal_removed">
<title><literal>search_type=scan</literal> removed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/search.asciidoc">Edit me</ulink></title>
<simpara>The <literal>scan</literal> search type was deprecated since version 2.1.0 and is now removed.
All benefits from this search type can now be achieved by doing a scroll
request that sorts documents in <literal>_doc</literal> order, for instance:</simpara>
<programlisting language="sh" linenumbering="unnumbered">GET /my_index/_search?scroll=2m
{
  "sort": [
    "_doc"
  ]
}</programlisting>
<simpara>Scroll requests sorted by <literal>_doc</literal> have been optimized to more efficiently resume
from where the previous request stopped, so this will have the same performance
characteristics as the former <literal>scan</literal> search type.</simpara>
</section>
</section>
<section id="_search_shard_limit">
<title>Search shard limit<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/search.asciidoc">Edit me</ulink></title>
<simpara>In 5.0, Elasticsearch rejects requests that would query more than 1000 shard
copies (primaries or replicas).  The reason is that such large numbers of
shards make the job of the coordinating node very CPU and memory intensive. It
is usually a better idea to organize data in such a way that there are fewer
larger shards. In case you would like to bypass this limit, which is
discouraged, you can update the <literal>action.search.shard_count.limit</literal> cluster
setting to a greater value.</simpara>
</section>
<section id="_literal_fields_literal_parameter">
<title><literal>fields</literal> parameter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/search.asciidoc">Edit me</ulink></title>
<simpara>The <literal>fields</literal> parameter has been replaced by <literal>stored_fields</literal>.
The <literal>stored_fields</literal> parameter will only return stored fields&#8201;&#8212;&#8201;it will no longer extract values from the <literal>_source</literal>.</simpara>
</section>
<section id="_literal_fielddata_fields_literal_parameter">
<title><literal>fielddata_fields</literal> parameter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/search.asciidoc">Edit me</ulink></title>
<simpara>The <literal>fielddata_fields</literal> has been deprecated, use parameter <literal>docvalue_fields</literal> instead.</simpara>
</section>
<section id="_search_exists_api_removed">
<title>search-exists API removed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/search.asciidoc">Edit me</ulink></title>
<simpara>The search exists api has been removed in favour of using the search api with
<literal>size</literal> set to <literal>0</literal> and <literal>terminate_after</literal> set to <literal>1</literal>.</simpara>
</section>
<section id="_deprecated_queries_removed">
<title>Deprecated queries removed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/search.asciidoc">Edit me</ulink></title>
<simpara>The following deprecated queries have been removed:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>filtered</literal>
</term>
<listitem>
<simpara>
Use <literal>bool</literal> query instead, which supports <literal>filter</literal> clauses too.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>and</literal>
</term>
<listitem>
<simpara>
Use <literal>must</literal> clauses in a <literal>bool</literal> query instead.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>or</literal>
</term>
<listitem>
<simpara>
Use <literal>should</literal> clauses in a <literal>bool</literal> query instead.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>missing</literal>
</term>
<listitem>
<simpara>
Use a negated <literal>exists</literal> query instead.  (Also removed <literal>_missing_</literal> from the <literal>query_string</literal> query)
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>limit</literal>
</term>
<listitem>
<simpara>
Use the <literal>terminate_after</literal> parameter instead.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fquery</literal>
</term>
<listitem>
<simpara>
Is obsolete after filters and queries have been merged.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>query</literal>
</term>
<listitem>
<simpara>
Is obsolete after filters and queries have been merged.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>query_binary</literal>
</term>
<listitem>
<simpara>
Was undocumented and has been removed.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>filter_binary</literal>
</term>
<listitem>
<simpara>
Was undocumented and has been removed.
</simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
<section id="_changes_to_queries">
<title>Changes to queries<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/search.asciidoc">Edit me</ulink></title>
<itemizedlist>
<listitem>
<simpara>
Unsupported queries such as term queries on <literal>geo_point</literal> fields will now fail
  rather than returning no hits.
</simpara>
</listitem>
<listitem>
<simpara>
Removed support for fuzzy queries on numeric, date and ip fields, use range
  queries instead.
</simpara>
</listitem>
<listitem>
<simpara>
Removed support for range and prefix queries on <literal>_uid</literal> and <literal>_id</literal> fields.
</simpara>
</listitem>
<listitem>
<simpara>
Querying an unindexed field will now fail rather than returning no hits.
</simpara>
</listitem>
<listitem>
<simpara>
Removed support for the deprecated <literal>min_similarity</literal> parameter in <literal>fuzzy
  query</literal>, in favour of <literal>fuzziness</literal>.
</simpara>
</listitem>
<listitem>
<simpara>
Removed support for the deprecated <literal>fuzzy_min_sim</literal> parameter in
  <literal>query_string</literal> query, in favour of <literal>fuzziness</literal>.
</simpara>
</listitem>
<listitem>
<simpara>
Removed support for the deprecated <literal>edit_distance</literal> parameter in completion
  suggester, in favour of <literal>fuzziness</literal>.
</simpara>
</listitem>
<listitem>
<simpara>
Removed support for the deprecated <literal>filter</literal> and <literal>no_match_filter</literal> fields in <literal>indices</literal> query,
in favour of <literal>query</literal> and <literal>no_match_query</literal>.
</simpara>
</listitem>
<listitem>
<simpara>
Removed support for the deprecated <literal>filter</literal> fields in <literal>nested</literal> query, in favour of <literal>query</literal>.
</simpara>
</listitem>
<listitem>
<simpara>
Removed support for the deprecated <literal>minimum_should_match</literal> and
  <literal>disable_coord</literal> in <literal>terms</literal> query, use <literal>bool</literal> query instead. Also removed
  support for the deprecated <literal>execution</literal> parameter.
</simpara>
</listitem>
<listitem>
<simpara>
Removed support for the top level <literal>filter</literal> element in <literal>function_score</literal> query, replaced by <literal>query</literal>.
</simpara>
</listitem>
<listitem>
<simpara>
The <literal>collect_payloads</literal> parameter of the <literal>span_near</literal> query has been deprecated.  Payloads will be loaded when needed.
</simpara>
</listitem>
<listitem>
<simpara>
The <literal>score_type</literal> parameter to the <literal>nested</literal> and <literal>has_child</literal> queries has been
  removed in favour of <literal>score_mode</literal>.  The <literal>score_mode</literal> parameter to <literal>has_parent</literal>
  has been deprecated in favour of the <literal>score</literal> boolean parameter.   Also, the
  <literal>total</literal> score mode has been removed in favour of the <literal>sum</literal> mode.
</simpara>
</listitem>
<listitem>
<simpara>
When the <literal>max_children</literal> parameter was set to <literal>0</literal> on the <literal>has_child</literal> query
  then there was no upper limit on how many child documents were allowed to
  match. Now, <literal>0</literal> really means that zero child documents are allowed. If no
  upper limit is needed then the <literal>max_children</literal> parameter shouldn&#8217;t be specified
  at all.
</simpara>
</listitem>
<listitem>
<simpara>
The <literal>exists</literal> query will now fail if the <literal>_field_names</literal> field is disabled.
</simpara>
</listitem>
<listitem>
<simpara>
The <literal>multi_match</literal> query will fail if <literal>fuzziness</literal> is used for <literal>cross_fields</literal>, <literal>phrase</literal> or <literal>phrase_prefix</literal> type.
This parameter was undocumented and silently ignored before for these types of <literal>multi_match</literal>.
</simpara>
</listitem>
<listitem>
<simpara>
Deprecated support for the coerce, normalize, ignore_malformed parameters in GeoPolygonQuery. Use parameter validation_method instead.
</simpara>
</listitem>
<listitem>
<simpara>
Deprecated support for the coerce, normalize, ignore_malformed parameters in GeoDistanceQuery. Use parameter validation_method instead.
</simpara>
</listitem>
<listitem>
<simpara>
Deprecated support for the coerce, normalize, ignore_malformed parameters in GeoBoundingBoxQuery. Use parameter validation_method instead.
</simpara>
</listitem>
<listitem>
<simpara>
The <literal>geo_distance_range</literal> query is no longer supported and should be replaced by the <literal>geo_distance</literal> bucket aggregation.
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_top_level_literal_filter_literal_parameter">
<title>Top level <literal>filter</literal> parameter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/search.asciidoc">Edit me</ulink></title>
<simpara>Removed support for the deprecated top level <literal>filter</literal> in the search api,
replaced by <literal>post_filter</literal>.</simpara>
</section>
<section id="_highlighters">
<title>Highlighters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/search.asciidoc">Edit me</ulink></title>
<simpara>Removed support for multiple highlighter names, the only supported ones are:
<literal>plain</literal>, <literal>fvh</literal> and <literal>postings</literal>.</simpara>
</section>
<section id="_term_vectors_api">
<title>Term vectors API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/search.asciidoc">Edit me</ulink></title>
<simpara>The term vectors APIs no longer persist unmapped fields in the mappings.</simpara>
<simpara>The <literal>dfs</literal> parameter to the term vectors API has been removed completely. Term
vectors don&#8217;t support distributed document frequencies anymore.</simpara>
</section>
<section id="_sort">
<title>Sort<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/search.asciidoc">Edit me</ulink></title>
<simpara>The <literal>reverse</literal> parameter has been removed, in favour of explicitly
specifying the sort order with the <literal>order</literal> option.</simpara>
<simpara>The <literal>coerce</literal> and <literal>ignore_malformed</literal> parameters were deprecated in favour of <literal>validation_method</literal>.</simpara>
</section>
<section id="_inner_hits">
<title>Inner hits<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/search.asciidoc">Edit me</ulink></title>
<itemizedlist>
<listitem>
<simpara>
Top level inner hits syntax has been removed. Inner hits can now only be specified as part of the <literal>nested</literal>,
<literal>has_child</literal> and <literal>has_parent</literal> queries. Use cases previously only possible with top level inner hits can now be done
with inner hits defined inside the query dsl.
</simpara>
</listitem>
<listitem>
<simpara>
Source filtering for inner hits inside nested queries requires full field names instead of relative field names.
This is now consistent for source filtering on other places in the search API.
</simpara>
</listitem>
<listitem>
<simpara>
Nested inner hits will now no longer include <literal>_index</literal>, <literal>_type</literal> and <literal>_id</literal> keys. For nested inner hits these values
are always the same as the <literal>_index</literal>, <literal>_type</literal> and <literal>_id</literal> keys of the root search hit.
</simpara>
</listitem>
<listitem>
<simpara>
Parent/child inner hits will now no longer include the <literal>_index</literal> key. For parent/child inner hits the <literal>_index</literal> key is
always the same as the the parent search hit.
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_query_profiler">
<title>Query Profiler<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/search.asciidoc">Edit me</ulink></title>
<simpara>In the response for profiling queries, the <literal>query_type</literal> has been renamed to <literal>type</literal> and <literal>lucene</literal> has been renamed to
<literal>description</literal>. These changes have been made so the response format is more friendly to supporting other types of profiling
in the future.</simpara>
</section>
<section id="_search_preferences">
<title>Search preferences<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/search.asciidoc">Edit me</ulink></title>
<simpara>The <link linkend="search-request-preference">search preference</link> <literal>_only_node</literal> has
been removed. The same behavior can be achieved by using <literal>_only_nodes</literal>
and specifying a single node ID.</simpara>
<simpara>The <link linkend="search-request-preference">search preference</link> <literal>_prefer_node</literal> has
been superseded by <literal>_prefer_nodes</literal>. By specifying a single node,
<literal>_prefer_nodes</literal> provides the same functionality as <literal>_prefer_node</literal> but
also supports specifying multiple nodes.</simpara>
<simpara>The <link linkend="search-request-preference">search preference</link> <literal>_shards</literal> accepts a
secondary preference, for example <literal>_primary</literal> to specify the primary copy
of the specified shards. The separator previously used to separate the
<literal>_shards</literal> portion of the parameter from the secondary preference was
<literal>;</literal>. However, this is also an acceptable separator between query string
parameters which means that unless the <literal>;</literal> was escaped, the secondary
preference was never observed. The separator has been changed to <literal>|</literal> and
does not need to be escaped.</simpara>
</section>
<section id="_default_similarity">
<title>Default similarity<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/search.asciidoc">Edit me</ulink></title>
<simpara>The default similarity has been changed to <literal>BM25</literal>.</simpara>
</section>
<section id="_explain_api">
<title>explain API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/search.asciidoc">Edit me</ulink></title>
<simpara>The <literal>fields</literal> field has been renamed to <literal>stored_fields</literal></simpara>
</section>
</section>
<section id="breaking_50_mapping_changes">
<title>Mapping changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/mapping.asciidoc">Edit me</ulink></title>
<section id="_literal_string_literal_fields_replaced_by_literal_text_literal_literal_keyword_literal_fields">
<title><literal>string</literal> fields replaced by <literal>text</literal>/<literal>keyword</literal> fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/mapping.asciidoc">Edit me</ulink></title>
<simpara>The <literal>string</literal> field datatype has been replaced by the <literal>text</literal> field for full
text analyzed content, and the <literal>keyword</literal> field for not-analyzed exact string
values.  For backwards compatibility purposes, during the 5.x series:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>string</literal> fields on pre-5.0 indices will function as before.
</simpara>
</listitem>
<listitem>
<simpara>
New <literal>string</literal> fields can be added to pre-5.0 indices as before.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>text</literal> and <literal>keyword</literal> fields can also be added to pre-5.0 indices.
</simpara>
</listitem>
<listitem>
<simpara>
When adding a <literal>string</literal> field to a new index, the field mapping will be
  rewritten as a <literal>text</literal> or <literal>keyword</literal> field if possible, otherwise
  an exception will be thrown.  Certain configurations that were possible
  with <literal>string</literal> fields are no longer possible with <literal>text</literal>/<literal>keyword</literal> fields
  such as enabling <literal>term_vectors</literal> on a not-analyzed <literal>keyword</literal> field.
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_default_string_mappings">
<title>Default string mappings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/mapping.asciidoc">Edit me</ulink></title>
<simpara>String mappings now have the following default mappings:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "type": "text",
  "fields": {
    "keyword": {
      "type": "keyword",
      "ignore_above": 256
    }
  }
}</programlisting>
<simpara>This allows to perform full-text search on the original field name and to sort
and run aggregations on the sub keyword field.</simpara>
</section>
<section id="_numeric_fields">
<title>Numeric fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/mapping.asciidoc">Edit me</ulink></title>
<simpara>Numeric fields are now indexed with a completely different data-structure, called
BKD tree, that is expected to require less disk space and be faster for range
queries than the previous way that numerics were indexed.</simpara>
<simpara>Term queries will return constant scores now, while they used to return higher
scores for rare terms due to the contribution of the document frequency, which
this new BKD structure does not record. If scoring is needed, then it is advised
to map the numeric fields as <link linkend="keyword">`keyword`s</link> too.</simpara>
<simpara>Note that this <link linkend="keyword"><literal>keyword</literal></link> mapping do not need to replace the numeric
mapping. For instance if you need both sorting and scoring on your numeric field,
you could map it both as a number and a <literal>keyword</literal> using <xref linkend="multi-fields"/>:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "my_number": {
          "type": "long",
          "fields": {
            "keyword": {
              "type":  "keyword"
            }
          }
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Also the <literal>precision_step</literal> parameter is now irrelevant and will be rejected on
indices that are created on or after 5.0.</simpara>
</section>
<section id="_literal_geo_point_literal_fields">
<title><literal>geo_point</literal> fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/mapping.asciidoc">Edit me</ulink></title>
<simpara>Like Numeric fields the Geo point field now uses the new BKD tree structure. Since
this structure is fundamentally designed for multi-dimension spatial data, the
following field parameters are no longer needed or supported: <literal>geohash</literal>,
<literal>geohash_prefix</literal>, <literal>geohash_precision</literal>, <literal>lat_lon</literal>. Geohashes are still supported from
an API perspective, and can still be accessed using the <literal>.geohash</literal> field extension,
but they are no longer used to index geo point data.</simpara>
</section>
<section id="_literal__timestamp_literal_and_literal__ttl_literal">
<title><literal>_timestamp</literal> and <literal>_ttl</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/mapping.asciidoc">Edit me</ulink></title>
<simpara>The <literal>_timestamp</literal> and <literal>_ttl</literal> fields were deprecated and are now removed. As a
replacement for <literal>_timestamp</literal>, you should populate a regular date field with the
current timestamp on application side. For <literal>_ttl</literal>, you should either use
time-based indices when applicable, or cron a delete-by-query with a range
query on a timestamp field</simpara>
</section>
<section id="_literal_index_literal_property">
<title><literal>index</literal> property<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/mapping.asciidoc">Edit me</ulink></title>
<simpara>On all field datatypes (except for the deprecated <literal>string</literal> field), the <literal>index</literal>
property now only accepts <literal>true</literal>/<literal>false</literal> instead of <literal>not_analyzed</literal>/<literal>no</literal>. The
<literal>string</literal> field still accepts <literal>analyzed</literal>/<literal>not_analyzed</literal>/<literal>no</literal>.</simpara>
</section>
<section id="_doc_values_on_unindexed_fields">
<title>Doc values on unindexed fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/mapping.asciidoc">Edit me</ulink></title>
<simpara>Previously, setting a field to <literal>index:no</literal> would also disable doc-values.  Now,
doc-values are enabled by default on all types but <literal>text</literal> and <literal>binary</literal>,
regardless of the value of the <literal>index</literal> property.</simpara>
</section>
<section id="_floating_points_use_literal_float_literal_instead_of_literal_double_literal">
<title>Floating points use <literal>float</literal> instead of <literal>double</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/mapping.asciidoc">Edit me</ulink></title>
<simpara>When dynamically mapping a field containing a floating point number, the field
now defaults to using <literal>float</literal> instead of <literal>double</literal>. The reasoning is that
floats should be more than enough for most cases but would decrease storage
requirements significantly.</simpara>
</section>
<section id="_literal_norms_literal">
<title><literal>norms</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/mapping.asciidoc">Edit me</ulink></title>
<simpara><literal>norms</literal> now take a boolean instead of an object. This boolean is the replacement
for <literal>norms.enabled</literal>. There is no replacement for <literal>norms.loading</literal> since eager
loading of norms is not useful anymore now that norms are disk-based.</simpara>
</section>
<section id="_literal_fielddata_format_literal">
<title><literal>fielddata.format</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/mapping.asciidoc">Edit me</ulink></title>
<simpara>Setting <literal>fielddata.format: doc_values</literal> in the mappings used to implicitly
enable doc-values on a field. This no longer works: the only way to enable or
disable doc-values is by using the <literal>doc_values</literal> property of mappings.</simpara>
</section>
<section id="_literal_fielddata_filter_regex_literal">
<title><literal>fielddata.filter.regex</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/mapping.asciidoc">Edit me</ulink></title>
<simpara>Regex filters are not supported anymore and will be dropped on upgrade.</simpara>
</section>
<section id="_source_transform_removed">
<title>Source-transform removed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/mapping.asciidoc">Edit me</ulink></title>
<simpara>The source <literal>transform</literal> feature has been removed. Instead, use an ingest pipeline.</simpara>
</section>
<section id="_field_mapping_limits">
<title>Field mapping limits<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/mapping.asciidoc">Edit me</ulink></title>
<simpara>To prevent mapping explosions, the following limits are applied to indices
created in 5.x:</simpara>
<itemizedlist>
<listitem>
<simpara>
The maximum number of fields in an index is limited to 1000.
</simpara>
</listitem>
<listitem>
<simpara>
The maximum depth for a field (1 plus the number of <literal>object</literal> or <literal>nested</literal> parents) is limited to 20.
</simpara>
</listitem>
<listitem>
<simpara>
The maximum number of <literal>nested</literal> fields in an index is limited to 50.
</simpara>
</listitem>
</itemizedlist>
<simpara>See <xref linkend="mapping-limit-settings"/> for more.</simpara>
</section>
<section id="_literal__parent_literal_field_no_longer_indexed">
<title><literal>_parent</literal> field no longer indexed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/mapping.asciidoc">Edit me</ulink></title>
<simpara>The join between parent and child documents no longer relies on indexed fields
and therefore from 5.0.0 onwards the <literal>_parent</literal> field is no longer indexed. In
order to find documents that refer to a specific parent id, the new
<literal>parent_id</literal> query can be used. The GET response and hits inside the search
response still include the parent id under the <literal>_parent</literal> key.</simpara>
</section>
<section id="_source_literal_format_literal_option">
<title>Source <literal>format</literal> option<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/mapping.asciidoc">Edit me</ulink></title>
<simpara>The <literal>_source</literal> mapping no longer supports the <literal>format</literal> option. It will still be
accepted for indices created before the upgrade to 5.0 for backwards
compatibility, but it will have no effect. Indices created on or after 5.0
will reject this option.</simpara>
</section>
<section id="_object_notation">
<title>Object notation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/mapping.asciidoc">Edit me</ulink></title>
<simpara>Core types no longer support the object notation, which was used to provide
per document boosts as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "value": "field_value",
  "boost": 42
}</programlisting>
</section>
<section id="_boost_accuracy_for_queries_on_literal__all_literal">
<title>Boost accuracy for queries on <literal>_all</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/mapping.asciidoc">Edit me</ulink></title>
<simpara>Per-field boosts on the <literal>_all</literal> are now compressed into a single byte instead
of the 4 bytes used previously. While this will make the index much more
space-efficient, it also means that index time boosts will be less accurately
encoded.</simpara>
</section>
<section id="_literal__ttl_literal_and_literal__timestamp_literal_cannot_be_created">
<title><literal>_ttl</literal> and <literal>_timestamp</literal> cannot be created<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/mapping.asciidoc">Edit me</ulink></title>
<simpara>You can no longer create indexes with <literal>_ttl</literal> or <literal>_timestamp</literal> enabled. Indexes
with them enabled created before 5.0 will continue to work.</simpara>
<simpara>You should replace <literal>_timestamp</literal> in new indexes by adding a field to your source
either in the application producing the data or with an ingest pipline like
this one:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT _ingest/pipeline/timestamp
{
  "description" : "Adds a timestamp field at the current time",
  "processors" : [ {
    "set" : {
      "field": "timestamp",
      "value": "{{_ingest.timestamp}}"
    }
  } ]
}

PUT newindex/type/1?pipeline=timestamp
{
  "example": "data"
}

GET newindex/type/1</programlisting>
<remark> CONSOLE</remark>
<simpara>Which produces</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "_source": {
    "example": "data",
    "timestamp": "2016-06-21T18:48:55.560+0000"
  },
  ...
}</programlisting>
<remark> TESTRESPONSE[s/\.\.\./"found": true, "_id": "1", "_index": "newindex", "_type": "type", "_version": 1/]</remark>
<remark> TESTRESPONSE[s/"2016-06-21T18:48:55.560\+0000"/"$body._source.timestamp"/]</remark>
<simpara>If you have an old index created with 2.x that has <literal>_timestamp</literal> enabled then
you can migrate it to a new index with the a <literal>timestamp</literal> field in the source
with reindex:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _reindex
{
  "source": {
    "index": "oldindex"
  },
  "dest": {
    "index": "newindex"
  },
  "script": {
    "lang": "painless",
    "inline": "ctx._source.timestamp = ctx._timestamp; ctx._timestamp = null"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT oldindex\n/]</remark>
<simpara>You can replace <literal>_ttl</literal> with time based index names (preferred) or by adding a
cron job which runs a delete-by-query on a timestamp field in the source
document. If you had documents like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST index/type/_bulk
{"index":{"_id":1}}
{"example": "data", "timestamp": "2016-06-21T18:48:55.560+0000" }
{"index":{"_id":2}}
{"example": "data", "timestamp": "2016-04-21T18:48:55.560+0000" }</programlisting>
<remark> CONSOLE</remark>
<simpara>Then you could delete all of the documents from before June 1st with:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST index/type/_delete_by_query
{
  "query": {
    "range" : {
      "timestamp" : {
        "lt" : "2016-05-01"
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<important><simpara>Keep in mind that deleting documents from an index is very expensive
compared to deleting whole indexes. That is why time based indexes are
recommended over this sort of thing and why <literal>_ttl</literal> was deprecated in the first
place.</simpara></important>
</section>
<section id="_blank_field_names_is_not_supported">
<title>Blank field names is not supported<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/mapping.asciidoc">Edit me</ulink></title>
<simpara>Blank field names in mappings is not allowed after 5.0.</simpara>
</section>
</section>
<section id="breaking_50_percolator">
<title>Percolator changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/percolator.asciidoc">Edit me</ulink></title>
<section id="_percolator_is_near_real_time">
<title>Percolator is near-real time<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/percolator.asciidoc">Edit me</ulink></title>
<simpara>Previously percolators were activated in real-time, i.e. as soon as they were
indexed.  Now, changes to the <literal>percolate</literal> query are visible in near-real time,
as soon as the index has been refreshed. This change was required because, in
indices created from 5.0 onwards, the terms used in a percolator query are
automatically indexed to allow for more efficient query selection during
percolation.</simpara>
</section>
<section id="_percolate_and_multi_percolator_apis">
<title>Percolate and multi percolator APIs<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/percolator.asciidoc">Edit me</ulink></title>
<simpara>Percolator and multi percolate APIs have been deprecated and will be removed in the next major release. These APIs have
been replaced by the <literal>percolate</literal> query that can be used in the search and multi search APIs.</simpara>
</section>
<section id="_percolator_field_mapping">
<title>Percolator field mapping<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/percolator.asciidoc">Edit me</ulink></title>
<simpara>The <literal>.percolator</literal> type can no longer be used to index percolator queries.</simpara>
<simpara>Instead a <link linkend="percolator">percolator field type</link> must be configured prior to indexing percolator queries.</simpara>
<simpara>Indices with a <literal>.percolator</literal> type created on a version before 5.0.0 can still be used,
but new indices no longer accept the <literal>.percolator</literal> type.</simpara>
<simpara>However it is strongly recommended to reindex any indices containing percolator queries created prior
upgrading to Elasticsearch 5. By doing this the <literal>percolate</literal> query utilize the extracted terms the <literal>percolator</literal>
field type extracted from the percolator queries and potentially execute many times faster.</simpara>
</section>
<section id="_percolate_document_mapping">
<title>Percolate document mapping<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/percolator.asciidoc">Edit me</ulink></title>
<simpara>The <literal>percolate</literal> query no longer modifies the mappings. Before the percolate API
could be used to dynamically introduce new fields to the mappings based on the
fields in the document being percolated. This no longer works, because these
unmapped fields are not persisted in the mapping.</simpara>
</section>
<section id="_percolator_documents_returned_by_search">
<title>Percolator documents returned by search<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/percolator.asciidoc">Edit me</ulink></title>
<simpara>Documents with the <literal>.percolate</literal> type were previously excluded from the search
response, unless the <literal>.percolate</literal> type was specified explicitly in the search
request.  Now, percolator documents are treated in the same way as any other
document and are returned by search requests.</simpara>
</section>
<section id="_percolating_existing_document">
<title>Percolating existing document<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/percolator.asciidoc">Edit me</ulink></title>
<simpara>When percolating an existing document then also specifying a document as source in the
<literal>percolate</literal> query is not allowed any more. Before the percolate API allowed and ignored
the existing document.</simpara>
</section>
<section id="_percolate_stats">
<title>Percolate Stats<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/percolator.asciidoc">Edit me</ulink></title>
<simpara>The percolate stats have been removed. This is because the percolator no longer caches the percolator queries.</simpara>
</section>
<section id="_percolator_queries_containing_range_queries_with_now_ranges">
<title>Percolator queries containing range queries with now ranges<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/percolator.asciidoc">Edit me</ulink></title>
<simpara>The percolator no longer accepts percolator queries containing <literal>range</literal> queries with ranges that are based on current
time (using <literal>now</literal>).</simpara>
</section>
<section id="_percolator_queries_containing_scripts">
<title>Percolator queries containing scripts.<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/percolator.asciidoc">Edit me</ulink></title>
<simpara>Percolator queries that contain scripts (For example: <literal>script</literal> query or a <literal>function_score</literal> query script function) that
have no explicit language specified will use the Painless scripting language from version 5.0 and up.</simpara>
<simpara>Scripts with no explicit language set in percolator queries stored in indices created prior to version 5.0
will use the language that has been configured in the <literal>script.legacy.default_lang</literal> setting. This setting defaults to
the Groovy scripting language, which was the default for versions prior to 5.0. If your default scripting language was
different then set the <literal>script.legacy.default_lang</literal> setting to the language you used before.</simpara>
<simpara>In order to make use of the new <literal>percolator</literal> field type all percolator queries should be reindexed into a new index.
When reindexing percolator queries with scripts that have no explicit language defined into a new index, one of the
following two things should be done in order to make the scripts work:
* (Recommended approach) While reindexing the percolator documents, migrate the scripts to the Painless scripting language.
* or add <literal>lang</literal> parameter on the script and set it the language these scripts were written in.</simpara>
</section>
<section id="_java_client">
<title>Java client<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/percolator.asciidoc">Edit me</ulink></title>
<simpara>The percolator is no longer part of the core elasticsearch dependency. It has moved to the percolator module.
Therefor when using the percolator feature from the Java client the new percolator module should also be on the
classpath. Also the transport client should load the percolator module as plugin:</simpara>
<programlisting language="java" linenumbering="unnumbered">TransportClient transportClient = TransportClient.builder()
        .settings(Settings.builder().put("node.name", "node"))
        .addPlugin(PercolatorPlugin.class)
        .build();
transportClient.addTransportAddress(
        new InetSocketTransportAddress(new InetSocketAddress(InetAddresses.forString("127.0.0.1"), 9300))
);</programlisting>
<simpara>The percolator and multi percolate related methods from the <literal>Client</literal> interface have been removed. These APIs have been
deprecated and it is recommended to use the <literal>percolate</literal> query in either the search or multi search APIs. However the
percolate and multi percolate APIs can still be used from the Java client.</simpara>
<simpara>Using percolate request:</simpara>
<programlisting language="java" linenumbering="unnumbered">PercolateRequest request = new PercolateRequest();
// set stuff and then execute:
PercolateResponse response = transportClient.execute(PercolateAction.INSTANCE, request).actionGet();</programlisting>
<simpara>Using percolate request builder:</simpara>
<programlisting language="java" linenumbering="unnumbered">PercolateRequestBuilder builder = new PercolateRequestBuilder(transportClient, PercolateAction.INSTANCE);
// set stuff and then execute:
PercolateResponse response = builder.get();</programlisting>
<simpara>Using multi percolate request:</simpara>
<programlisting language="java" linenumbering="unnumbered">MultiPercolateRequest request = new MultiPercolateRequest();
// set stuff and then execute:
MultiPercolateResponse response = transportClient.execute(MultiPercolateAction.INSTANCE, request).get();</programlisting>
<simpara>Using multi percolate request builder:</simpara>
<programlisting language="java" linenumbering="unnumbered">MultiPercolateRequestBuilder builder = new MultiPercolateRequestBuilder(transportClient, MultiPercolateAction.INSTANCE);
// set stuff and then execute:
MultiPercolateResponse response = builder.get();</programlisting>
</section>
</section>
<section id="breaking_50_suggester">
<title>Suggester changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/suggest.asciidoc">Edit me</ulink></title>
<simpara>The completion suggester has undergone a complete rewrite. This means that the
syntax and data structure for fields of type <literal>completion</literal> have changed, as
have the syntax and response of completion suggester requests. See
<link linkend="search-suggesters-completion">completion suggester</link> for details.</simpara>
<simpara>For indices created before Elasticsearch 5.0.0, <literal>completion</literal> fields and the
completion suggester will continue to work as they did in Elasticsearch 2.x.
However, it is not possible to run a completion suggester query across indices
created in 2.x and indices created in 5.x.</simpara>
<simpara>It is strongly recommended to reindex indices containing 2.x <literal>completion</literal>
fields in 5.x to take advantage of the new features listed below.</simpara>
<note><simpara>You will need to change the structure of the completion field values
when reindexing.</simpara></note>
<section id="_completion_suggester_is_near_real_time">
<title>Completion suggester is near-real time<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/suggest.asciidoc">Edit me</ulink></title>
<simpara>Previously, deleted suggestions could be included in results even
after refreshing an index. Now, deletions are visible in near-real
time, i.e. as soon as the index has been refreshed. This applies
to suggestion entries for both context and completion suggesters.</simpara>
</section>
<section id="_completion_suggester_is_document_oriented">
<title>Completion suggester is document-oriented<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/suggest.asciidoc">Edit me</ulink></title>
<simpara>Suggestions are aware of the document they belong to. Now, associated
documents (<literal>_source</literal>) are returned as part of <literal>completion</literal> suggestions.</simpara>
<important><simpara><literal>_source</literal> meta-field must be enabled, which is the default behavior,
to enable returning <literal>_source</literal> with suggestions.</simpara></important>
<simpara>Previously, <literal>context</literal> and <literal>completion</literal> suggesters supported an index-time
<literal>payloads</literal> option, which was used to store and return metadata with suggestions.
Now metadata can be stored as part of the the same document as the
suggestion for retrieval at query-time. The support for index-time <literal>payloads</literal>
has been removed to avoid bloating the in-memory index with suggestion metadata.</simpara>
</section>
<section id="_simpler_completion_indexing">
<title>Simpler completion indexing<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/suggest.asciidoc">Edit me</ulink></title>
<simpara>As suggestions are document-oriented, suggestion metadata (e.g. <literal>output</literal>)
should now be specified as a field in the document. The support for specifying
<literal>output</literal> when indexing suggestion entries has been removed. Now suggestion
result entry&#8217;s <literal>text</literal> is always the un-analyzed value of the suggestion&#8217;s
<literal>input</literal> (same as not specifying <literal>output</literal> while indexing suggestions in pre-5.0
indices).</simpara>
</section>
<section id="_completion_mapping_with_multiple_contexts">
<title>Completion mapping with multiple contexts<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/suggest.asciidoc">Edit me</ulink></title>
<simpara>The <literal>context</literal> option in <literal>completion</literal> field mapping is now an array to support
multiple named contexts per completion field. Note that this is sugar for
indexing same suggestions under different name with different contexts.
The <literal>default</literal> option for a named <literal>context</literal> has been removed. Now querying with
no <literal>context</literal> against a context-enabled completion field yields results from all
indexed suggestions. Note that performance for match-all-context query
degrades with the number of unique context value for a given <literal>completion</literal> field.</simpara>
</section>
<section id="_completion_suggestion_with_multiple_context_filtering">
<title>Completion suggestion with multiple context filtering<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/suggest.asciidoc">Edit me</ulink></title>
<simpara>Previously <literal>context</literal> option in a suggest request was used for filtering suggestions
by <literal>context</literal> value. Now, the option has been named to <literal>contexts</literal> to specify
multiple named context filters. Note that this is not supported by pre-5.0 indices.
Following is the <literal>contexts</literal> snippet for a suggest query filtered by both <emphasis>color</emphasis>
and <emphasis>location</emphasis> contexts:</simpara>
<programlisting language="sh" linenumbering="unnumbered">"contexts": {
  "color": [ {...} ],
  "location": [ {...} ]
}</programlisting>
</section>
</section>
<section id="breaking_50_index_apis">
<title>Index APIs changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/index-apis.asciidoc">Edit me</ulink></title>
<section id="_closing_deleting_indices_while_running_snapshot">
<title>Closing / deleting indices while running snapshot<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/index-apis.asciidoc">Edit me</ulink></title>
<simpara>In previous versions of Elasticsearch, closing or deleting an index during a
full snapshot would make the snapshot fail. In 5.0, the close/delete index
request will fail instead. The behavior for partial snapshots remains
unchanged: Closing or deleting an index during a partial snapshot is still
possible. The snapshot result is then marked as partial.</simpara>
</section>
<section id="_warmers">
<title>Warmers<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/index-apis.asciidoc">Edit me</ulink></title>
<simpara>Thanks to several changes like doc values by default and disk-based norms,
warmers are no longer useful. As a consequence, warmers and the warmer API
have been removed: it is no longer possible to register queries that will run
before a new IndexSearcher is published.</simpara>
<simpara>Don&#8217;t worry if you have warmers defined on your indices, they will simply be
ignored when upgrading to 5.0.</simpara>
</section>
<section id="_system_cpu_stats">
<title>System CPU stats<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/index-apis.asciidoc">Edit me</ulink></title>
<simpara>The recent CPU usage (as a percent) has been added to the OS stats
reported under the node stats API and the cat nodes API. The breaking
change here is that there is a new object in the <literal>os</literal> object in the node
stats response. This object is called <literal>cpu</literal> and includes <literal>percent</literal> and
<literal>load_average</literal> as fields. This moves the <literal>load_average</literal> field that was
previously a top-level field in the <literal>os</literal> object to the <literal>cpu</literal> object. The
format of the <literal>load_average</literal> field has changed to an object with fields
<literal>1m</literal>, <literal>5m</literal>, and <literal>15m</literal> representing the one-minute, five-minute and
fifteen-minute loads respectively. If any of these fields are not present,
it indicates that the corresponding value is not available.</simpara>
<simpara>In the cat nodes API response, the <literal>cpu</literal> field is output by default. The
previous <literal>load</literal> field has been removed and is replaced by <literal>load_1m</literal>,
<literal>load_5m</literal>, and <literal>load_15m</literal> which represent the one-minute, five-minute
and fifteen-minute loads respectively. The field will be null if the
corresponding value is not available.</simpara>
<simpara>Finally, the API for <literal>org.elasticsearch.monitor.os.OsStats</literal> has
changed. The <literal>getLoadAverage</literal> method has been removed. The value for
this can now be obtained from <literal>OsStats.Cpu#getLoadAverage</literal> but it is no
longer a double and is instead an object encapsulating the one-minute,
five-minute and fifteen-minute load averages. Additionally, the recent
CPU usage can be obtained from <literal>OsStats.Cpu#getPercent</literal>.</simpara>
</section>
<section id="_suggest_stats">
<title>Suggest stats<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/index-apis.asciidoc">Edit me</ulink></title>
<simpara>Suggest stats exposed through <literal>suggest</literal> in indices stats has been merged
with <literal>search</literal> stats. <literal>suggest</literal> stats is exposed as part of <literal>search</literal> stats.</simpara>
</section>
<section id="_creating_indices_starting_with_emphasis_emphasis_or_emphasis_emphasis">
<title>Creating indices starting with <emphasis>-</emphasis> or <emphasis>+</emphasis><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/index-apis.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch no longer allows indices to be created started with <emphasis>-</emphasis> or <emphasis>+</emphasis>, so
that the multi-index matching and expansion is not confused. It was previously
possible (but a really bad idea) to create indices starting with a hyphen or
plus sign. Any index already existing with these preceding characters will
continue to work normally.</simpara>
</section>
<section id="_aliases_api">
<title>Aliases API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/index-apis.asciidoc">Edit me</ulink></title>
<simpara>The <literal>/_aliases</literal> API no longer supports <literal>indexRouting</literal> and <literal>index-routing</literal>, only
<literal>index_routing</literal>. It also no longer support <literal>searchRouting</literal> and <literal>search-routing</literal>,
only <literal>search_routing</literal>. These were removed because they were untested and we
prefer there to be only one (obvious) way to do things like this.</simpara>
</section>
<section id="_optype_create_without_an_id">
<title>OpType Create without an ID<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/index-apis.asciidoc">Edit me</ulink></title>
<simpara>As of 5.0 indexing a document with <literal>op_type=create</literal> without specifying an ID is not
supported anymore.</simpara>
</section>
<section id="_flush_api">
<title>Flush API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/index-apis.asciidoc">Edit me</ulink></title>
<simpara>The <literal>wait_if_ongoing</literal> flag default has changed to <literal>true</literal> causing <literal>_flush</literal> calls to wait and block
if another flush operation is currently running on the same shard. In turn, if <literal>wait_if_ongoing</literal> is set to
<literal>false</literal> and another flush operation is already running the flush is skipped and the shards flush call will return
immediately without any error. In previous versions <literal>flush_not_allowed</literal> exceptions where reported for each skipped shard.</simpara>
</section>
</section>
<section id="breaking_50_document_api_changes">
<title>Document API changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/docs.asciidoc">Edit me</ulink></title>
<section id="_literal_refresh_literal_no_longer_supports_truthy_and_falsy_values">
<title><literal>?refresh</literal> no longer supports truthy and falsy values<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/docs.asciidoc">Edit me</ulink></title>
<simpara>The <literal>?refresh</literal> request parameter used to accept any value other than <literal>false</literal>,
<literal>0</literal>, <literal>off</literal>, and <literal>no</literal> to mean "make the changes from this request visible for
search immediately." Now it only accepts <literal>?refresh</literal> and <literal>?refresh=true</literal> to
mean that. You can set it to <literal>?refresh=false</literal> and the request will take no
refresh-related action. The same is true if you leave <literal>refresh</literal> off of the
url entirely. If you add <literal>?refresh=wait_for</literal> Elasticsearch will wait for the
changes to become visible before replying to the request but won&#8217;t take any
immediate refresh related action. See <xref linkend="docs-refresh"/>.</simpara>
</section>
<section id="_literal_created_literal_field_deprecated_in_the_index_api">
<title><literal>created</literal> field deprecated in the Index API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/docs.asciidoc">Edit me</ulink></title>
<simpara>The <literal>created</literal> field has been deprecated in the Index API. It now returns
<literal>operation</literal>, returning <literal>"operation": "create"</literal> when it created a document and
<literal>"operation": "index"</literal> when it updated the document. This is also true for
<literal>index</literal> bulk operations.</simpara>
</section>
<section id="_literal_found_literal_field_deprecated_in_the_delete_api">
<title><literal>found</literal> field deprecated in the Delete API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/docs.asciidoc">Edit me</ulink></title>
<simpara>The <literal>found</literal> field has been deprecated in the Delete API. It now returns
<literal>operation</literal>, returning <literal>"operation": "deleted"</literal> when it deleted a document and
<literal>"operation": "noop"</literal> when it didn&#8217;t found the document. This is also true for
<literal>index</literal> bulk operations.</simpara>
</section>
<section id="_reindex_and_update_by_query">
<title>Reindex and Update By Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/docs.asciidoc">Edit me</ulink></title>
<simpara>Before 5.0.0 <literal>_reindex</literal> and <literal>_update_by_query</literal> only retried bulk failures so
they used the following response format:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   ...
   "retries": 10
   ...
}</programlisting>
<simpara>Where <literal>retries</literal> counts the number of bulk retries. Now they retry on search
failures as well and use this response format:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   ...
   "retries": {
     "bulk": 10,
     "search": 1
   }
   ...
}</programlisting>
<simpara>Where <literal>bulk</literal> counts the number of bulk retries and <literal>search</literal> counts the number
of search retries.</simpara>
</section>
<section id="_get_api">
<title>get API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/docs.asciidoc">Edit me</ulink></title>
<simpara>As of 5.0.0 the get API will issue a refresh if the requested document has
been changed since the last refresh but the change hasn&#8217;t been refreshed yet. This
will also make all other changes visible immediately. This can have an impact on
performance if the same document is updated very frequently using a read modify update
pattern since it might create many small segments. This behavior can be disabled by
passing <literal>realtime=false</literal> to the get request.</simpara>
<simpara>The <literal>fields</literal> field has been renamed to <literal>stored_fields</literal></simpara>
</section>
<section id="_mget_api">
<title>mget API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/docs.asciidoc">Edit me</ulink></title>
<simpara>The <literal>fields</literal> field has been renamed to <literal>stored_fields</literal></simpara>
</section>
<section id="_update_api">
<title>update API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/docs.asciidoc">Edit me</ulink></title>
<simpara>The <literal>fields</literal> field has been deprecated. You should use <literal>_source</literal> to load the field from _source.</simpara>
</section>
<section id="_bulk_api">
<title>bulk API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/docs.asciidoc">Edit me</ulink></title>
<simpara>The <literal>fields</literal> field has been deprecated. You should use <literal>_source</literal> to load the field from _source.</simpara>
</section>
</section>
<section id="breaking_50_settings_changes">
<title>Settings changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>From Elasticsearch 5.0 on all settings are validated before they are applied.
Node level and default index level settings are validated on node startup,
dynamic cluster and index setting are validated before they are updated/added
to the cluster state.</simpara>
<simpara>Every setting must be a <emphasis role="strong">known</emphasis> setting. All settings must have been
registered with the node or transport client they are used with. This implies
that plugins that define custom settings must register all of their settings
during plugin loading using the <literal>SettingsModule#registerSettings(Setting)</literal>
method.</simpara>
<section id="_index_level_settings">
<title>Index Level Settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>In previous versions Elasticsearch allowed to specify index level setting
as <emphasis>defaults</emphasis> on the node level, inside the <literal>elasticsearch.yaml</literal> file or even via
command-line parameters. From Elasticsearch 5.0 on only selected settings like
for instance <literal>index.codec</literal> can be set on the node level. All other settings must be
set on each individual index. To set default values on every index, index templates
should be used instead.</simpara>
</section>
<section id="_node_settings">
<title>Node settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>The <literal>name</literal> setting has been removed and is replaced by <literal>node.name</literal>. Usage of
<literal>-Dname=some_node_name</literal> is not supported anymore.</simpara>
<simpara>The <literal>node.add_id_to_custom_path</literal> was renamed to <literal>add_lock_id_to_custom_path</literal>.</simpara>
<simpara>The default for the <literal>node.name</literal> settings is now the first 7 characters of the node id,
which is in turn a randomly generated UUID.</simpara>
<simpara>The settings <literal>node.mode</literal> and <literal>node.local</literal> are removed. Local mode should be configured via
<literal>discovery.type: local</literal> and <literal>transport.type:local</literal>. In order to disable <emphasis>http</emphasis> please use <literal>http.enabled: false</literal></simpara>
</section>
<section id="_node_attribute_settings">
<title>Node attribute settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>Node level attributes used for allocation filtering, forced awareness or other node identification / grouping
must be prefixed with <literal>node.attr</literal>. In previous versions it was possible to specify node attributes with the <literal>node.</literal>
prefix. All node attributes except of <literal>node.master</literal>, <literal>node.data</literal> and <literal>node.ingest</literal> must be moved to the new <literal>node.attr.</literal>
namespace.</simpara>
</section>
<section id="_node_types_settings">
<title>Node types settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>The <literal>node.client</literal> setting has been removed. A node with such a setting set will not
start up. Instead, each node role needs to be set separately using the existing
<literal>node.master</literal>, <literal>node.data</literal> and <literal>node.ingest</literal> supported static settings.</simpara>
</section>
<section id="_gateway_settings">
<title>Gateway settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>The <literal>gateway.format</literal> setting for configuring global and index state serialization
format has been removed. By default, <literal>smile</literal> is used as the format.</simpara>
</section>
<section id="_transport_settings">
<title>Transport Settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>All settings with a <literal>netty</literal> infix have been replaced by their already existing
<literal>transport</literal> synonyms. For instance <literal>transport.netty.bind_host</literal> is no longer
supported and should be replaced by the superseding setting
<literal>transport.bind_host</literal>.</simpara>
</section>
<section id="_security_manager_settings">
<title>Security manager settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>The option to disable the security manager <literal>security.manager.enabled</literal> has been
removed. In order to grant special permissions to elasticsearch users must
edit the local Java Security Policy.</simpara>
</section>
<section id="_network_settings">
<title>Network settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>The <literal>_non_loopback_</literal> value for settings like <literal>network.host</literal> would arbitrarily
pick the first interface not marked as loopback. Instead, specify by address
scope (e.g. <literal>_local_,_site_</literal> for all loopback and private network addresses)
or by explicit interface names, hostnames, or addresses.</simpara>
<simpara>The <literal>netty.epollBugWorkaround</literal> settings is removed. This settings allow people to enable
a netty work around for <ulink url="https://github.com/netty/netty/issues/327">a high CPU usage issue</ulink> with early JVM versions.
This bug was <ulink url="http://bugs.java.com/view_bug.do?bug_id=6403933">fixed in Java 7</ulink>. Since Elasticsearch 5.0 requires Java 8 the settings is removed. Note that if the workaround needs to be reintroduced you can still set the <literal>org.jboss.netty.epollBugWorkaround</literal> system property to control Netty directly.</simpara>
</section>
<section id="_forbid_changing_of_thread_pool_types">
<title>Forbid changing of thread pool types<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>Previously, <link linkend="modules-threadpool">thread pool types</link> could be dynamically
adjusted. The thread pool type effectively controls the backing queue for the
thread pool and modifying this is an expert setting with minimal practical
benefits and high risk of being misused. The ability to change the thread pool
type for any thread pool has been removed. It is still possible to adjust
relevant thread pool parameters for each of the thread pools (e.g., depending
on the thread pool type, <literal>keep_alive</literal>, <literal>queue_size</literal>, etc.).</simpara>
</section>
<section id="_threadpool_settings">
<title>Threadpool settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>The <literal>suggest</literal> threadpool has been removed, now suggest requests use the
<literal>search</literal> threadpool.</simpara>
<simpara>The prefix on all thread pool settings has been changed from
<literal>threadpool</literal> to <literal>thread_pool</literal>.</simpara>
<simpara>The minimum size setting for a scaling thread pool has been changed
from <literal>min</literal> to <literal>core</literal>.</simpara>
<simpara>The maximum size setting for a scaling thread pool has been changed
from <literal>size</literal> to <literal>max</literal>.</simpara>
<simpara>The queue size setting for a fixed thread pool must be <literal>queue_size</literal>
(all other variants that were previously supported are no longer
supported).</simpara>
<simpara>Thread pool settings are now node-level settings. As such, it is not
possible to update thread pool settings via the cluster settings API.</simpara>
</section>
<section id="_analysis_settings">
<title>Analysis settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>The <literal>index.analysis.analyzer.default_index</literal> analyzer is not supported anymore.
If you wish to change the analyzer to use for indexing, change the
<literal>index.analysis.analyzer.default</literal> analyzer instead.</simpara>
</section>
<section id="_ping_settings">
<title>Ping settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>Previously, there were three settings for the ping timeout:
<literal>discovery.zen.initial_ping_timeout</literal>, <literal>discovery.zen.ping.timeout</literal> and
<literal>discovery.zen.ping_timeout</literal>. The former two have been removed and the only
setting key for the ping timeout is now <literal>discovery.zen.ping_timeout</literal>. The
default value for ping timeouts remains at three seconds.</simpara>
<simpara><literal>discovery.zen.master_election.filter_client</literal> and <literal>discovery.zen.master_election.filter_data</literal> have
been removed in favor of the new <literal>discovery.zen.master_election.ignore_non_master_pings</literal>. This setting control how ping responses
are interpreted during master election and should be used with care and only in extreme cases. See documentation for details.</simpara>
</section>
<section id="_recovery_settings">
<title>Recovery settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>Recovery settings deprecated in 1.x have been removed:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>index.shard.recovery.translog_size</literal> is superseded by <literal>indices.recovery.translog_size</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>index.shard.recovery.translog_ops</literal> is superseded by <literal>indices.recovery.translog_ops</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>index.shard.recovery.file_chunk_size</literal> is superseded by <literal>indices.recovery.file_chunk_size</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>index.shard.recovery.concurrent_streams</literal> is superseded by <literal>indices.recovery.concurrent_streams</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>index.shard.recovery.concurrent_small_file_streams</literal> is superseded by <literal>indices.recovery.concurrent_small_file_streams</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>indices.recovery.max_size_per_sec</literal> is superseded by <literal>indices.recovery.max_bytes_per_sec</literal>
</simpara>
</listitem>
</itemizedlist>
<simpara>If you are using any of these settings please take the time to review their
purpose. All of the settings above are considered <emphasis>expert settings</emphasis> and should
only be used if absolutely necessary. If you have set any of the above setting
as persistent cluster settings please use the settings update API and set
their superseded keys accordingly.</simpara>
<simpara>The following settings have been removed without replacement</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>indices.recovery.concurrent_small_file_streams</literal> - recoveries are now single threaded. The number of concurrent outgoing recoveries are throttled via allocation deciders
</simpara>
</listitem>
<listitem>
<simpara>
<literal>indices.recovery.concurrent_file_streams</literal> - recoveries are now single threaded. The number of concurrent outgoing recoveries are throttled via allocation deciders
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_translog_settings">
<title>Translog settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>The <literal>index.translog.flush_threshold_ops</literal> setting is not supported anymore. In
order to control flushes based on the transaction log growth use
<literal>index.translog.flush_threshold_size</literal> instead.</simpara>
<simpara>Changing the translog type with <literal>index.translog.fs.type</literal> is not supported
anymore, the <literal>buffered</literal> implementation is now the only available option and
uses a fixed <literal>8kb</literal> buffer.</simpara>
<simpara>The translog by default is fsynced after every <literal>index</literal>, <literal>create</literal>, <literal>update</literal>,
<literal>delete</literal>, or <literal>bulk</literal> request.  The ability to fsync on every operation is not
necessary anymore. In fact, it can be a performance bottleneck and it&#8217;s trappy
since it enabled by a special value set on <literal>index.translog.sync_interval</literal>.
Now, <literal>index.translog.sync_interval</literal>  doesn&#8217;t accept a value less than <literal>100ms</literal>
which prevents fsyncing too often if async durability is enabled. The special
value <literal>0</literal> is no longer supported.</simpara>
<simpara><literal>index.translog.interval</literal> has been removed.</simpara>
</section>
<section id="_request_cache_settings">
<title>Request Cache Settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>The deprecated settings <literal>index.cache.query.enable</literal> and
<literal>indices.cache.query.size</literal> have been removed and are replaced with
<literal>index.requests.cache.enable</literal> and <literal>indices.requests.cache.size</literal> respectively.</simpara>
<simpara><literal>indices.requests.cache.clean_interval</literal> has been replaced with
<literal>indices.cache.clean_interval</literal> and is no longer supported.</simpara>
</section>
<section id="_field_data_cache_settings">
<title>Field Data Cache Settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>The <literal>indices.fielddata.cache.clean_interval</literal> setting has been replaced with
<literal>indices.cache.clean_interval</literal>.</simpara>
</section>
<section id="_allocation_settings">
<title>Allocation settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>The <literal>cluster.routing.allocation.concurrent_recoveries</literal> setting has been
replaced with <literal>cluster.routing.allocation.node_concurrent_recoveries</literal>.</simpara>
</section>
<section id="_similarity_settings">
<title>Similarity settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>The <emphasis>default</emphasis> similarity has been renamed to <emphasis>classic</emphasis>.</simpara>
</section>
<section id="_indexing_settings">
<title>Indexing settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>The <literal>indices.memory.min_shard_index_buffer_size</literal> and
<literal>indices.memory.max_shard_index_buffer_size</literal> have been removed as
Elasticsearch now allows any one shard to use  amount of heap as long as the
total indexing buffer heap used across all shards is below the node&#8217;s
<literal>indices.memory.index_buffer_size</literal> (defaults to 10% of the JVM heap).</simpara>
</section>
<section id="_removed_es_max_open_files">
<title>Removed es.max-open-files<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>Setting the system property es.max-open-files to true to get
Elasticsearch to print the number of maximum open files for the
Elasticsearch process has been removed. This same information can be
obtained from the <xref linkend="cluster-nodes-info"/> API, and a warning is logged
on startup if it is set too low.</simpara>
</section>
<section id="_removed_es_netty_gathering">
<title>Removed es.netty.gathering<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>Disabling Netty from using NIO gathering could be done via the escape
hatch of setting the system property "es.netty.gathering" to "false".
Time has proven enabling gathering by default is a non-issue and this
non-documented setting has been removed.</simpara>
</section>
<section id="_removed_es_uselinkedtransferqueue">
<title>Removed es.useLinkedTransferQueue<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>The system property <literal>es.useLinkedTransferQueue</literal> could be used to
control the queue implementation used in the cluster service and the
handling of ping responses during discovery. This was an undocumented
setting and has been removed.</simpara>
</section>
<section id="_cache_concurrency_level_settings_removed">
<title>Cache concurrency level settings removed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>Two cache concurrency level settings
<literal>indices.requests.cache.concurrency_level</literal> and
<literal>indices.fielddata.cache.concurrency_level</literal> because they no longer apply to
the cache implementation used for the request cache and the field data cache.</simpara>
</section>
<section id="_using_system_properties_to_configure_elasticsearch">
<title>Using system properties to configure Elasticsearch<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch can no longer be configured by setting system properties. This means that support for all of the following has been removed:</simpara>
<itemizedlist>
<listitem>
<simpara>
setting via command line arguments to <literal>elasticsearch</literal> as <literal>-Des.name.of.setting=value.of.setting</literal>
</simpara>
</listitem>
<listitem>
<simpara>
setting via the JAVA_OPTS environment variable <literal>JAVA_OPTS=$JAVA_OPTS -Des.name.of.setting=value.of.setting</literal>
</simpara>
</listitem>
<listitem>
<simpara>
setting via the ES_JAVA_OPTS environment variable <literal>ES_JAVA_OPTS=$ES_JAVA_OPTS -Des.name.of.setting=value.of.setting</literal>
</simpara>
</listitem>
</itemizedlist>
<simpara>Instead, use <literal>-Ename.of.setting=value.of.setting</literal>.</simpara>
</section>
<section id="_removed_using_double_dashes_to_configure_elasticsearch">
<title>Removed using double-dashes to configure Elasticsearch<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch could previously be configured on the command line by
setting settings via <literal>--name.of.setting value.of.setting</literal>. This feature
has been removed. Instead, use <literal>-Ename.of.setting=value.of.setting</literal>.</simpara>
</section>
<section id="_remove_support_for_properties_config_files">
<title>Remove support for .properties config files<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>The Elasticsearch configuration and logging configuration can no longer be stored in the Java
properties file format (line-delimited key=value pairs with a <literal>.properties</literal> extension).</simpara>
</section>
<section id="_discovery_settings">
<title>Discovery Settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>The <literal>discovery.zen.minimum_master_node</literal> must be set for nodes that have
<literal>network.host</literal>, <literal>network.bind_host</literal>, <literal>network.publish_host</literal>,
<literal>transport.host</literal>, <literal>transport.bind_host</literal>, or <literal>transport.publish_host</literal>
configuration options set. We see those nodes as in "production" mode
and thus require the setting.</simpara>
</section>
<section id="_realtime_get_setting">
<title>Realtime get setting<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>The <literal>action.get.realtime</literal> setting has been removed. This setting was
a fallback realtime setting for the get and mget APIs when realtime
wasn&#8217;t specified. Now if the parameter isn&#8217;t specified we always
default to true.</simpara>
</section>
<section id="_memory_lock_settings">
<title>Memory lock settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>The setting <literal>bootstrap.mlockall</literal> has been renamed to
<literal>bootstrap.memory_lock</literal>.</simpara>
</section>
<section id="_snapshot_settings">
<title>Snapshot settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>The default setting <literal>include_global_state</literal> for restoring snapshots has been
changed from <literal>true</literal> to <literal>false</literal>. It has not been changed for taking snapshots and
still defaults to <literal>true</literal> in that case.</simpara>
</section>
<section id="_time_value_parsing">
<title>Time value parsing<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>The unit <emphasis>w</emphasis> representing weeks is no longer supported.</simpara>
<simpara>Fractional time values (e.g., 0.5s) are no longer supported. For example, this means when setting
timeouts "0.5s" will be rejected and should instead be input as "500ms".</simpara>
</section>
<section id="_node_max_local_storage_nodes">
<title>Node max local storage nodes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>Previous versions of Elasticsearch defaulted to allowing multiple nodes to share the same data
directory (up to 50). This can be confusing where users accidentally startup multiple nodes and end
up thinking that they&#8217;ve lost data because the second node will start with an empty data directory.
While the default of allowing multiple nodes is friendly to playing with forming a small cluster on
a laptop, and end-users do sometimes run multiple nodes on the same host, this tends to be the
exception. Keeping with Elasticsearch&#8217;s continual movement towards safer out-of-the-box defaults,
and optimizing for the norm instead of the exception, the default for
<literal>node.max_local_storage_nodes</literal> is now one.</simpara>
<bridgehead id="_script_settings" renderas="sect2">Script settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></bridgehead>
</section>
<section id="_indexed_script_settings">
<title>Indexed script settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>Due to the fact that indexed script has been replaced by stored
scripts the following settings have been replaced to:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>script.indexed</literal> has been replaced by <literal>script.stored</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>script.engine.*.indexed.aggs</literal> has been replaced by <literal>script.engine.*.stored.aggs</literal> (where <literal>*</literal> represents the script language, like <literal>groovy</literal>, <literal>mustache</literal>, <literal>painless</literal> etc.)
</simpara>
</listitem>
<listitem>
<simpara>
<literal>script.engine.*.indexed.mapping</literal> has been replaced by <literal>script.engine.*.stored.mapping</literal> (where <literal>*</literal> represents the script language, like <literal>groovy</literal>, <literal>mustache</literal>, <literal>painless</literal> etc.)
</simpara>
</listitem>
<listitem>
<simpara>
<literal>script.engine.*.indexed.search</literal> has been replaced by <literal>script.engine.*.stored.search</literal> (where <literal>*</literal> represents the script language, like <literal>groovy</literal>, <literal>mustache</literal>, <literal>painless</literal> etc.)
</simpara>
</listitem>
<listitem>
<simpara>
<literal>script.engine.*.indexed.update</literal> has been replaced by <literal>script.engine.*.stored.update</literal> (where <literal>*</literal> represents the script language, like <literal>groovy</literal>, <literal>mustache</literal>, <literal>painless</literal> etc.)
</simpara>
</listitem>
<listitem>
<simpara>
<literal>script.engine.*.indexed.plugin</literal> has been replaced by <literal>script.engine.*.stored.plugin</literal> (where <literal>*</literal> represents the script language, like <literal>groovy</literal>, <literal>mustache</literal>, <literal>painless</literal> etc.)
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_script_mode_settings">
<title>Script mode settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>Previously script mode settings (e.g., "script.inline: true",
"script.engine.groovy.inline.aggs: false", etc.) accepted a wide range of
"truthy" or "falsy" values. This is now much stricter and supports only the
<literal>true</literal> and <literal>false</literal> options.</simpara>
</section>
<section id="_script_sandbox_settings_removed">
<title>Script sandbox settings removed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>Prior to 5.0 a third option could be specified for the <literal>script.inline</literal> and
<literal>script.stored</literal> settings ("sandbox"). This has been removed, You can now only
set <literal>script.line: true</literal> or <literal>script.stored: true</literal>.</simpara>
</section>
<section id="_search_settings">
<title>Search settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/settings.asciidoc">Edit me</ulink></title>
<simpara>The setting <literal>index.query.bool.max_clause_count</literal> has been removed. In order to
set the maximum number of boolean clauses <literal>indices.query.bool.max_clause_count</literal>
should be used instead.</simpara>
</section>
</section>
<section id="breaking_50_allocation">
<title>Allocation changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/allocation.asciidoc">Edit me</ulink></title>
<section id="_primary_shard_allocation">
<title>Primary shard allocation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/allocation.asciidoc">Edit me</ulink></title>
<simpara>Previously, primary shards were only assigned if a quorum of shard copies were
found (configurable using <literal>index.recovery.initial_shards</literal>, now deprecated). In
case where a primary had only a single replica, quorum was defined to be a
single shard. This meant that any shard copy of an index with replication
factor 1 could become primary, even it was a stale copy of the data on disk.
This is now fixed thanks to shard allocation IDs.</simpara>
<simpara>Allocation IDs assign unique identifiers to shard copies. This allows the
cluster to differentiate between multiple copies of the same data and track
which shards have been active so that, after a cluster restart, only shard
copies containing the most recent data can become primaries.</simpara>
</section>
<section id="_indices_shard_stores_command">
<title>Indices Shard Stores command<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/allocation.asciidoc">Edit me</ulink></title>
<simpara>By using allocation IDs instead of version numbers to identify shard copies
for primary shard allocation, the former versioning scheme has become
obsolete. This is reflected in the
<link linkend="indices-shards-stores">Indices Shard Stores API</link>.</simpara>
<simpara>A new <literal>allocation_id</literal> field replaces the former <literal>version</literal> field in the result
of the Indices Shard Stores command. This field is available for all shard
copies that have been either created with the current version of Elasticsearch
or have been active in a cluster running a current version of Elasticsearch.
For legacy shard copies that have not been active in a current version of
Elasticsearch, a <literal>legacy_version</literal> field is available instead (equivalent to
the former <literal>version</literal> field).</simpara>
</section>
<section id="_reroute_commands">
<title>Reroute commands<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/allocation.asciidoc">Edit me</ulink></title>
<simpara>The reroute command <literal>allocate</literal> has been split into two distinct commands
<literal>allocate_replica</literal> and <literal>allocate_empty_primary</literal>. This was done as we
introduced a new <literal>allocate_stale_primary</literal> command. The new <literal>allocate_replica</literal>
command corresponds to the old <literal>allocate</literal> command  with <literal>allow_primary</literal> set to
false. The new <literal>allocate_empty_primary</literal> command corresponds to the old
<literal>allocate</literal> command with <literal>allow_primary</literal> set to true.</simpara>
</section>
<section id="_custom_reroute_commands">
<title>Custom Reroute Commands<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/allocation.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch no longer supports plugins registering custom allocation
commands. It was unused and hopefully unneeded.</simpara>
</section>
<section id="_literal_index_shared_filesystem_recover_on_any_node_literal_changes">
<title><literal>index.shared_filesystem.recover_on_any_node</literal> changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/allocation.asciidoc">Edit me</ulink></title>
<simpara>The behavior of <literal>index.shared_filesystem.recover_on_any_node: true</literal> has been
changed. Previously, in the case where no shard copies could be found, an
arbitrary node was chosen by potentially ignoring allocation deciders. Now, we
take balancing into account but don&#8217;t assign the shard if the allocation
deciders are not satisfied.</simpara>
<simpara>The behavior has also changed in the case where shard copies can be found.
Previously, a node not holding the shard copy was chosen if none of the nodes
holding shard copies were satisfying the allocation deciders. Now, the shard
will be assigned to a node having a shard copy, even if none of the nodes
holding a shard copy satisfy the allocation deciders.</simpara>
</section>
</section>
<section id="breaking_50_http_changes">
<title>HTTP changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/http.asciidoc">Edit me</ulink></title>
<section id="_compressed_http_requests_are_always_accepted">
<title>Compressed HTTP requests are always accepted<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/http.asciidoc">Edit me</ulink></title>
<simpara>Before 5.0, Elasticsearch accepted compressed HTTP requests only if the setting
 <literal>http.compressed</literal> was set to <literal>true</literal>. Elasticsearch accepts compressed requests
 now but will continue to send compressed responses only if <literal>http.compressed</literal>
 is set to <literal>true</literal>.</simpara>
</section>
</section>
<section id="breaking_50_rest_api_changes">
<title>REST API changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/rest.asciidoc">Edit me</ulink></title>
<section id="_strict_rest_query_string_parameter_parsing">
<title>Strict REST query string parameter parsing<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/rest.asciidoc">Edit me</ulink></title>
<simpara>Previous versions of Elasticsearch ignored unrecognized URL query
string parameters. This means that extraneous parameters or parameters
containing typographical errors would be silently accepted by
Elasticsearch. This is dangerous from an end-user perspective because it
means a submitted request will silently execute not as intended. This
leniency has been removed and Elasticsearch will now fail any request
that contains unrecognized query string parameters.</simpara>
</section>
<section id="_id_values_longer_than_512_bytes_are_rejected">
<title>id values longer than 512 bytes are rejected<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/rest.asciidoc">Edit me</ulink></title>
<simpara>When specifying an <literal>_id</literal> value longer than 512 bytes, the request will be
rejected.</simpara>
</section>
<section id="_literal__optimize_literal_endpoint_removed">
<title><literal>/_optimize</literal> endpoint removed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/rest.asciidoc">Edit me</ulink></title>
<simpara>The deprecated <literal>/_optimize</literal> endpoint has been removed. The <literal>/_forcemerge</literal>
endpoint should be used in lieu of optimize.</simpara>
<simpara>The <literal>GET</literal> HTTP verb for <literal>/_forcemerge</literal> is no longer supported, please use the
<literal>POST</literal> HTTP verb.</simpara>
</section>
<section id="_index_creation_endpoint_only_accepts_literal_put_literal">
<title>Index creation endpoint only accepts <literal>PUT</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/rest.asciidoc">Edit me</ulink></title>
<simpara>It used to be possible to create an index by either calling <literal>PUT index_name</literal>
or <literal>POST index_name</literal>. Only the former is now supported.</simpara>
</section>
<section id="_literal_head_index_type_literal_replaced_with_literal_head_index__mapping_type_literal">
<title><literal>HEAD {index}/{type}</literal> replaced with <literal>HEAD {index}/_mapping/{type}</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/rest.asciidoc">Edit me</ulink></title>
<simpara>The endpoint for checking whether a type exists has been changed from
<literal>{index}/{type}</literal> to <literal>{index}/_mapping/{type}</literal> in order to prepare for the
removal of types when <literal>HEAD {index}/{id}</literal> will be used to check whether a
document exists in an index. The old endpoint will keep working until 6.0.</simpara>
</section>
<section id="_removed_literal_mem_literal_section_from_literal__cluster_stats_literal_response">
<title>Removed <literal>mem</literal> section from <literal>/_cluster/stats</literal> response<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/rest.asciidoc">Edit me</ulink></title>
<simpara>The <literal>mem</literal> section contained only the <literal>total</literal> value, which was actually the
memory available throughout all nodes in the cluster. The section contains now
<literal>total</literal>, <literal>free</literal>, <literal>used</literal>, <literal>used_percent</literal> and <literal>free_percent</literal>.</simpara>
</section>
<section id="_revised_node_roles_aggregate_returned_by_literal__cluster_stats_literal">
<title>Revised node roles aggregate returned by <literal>/_cluster/stats</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/rest.asciidoc">Edit me</ulink></title>
<simpara>The <literal>client</literal>, <literal>master_only</literal>, <literal>data_only</literal> and <literal>master_data</literal> fields have been
removed in favor of <literal>master</literal>, <literal>data</literal>, <literal>ingest</literal> and <literal>coordinating_only</literal>. A
node can contribute to multiple counts as it can have multiple roles. Every
node is implicitly a coordinating node, so whenever a node has no explicit
roles, it will be counted as coordinating only.</simpara>
</section>
<section id="_removed_shard_literal_version_literal_information_from_literal__cluster_state_literal_routing_table">
<title>Removed shard <literal>version</literal> information from <literal>/_cluster/state</literal> routing table<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/rest.asciidoc">Edit me</ulink></title>
<simpara>We now store allocation id&#8217;s of shards in the cluster state and use that to
select primary shards instead of the version information.</simpara>
</section>
<section id="_node_roles_are_not_part_of_node_attributes_anymore">
<title>Node roles are not part of node attributes anymore<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/rest.asciidoc">Edit me</ulink></title>
<simpara>Node roles are now returned in a specific section, called <literal>roles</literal>, as part of
nodes stats and nodes info response. The new section is an array that holds all
the different roles that each node fulfills. In case the array is returned
empty, that means that the node is a coordinating only node.</simpara>
</section>
<section id="_forbid_unquoted_json">
<title>Forbid unquoted JSON<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/rest.asciidoc">Edit me</ulink></title>
<simpara>Previously, JSON documents were allowed with unquoted field names, which isn&#8217;t
strictly JSON and broke some Elasticsearch clients. If documents were already
indexed with unquoted fields in a previous vesrion of Elasticsearch, some
operations may throw errors. To accompany this, a commented out JVM option has
been added to the <literal>jvm.options</literal> file:
<literal>-Delasticsearch.json.allow_unquoted_field_names</literal>.</simpara>
<simpara>Note that this option is provided solely for migration purposes and will be
removed in Elasticsearch 6.0.0.</simpara>
</section>
<section id="_analyze_api_changes">
<title>Analyze API changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/rest.asciidoc">Edit me</ulink></title>
<simpara>The <literal>filters</literal> and <literal>char_filters</literal> parameters have been renamed <literal>filter</literal> and <literal>char_filter</literal>.
The <literal>token_filters</literal> parameter has been removed. Use <literal>filter</literal> instead.</simpara>
</section>
<section id="_literal_delete__query_literal_endpoint_removed">
<title><literal>DELETE /_query</literal> endpoint removed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/rest.asciidoc">Edit me</ulink></title>
<simpara>The <literal>DELETE /_query</literal> endpoint provided by the Delete-By-Query plugin has been
removed and replaced by the <link linkend="docs-delete-by-query">Delete By Query API</link>.</simpara>
</section>
<section id="_create_stored_script_endpoint_removed">
<title>Create stored script endpoint removed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/rest.asciidoc">Edit me</ulink></title>
<simpara>The <literal>PUT /_scripts/{lang}/{id}/_create</literal> endpoint that previously allowed to create
 indexed scripts has been removed. Indexed scripts have been replaced
 by <link linkend="modules-scripting-stored-scripts">stored scripts</link>.</simpara>
</section>
<section id="_create_stored_template_endpoint_removed">
<title>Create stored template endpoint removed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/rest.asciidoc">Edit me</ulink></title>
<simpara>The <literal>PUT /_search/template/{id}/_create</literal> endpoint that previously allowed to create
 indexed template has been removed. Indexed templates have been replaced
 by <link linkend="pre-registered-templates">Pre-registered templates</link>.</simpara>
</section>
<section id="_remove_properties_support">
<title>Remove properties support<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/rest.asciidoc">Edit me</ulink></title>
<simpara>Some REST endpoints (e.g., cluster update index settings) supported detecting content in the Java
properties format (line-delimited key=value pairs). This support has been removed.</simpara>
</section>
<section id="_literal_wait_for_relocating_shards_literal_is_now_literal_wait_for_no_relocating_shards_literal_in_literal__cluster_health_literal">
<title><literal>wait_for_relocating_shards</literal> is now <literal>wait_for_no_relocating_shards</literal> in <literal>/_cluster/health</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/rest.asciidoc">Edit me</ulink></title>
<simpara>The <literal>wait_for_relocating_shards</literal> parameter that used to take a number is now simply a boolean
flag <literal>wait_for_no_relocating_shards</literal>, which if set to true, means the request will wait (up
until the configured timeout) for the cluster to have no shard relocations before returning.
Defaults to false, which means the operation will not wait.</simpara>
</section>
</section>
<section id="breaking_50_cat_api">
<title>CAT API changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/cat.asciidoc">Edit me</ulink></title>
<section id="_use_accept_header_for_specifying_response_media_type">
<title>Use Accept header for specifying response media type<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/cat.asciidoc">Edit me</ulink></title>
<simpara>Previous versions of Elasticsearch accepted the Content-type header
field for controlling the media type of the response in the cat API.
This is in opposition to the HTTP spec which specifies the Accept
header field for this purpose. Elasticsearch now uses the Accept header
field and support for using the Content-Type header field for this
purpose has been removed.</simpara>
</section>
<section id="_host_field_removed_from_the_cat_nodes_api">
<title>Host field removed from the cat nodes API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/cat.asciidoc">Edit me</ulink></title>
<simpara>The <literal>host</literal> field has been removed from the cat nodes API as its value
is always equal to the <literal>ip</literal> field. The <literal>name</literal> field is available in the
cat nodes API and should be used instead of the <literal>host</literal> field.</simpara>
</section>
<section id="_changes_to_cat_recovery_api">
<title>Changes to cat recovery API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/cat.asciidoc">Edit me</ulink></title>
<simpara>The fields <literal>bytes_recovered</literal> and <literal>files_recovered</literal> have been added to
the cat recovery API. These fields, respectively, indicate the total
number of bytes and files that have been recovered.</simpara>
<simpara>The fields <literal>total_files</literal> and <literal>total_bytes</literal> have been renamed to
<literal>files_total</literal> and <literal>bytes_total</literal>, respectively.</simpara>
<simpara>Additionally, the field <literal>translog</literal> has been renamed to
<literal>translog_ops_recovered</literal>, the field <literal>translog_total</literal> to
<literal>translog_ops</literal> and the field <literal>translog_percent</literal> to
<literal>translog_ops_percent</literal>. The short aliases for these fields are <literal>tor</literal>,
<literal>to</literal>, and <literal>top</literal>, respectively.</simpara>
</section>
<section id="_changes_to_cat_nodes_api">
<title>Changes to cat nodes API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/cat.asciidoc">Edit me</ulink></title>
<simpara>The cat nodes endpoint returns <literal>m</literal> for master eligible, <literal>d</literal> for data,
and <literal>i</literal> for ingest. A node with no explicit roles will be a coordinating
only node and marked with <literal>-</literal>. A node can have multiple roles. The
master column has been adapted to return only whether a node is the
current master (<literal>*</literal>) or not (<literal>-</literal>).</simpara>
</section>
<section id="_changes_to_cat_field_data_api">
<title>Changes to cat field data API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/cat.asciidoc">Edit me</ulink></title>
<simpara>The cat field data endpoint adds a row per field instead of a column per field.</simpara>
<simpara>The <literal>total</literal> field has been removed from the field data API. Total field data usage per node
can be got by cat nodes API.</simpara>
</section>
</section>
<section id="breaking_50_java_api_changes">
<title>Java API changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<section id="_transport_client_has_been_moved">
<title>Transport client  has been moved<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>The Java transport client has been moved to its own module which can be referenced using:</simpara>
<programlisting language="xml" linenumbering="unnumbered">&lt;dependency&gt;
    &lt;groupId&gt;org.elasticsearch.client&lt;/groupId&gt;
    &lt;artifactId&gt;transport&lt;/artifactId&gt;
    &lt;version&gt;5.0.0&lt;/version&gt;
&lt;/dependency&gt;</programlisting>
<simpara>The transport client is now created using the following snippet:</simpara>
<programlisting language="java" linenumbering="unnumbered">TransportClient client = new PreBuiltTransportClient(Settings.EMPTY)
        .addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName("host1"), 9300))
        .addTransportAddress(new InetSocketTransportAddress(InetAddress.getByName("host2"), 9300));</programlisting>
<simpara>For more information please see the <ulink url="https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.x/java-api.html">Java client documentation</ulink></simpara>
</section>
<section id="_count_api_has_been_removed">
<title>Count api has been removed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>The deprecated count api has been removed from the Java api, use the search api instead and set size to 0.</simpara>
<simpara>The following call</simpara>
<programlisting language="java" linenumbering="unnumbered">client.prepareCount(indices).setQuery(query).get();</programlisting>
<simpara>can be replaced with</simpara>
<programlisting language="java" linenumbering="unnumbered">client.prepareSearch(indices).setSource(new SearchSourceBuilder().size(0).query(query)).get();</programlisting>
</section>
<section id="_suggest_api_has_been_removed">
<title>Suggest api has been removed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>The suggest api has been removed from the Java api, use the suggest option in search api, it has been optimized
for suggest-only request.</simpara>
<simpara>The following call</simpara>
<programlisting language="java" linenumbering="unnumbered">client.prepareSuggest(indices).addSuggestion("foo", SuggestBuilders.completionSuggestion("field").text("s")).get();</programlisting>
<simpara>can be replaced with</simpara>
<programlisting language="java" linenumbering="unnumbered">client.prepareSearch(indices).suggest(new SuggestBuilder().addSuggestion("foo", SuggestBuilders.completionSuggestion("field").text("s"))).get();</programlisting>
</section>
<section id="_elasticsearch_will_no_longer_detect_logging_implementations">
<title>Elasticsearch will no longer detect logging implementations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch now logs using Log4j 2. Previously if Log4j wasn&#8217;t on the
classpath it made some effort to degrade to SLF4J or Java logging. Now it will
fail to work without the Log4j 2 API. The log4j-over-slf4j bridge ought to work
when using the Java client. The log4j-1.2-api bridge is used for third-party
dependencies that still use the Log4j 1 API. The Elasticsearch server now only
supports Log4j 2 as configured by <literal>log4j2.properties</literal> and will fail if Log4j
isn&#8217;t present.</simpara>
</section>
<section id="_groovy_dependencies">
<title>Groovy dependencies<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>In previous versions of Elasticsearch, the Groovy scripting capabilities
depended on the <literal>org.codehaus.groovy:groovy-all</literal> artifact.  In addition
to pulling in the Groovy language, this pulls in a very large set of
functionality, none of which is needed for scripting within
Elasticsearch. Aside from the inherent difficulties in managing such a
large set of dependencies, this also increases the surface area for
security issues. This dependency has been reduced to the core Groovy
language <literal>org.codehaus.groovy:groovy</literal> artifact.</simpara>
</section>
<section id="_documentalreadyexistsexception_removed">
<title>DocumentAlreadyExistsException removed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara><literal>DocumentAlreadyExistsException</literal> is removed and a <literal>VersionConflictException</literal> is thrown instead (with a better
error description). This will influence code that use the <literal>IndexRequest.opType()</literal> or <literal>IndexRequest.create()</literal>
to index a document only if it doesn&#8217;t already exist.</simpara>
</section>
<section id="_writeconsistencylevel_removed_on_write_requests">
<title>writeConsistencyLevel removed on write requests<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>In previous versions of Elasticsearch, the various write requests had a
<literal>setWriteConsistencyLevel</literal> method to set the shard consistency level for
write operations. However, the semantics of write consistency were ambiguous
as this is just a pre-operation check to ensure the specified number of
shards were available before the operation commenced. The write consistency
level did not guarantee that the data would be replicated to those number
of copies by the time the operation finished. The <literal>setWriteConsistencyLevel</literal>
method on these write requests has been changed to <literal>setWaitForActiveShards</literal>,
which can take a numerical value up to the total number of shard copies or
<literal>ActiveShardCount.ALL</literal> for all shard copies. The default is to just wait
for the primary shard to be active before proceeding with the operation.
See the section on <link linkend="index-wait-for-active-shards">wait for active shards</link>
for more details.</simpara>
<simpara>This change affects <literal>IndexRequest</literal>, <literal>IndexRequestBuilder</literal>, <literal>BulkRequest</literal>,
<literal>BulkRequestBuilder</literal>, <literal>UpdateRequest</literal>, <literal>UpdateRequestBuilder</literal>, <literal>DeleteRequest</literal>,
and <literal>DeleteRequestBuilder</literal>.</simpara>
</section>
<section id="_changes_to_query_builders">
<title>Changes to Query Builders<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<section id="_boostingquerybuilder">
<title>BoostingQueryBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>Removed setters for mandatory positive/negative query. Both arguments now have
to be supplied at construction time already and have to be non-null.</simpara>
</section>
<section id="_spancontainingquerybuilder">
<title>SpanContainingQueryBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>Removed setters for mandatory big/little inner span queries. Both arguments now have
to be supplied at construction time already and have to be non-null. Updated
static factory methods in QueryBuilders accordingly.</simpara>
</section>
<section id="_spanorquerybuilder">
<title>SpanOrQueryBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>Making sure that query contains at least one clause by making initial clause mandatory
in constructor.
Renaming method to add clauses from <literal>clause(SpanQueryBuilder)</literal> to <literal>addClause(SpanQueryBuilder)</literal>.</simpara>
</section>
<section id="_spannearquerybuilder">
<title>SpanNearQueryBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>Removed setter for mandatory slop parameter, needs to be set in constructor now. Also
making sure that query contains at least one clause by making initial clause mandatory
in constructor. Updated the static factory methods in QueryBuilders accordingly.
Renaming method to add clauses from <literal>clause(SpanQueryBuilder)</literal> to <literal>addClause(SpanQueryBuilder)</literal>.</simpara>
</section>
<section id="_spannotquerybuilder">
<title>SpanNotQueryBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>Removed setter for mandatory include/exclude span query clause, needs to be set in constructor now.
Updated the static factory methods in QueryBuilders and tests accordingly.</simpara>
</section>
<section id="_spanwithinquerybuilder">
<title>SpanWithinQueryBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>Removed setters for mandatory big/little inner span queries. Both arguments now have
to be supplied at construction time already and have to be non-null. Updated
static factory methods in QueryBuilders accordingly.</simpara>
</section>
<section id="_wrapperquerybuilder">
<title>WrapperQueryBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>Removed <literal>wrapperQueryBuilder(byte[] source, int offset, int length)</literal>. Instead simply
use  <literal>wrapperQueryBuilder(byte[] source)</literal>. Updated the static factory methods in
QueryBuilders accordingly.</simpara>
</section>
<section id="_querystringquerybuilder">
<title>QueryStringQueryBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>Removed ability to pass in boost value using <literal>field(String field)</literal> method in form e.g. <literal>field^2</literal>.
Use the <literal>field(String, float)</literal> method instead.</simpara>
</section>
<section id="_operator">
<title>Operator<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>Removed the enums called <literal>Operator</literal> from <literal>MatchQueryBuilder</literal>, <literal>QueryStringQueryBuilder</literal>,
<literal>SimpleQueryStringBuilder</literal>, and <literal>CommonTermsQueryBuilder</literal> in favour of using the enum
defined in <literal>org.elasticsearch.index.query.Operator</literal> in an effort to consolidate the
codebase and avoid duplication.</simpara>
</section>
<section id="_queryname_and_boost_support">
<title>queryName and boost support<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>Support for <literal>queryName</literal> and <literal>boost</literal> has been streamlined to all of the queries. That is
a breaking change till queries get sent over the network as serialized json rather
than in <literal>Streamable</literal> format. In fact whenever additional fields are added to the json
representation of the query, older nodes might throw error when they find unknown fields.</simpara>
</section>
<section id="_innerhitsbuilder">
<title>InnerHitsBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>InnerHitsBuilder now has a dedicated addParentChildInnerHits and addNestedInnerHits methods
to differentiate between inner hits for nested vs. parent / child documents. This change
makes the type / path parameter mandatory.</simpara>
</section>
<section id="_matchquerybuilder">
<title>MatchQueryBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>Moving MatchQueryBuilder.Type and MatchQueryBuilder.ZeroTermsQuery enum to MatchQuery.Type.
Also reusing new Operator enum.</simpara>
</section>
<section id="_morelikethisquerybuilder">
<title>MoreLikeThisQueryBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>Removed <literal>MoreLikeThisQueryBuilder.Item#id(String id)</literal>, <literal>Item#doc(BytesReference doc)</literal>,
<literal>Item#doc(XContentBuilder doc)</literal>. Use provided constructors instead.</simpara>
<simpara>Removed <literal>MoreLikeThisQueryBuilder#addLike</literal> in favor of texts and/or items being provided
at construction time. Using arrays there instead of lists now.</simpara>
<simpara>Removed <literal>MoreLikeThisQueryBuilder#addUnlike</literal> in favor to using the <literal>unlike</literal> methods
which take arrays as arguments now rather than the lists used before.</simpara>
<simpara>The deprecated <literal>docs(Item... docs)</literal>, <literal>ignoreLike(Item... docs)</literal>,
<literal>ignoreLike(String... likeText)</literal>, <literal>addItem(Item... likeItems)</literal> have been removed.</simpara>
</section>
<section id="_geodistancequerybuilder">
<title>GeoDistanceQueryBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>Removing individual setters for lon() and lat() values, both values should be set together
 using point(lon, lat).</simpara>
</section>
<section id="_geodistancerangequerybuilder">
<title>GeoDistanceRangeQueryBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>Removing setters for to(Object &#8230;) and from(Object &#8230;) in favour of the only two allowed input
arguments (String, Number). Removing setter for center point (point(), geohash()) because parameter
is mandatory and should already be set in constructor.
Also removing setters for lt(), lte(), gt(), gte() since they can all be replaced by equivalent
calls to to/from() and inludeLower()/includeUpper().</simpara>
</section>
<section id="_geopolygonquerybuilder">
<title>GeoPolygonQueryBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>Require shell of polygon already to be specified in constructor instead of adding it pointwise.
This enables validation, but makes it necessary to remove the addPoint() methods.</simpara>
</section>
<section id="_multimatchquerybuilder">
<title>MultiMatchQueryBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>Moving MultiMatchQueryBuilder.ZeroTermsQuery enum to MatchQuery.ZeroTermsQuery.
Also reusing new Operator enum.</simpara>
<simpara>Removed ability to pass in boost value using <literal>field(String field)</literal> method in form e.g. <literal>field^2</literal>.
Use the <literal>field(String, float)</literal> method instead.</simpara>
</section>
<section id="_missingquerybuilder">
<title>MissingQueryBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>The MissingQueryBuilder which was deprecated in 2.2.0 is removed. As a replacement use ExistsQueryBuilder
inside a mustNot() clause. So instead of using <literal>new ExistsQueryBuilder(name)</literal> now use
<literal>new BoolQueryBuilder().mustNot(new ExistsQueryBuilder(name))</literal>.</simpara>
</section>
<section id="_notquerybuilder">
<title>NotQueryBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>The NotQueryBuilder which was deprecated in 2.1.0 is removed. As a replacement use BoolQueryBuilder
with added mustNot() clause. So instead of using <literal>new NotQueryBuilder(filter)</literal> now use
<literal>new BoolQueryBuilder().mustNot(filter)</literal>.</simpara>
</section>
<section id="_termsquerybuilder">
<title>TermsQueryBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>Remove the setter for <literal>termsLookup()</literal>, making it only possible to either use a TermsLookup object or
individual values at construction time. Also moving individual settings for the TermsLookup (lookupIndex,
lookupType, lookupId, lookupPath) to the separate TermsLookup class, using constructor only and moving
checks for validation there. Removed <literal>TermsLookupQueryBuilder</literal> in favour of <literal>TermsQueryBuilder</literal>.</simpara>
</section>
<section id="_functionscorequerybuilder">
<title>FunctionScoreQueryBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara><literal>add</literal> methods have been removed, all filters and functions must be provided as constructor arguments by
creating an array of <literal>FunctionScoreQueryBuilder.FilterFunctionBuilder</literal> objects, containing one element
for each filter/function pair.</simpara>
<simpara><literal>scoreMode</literal> and <literal>boostMode</literal> can only be provided using corresponding enum members instead
of string values: see <literal>FilterFunctionScoreQuery.ScoreMode</literal> and <literal>CombineFunction</literal>.</simpara>
<simpara><literal>CombineFunction.MULT</literal> has been renamed to <literal>MULTIPLY</literal>.</simpara>
</section>
<section id="_idsquerybuilder">
<title>IdsQueryBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>For simplicity, only one way of adding the ids to the existing list (empty by default)  is left: <literal>addIds(String...)</literal></simpara>
</section>
<section id="_shapebuilders">
<title>ShapeBuilders<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara><literal>InternalLineStringBuilder</literal> is removed in favour of <literal>LineStringBuilder</literal>, <literal>InternalPolygonBuilder</literal> in favour of PolygonBuilder` and <literal>Ring</literal> has been replaced with <literal>LineStringBuilder</literal>. Also the abstract base classes <literal>BaseLineStringBuilder</literal> and <literal>BasePolygonBuilder</literal> haven been merged with their corresponding implementations.</simpara>
</section>
<section id="_rescorebuilder">
<title>RescoreBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara><literal>RecoreBuilder.Rescorer</literal> was merged with <literal>RescoreBuilder</literal>, which now is an abstract superclass. QueryRescoreBuilder currently is its only implementation.</simpara>
</section>
<section id="_phrasesuggestionbuilder">
<title>PhraseSuggestionBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>The inner DirectCandidateGenerator class has been moved out to its own class called DirectCandidateGeneratorBuilder.</simpara>
</section>
<section id="_sortbuilders">
<title>SortBuilders<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>The <literal>sortMode</literal> setter in <literal>FieldSortBuilder</literal>, <literal>GeoDistanceSortBuilder</literal> and <literal>ScriptSortBuilder</literal> now
accept a <literal>SortMode</literal> enum instead of a String constant. Also the getter returns the same enum type.</simpara>
</section>
<section id="_suggestbuilder">
<title>SuggestBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>The <literal>setText</literal> method has been changed to <literal>setGlobalText</literal> to make the intent more clear, and a <literal>getGlobalText</literal> method has been added.</simpara>
<simpara>The <literal>addSuggestion</literal> method now required the user specified suggestion name, previously used in the ctor of each suggestion.</simpara>
</section>
<section id="_suggestionbuilder">
<title>SuggestionBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>The <literal>field</literal> setter has been deleted. Instead the field name needs to be specified as constructor argument.</simpara>
</section>
</section>
<section id="_searchsourcebuilder">
<title>SearchSourceBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>All methods which take an <literal>XContentBuilder</literal>, <literal>BytesReference</literal> <literal>Map&lt;String, Object&gt;</literal> or <literal>bytes[]</literal> have been removed in favor of providing the
relevant builder object for that feature (e.g. <literal>HighlightBuilder</literal>, <literal>AggregationBuilder</literal>, <literal>SuggestBuilder</literal>) . This means that all search requests
can now be validated at call time which results in much clearer errors.</simpara>
<simpara>The <literal>defaultResourceWindowSize(int)</literal> method has been removed. The window size should be set explicitly on all <literal>RescoreBuilder</literal> objects.</simpara>
</section>
<section id="_searchrequestbuilder">
<title>SearchRequestBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>All methods which take an <literal>XContentBuilder</literal>, <literal>BytesReference</literal> <literal>Map&lt;String, Object&gt;</literal> or <literal>bytes[]</literal> have been removed in favor of providing the
relevant builder object for that feature (e.g. <literal>HighlightBuilder</literal>, <literal>AggregationBuilder</literal>, <literal>SuggestBuilder</literal>) . This means that all search requests
can now be validated at call time which results in much clearer errors.</simpara>
<simpara>All highlighter methods have been removed in favor of a single <literal>highlighter(HighlightBuilder)</literal> method.</simpara>
<simpara>The <literal>setExtraSource(SearchSourceBuilder)</literal> method has been removed.</simpara>
<simpara>The <literal>setTemplateSource(String)</literal> and <literal>setTemplateSource(BytesReference)</literal> methods have been removed. Use <literal>setTemplate(Template)</literal> instead.</simpara>
<simpara><literal>setRescorer(Rescorer)</literal> and <literal>setRescorer(Rescorer, int)</literal> have been removed infavor of <literal>setRescorer(RescoreBuilder)</literal> and <literal>setRescorer(RescoreBuilder, int)</literal></simpara>
</section>
<section id="_searchrequest">
<title>SearchRequest<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>All <literal>source</literal> methods have been removed in favor of a single <literal>source(SearchSourceBuilder)</literal> method. This means that all search requests can now be validated
at call time which results in much clearer errors.</simpara>
<simpara>All <literal>extraSource</literal> methods have been removed.</simpara>
<simpara>All <literal>template</literal> methods have been removed in favor of a new Search Template API. A new <literal>SearchTemplateRequest</literal> now accepts a template and
a <literal>SearchRequest</literal> and must be executed using the new <literal>SearchTemplateAction</literal> action.</simpara>
</section>
<section id="_searchresponse">
<title>SearchResponse<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>Sort values for <literal>string</literal> fields are now return as <literal>java.lang.String</literal> objects rather than <literal>org.elasticsearch.common.text.Text</literal>.</simpara>
</section>
<section id="_aggregationbuilder">
<title>AggregationBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>All methods which take an <literal>XContentBuilder</literal>, <literal>BytesReference</literal> <literal>Map&lt;String, Object&gt;</literal> or <literal>bytes[]</literal> have been removed in favor of providing the
relevant builder object (i.e. <literal>subAggregation(AggregationBuilder)</literal> or <literal>subAggregation(PipelineAggregationBuilder)</literal>). This means that all
requests can now be validated at call time which results in much clearer errors.</simpara>
</section>
<section id="_validatequeryrequest">
<title>ValidateQueryRequest<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara><literal>source(QuerySourceBuilder)</literal>, <literal>source(Map)</literal>, <literal>source(XContentBuilder)</literal>, <literal>source(String)</literal>, <literal>source(byte[])</literal>, <literal>source(byte[], int, int)</literal>,
<literal>source(BytesReference)</literal> and <literal>source()</literal> have been removed in favor of using <literal>query(QueryBuilder)</literal> and <literal>query()</literal></simpara>
</section>
<section id="_validatequeryrequestbuilder">
<title>ValidateQueryRequestBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara><literal>setSource()</literal> methods have been removed in favor of using <literal>setQuery(QueryBuilder)</literal></simpara>
</section>
<section id="_explainrequest">
<title>ExplainRequest<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara><literal>source(QuerySourceBuilder)</literal>, <literal>source(Map)</literal>, <literal>source(BytesReference)</literal> and <literal>source()</literal> have been removed in favor of using
<literal>query(QueryBuilder)</literal> and <literal>query()</literal></simpara>
</section>
<section id="_explainrequestbuilder">
<title>ExplainRequestBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>The <literal>setQuery(BytesReference)</literal> method have been removed in favor of using <literal>setQuery(QueryBuilder)</literal></simpara>
</section>
<section id="_clusterstatsresponse">
<title>ClusterStatsResponse<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>Removed the <literal>getMemoryAvailable</literal> method from <literal>OsStats</literal>, which could be previously accessed calling
<literal>clusterStatsResponse.getNodesStats().getOs().getMemoryAvailable()</literal>. It is now replaced with
<literal>clusterStatsResponse.getNodesStats().getOs().getMem()</literal> which exposes <literal>getTotal()</literal>, <literal>getFree()</literal>,
<literal>getUsed()</literal>, <literal>getFreePercent()</literal> and <literal>getUsedPercent()</literal>.</simpara>
</section>
<section id="_setrefresh_boolean_has_been_removed">
<title>setRefresh(boolean) has been removed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara><literal>setRefresh(boolean)</literal> has been removed in favor of <literal>setRefreshPolicy(RefreshPolicy)</literal> because there
are now three options (NONE, IMMEDIATE, and WAIT_FOR). <literal>setRefresh(IMMEDIATE)</literal> has the same behavior
as <literal>setRefresh(true)</literal> used to have. See <literal>setRefreshPolicy</literal>'s javadoc for more.</simpara>
</section>
<section id="_remove_properties_support_2">
<title>Remove properties support<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>Some Java APIs (e.g., <literal>IndicesAdminClient#setSettings</literal>) would support Java properties syntax
(line-delimited key=value pairs). This support has been removed.</simpara>
</section>
<section id="_render_search_template_java_api_has_been_removed">
<title>Render Search Template Java API has been removed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>The Render Search Template Java API including <literal>RenderSearchTemplateAction</literal>, <literal>RenderSearchTemplateRequest</literal> and
<literal>RenderSearchTemplateResponse</literal> has been removed in favor of a new <literal>simulate</literal> option in the Search Template Java API.
 This Search Template API is now included in the <literal>lang-mustache</literal> module and the <literal>simulate</literal> flag must be set on the
 <literal>SearchTemplateRequest</literal> object.</simpara>
</section>
<section id="_analyzerequest">
<title>AnalyzeRequest<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>The <literal>tokenFilters(String...)</literal> and <literal>charFilters(String...)</literal> methods have been removed
in favor of using <literal>addTokenFilter(String)</literal>/<literal>addTokenFilter(Map)</literal> and <literal>addCharFilter(String)</literal>/<literal>addCharFilter(Map)</literal> each filters</simpara>
</section>
<section id="_analyzerequestbuilder">
<title>AnalyzeRequestBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>The <literal>setTokenFilters(String...)</literal> and <literal>setCharFilters(String...)</literal> methods have been removed
in favor of using <literal>addTokenFilter(String)</literal>/<literal>addTokenFilter(Map)</literal> and <literal>addCharFilter(String)</literal>/<literal>addCharFilter(Map)</literal> each filters</simpara>
</section>
<section id="_clusterhealthrequest">
<title>ClusterHealthRequest<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>The <literal>waitForRelocatingShards(int)</literal> method has been removed in favor of <literal>waitForNoRelocatingShards(boolean)</literal>
which instead uses a boolean flag to denote whether the cluster health operation should wait for there to
be no relocating shards in the cluster before returning.</simpara>
</section>
<section id="_clusterhealthrequestbuilder">
<title>ClusterHealthRequestBuilder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>The <literal>setWaitForRelocatingShards(int)</literal> method has been removed in favor of <literal>setWaitForNoRelocatingShards(boolean)</literal>
which instead uses a boolean flag to denote whether the cluster health operation should wait for there to
be no relocating shards in the cluster before returning.</simpara>
</section>
<section id="_blobcontainer_interface_for_snapshot_restore">
<title>BlobContainer Interface for Snapshot/Restore<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>Some methods have been removed from the <literal>BlobContainer</literal> interface for Snapshot/Restore repositories.  In particular,
the following three methods have been removed:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>
<literal>deleteBlobs(Collection&lt;String&gt;)</literal> (use <literal>deleteBlob(String)</literal> instead)
</simpara>
</listitem>
<listitem>
<simpara>
<literal>deleteBlobsByPrefix(String)</literal> (use <literal>deleteBlob(String)</literal> instead)
</simpara>
</listitem>
<listitem>
<simpara>
<literal>writeBlob(String, BytesReference)</literal> (use <literal>writeBlob(String, InputStream, long)</literal> instead)
</simpara>
</listitem>
</orderedlist>
<simpara>The <literal>deleteBlob</literal> methods that took multiple blobs as arguments were deleted because no atomic guarantees can be made about either deleting all blobs or deleting none of them, and exception handling in such a situation is ambiguous and best left to the caller. Hence, all delete blob calls use the singular <literal>deleteBlob(String)</literal> method.</simpara>
<simpara>The extra <literal>writeBlob</literal> method offered no real advantage to the interface and all calls to <literal>writeBlob(blobName, bytesRef)</literal> can be replaced with:</simpara>
<programlisting language="java" linenumbering="unnumbered">try (InputStream stream = bytesRef.streamInput()) {
    blobContainer.writeBlob(blobName, stream, bytesRef.length());
}</programlisting>
<simpara>For any custom implementation of the <literal>BlobContainer</literal> interface, these three methods must be removed.</simpara>
</section>
<section id="_nodebuilder_removed">
<title>NodeBuilder removed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/java.asciidoc">Edit me</ulink></title>
<simpara>NodeBuilder has been removed. While using Node directly within an application is not officially supported, it can still be constructed with the <literal>Node(Settings)</literal> constructor.</simpara>
</section>
</section>
<section id="breaking_50_packaging">
<title>Packaging<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/packaging.asciidoc">Edit me</ulink></title>
<section id="_apt_yum_repository_url_changes">
<title>APT/YUM repository URL changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/packaging.asciidoc">Edit me</ulink></title>
<simpara>The repository for apt and yum packages has changed from
<literal>https://packages.elastic.co</literal> to <literal>https://artifacts.elastic.co/</literal>.</simpara>
<simpara>Full details can be found in <xref linkend="install-elasticsearch"/>.</simpara>
</section>
<section id="_default_logging_using_systemd_since_elasticsearch_2_2_0">
<title>Default logging using systemd (since Elasticsearch 2.2.0)<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/packaging.asciidoc">Edit me</ulink></title>
<simpara>In previous versions of Elasticsearch, the default logging
configuration routed standard output to /dev/null and standard error to
the journal. However, there are often critical error messages at
startup that are logged to standard output rather than standard error
and these error messages would be lost to the nether. The default has
changed to now route standard output to the journal and standard error
to inherit this setting (these are the defaults for systemd). These
settings can be modified by editing the elasticsearch.service file.</simpara>
</section>
<section id="_longer_startup_times">
<title>Longer startup times<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/packaging.asciidoc">Edit me</ulink></title>
<simpara>In Elasticsearch 5.0.0 the <literal>-XX:+AlwaysPreTouch</literal> flag has been added to the JVM
startup options. This option touches all memory pages used by the JVM heap
during initialization of the HotSpot VM to reduce the chance of having to commit
a memory page during GC time. This will increase the startup time of
Elasticsearch as well as increasing the initial resident memory usage of the
Java process.</simpara>
</section>
<section id="_jvm_options">
<title>JVM options<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/packaging.asciidoc">Edit me</ulink></title>
<simpara>Arguments to the Java Virtual Machine have been centralized and moved
to a new configuration file jvm.options. This centralization allows for
simpler end-user management of JVM options.</simpara>
<simpara>This migration removes all previous mechanisms of setting JVM options
via the environment variables <literal>ES_MIN_MEM</literal>, <literal>ES_MAX_MEM</literal>,
<literal>ES_HEAP_SIZE</literal>, <literal>ES_HEAP_NEWSIZE</literal>, <literal>ES_DIRECT_SIZE</literal>, <literal>ES_USE_IPV4</literal>,
<literal>ES_GC_OPTS</literal>, <literal>ES_GC_LOG_FILE</literal>, and <literal>JAVA_OPTS</literal>.</simpara>
<simpara>The default location for this file is in config/jvm.options if installing
from the tar or zip distributions, and /etc/elasticsearch/jvm.options if installing
from the Debian or RPM packages. You can specify an alternative location by setting
the environment variable <literal>ES_JVM_OPTIONS</literal> to the path to the file.</simpara>
</section>
<section id="_thread_stack_size_for_the_windows_service">
<title>Thread stack size for the Windows service<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/packaging.asciidoc">Edit me</ulink></title>
<simpara>Previously when installing the Windows service, the installation script
would configure the thread stack size (this is required for the service
daemon). As a result of moving all JVM configuration to the
<link linkend="jvm-options">jvm.options file</link>, the service installation script no
longer configures the thread stack size. When installing the Windows
service, you must configure thread stack size. For additional details,
see the <link linkend="windows-service">installation docs</link>.</simpara>
</section>
<section id="_bin_bash_is_now_required">
<title>/bin/bash is now required<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/packaging.asciidoc">Edit me</ulink></title>
<simpara>Previously, the scripts used to start Elasticsearch and run plugin
commands only required a Bourne-compatible shell. Starting in
Elasticsearch 5.0.0, the bash shell is now required and <literal>/bin/bash</literal> is a
hard-dependency for the RPM and Debian packages.</simpara>
</section>
<section id="_environmental_settings">
<title>Environmental Settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/packaging.asciidoc">Edit me</ulink></title>
<simpara>Previously, Elasticsearch could be configured via environment variables
in two ways: first by using the placeholder syntax
<literal>${env.ENV_VAR_NAME}</literal> and the second by using the same syntax without
the <literal>env</literal> prefix: <literal>${ENV_VAR_NAME}</literal>. The first method has been removed
from Elasticsearch.</simpara>
<simpara>Additionally, it was previously possible to set any setting in
Elasticsearch via JVM system properties. This has been removed from
Elasticsearch.</simpara>
</section>
<section id="_dying_on_fatal_errors">
<title>Dying on fatal errors<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/packaging.asciidoc">Edit me</ulink></title>
<simpara>Previous versions of Elasticsearch would not halt the JVM if out of memory errors or other fatal
errors were encountered during the life of the Elasticsearch instance. Because such errors leave
the JVM in a questionable state, the best course of action is to halt the JVM when this occurs.
Starting in Elasticsearch 5.x, this is now the case. Operators should consider configuring their
Elasticsearch services so that they respawn automatically in the case of such a fatal crash.</simpara>
</section>
</section>
<section id="breaking_50_plugins">
<title>Plugin changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/plugins.asciidoc">Edit me</ulink></title>
<simpara>The command <literal>bin/plugin</literal> has been renamed to <literal>bin/elasticsearch-plugin</literal>. The
structure of the plugin ZIP archive has changed. All the plugin files must be
contained in a top-level directory called <literal>elasticsearch</literal>. If you use the
gradle build, this structure is automatically generated.</simpara>
<section id="_plugins_isolation">
<title>Plugins isolation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/plugins.asciidoc">Edit me</ulink></title>
<simpara><literal>isolated</literal> option has been removed. Each plugin will have its own classloader.</simpara>
</section>
<section id="_site_plugins_removed">
<title>Site plugins removed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/plugins.asciidoc">Edit me</ulink></title>
<simpara>Site plugins have been removed. Site plugins should be reimplemented as Kibana
plugins.</simpara>
</section>
<section id="_multicast_plugin_removed">
<title>Multicast plugin removed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/plugins.asciidoc">Edit me</ulink></title>
<simpara>Multicast has been removed. Use unicast discovery, or one of the cloud
discovery plugins.</simpara>
</section>
<section id="_plugins_with_custom_query_implementations">
<title>Plugins with custom query implementations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/plugins.asciidoc">Edit me</ulink></title>
<simpara>Plugins implementing custom queries need to implement the <literal>fromXContent(QueryParseContext)</literal> method in their
<literal>QueryParser</literal> subclass rather than <literal>parse</literal>. This method will take care of parsing the query from <literal>XContent</literal> format
into an intermediate query representation that can be streamed between the nodes in binary format, effectively the
query object used in the java api. Also, the query builder needs to be registered as a <literal>NamedWriteable</literal>. This is
all done by implementing the <literal>SearchPlugin</literal> interface and overriding the <literal>getQueries</literal> method.
The query object can then transform itself into a lucene query through the new <literal>toQuery(QueryShardContext)</literal> method,
which returns a lucene query to be executed on the data node.</simpara>
<simpara>Similarly, plugins implementing custom score functions need to implement the <literal>fromXContent(QueryParseContext)</literal>
method in their <literal>ScoreFunctionParser</literal> subclass rather than <literal>parse</literal>. This method will take care of parsing
the function from <literal>XContent</literal> format into an intermediate function representation that can be streamed between
the nodes in binary format, effectively the function object used in the java api. The function object can then
transform itself into a lucene function through the new <literal>toFunction(QueryShardContext)</literal> method, which returns
a lucene function to be executed on the data node.</simpara>
</section>
<section id="_cloud_aws_plugin_changes">
<title>Cloud AWS plugin changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/plugins.asciidoc">Edit me</ulink></title>
<simpara>Cloud AWS plugin has been split in two plugins:</simpara>
<itemizedlist>
<listitem>
<simpara>
<ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/discovery-ec2.html">Discovery EC2 plugin</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
<ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/repository-s3.html">Repository S3 plugin</ulink>
</simpara>
</listitem>
</itemizedlist>
<simpara>Proxy settings for both plugins have been renamed:</simpara>
<itemizedlist>
<listitem>
<simpara>
from <literal>cloud.aws.proxy_host</literal> to <literal>cloud.aws.proxy.host</literal>
</simpara>
</listitem>
<listitem>
<simpara>
from <literal>cloud.aws.ec2.proxy_host</literal> to <literal>cloud.aws.ec2.proxy.host</literal>
</simpara>
</listitem>
<listitem>
<simpara>
from <literal>cloud.aws.s3.proxy_host</literal> to <literal>cloud.aws.s3.proxy.host</literal>
</simpara>
</listitem>
<listitem>
<simpara>
from <literal>cloud.aws.proxy_port</literal> to <literal>cloud.aws.proxy.port</literal>
</simpara>
</listitem>
<listitem>
<simpara>
from <literal>cloud.aws.ec2.proxy_port</literal> to <literal>cloud.aws.ec2.proxy.port</literal>
</simpara>
</listitem>
<listitem>
<simpara>
from <literal>cloud.aws.s3.proxy_port</literal> to <literal>cloud.aws.s3.proxy.port</literal>
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_cloud_azure_plugin_changes">
<title>Cloud Azure plugin changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/plugins.asciidoc">Edit me</ulink></title>
<simpara>Cloud Azure plugin has been split in three plugins:</simpara>
<itemizedlist>
<listitem>
<simpara>
<ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/discovery-azure-classic.html">Discovery Azure plugin</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
<ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/repository-azure.html">Repository Azure plugin</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
<ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/store-smb.html">Store SMB plugin</ulink>
</simpara>
</listitem>
</itemizedlist>
<simpara>If you were using the <literal>cloud-azure</literal> plugin for snapshot and restore, you had in <literal>elasticsearch.yml</literal>:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">cloud:
    azure:
        storage:
            account: your_azure_storage_account
            key: your_azure_storage_key</programlisting>
<simpara>You need to give a unique id to the storage details now as you can define multiple storage accounts:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">cloud:
    azure:
        storage:
            my_account:
                account: your_azure_storage_account
                key: your_azure_storage_key</programlisting>
</section>
<section id="_cloud_gce_plugin_changes">
<title>Cloud GCE plugin changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/plugins.asciidoc">Edit me</ulink></title>
<simpara>Cloud GCE plugin has been renamed to <ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/discovery-gce.html">Discovery GCE plugin</ulink>.</simpara>
</section>
<section id="_delete_by_query_plugin_removed">
<title>Delete-By-Query plugin removed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/plugins.asciidoc">Edit me</ulink></title>
<simpara>The Delete-By-Query plugin has been removed in favor of a new <link linkend="docs-delete-by-query">Delete By Query API</link>
implementation in core. It now supports throttling, retries and cancellation but no longer supports timeouts.
Instead use the <link linkend="docs-delete-by-query-cancel-task-api">cancel API</link> to cancel deletes that run too long.</simpara>
</section>
<section id="_mapper_attachments_plugin_deprecated">
<title>Mapper Attachments plugin deprecated<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/plugins.asciidoc">Edit me</ulink></title>
<simpara>Mapper attachments has been deprecated. Users should use now the <ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/ingest-attachment.html"><literal>ingest-attachment</literal></ulink>
plugin.</simpara>
</section>
<section id="_passing_of_java_system_properties">
<title>Passing of Java System Properties<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/plugins.asciidoc">Edit me</ulink></title>
<simpara>Previously, Java system properties could be passed to the plugin
command by passing <literal>-D</literal> style arguments directly to the plugin script.
This is no longer permitted and such system properties must be passed
via ES_JAVA_OPTS.</simpara>
</section>
<section id="_custom_plugins_path">
<title>Custom plugins path<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/plugins.asciidoc">Edit me</ulink></title>
<simpara>The ability to specify a custom plugins path via <literal>path.plugins</literal> has
been removed.</simpara>
</section>
<section id="_scriptplugin">
<title>ScriptPlugin<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/plugins.asciidoc">Edit me</ulink></title>
<simpara>Plugins that register custom scripts should implement <literal>ScriptPlugin</literal> and remove
their <literal>onModule(ScriptModule)</literal> implementation.</simpara>
</section>
<section id="_analysisplugin">
<title>AnalysisPlugin<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/plugins.asciidoc">Edit me</ulink></title>
<simpara>Plugins that register custom analysis components should implement
<literal>AnalysisPlugin</literal> and remove their <literal>onModule(AnalysisModule)</literal> implementation.</simpara>
</section>
<section id="_mapperplugin">
<title>MapperPlugin<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/plugins.asciidoc">Edit me</ulink></title>
<simpara>Plugins that register custom mappers should implement
<literal>MapperPlugin</literal> and remove their <literal>onModule(IndicesModule)</literal> implementation.</simpara>
</section>
<section id="_actionplugin">
<title>ActionPlugin<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/plugins.asciidoc">Edit me</ulink></title>
<simpara>Plugins that register custom actions should implement <literal>ActionPlugin</literal> and
remove their <literal>onModule(ActionModule)</literal> implementation.</simpara>
<simpara>Plugins that register custom <literal>RestHandler`s should implement `ActionPlugin</literal> and
remove their <literal>onModule(NetworkModule)</literal> implemnetation.</simpara>
</section>
<section id="_searchplugin">
<title>SearchPlugin<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/plugins.asciidoc">Edit me</ulink></title>
<simpara>Plugins that register custom search time behavior (<literal>Query</literal>, <literal>Suggester</literal>,
<literal>ScoreFunction</literal>, <literal>FetchSubPhase</literal>, <literal>Highlighter</literal>, etc) should implement
<literal>SearchPlugin</literal> and remove their <literal>onModule(SearchModule)</literal> implementation.</simpara>
</section>
<section id="_searchparseelement">
<title>SearchParseElement<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/plugins.asciidoc">Edit me</ulink></title>
<simpara>The <literal>SearchParseElement</literal> interface has been removed. Custom search request
 sections can only be provided under the <literal>ext</literal> element. Plugins can
 plug in custom parsers for those additional sections by providing a
 <literal>SearchPlugin.SearchExtSpec</literal>, which consists of a <literal>SearchExtParser</literal>
 implementation that can parse`XContent` into a <literal>SearchExtBuilder</literal>
 implementation. The parsing happens now in the coordinating node. The
 result of parsing is serialized to the data nodes through transport layer
 together with the rest of the search request and stored in the search
 context for later retrieval.</simpara>
</section>
<section id="_testing_custom_plugins">
<title>Testing Custom Plugins<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/plugins.asciidoc">Edit me</ulink></title>
<simpara><literal>ESIntegTestCase#pluginList</literal> has been removed. Use <literal>Arrays.asList</literal> instead. It
isn&#8217;t needed now that all plugins require Java 1.8.</simpara>
</section>
<section id="_mapper_size_plugin">
<title>Mapper-Size plugin<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/plugins.asciidoc">Edit me</ulink></title>
<simpara>The metadata field <literal>_size</literal> is not accessible in aggregations, scripts and when
sorting for indices created in 2.x.
If these features are needed in your application it is required to reindex the data with Elasticsearch 5.x.</simpara>
</section>
</section>
<section id="breaking_50_fs">
<title>Filesystem related changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/fs.asciidoc">Edit me</ulink></title>
<simpara>Only a subset of index files were open with <literal>mmap</literal> on Elasticsearch 2.x. As of
Elasticsearch 5.0, all index files will be open with <literal>mmap</literal> on 64-bit systems.
While this may increase the amount of virtual memory used by Elasticsearch,
there is nothing to worry about since this is only address space consumption
and the actual memory usage of Elasticsearch will stay similar to what it was
in 2.x. See <ulink url="http://blog.thetaphi.de/2012/07/use-lucenes-mmapdirectory-on-64bit.html">http://blog.thetaphi.de/2012/07/use-lucenes-mmapdirectory-on-64bit.html</ulink>
for more information.</simpara>
</section>
<section id="_path_to_data_on_disk">
<title>Path to data on disk<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/fs.asciidoc">Edit me</ulink></title>
<simpara>In prior versions of Elasticsearch, the <literal>path.data</literal> directory included a folder
for the cluster name, so that data was in a folder such as
<literal>$DATA_DIR/$CLUSTER_NAME/nodes/$nodeOrdinal</literal>. In 5.0 the cluster name as a
directory is deprecated. Data will now be stored in
<literal>$DATA_DIR/nodes/$nodeOrdinal</literal> if there is no existing data. Upon startup,
Elasticsearch will check to see if the cluster folder exists and has data, and
will read from it if necessary. In Elasticsearch 6.0 this backwards-compatible
behavior will be removed.</simpara>
<simpara>If you are using a multi-cluster setup with both instances of Elasticsearch
pointing to the same data path, you will need to add the cluster name to the
data path so that different clusters do not overwrite data.</simpara>
<section id="_local_files">
<title>Local files<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/fs.asciidoc">Edit me</ulink></title>
<simpara>Prior to 5.0, nodes that were marked with both <literal>node.data: false</literal> and <literal>node.master: false</literal> (or the now removed <literal>node.client: true</literal>)
didn&#8217;t write any files or folder to disk. 5.x added persistent node ids, requiring nodes to store that information. As such, all
node types will write a small state file to their data folders.</simpara>
</section>
</section>
<section id="breaking_50_aggregations_changes">
<title>Aggregation changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/aggregations.asciidoc">Edit me</ulink></title>
<section id="_significant_terms_on_numeric_fields">
<title>Significant terms on numeric fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/aggregations.asciidoc">Edit me</ulink></title>
<simpara>Numeric fields have been refactored to use a different data structure that
performs better for range queries. However, since this data structure does
not record document frequencies, numeric fields need to fall back to running
queries in order to estimate the number of matching documents in the
background set, which may incur a performance degradation.</simpara>
<simpara>It is recommended to use <link linkend="keyword"><literal>keyword</literal></link> fields instead, either directly
or through a <link linkend="multi-fields">multi-field</link> if the numeric representation is
still needed for sorting, range queries or numeric aggregations like
<link linkend="search-aggregations-metrics-stats-aggregation"><literal>stats</literal> aggregations</link>.</simpara>
</section>
<section id="_literal_ip_range_literal_aggregations">
<title><literal>ip_range</literal> aggregations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/aggregations.asciidoc">Edit me</ulink></title>
<simpara>Now that Elasticsearch supports <literal>ipv6</literal>, <literal>ip</literal> addresses are encoded in the index
using a binary representation rather than a numeric representation. As a
consequence, the output of <literal>ip_range</literal> aggregations does not give numeric values
for <literal>from</literal> and <literal>to</literal> anymore.</simpara>
</section>
<section id="_literal_size_0_literal_on_terms_significant_terms_and_geohash_grid_aggregations">
<title><literal>size: 0</literal> on Terms, Significant Terms and Geohash Grid Aggregations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/aggregations.asciidoc">Edit me</ulink></title>
<simpara><literal>size: 0</literal> is no longer valid for the terms, significant terms and geohash grid
aggregations. Instead a size should be explicitly specified with a number greater
than zero.</simpara>
</section>
<section id="_fractional_time_values">
<title>Fractional time values<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/aggregations.asciidoc">Edit me</ulink></title>
<simpara>Fractional time values (e.g., 0.5s) are no longer supported. For example, this means when setting
date histogram intervals "1.5h" will be rejected and should instead be input as "90m".</simpara>
</section>
</section>
<section id="breaking_50_scripting">
<title>Script related changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/scripting.asciidoc">Edit me</ulink></title>
<section id="_switched_default_language_from_groovy_to_painless">
<title>Switched Default Language from Groovy to Painless<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/scripting.asciidoc">Edit me</ulink></title>
<simpara>The default scripting language for Elasticsearch is now Painless.  Painless is a custom-built language with syntax
similar to Groovy designed to be fast as well as secure.  Many Groovy scripts will be identitical to Painless scripts
to help make the transition between languages as simple as possible.</simpara>
<simpara>Documentation for Painless can be found at <link linkend="modules-scripting-painless">Painless Scripting Language</link></simpara>
<simpara>One common difference to note between Groovy and Painless is the use of parameters&#8201;&#8212;&#8201;all parameters in Painless
must be prefixed with <literal>params.</literal> now.  The following example shows the difference:</simpara>
<simpara>Groovy:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "script_score": {
    "script": {
      "lang": "groovy",
      "inline": "Math.log(_score * 2) + my_modifier",
      "params": {
        "my_modifier": 8
      }
    }
  }
}</programlisting>
<simpara>Painless (<literal>my_modifer</literal> is prefixed with <literal>params</literal>):</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "script_score": {
    "script": {
      "lang": "painless",
      "inline": "Math.log(_score * 2) + params.my_modifier",
      "params": {
        "my_modifier": 8
      }
    }
  }
}</programlisting>
<simpara>The <literal>script.default_lang</literal> setting has been removed. It is no longer possible set the default scripting language. If a
different language than <literal>painless</literal> is used then this should be explicitly specified on the script itself.</simpara>
<simpara>For scripts with no explicit language defined, that are part of already stored percolator queries, the default language
can be controlled with the <literal>script.legacy.default_lang</literal> setting.</simpara>
</section>
<section id="_removed_1_x_script_and_template_syntax">
<title>Removed 1.x script and template syntax<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/scripting.asciidoc">Edit me</ulink></title>
<simpara>The deprecated 1.x syntax of defining inline scripts / templates and referring to file or index base scripts / templates
have been removed.</simpara>
<simpara>The <literal>script</literal> and <literal>params</literal> string parameters can no longer be used and instead the <literal>script</literal> object syntax must be used.
This applies for the update api, script sort, <literal>script_score</literal> function, <literal>script</literal> query, <literal>scripted_metric</literal> aggregation and
<literal>script_heuristic</literal> aggregation.</simpara>
<simpara>So this usage of inline scripts is no longer allowed:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "script_score": {
    "lang": "groovy",
    "script": "Math.log(_score * 2) + my_modifier",
    "params": {
      "my_modifier": 8
    }
  }
}</programlisting>
<simpara>and instead this syntax must be used:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "script_score": {
    "script": {
      "lang": "groovy",
      "inline": "Math.log(_score * 2) + my_modifier",
      "params": {
        "my_modifier": 8
      }
    }
  }
}</programlisting>
<simpara>The <literal>script</literal> or <literal>script_file</literal> parameter can no longer be used to refer to file based scripts and templates and instead
<literal>file</literal> must be used.</simpara>
<simpara>This usage of referring to file based scripts is no longer valid:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "script_score": {
    "script": "calculate-score",
    "params": {
      "my_modifier": 8
    }
  }
}</programlisting>
<simpara>This usage is valid:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "script_score": {
    "script": {
      "lang": "groovy",
      "file": "calculate-score",
      "params": {
        "my_modifier": 8
      }
    }
  }
}</programlisting>
<simpara>The <literal>script_id</literal> parameter can no longer be used the refer to indexed based scripts and templates and instead <literal>id</literal> must
be used.</simpara>
<simpara>This usage of referring to indexed scripts is no longer valid:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "script_score": {
    "script_id": "indexedCalculateScore",
    "params": {
      "my_modifier": 8
    }
  }
}</programlisting>
<simpara>This usage is valid:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "script_score": {
    "script": {
      "id": "indexedCalculateScore",
      "lang" : "groovy",
      "params": {
        "my_modifier": 8
      }
    }
  }
}</programlisting>
</section>
<section id="_template_query">
<title>Template query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/scripting.asciidoc">Edit me</ulink></title>
<simpara>The <literal>query</literal> field in the <literal>template</literal> query can no longer be used.
This 1.x syntax can no longer be used:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "query": {
        "template": {
            "query": {"match_{{template}}": {}},
            "params" : {
                "template" : "all"
            }
        }
    }
}</programlisting>
<simpara>and instead the following syntax should be used:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "query": {
        "template": {
            "inline": {"match_{{template}}": {}},
            "params" : {
                "template" : "all"
            }
        }
    }
}</programlisting>
</section>
<section id="_search_templates">
<title>Search templates<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/scripting.asciidoc">Edit me</ulink></title>
<simpara>The top level <literal>template</literal> field in the search template api has been replaced with consistent template / script object
syntax. This 1.x syntax can no longer be used:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "template" : {
        "query": { "match" : { "{{my_field}}" : "{{my_value}}" } },
        "size" : "{{my_size}}"
    },
    "params" : {
        "my_field" : "foo",
        "my_value" : "bar",
        "my_size" : 5
    }
}</programlisting>
<simpara>and instead the following syntax should be used:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "inline" : {
        "query": { "match" : { "{{my_field}}" : "{{my_value}}" } },
        "size" : "{{my_size}}"
    },
    "params" : {
        "my_field" : "foo",
        "my_value" : "bar",
        "my_size" : 5
    }
}</programlisting>
</section>
<section id="_indexed_scripts_and_templates">
<title>Indexed scripts and templates<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/scripting.asciidoc">Edit me</ulink></title>
<simpara>Indexed scripts and templates have been replaced by <link linkend="modules-scripting-stored-scripts">stored scripts</link>
which stores the scripts and templates in the cluster state instead of a dedicate <literal>.scripts</literal> index.</simpara>
<simpara>For the size of stored scripts there is a soft limit of 65535 bytes. If scripts exceed that size then
the <literal>script.max_size_in_bytes</literal> setting can be added to elasticsearch.yml to change the soft limit to a higher value.
If scripts are really large, other options like native scripts should be considered.</simpara>
<simpara>Previously indexed scripts in the <literal>.scripts</literal> index will not be used any more as
Elasticsearch will now try to fetch the scripts from the cluster state. Upon upgrading
to 5.x the <literal>.scripts</literal> index will remain to exist, so it can be used by a script to migrate
the stored scripts from the <literal>.scripts</literal> index into the cluster state. The current format of the scripts
and templates hasn&#8217;t been changed, only the 1.x format has been removed.</simpara>
<section id="_python_migration_script">
<title>Python migration script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/scripting.asciidoc">Edit me</ulink></title>
<simpara>The following Python script can be used to import your indexed scripts into the cluster state
as stored scripts:</simpara>
<programlisting language="python" linenumbering="unnumbered">from elasticsearch import Elasticsearch,helpers

es = Elasticsearch([
        {'host': 'localhost'}
])

for doc in helpers.scan(es, index=".scripts", preserve_order=True):
        es.put_script(lang=doc['_type'], id=doc['_id'], body=doc['_source'])</programlisting>
<simpara>This script makes use of the official Elasticsearch Python client and
therefore you need to make sure that your have installed the client in your
environment. For more information on this please see
<ulink url="https://www.elastic.co/guide/en/elasticsearch/client/python-api/current/index.html"><literal>elasticsearch-py</literal></ulink>.</simpara>
</section>
<section id="_perl_migration_script">
<title>Perl migration script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/scripting.asciidoc">Edit me</ulink></title>
<simpara>The following Perl script can be used to import your indexed scripts into the cluster state
as stored scripts:</simpara>
<programlisting language="perl" linenumbering="unnumbered">use Search::Elasticsearch;

my $es     = Search::Elasticsearch-&gt;new( nodes =&gt; 'localhost:9200');
my $scroll = $es-&gt;scroll_helper( index =&gt; '.scripts', sort =&gt; '_doc');

while (my $doc = $scroll-&gt;next) {
  $e-&gt;put_script(
    lang =&gt; $doc-&gt;{_type},
    id   =&gt; $doc-&gt;{_id},
    body =&gt; $doc-&gt;{_source}
  );
}</programlisting>
<simpara>This script makes use of the official Elasticsearch Perl client and
therefore you need to make sure that your have installed the client in your
environment. For more information on this please see
<ulink url="https://metacpan.org/pod/Search::Elasticsearch"><literal>Search::Elasticsearch</literal></ulink>.</simpara>
</section>
<section id="_verifying_script_migration">
<title>Verifying script migration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/scripting.asciidoc">Edit me</ulink></title>
<simpara>After you have moved the scripts via the provided script or otherwise then you can verify with the following
request if the migration has happened successfully:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _cluster/state?filter_path=metadata.stored_scripts</programlisting>
<simpara>The response should include all your scripts from the <literal>.scripts</literal> index.
After you have verified that all your scripts have been moved, optionally as a last step,
you can delete the <literal>.scripts</literal> index as Elasticsearch no longer uses it.</simpara>
</section>
</section>
<section id="_indexed_scripts_java_apis">
<title>Indexed scripts Java APIs<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/scripting.asciidoc">Edit me</ulink></title>
<simpara>All the methods related to interacting with indexed scripts have been removed.
The Java API methods for interacting with stored scripts have been added under <literal>ClusterAdminClient</literal> class.
The sugar methods that used to exist on the indexed scripts API methods don&#8217;t exist on the methods for
stored scripts. The only way to provide scripts is by using <literal>BytesReference</literal> implementation, if a string needs to be
provided the <literal>BytesArray</literal> class should be used.</simpara>
</section>
<section id="_scripting_engines_now_register_only_a_single_language">
<title>Scripting engines now register only a single language<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/scripting.asciidoc">Edit me</ulink></title>
<simpara>Prior to 5.0.0, script engines could register multiple languages. The Javascript
script engine in particular registered both <literal>"lang": "js"</literal> and <literal>"lang":
"javascript"</literal>. Script engines can now only register a single language. All
references to <literal>"lang": "js"</literal> should be changed to <literal>"lang": "javascript"</literal> for
existing users of the lang-javascript plugin.</simpara>
</section>
<section id="_scripting_engines_now_register_only_a_single_extension">
<title>Scripting engines now register only a single extension<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/scripting.asciidoc">Edit me</ulink></title>
<simpara>Prior to 5.0.0 scripting engines could register multiple extensions. The only
engine doing this was the Javascript engine, which registered "js" and
"javascript". It now only registers the "js" file extension for on-disk scripts.</simpara>
</section>
<section id="_literal_javascript_literal_files_are_no_longer_supported_use_literal_js_literal">
<title><literal>.javascript</literal> files are no longer supported (use <literal>.js</literal>)<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/scripting.asciidoc">Edit me</ulink></title>
<simpara>The Javascript engine previously registered "js" and "javascript". It now only
registers the "js" file extension for on-disk scripts.</simpara>
</section>
<section id="_removed_scripting_query_string_parameters_from_update_rest_api">
<title>Removed scripting query string parameters from update rest api<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/scripting.asciidoc">Edit me</ulink></title>
<simpara>The <literal>script</literal>, <literal>script_id</literal> and <literal>scripting_upsert</literal> query string parameters have been removed from the update api.</simpara>
</section>
<section id="_java_transport_client">
<title>Java transport client<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/scripting.asciidoc">Edit me</ulink></title>
<simpara>The <literal>TemplateQueryBuilder</literal> has been moved to the <literal>lang-mustache</literal> module.
Therefor when using the <literal>TemplateQueryBuilder</literal> from the Java native client the
lang-mustache module should be on the classpath. Also the transport client
should load the lang-mustache module as plugin:</simpara>
<programlisting language="java" linenumbering="unnumbered">TransportClient transportClient = TransportClient.builder()
        .settings(Settings.builder().put("node.name", "node"))
        .addPlugin(MustachePlugin.class)
        .build();
transportClient.addTransportAddress(
        new InetSocketTransportAddress(new InetSocketAddress(InetAddresses.forString("127.0.0.1"), 9300))
);</programlisting>
<simpara>Also the helper methods in <literal>QueryBuilders</literal> class that create a <literal>TemplateQueryBuilder</literal> instance have been removed,
instead the constructors on <literal>TemplateQueryBuilder</literal> should be used.</simpara>
</section>
<section id="_template_query_2">
<title>Template query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/scripting.asciidoc">Edit me</ulink></title>
<simpara>The <literal>template</literal> query has been deprecated in favour of the search template api. The <literal>template</literal> query is scheduled
to be removed in the next major version.</simpara>
</section>
<section id="_geopoint_scripts">
<title>GeoPoint scripts<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/migration/migrate_5_0/scripting.asciidoc">Edit me</ulink></title>
<simpara>The following helper methods have been removed from GeoPoint scripting:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>factorDistance</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>factorDistanceWithDefault</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>factorDistance02</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>factorDistance13</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>arcDistanceInKm</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>arcDistanceInKmWithDefault</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>arcDistanceInMiles</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>arcDistanceInMilesWithDefault</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>distanceWithDefault</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>distanceInKm</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>distanceInKmWithDefault</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>distanceInMiles</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>distanceInMilesWithDefault</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>geohashDistanceInKm</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>geohashDistanceInMiles</literal>
</simpara>
</listitem>
</itemizedlist>
<simpara>Instead use <literal>arcDistance</literal>, <literal>arcDistanceWithDefault</literal>, <literal>planeDistance</literal>, <literal>planeDistanceWithDefault</literal>, <literal>geohashDistance</literal>,
<literal>geohashDistanceWithDefault</literal> and convert from default units (meters) to desired units using the appropriate constance
(e.g., multiply by <literal>0.001</literal> to convert to Km).</simpara>
</section>
</section>
</chapter>
</part>
<part id="api-conventions">
<title>API Conventions <ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/api-conventions.asciidoc">Edit me</ulink></title>
<partintro>
<simpara>The <emphasis role="strong">elasticsearch</emphasis> REST APIs are exposed using <link linkend="modules-http">JSON over HTTP</link>.</simpara>
<simpara>The conventions listed in this chapter can be applied throughout the REST
API, unless otherwise specified.</simpara>
<itemizedlist>
<listitem>
<simpara>
<xref linkend="multi-index"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="date-math-index-names"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="common-options"/>
</simpara>
</listitem>
</itemizedlist>
</partintro>
<chapter id="multi-index">
<title>Multiple Indices<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/api-conventions.asciidoc">Edit me</ulink></title>
<simpara>Most APIs that refer to an <literal>index</literal> parameter support execution across multiple indices,
using simple <literal>test1,test2,test3</literal> notation (or <literal>_all</literal> for all indices). It also
support wildcards, for example: <literal>test*</literal> or <literal>*test</literal> or <literal>te*t</literal> or <literal>*test*</literal>, and the ability to "add" (<literal>+</literal>)
and "remove" (<literal>-</literal>), for example: <literal>+test*,-test3</literal>.</simpara>
<simpara>All multi indices API support the following url query string parameters:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>ignore_unavailable</literal>
</term>
<listitem>
<simpara>
Controls whether to ignore if any specified indices are unavailable, this
includes indices that don&#8217;t exist or closed indices. Either <literal>true</literal> or <literal>false</literal>
can be specified.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>allow_no_indices</literal>
</term>
<listitem>
<simpara>
Controls whether to fail if a wildcard indices expressions results into no
concrete indices. Either <literal>true</literal> or <literal>false</literal> can be specified. For example if
the wildcard expression <literal>foo*</literal> is specified and no indices are available that
start with <literal>foo</literal> then depending on this setting the request will fail. This
setting is also applicable when <literal>_all</literal>, <literal>*</literal> or no index has been specified. This
settings also applies for aliases, in case an alias points to a closed index.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>expand_wildcards</literal>
</term>
<listitem>
<simpara>
Controls to what kind of concrete indices wildcard indices expression expand
to. If <literal>open</literal> is specified then the wildcard expression is expanded to only
open indices and if <literal>closed</literal> is specified then the wildcard expression is
expanded only to closed indices. Also both values (<literal>open,closed</literal>) can be
specified to expand to all indices.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>If <literal>none</literal> is specified then wildcard expansion will be disabled and if <literal>all</literal>
is specified, wildcard expressions will expand to all indices (this is equivalent
to specifying <literal>open,closed</literal>).</simpara>
<simpara>The defaults settings for the above parameters depend on the api being used.</simpara>
<note><simpara>Single index APIs such as the <xref linkend="docs"/> and the
<link linkend="indices-aliases">single-index <literal>alias</literal> APIs</link> do not support multiple indices.</simpara></note>
</chapter>
<chapter id="date-math-index-names">
<title>Date math support in index names<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/api-conventions.asciidoc">Edit me</ulink></title>
<simpara>Date math index name resolution enables you to search a range of time-series indices, rather
than searching all of your time-series indices and filtering the results or maintaining aliases.
Limiting the number of indices that are searched reduces the load on the cluster and improves
execution performance. For example, if you are searching for errors in your
daily logs, you can use a date math name template to restrict the search to the past
two days.</simpara>
<simpara>Almost all APIs that have an <literal>index</literal> parameter, support date math in the <literal>index</literal> parameter
value.</simpara>
<simpara>A date math index name takes the following form:</simpara>
<programlisting language="txt" linenumbering="unnumbered">&lt;static_name{date_math_expr{date_format|time_zone}}&gt;</programlisting>
<simpara>Where:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>static_name</literal>
</simpara>
</entry>
<entry>
<simpara>
is the static text part of the name
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>date_math_expr</literal>
</simpara>
</entry>
<entry>
<simpara>
is a dynamic date math expression that computes the date dynamically
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>date_format</literal>
</simpara>
</entry>
<entry>
<simpara>
is the optional format in which the computed date should be rendered. Defaults to <literal>YYYY.MM.dd</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>time_zone</literal>
</simpara>
</entry>
<entry>
<simpara>
is the optional time zone . Defaults to <literal>utc</literal>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>You must enclose date math index name expressions within angle brackets, and
all special characters should be URI encoded. For example:</simpara>
<programlisting language="js" linenumbering="unnumbered"># GET /&lt;logstash-{now/d}&gt;/_search
GET /%3Clogstash-%7Bnow%2Fd%7D%3E/_search
{
  "query" : {
    "match": {
      "test": "data"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT logstash-2016.09.20\n/]</remark>
<remark> TEST[s/now/2016.09.20||/]</remark>
<note>
<title>Percent encoding of date math characters</title>
<simpara>The special characters used for date rounding must be URI encoded as follows:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>&lt;</literal>
</simpara>
</entry>
<entry>
<simpara>
<literal>%3C</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>&gt;</literal>
</simpara>
</entry>
<entry>
<simpara>
<literal>%3E</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>/</literal>
</simpara>
</entry>
<entry>
<simpara>
<literal>%2F</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>{</literal>
</simpara>
</entry>
<entry>
<simpara>
<literal>%7B</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>}</literal>
</simpara>
</entry>
<entry>
<simpara>
<literal>%7D</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>|</literal>
</simpara>
</entry>
<entry>
<simpara>
<literal>%7C</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>+</literal>
</simpara>
</entry>
<entry>
<simpara>
<literal>%2B</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>:</literal>
</simpara>
</entry>
<entry>
<simpara>
<literal>%3A</literal>
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</note>
<simpara>The following example shows different forms of date math index names and the final index names
they resolve to given the current time is 22rd March 2024 noon utc.</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top"> Expression                                </entry>
<entry align="left" valign="top">Resolves to</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>&lt;logstash-{now/d}&gt;</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>logstash-2024.03.22</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>&lt;logstash-{now/M}&gt;</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>logstash-2024.03.01</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>&lt;logstash-{now/M{YYYY.MM}}&gt;</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>logstash-2024.03</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>&lt;logstash-{now/M-1M{YYYY.MM}}&gt;</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>logstash-2024.02</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>&lt;logstash-{now/d{YYYY.MM.dd|+12:00}}&gt;</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>logstash-2024.03.23</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>To use the characters <literal>{</literal> and <literal>}</literal> in the static part of an index name template, escape them
with a backslash <literal>\</literal>, for example:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>&lt;elastic\\{ON\\}-{now/M}&gt;</literal> resolves to <literal>elastic{ON}-2024.03.01</literal>
</simpara>
</listitem>
</itemizedlist>
<simpara>The following example shows a search request that searches the Logstash indices for the past
three days, assuming the indices use the default Logstash index name format,
<literal>logstash-YYYY.MM.dd</literal>.</simpara>
<programlisting language="js" linenumbering="unnumbered"># GET /&lt;logstash-{now/d-2d}&gt;,&lt;logstash-{now/d-1d}&gt;,&lt;logstash-{now/d}&gt;/_search
GET /%3Clogstash-%7Bnow%2Fd-2d%7D%3E%2C%3Clogstash-%7Bnow%2Fd-1d%7D%3E%2C%3Clogstash-%7Bnow%2Fd%7D%3E/_search
{
  "query" : {
    "match": {
      "test": "data"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT logstash-2016.09.20\nPUT logstash-2016.09.19\nPUT logstash-2016.09.18\n/]</remark>
<remark> TEST[s/now/2016.09.20||/]</remark>
</chapter>
<chapter id="common-options">
<title>Common options<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/api-conventions.asciidoc">Edit me</ulink></title>
<simpara>The following options can be applied to all of the REST APIs.</simpara>
<bridgehead id="_pretty_results" renderas="sect2">Pretty Results<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/api-conventions.asciidoc">Edit me</ulink></bridgehead>
<simpara>When appending <literal>?pretty=true</literal> to any request made, the JSON returned
will be pretty formatted (use it for debugging only!). Another option is
to set <literal>?format=yaml</literal> which will cause the result to be returned in the
(sometimes) more readable yaml format.</simpara>
<bridgehead id="_human_readable_output" renderas="sect2">Human readable output<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/api-conventions.asciidoc">Edit me</ulink></bridgehead>
<simpara>Statistics are returned in a format suitable for humans
(eg <literal>"exists_time": "1h"</literal> or <literal>"size": "1kb"</literal>) and for computers
(eg <literal>"exists_time_in_millis": 3600000</literal> or <literal>"size_in_bytes": 1024</literal>).
The human readable values can be turned off by adding <literal>?human=false</literal>
to the query string. This makes sense when the stats results are
being consumed by a monitoring tool, rather than intended for human
consumption.  The default for the <literal>human</literal> flag is
<literal>false</literal>.</simpara>
<bridgehead id="date-math" renderas="sect2">Date Math<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/api-conventions.asciidoc">Edit me</ulink></bridgehead>
<simpara>Most parameters which accept a formatted date value&#8201;&#8212;&#8201;such as <literal>gt</literal> and <literal>lt</literal>
in <link linkend="query-dsl-range-query">range queries</link> <literal>range</literal> queries, or <literal>from</literal> and <literal>to</literal>
in <link linkend="search-aggregations-bucket-daterange-aggregation"><literal>daterange</literal> aggregations</link>&#8201;&#8212;&#8201;understand date maths.</simpara>
<simpara>The expression starts with an anchor date, which can either be <literal>now</literal>, or a
date string ending with <literal>||</literal>. This anchor date can optionally be followed by
one or more maths expressions:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>+1h</literal> - add one hour
</simpara>
</listitem>
<listitem>
<simpara>
<literal>-1d</literal> - subtract one day
</simpara>
</listitem>
<listitem>
<simpara>
<literal>/d</literal>  - round down to the nearest day
</simpara>
</listitem>
</itemizedlist>
<simpara>The supported time units differ than those supported by <link linkend="time-units">time units</link> for durations.
The supported units are:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>y</literal>
</simpara>
</entry>
<entry>
<simpara>
years
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>M</literal>
</simpara>
</entry>
<entry>
<simpara>
months
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>w</literal>
</simpara>
</entry>
<entry>
<simpara>
weeks
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>d</literal>
</simpara>
</entry>
<entry>
<simpara>
days
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>h</literal>
</simpara>
</entry>
<entry>
<simpara>
hours
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>H</literal>
</simpara>
</entry>
<entry>
<simpara>
hours
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>m</literal>
</simpara>
</entry>
<entry>
<simpara>
minutes
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>s</literal>
</simpara>
</entry>
<entry>
<simpara>
seconds
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>Some examples are:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>now+1h</literal>
</simpara>
</entry>
<entry>
<simpara>
The current time plus one hour, with ms resolution.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>now+1h+1m</literal>
</simpara>
</entry>
<entry>
<simpara>
The current time plus one hour plus one minute, with ms resolution.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>now+1h/d</literal>
</simpara>
</entry>
<entry>
<simpara>
The current time plus one hour, rounded down to the nearest day.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>2015-01-01||+1M/d</literal>
</simpara>
</entry>
<entry>
<simpara>
<literal>2015-01-01</literal> plus one month, rounded down to the nearest day.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="common-options-response-filtering" renderas="sect2">Response Filtering<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/api-conventions.asciidoc">Edit me</ulink></bridgehead>
<simpara>All REST APIs accept a <literal>filter_path</literal> parameter that can be used to reduce
the response returned by elasticsearch. This parameter takes a comma
separated list of filters expressed with the dot notation:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search?q=elasticsearch&amp;filter_path=took,hits.hits._id,hits.hits._score</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>Responds:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "took" : 3,
  "hits" : {
    "hits" : [
      {
        "_id" : "0",
        "_score" : 1.6375021
      }
    ]
  }
}</programlisting>
<remark> TESTRESPONSE[s/"took" : 3/"took" : $body.took/]</remark>
<remark> TESTRESPONSE[s/1.6375021/$body.hits.hits.0._score/]</remark>
<simpara>It also supports the <literal>*</literal> wildcard character to match any field or part
of a field&#8217;s name:</simpara>
<programlisting language="sh" linenumbering="unnumbered">GET /_cluster/state?filter_path=metadata.indices.*.stat*</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT twitter\n/]</remark>
<simpara>Responds:</simpara>
<programlisting language="sh" linenumbering="unnumbered">{
  "metadata" : {
    "indices" : {
      "twitter": {"state": "open"}
    }
  }
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>And the <literal>**</literal> wildcard can be used to include fields without knowing the
exact path of the field. For example, we can return the Lucene version
of every segment with this request:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cluster/state?filter_path=routing_table.indices.**.state</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT twitter\n/]</remark>
<simpara>Responds:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "routing_table": {
    "indices": {
      "twitter": {
        "shards": {
          "0": [{"state": "STARTED"}, {"state": "UNASSIGNED"}],
          "1": [{"state": "STARTED"}, {"state": "UNASSIGNED"}],
          "2": [{"state": "STARTED"}, {"state": "UNASSIGNED"}],
          "3": [{"state": "STARTED"}, {"state": "UNASSIGNED"}],
          "4": [{"state": "STARTED"}, {"state": "UNASSIGNED"}]
        }
      }
    }
  }
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>It is also possible to exclude one or more fields by prefixing the filter with the char <literal>-</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_count?filter_path=-_shards</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>Responds:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "count" : 5
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>And for more control, both inclusive and exclusive filters can be combined in the same expression. In
this case, the exclusive filters will be applied first and the result will be filtered again using the
inclusive filters:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cluster/state?filter_path=metadata.indices.*.state,-metadata.indices.logstash-*</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT index-1\nPUT index-2\nPUT index-3\nPUT logstash-2016.01\n/]</remark>
<simpara>Responds:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "metadata" : {
    "indices" : {
      "index-1" : {"state" : "open"},
      "index-2" : {"state" : "open"},
      "index-3" : {"state" : "open"}
    }
  }
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>Note that elasticsearch sometimes returns directly the raw value of a field,
like the <literal>_source</literal> field. If you want to filter <literal>_source</literal> fields, you should
consider combining the already existing <literal>_source</literal> parameter (see
<link linkend="get-source-filtering">Get API</link> for more details) with the <literal>filter_path</literal>
parameter like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /library/book?refresh
{"title": "Book #1", "rating": 200.1}
POST /library/book?refresh
{"title": "Book #2", "rating": 1.7}
POST /library/book?refresh
{"title": "Book #3", "rating": 0.1}
GET /_search?filter_path=hits.hits._source&amp;_source=title&amp;sort=rating:desc</programlisting>
<remark> CONSOLE</remark>
<programlisting language="js" linenumbering="unnumbered">{
  "hits" : {
    "hits" : [ {
      "_source":{"title":"Book #1"}
    }, {
      "_source":{"title":"Book #2"}
    }, {
      "_source":{"title":"Book #3"}
    } ]
  }
}</programlisting>
<remark> TESTRESPONSE</remark>
<bridgehead id="_flat_settings" renderas="sect2">Flat Settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/api-conventions.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>flat_settings</literal> flag affects rendering of the lists of settings. When
<literal>flat_settings</literal> flag is <literal>true</literal> settings are returned in a flat format:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET twitter/_settings?flat_settings=true</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>Returns:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "twitter" : {
    "settings": {
      "index.number_of_replicas": "1",
      "index.number_of_shards": "1",
      "index.creation_date": "1474389951325",
      "index.uuid": "n6gzFZTgS664GUfx0Xrpjw",
      "index.version.created": ...,
      "index.provided_name" : "twitter"
    }
  }
}</programlisting>
<remark> TESTRESPONSE[s/1474389951325/$body.twitter.settings.index\\\\.creation_date/]</remark>
<remark> TESTRESPONSE[s/n6gzFZTgS664GUfx0Xrpjw/$body.twitter.settings.index\\\\.uuid/]</remark>
<remark> TESTRESPONSE[s/"index.version.created": \.\.\./"index.version.created": $body.twitter.settings.index\\\\.version\\\\.created/]</remark>
<simpara>When the <literal>flat_settings</literal> flag is <literal>false</literal> settings are returned in a more
human readable structured format:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET twitter/_settings?flat_settings=false</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>Returns:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "twitter" : {
    "settings" : {
      "index" : {
        "number_of_replicas": "1",
        "number_of_shards": "1",
        "creation_date": "1474389951325",
        "uuid": "n6gzFZTgS664GUfx0Xrpjw",
        "version": {
          "created": ...
        },
        "provided_name" : "twitter"
      }
    }
  }
}</programlisting>
<remark> TESTRESPONSE[s/1474389951325/$body.twitter.settings.index.creation_date/]</remark>
<remark> TESTRESPONSE[s/n6gzFZTgS664GUfx0Xrpjw/$body.twitter.settings.index.uuid/]</remark>
<remark> TESTRESPONSE[s/"created": \.\.\./"created": $body.twitter.settings.index.version.created/]</remark>
<simpara>By default the <literal>flat_settings</literal> is set to <literal>false</literal>.</simpara>
<bridgehead id="_parameters" renderas="sect2">Parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/api-conventions.asciidoc">Edit me</ulink></bridgehead>
<simpara>Rest parameters (when using HTTP, map to HTTP URL parameters) follow the
convention of using underscore casing.</simpara>
<bridgehead id="_boolean_values" renderas="sect2">Boolean Values<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/api-conventions.asciidoc">Edit me</ulink></bridgehead>
<simpara>All REST APIs parameters (both request parameters and JSON body) support
providing boolean "false" as the values: <literal>false</literal>, <literal>0</literal>, <literal>no</literal> and <literal>off</literal>.
All other values are considered "true". Note, this is not related to
fields within a document indexed treated as boolean fields.</simpara>
<bridgehead id="_number_values" renderas="sect2">Number Values<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/api-conventions.asciidoc">Edit me</ulink></bridgehead>
<simpara>All REST APIs support providing numbered parameters as <literal>string</literal> on top
of supporting the native JSON number types.</simpara>
<bridgehead id="time-units" renderas="sect2">Time units<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/api-conventions.asciidoc">Edit me</ulink></bridgehead>
<simpara>Whenever durations need to be specified, e.g. for a <literal>timeout</literal> parameter, the duration must specify
the unit, like <literal>2d</literal> for 2 days.  The supported units are:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>d</literal>
</simpara>
</entry>
<entry>
<simpara>
days
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>h</literal>
</simpara>
</entry>
<entry>
<simpara>
hours
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>m</literal>
</simpara>
</entry>
<entry>
<simpara>
minutes
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>s</literal>
</simpara>
</entry>
<entry>
<simpara>
seconds
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>ms</literal>
</simpara>
</entry>
<entry>
<simpara>
milliseconds
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>micros</literal>
</simpara>
</entry>
<entry>
<simpara>
microseconds
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>nanos</literal>
</simpara>
</entry>
<entry>
<simpara>
nanoseconds
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="byte-units" renderas="sect2">Byte size units<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/api-conventions.asciidoc">Edit me</ulink></bridgehead>
<simpara>Whenever the byte size of data needs to be specified, eg when setting a buffer size
parameter, the value must specify the unit, like <literal>10kb</literal> for 10 kilobytes.  The
supported units are:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>b</literal>
</simpara>
</entry>
<entry>
<simpara>
Bytes
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>kb</literal>
</simpara>
</entry>
<entry>
<simpara>
Kilobytes
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>mb</literal>
</simpara>
</entry>
<entry>
<simpara>
Megabytes
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>gb</literal>
</simpara>
</entry>
<entry>
<simpara>
Gigabytes
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>tb</literal>
</simpara>
</entry>
<entry>
<simpara>
Terabytes
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>pb</literal>
</simpara>
</entry>
<entry>
<simpara>
Petabytes
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="size-units" renderas="sect2">Unit-less quantities<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/api-conventions.asciidoc">Edit me</ulink></bridgehead>
<simpara>Unit-less quantities means that they don&#8217;t have a "unit" like "bytes" or "Hertz" or "meter" or "long tonne".</simpara>
<simpara>If one of these quantities is large we&#8217;ll print it out like 10m for 10,000,000 or 7k for 7,000. We&#8217;ll still print 87
when we mean 87 though. These are the supported multipliers:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
``
</simpara>
</entry>
<entry>
<simpara>
Single
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>k</literal>
</simpara>
</entry>
<entry>
<simpara>
Kilo
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>m</literal>
</simpara>
</entry>
<entry>
<simpara>
Mega
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>g</literal>
</simpara>
</entry>
<entry>
<simpara>
Giga
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>t</literal>
</simpara>
</entry>
<entry>
<simpara>
Tera
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>p</literal>
</simpara>
</entry>
<entry>
<simpara>
Peta
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="distance-units" renderas="sect2">Distance Units<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/api-conventions.asciidoc">Edit me</ulink></bridgehead>
<simpara>Wherever distances need to be specified, such as the <literal>distance</literal> parameter in
the <xref linkend="query-dsl-geo-distance-query"/>), the default unit if none is specified is
the meter. Distances can be specified in other units, such as <literal>"1km"</literal> or
<literal>"2mi"</literal> (2 miles).</simpara>
<simpara>The full list of units is listed below:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
Mile
</simpara>
</entry>
<entry>
<simpara>
<literal>mi</literal> or <literal>miles</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Yard
</simpara>
</entry>
<entry>
<simpara>
<literal>yd</literal> or <literal>yards</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Feet
</simpara>
</entry>
<entry>
<simpara>
<literal>ft</literal> or <literal>feet</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Inch
</simpara>
</entry>
<entry>
<simpara>
<literal>in</literal> or <literal>inch</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Kilometer
</simpara>
</entry>
<entry>
<simpara>
<literal>km</literal> or <literal>kilometers</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Meter
</simpara>
</entry>
<entry>
<simpara>
<literal>m</literal> or <literal>meters</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Centimeter
</simpara>
</entry>
<entry>
<simpara>
<literal>cm</literal> or <literal>centimeters</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Millimeter
</simpara>
</entry>
<entry>
<simpara>
<literal>mm</literal> or <literal>millimeters</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Nautical mile
</simpara>
</entry>
<entry>
<simpara>
<literal>NM</literal>, <literal>nmi</literal> or <literal>nauticalmiles</literal>
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="fuzziness" renderas="sect2">Fuzziness<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/api-conventions.asciidoc">Edit me</ulink></bridgehead>
<simpara>Some queries and APIs support parameters to allow inexact <emphasis>fuzzy</emphasis> matching,
using the <literal>fuzziness</literal> parameter.</simpara>
<simpara>When querying <literal>text</literal> or <literal>keyword</literal> fields, <literal>fuzziness</literal> is interpreted as a
<ulink url="http://en.wikipedia.org/wiki/Levenshtein_distance">Levenshtein Edit Distance</ulink>&#8201;&#8212;&#8201;the number of one character changes that need to be made to one string to
make it the same as another string.</simpara>
<simpara>The <literal>fuzziness</literal> parameter can be specified as:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>0</literal>, <literal>1</literal>, <literal>2</literal>
</term>
<listitem>
<simpara>
the maximum allowed Levenshtein Edit Distance (or number of edits)
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>AUTO</literal>
</term>
<listitem>
<simpara>generates an edit distance based on the length of the term. For lengths:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>0..2</literal>
</term>
<listitem>
<simpara>
must match exactly
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>3..5</literal>
</term>
<listitem>
<simpara>
one edit allowed
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>&gt;5</literal>
</term>
<listitem>
<simpara>
two edits allowed
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara><literal>AUTO</literal> should generally be the preferred value for <literal>fuzziness</literal>.</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="common-options-error-options" renderas="sect2">Enabling stack traces<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/api-conventions.asciidoc">Edit me</ulink></bridgehead>
<simpara>By default when a request returns an error Elasticsearch doesn&#8217;t include the
stack trace of the error. You can enable that behavior by setting the
<literal>error_trace</literal> url parameter to <literal>true</literal>. For example, by default when you send an
invalid <literal>size</literal> parameter to the <literal>_search</literal> API:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /twitter/_search?size=surprise_me</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[catch:request]</remark>
<simpara>The response looks like:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "error" : {
    "root_cause" : [
      {
        "type" : "illegal_argument_exception",
        "reason" : "Failed to parse int parameter [size] with value [surprise_me]"
      }
    ],
    "type" : "illegal_argument_exception",
    "reason" : "Failed to parse int parameter [size] with value [surprise_me]",
    "caused_by" : {
      "type" : "number_format_exception",
      "reason" : "For input string: \"surprise_me\""
    }
  },
  "status" : 400
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>But if you set <literal>error_trace=true</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /twitter/_search?size=surprise_me&amp;error_trace=true</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[catch:request]</remark>
<simpara>The response looks like:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "error": {
    "root_cause": [
      {
        "type": "illegal_argument_exception",
        "reason": "Failed to parse int parameter [size] with value [surprise_me]",
        "stack_trace": "Failed to parse int parameter [size] with value [surprise_me]]; nested: IllegalArgumentException..."
      }
    ],
    "type": "illegal_argument_exception",
    "reason": "Failed to parse int parameter [size] with value [surprise_me]",
    "stack_trace": "java.lang.IllegalArgumentException: Failed to parse int parameter [size] with value [surprise_me]\n    at org.elasticsearch.rest.RestRequest.paramAsInt(RestRequest.java:175)...",
    "caused_by": {
      "type": "number_format_exception",
      "reason": "For input string: \"surprise_me\"",
      "stack_trace": "java.lang.NumberFormatException: For input string: \"surprise_me\"\n    at java.lang.NumberFormatException.forInputString(NumberFormatException.java:65)..."
    }
  },
  "status": 400
}</programlisting>
<remark> TESTRESPONSE[s/"stack_trace": "Failed to parse int parameter.+\.\.\."/"stack_trace": $body.error.root_cause.0.stack_trace/]</remark>
<remark> TESTRESPONSE[s/"stack_trace": "java.lang.IllegalArgum.+\.\.\."/"stack_trace": $body.error.stack_trace/]</remark>
<remark> TESTRESPONSE[s/"stack_trace": "java.lang.Number.+\.\.\."/"stack_trace": $body.error.caused_by.stack_trace/]</remark>
<bridgehead id="_request_body_in_query_string" renderas="sect2">Request body in query string<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/api-conventions.asciidoc">Edit me</ulink></bridgehead>
<simpara>For libraries that don&#8217;t accept a request body for non-POST requests,
you can pass the request body as the <literal>source</literal> query string parameter
instead.</simpara>
</chapter>
<chapter id="url-access-control">
<title>URL-based access control<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/api-conventions.asciidoc">Edit me</ulink></title>
<simpara>Many users use a proxy with URL-based access control to secure access to
Elasticsearch indices. For <link linkend="search-multi-search">multi-search</link>,
<link linkend="docs-multi-get">multi-get</link> and <link linkend="docs-bulk">bulk</link> requests, the user has
the choice of specifying an index in the URL and on each individual request
within the request body. This can make URL-based access control challenging.</simpara>
<simpara>To prevent the user from overriding the index which has been specified in the
URL, add this setting to the <literal>config.yml</literal> file:</simpara>
<literallayout class="monospaced">rest.action.multi.allow_explicit_index: false</literallayout>
<simpara>The default value is <literal>true</literal>, but when set to <literal>false</literal>, Elasticsearch will
reject requests that have an explicit index specified in the request body.</simpara>
</chapter>
</part>
<part id="docs">
<title>Document APIs <ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs.asciidoc">Edit me</ulink></title>
<partintro>
<simpara>This section describes the following CRUD APIs:</simpara>
<itemizedlist><title>Single document APIs</title>
<listitem>
<simpara>
<xref linkend="docs-index_"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="docs-get"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="docs-delete"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="docs-update"/>
</simpara>
</listitem>
</itemizedlist>
<itemizedlist><title>Multi-document APIs</title>
<listitem>
<simpara>
<xref linkend="docs-multi-get"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="docs-bulk"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="docs-update-by-query"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="docs-reindex"/>
</simpara>
</listitem>
</itemizedlist>
<note><simpara>All CRUD APIs are single-index APIs. The <literal>index</literal> parameter accepts a single
index name, or an <literal>alias</literal> which points to a single index.</simpara></note>
</partintro>
<chapter id="docs-index_">
<title>Index API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/index_.asciidoc">Edit me</ulink></title>
<simpara>The index API adds or updates a typed JSON document in a specific index,
making it searchable. The following example inserts the JSON document
into the "twitter" index, under a type called "tweet" with an id of 1:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT twitter/tweet/1
{
    "user" : "kimchy",
    "post_date" : "2009-11-15T14:12:12",
    "message" : "trying out Elasticsearch"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The result of the above index operation is:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "_shards" : {
        "total" : 2,
        "failed" : 0,
        "successful" : 2
    },
    "_index" : "twitter",
    "_type" : "tweet",
    "_id" : "1",
    "_version" : 1,
    "created" : true,
    "result" : created
}</programlisting>
<remark> TESTRESPONSE[s/"successful" : 2/"successful" : 1/]</remark>
<simpara>The <literal>_shards</literal> header provides information about the replication process of the index operation.</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>total</literal> - Indicates to how many shard copies (primary and replica shards) the index operation should be executed on.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>successful</literal>- Indicates the number of shard copies the index operation succeeded on.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>failed</literal> - An array that contains replication related errors in the case an index operation failed on a replica shard.
</simpara>
</listitem>
</itemizedlist>
<simpara>The index operation is successful in the case <literal>successful</literal> is at least 1.</simpara>
<note><simpara>Replica shards may not all be started when an indexing operation successfully returns (by default, only the
        primary is required, but this behavior can be <link linkend="index-wait-for-active-shards">changed</link>). In that case,
        <literal>total</literal> will be equal to the total shards based on the <literal>number_of_replicas</literal> setting and <literal>successful</literal> will be
        equal to the number of shards started (primary plus replicas). If there were no failures, the <literal>failed</literal> will be 0.</simpara></note>
<bridgehead id="index-creation" renderas="sect2">Automatic Index Creation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/index_.asciidoc">Edit me</ulink></bridgehead>
<simpara>The index operation automatically creates an index if it has not been
created before (check out the
<link linkend="indices-create-index">create index API</link> for manually
creating an index), and also automatically creates a
dynamic type mapping for the specific type if one has not yet been
created (check out the <link linkend="indices-put-mapping">put mapping</link>
API for manually creating a type mapping).</simpara>
<simpara>The mapping itself is very flexible and is schema-free. New fields and
objects will automatically be added to the mapping definition of the
type specified. Check out the <link linkend="mapping">mapping</link>
section for more information on mapping definitions.</simpara>
<simpara>Automatic index creation can be disabled by setting
<literal>action.auto_create_index</literal> to <literal>false</literal> in the config file of all nodes.
Automatic mapping creation can be disabled by setting
<literal>index.mapper.dynamic</literal> to <literal>false</literal> per-index as an index setting.</simpara>
<simpara>Automatic index creation can include a pattern based white/black list,
for example, set <literal>action.auto_create_index</literal> to <literal>+aaa*,-bbb*,+ccc*,-*</literal> (+
meaning allowed, and - meaning disallowed).</simpara>
<bridgehead id="index-versioning" renderas="sect2">Versioning<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/index_.asciidoc">Edit me</ulink></bridgehead>
<simpara>Each indexed document is given a version number. The associated
<literal>version</literal> number is returned as part of the response to the index API
request. The index API optionally allows for
<ulink url="http://en.wikipedia.org/wiki/Optimistic_concurrency_control">optimistic
concurrency control</ulink> when the <literal>version</literal> parameter is specified. This
will control the version of the document the operation is intended to be
executed against. A good example of a use case for versioning is
performing a transactional read-then-update. Specifying a <literal>version</literal> from
the document initially read ensures no changes have happened in the
meantime (when reading in order to update, it is recommended to set
<literal>preference</literal> to <literal>_primary</literal>). For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT twitter/tweet/1?version=2
{
    "message" : "elasticsearch now has versioning support, double cool!"
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[catch: conflict]</remark>
<simpara><emphasis role="strong">NOTE:</emphasis> versioning is completely real time, and is not affected by the
near real time aspects of search operations. If no version is provided,
then the operation is executed without any version checks.</simpara>
<simpara>By default, internal versioning is used that starts at 1 and increments
with each update, deletes included. Optionally, the version number can be
supplemented with an external value (for example, if maintained in a
database). To enable this functionality, <literal>version_type</literal> should be set to
<literal>external</literal>. The value provided must be a numeric, long value greater or equal to 0,
and less than around 9.2e+18. When using the external version type, instead
of checking for a matching version number, the system checks to see if
the version number passed to the index request is greater than the
version of the currently stored document. If true, the document will be
indexed and the new version number used. If the value provided is less
than or equal to the stored document&#8217;s version number, a version
conflict will occur and the index operation will fail.</simpara>
<warning><simpara>External versioning supports the value 0 as a valid version number.
This allows the version to be in sync with an external versioning system
where version numbers start from zero instead of one. It has the side effect
that documents with version number equal to zero cannot neither be updated
using the <link linkend="docs-update-by-query">Update-By-Query API</link> nor be deleted
using the <link linkend="docs-delete-by-query">Delete By Query API</link> as long as their
version number is equal to zero.</simpara></warning>
<simpara>A nice side effect is that there is no need to maintain strict ordering
of async indexing operations executed as a result of changes to a source
database, as long as version numbers from the source database are used.
Even the simple case of updating the elasticsearch index using data from
a database is simplified if external versioning is used, as only the
latest version will be used if the index operations are out of order for
whatever reason.</simpara>
<bridgehead id="_version_types" renderas="sect3">Version types<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/index_.asciidoc">Edit me</ulink></bridgehead>
<simpara>Next to the <literal>internal</literal> &amp; <literal>external</literal> version types explained above, Elasticsearch
also supports other types for specific use cases. Here is an overview of
the different version types and their semantics.</simpara>
<variablelist>
<varlistentry>
<term>
<literal>internal</literal>
</term>
<listitem>
<simpara>
only index the document if the given version is identical to the version
of the stored document.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>external</literal> or <literal>external_gt</literal>
</term>
<listitem>
<simpara>
only index the document if the given version is strictly higher
than the version of the stored document <emphasis role="strong">or</emphasis> if there is no existing document. The given
version will be used as the new version and will be stored with the new document. The supplied
version must be a non-negative long number.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>external_gte</literal>
</term>
<listitem>
<simpara>
only index the document if the given version is <emphasis role="strong">equal</emphasis> or higher
than the version of the stored document. If there is no existing document
the operation will succeed as well. The given version will be used as the new version
and will be stored with the new document. The supplied version must be a non-negative long number.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara><emphasis role="strong">NOTE</emphasis>: The <literal>external_gte</literal> version type is meant for special use cases and
should be used with care. If used incorrectly, it can result in loss of data.
There is another option, <literal>force</literal>, which is deprecated because it can cause
primary and replica shards to diverge.</simpara>
<bridgehead id="operation-type" renderas="sect2">Operation Type<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/index_.asciidoc">Edit me</ulink></bridgehead>
<simpara>The index operation also accepts an <literal>op_type</literal> that can be used to force
a <literal>create</literal> operation, allowing for "put-if-absent" behavior. When
<literal>create</literal> is used, the index operation will fail if a document by that id
already exists in the index.</simpara>
<simpara>Here is an example of using the <literal>op_type</literal> parameter:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT twitter/tweet/1?op_type=create
{
    "user" : "kimchy",
    "post_date" : "2009-11-15T14:12:12",
    "message" : "trying out Elasticsearch"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Another option to specify <literal>create</literal> is to use the following uri:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT twitter/tweet/1/_create
{
    "user" : "kimchy",
    "post_date" : "2009-11-15T14:12:12",
    "message" : "trying out Elasticsearch"
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_automatic_id_generation" renderas="sect2">Automatic ID Generation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/index_.asciidoc">Edit me</ulink></bridgehead>
<simpara>The index operation can be executed without specifying the id. In such a
case, an id will be generated automatically. In addition, the <literal>op_type</literal>
will automatically be set to <literal>create</literal>. Here is an example (note the
<emphasis role="strong">POST</emphasis> used instead of <emphasis role="strong">PUT</emphasis>):</simpara>
<programlisting language="js" linenumbering="unnumbered">POST twitter/tweet/
{
    "user" : "kimchy",
    "post_date" : "2009-11-15T14:12:12",
    "message" : "trying out Elasticsearch"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The result of the above index operation is:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "_shards" : {
        "total" : 2,
        "failed" : 0,
        "successful" : 2
    },
    "_index" : "twitter",
    "_type" : "tweet",
    "_id" : "6a8ca01c-7896-48e9-81cc-9f70661fcb32",
    "_version" : 1,
    "created" : true,
    "result": "created"
}</programlisting>
<remark> TESTRESPONSE[s/6a8ca01c-7896-48e9-81cc-9f70661fcb32/$body._id/ s/"successful" : 2/"successful" : 1/]</remark>
<bridgehead id="index-routing" renderas="sect2">Routing<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/index_.asciidoc">Edit me</ulink></bridgehead>
<simpara>By default, shard placement — or <literal>routing</literal> — is controlled by using a
hash of the document&#8217;s id value. For more explicit control, the value
fed into the hash function used by the router can be directly specified
on a per-operation basis using the <literal>routing</literal> parameter. For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST twitter/tweet?routing=kimchy
{
    "user" : "kimchy",
    "post_date" : "2009-11-15T14:12:12",
    "message" : "trying out Elasticsearch"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>In the example above, the "tweet" document is routed to a shard based on
the <literal>routing</literal> parameter provided: "kimchy".</simpara>
<simpara>When setting up explicit mapping, the <literal>_routing</literal> field can be optionally
used to direct the index operation to extract the routing value from the
document itself. This does come at the (very minimal) cost of an
additional document parsing pass. If the <literal>_routing</literal> mapping is defined
and set to be <literal>required</literal>, the index operation will fail if no routing
value is provided or extracted.</simpara>
<bridgehead id="parent-children" renderas="sect2">Parents &amp; Children<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/index_.asciidoc">Edit me</ulink></bridgehead>
<simpara>A child document can be indexed by specifying its parent when indexing.
For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT blogs
{
  "mappings": {
    "tag_parent": {},
    "blog_tag": {
      "_parent": {
        "type": "tag_parent"
      }
    }
  }
}

PUT blogs/blog_tag/1122?parent=1111
{
    "tag" : "something"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>When indexing a child document, the routing value is automatically set
to be the same as its parent, unless the routing value is explicitly
specified using the <literal>routing</literal> parameter.</simpara>
<bridgehead id="index-distributed" renderas="sect2">Distributed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/index_.asciidoc">Edit me</ulink></bridgehead>
<simpara>The index operation is directed to the primary shard based on its route
(see the Routing section above) and performed on the actual node
containing this shard. After the primary shard completes the operation,
if needed, the update is distributed to applicable replicas.</simpara>
<bridgehead id="index-wait-for-active-shards" renderas="sect2">Wait For Active Shards<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/index_.asciidoc">Edit me</ulink></bridgehead>
<simpara>To improve the resiliency of writes to the system, indexing operations
can be configured to wait for a certain number of active shard copies
before proceeding with the operation. If the requisite number of active
shard copies are not available, then the write operation must wait and
retry, until either the requisite shard copies have started or a timeout
occurs. By default, write operations only wait for the primary shards
to be active before proceeding (i.e. <literal>wait_for_active_shards=1</literal>).
This default can be overridden in the index settings dynamically
by setting <literal>index.write.wait_for_active_shards</literal>. To alter this behavior
per operation, the <literal>wait_for_active_shards</literal> request parameter can be used.</simpara>
<simpara>Valid values are <literal>all</literal> or any positive integer up to the total number
of configured copies per shard in the index (which is <literal>number_of_replicas+1</literal>).
Specifying a negative value or a number greater than the number of
shard copies will throw an error.</simpara>
<simpara>For example, suppose we have a cluster of three nodes, <literal>A</literal>, <literal>B</literal>, and <literal>C</literal> and
we create an index <literal>index</literal> with the number of replicas set to 3 (resulting in
4 shard copies, one more copy than there are nodes). If we
attempt an indexing operation, by default the operation will only ensure
the primary copy of each shard is available before proceeding. This means
that even if <literal>B</literal> and <literal>C</literal> went down, and <literal>A</literal> hosted the primary shard copies,
the indexing operation would still proceed with only one copy of the data.
If <literal>wait_for_active_shards</literal> is set on the request to <literal>3</literal> (and all 3 nodes
are up), then the indexing operation will require 3 active shard copies
before proceeding, a requirement which should be met because there are 3
active nodes in the cluster, each one holding a copy of the shard. However,
if we set <literal>wait_for_active_shards</literal> to <literal>all</literal> (or to <literal>4</literal>, which is the same),
the indexing operation will not proceed as we do not have all 4 copies of
each shard active in the index. The operation will timeout
unless a new node is brought up in the cluster to host the fourth copy of
the shard.</simpara>
<simpara>It is important to note that this setting greatly reduces the chances of
the write operation not writing to the requisite number of shard copies,
but it does not completely eliminate the possibility, because this check
occurs before the write operation commences. Once the write operation
is underway, it is still possible for replication to fail on any number of
shard copies but still succeed on the primary. The <literal>_shards</literal> section of the
write operation&#8217;s response reveals the number of shard copies on which
replication succeeded/failed.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "_shards" : {
        "total" : 2,
        "failed" : 0,
        "successful" : 2
    }
}</programlisting>
<bridgehead id="index-refresh" renderas="sect2">Refresh<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/index_.asciidoc">Edit me</ulink></bridgehead>
<simpara>Control when the changes made by this request are visible to search. See
<link linkend="docs-refresh">refresh</link>.</simpara>
<bridgehead id="index-noop" renderas="sect2">Noop Updates<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/index_.asciidoc">Edit me</ulink></bridgehead>
<simpara>When updating a document using the index api a new version of the document is
always created even if the document hasn&#8217;t changed. If this isn&#8217;t acceptable
use the <literal>_update</literal> api with <literal>detect_noop</literal> set to true. This option isn&#8217;t
available on the index api because the index api doesn&#8217;t fetch the old source
and isn&#8217;t able to compare it against the new source.</simpara>
<simpara>There isn&#8217;t a hard and fast rule about when noop updates aren&#8217;t acceptable.
It&#8217;s a combination of lots of factors like how frequently your data source
sends updates that are actually noops and how many queries per second
elasticsearch runs on the shard with receiving the updates.</simpara>
<bridgehead id="timeout" renderas="sect2">Timeout<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/index_.asciidoc">Edit me</ulink></bridgehead>
<simpara>The primary shard assigned to perform the index operation might not be
available when the index operation is executed. Some reasons for this
might be that the primary shard is currently recovering from a gateway
or undergoing relocation. By default, the index operation will wait on
the primary shard to become available for up to 1 minute before failing
and responding with an error. The <literal>timeout</literal> parameter can be used to
explicitly specify how long it waits. Here is an example of setting it
to 5 minutes:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT twitter/tweet/1?timeout=5m
{
    "user" : "kimchy",
    "post_date" : "2009-11-15T14:12:12",
    "message" : "trying out Elasticsearch"
}</programlisting>
<remark> CONSOLE</remark>
</chapter>
<chapter id="docs-get">
<title>Get API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/get.asciidoc">Edit me</ulink></title>
<simpara>The get API allows to get a typed JSON document from the index based on
its id. The following example gets a JSON document from an index called
twitter, under a type called tweet, with id valued 0:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET twitter/tweet/0</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>The result of the above get operation is:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "_index" : "twitter",
    "_type" : "tweet",
    "_id" : "0",
    "_version" : 1,
    "found": true,
    "_source" : {
        "user" : "kimchy",
        "date" : "2009-11-15T14:12:12",
        "likes": 0,
        "message" : "trying out Elasticsearch"
    }
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>The above result includes the <literal>_index</literal>, <literal>_type</literal>, <literal>_id</literal> and <literal>_version</literal>
of the document we wish to retrieve, including the actual <literal>_source</literal>
of the document if it could be found (as indicated by the <literal>found</literal>
field in the response).</simpara>
<simpara>The API also allows to check for the existence of a document using
<literal>HEAD</literal>, for example:</simpara>
<programlisting language="js" linenumbering="unnumbered">HEAD twitter/tweet/0</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<bridgehead id="realtime" renderas="sect2">Realtime<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/get.asciidoc">Edit me</ulink></bridgehead>
<simpara>By default, the get API is realtime, and is not affected by the refresh
rate of the index (when data will become visible for search). If a document
has been updated but is not yet refreshed, the get API will issue a refresh
call in-place to make the document visible. This will also make other documents
changed since the last refresh visible. In order to disable realtime GET,
one can set the <literal>realtime</literal> parameter to <literal>false</literal>.</simpara>
<bridgehead id="type" renderas="sect2">Optional Type<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/get.asciidoc">Edit me</ulink></bridgehead>
<simpara>The get API allows for <literal>_type</literal> to be optional. Set it to <literal>_all</literal> in order
to fetch the first document matching the id across all types.</simpara>
<bridgehead id="get-source-filtering" renderas="sect2">Source filtering<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/get.asciidoc">Edit me</ulink></bridgehead>
<simpara>By default, the get operation returns the contents of the <literal>_source</literal> field unless
you have used the <literal>stored_fields</literal> parameter or if the <literal>_source</literal> field is disabled.
You can turn off <literal>_source</literal> retrieval by using the <literal>_source</literal> parameter:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET twitter/tweet/0?_source=false</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>If you only need one or two fields from the complete <literal>_source</literal>, you can use the <literal>_source_include</literal>
&amp; <literal>_source_exclude</literal> parameters to include or filter out that parts you need. This can be especially helpful
with large documents where partial retrieval can save on network overhead. Both parameters take a comma separated list
of fields or wildcard expressions. Example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET twitter/tweet/0?_source_include=*.id&amp;_source_exclude=entities</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>If you only want to specify includes, you can use a shorter notation:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET twitter/tweet/0?_source=*.id,retweeted</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<bridgehead id="get-stored-fields" renderas="sect2">Stored Fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/get.asciidoc">Edit me</ulink></bridgehead>
<simpara>The get operation allows specifying a set of stored fields that will be
returned by passing the <literal>stored_fields</literal> parameter.
If the requested fields are not stored, they will be ignored.
Consider for instance the following mapping:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT twitter
{
   "mappings": {
      "tweet": {
         "properties": {
            "counter": {
               "type": "integer",
               "store": false
            },
            "tags": {
               "type": "keyword",
               "store": true
            }
         }
      }
   }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Now we can add a document:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT twitter/tweet/1
{
    "counter" : 1,
    "tags" : ["red"]
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<orderedlist numeration="lowerroman">
<listitem>
<simpara>
and try to retrieve it:
</simpara>
</listitem>
</orderedlist>
<programlisting language="js" linenumbering="unnumbered">GET twitter/tweet/1?stored_fields=tags,counter</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>The result of the above get operation is:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "_index": "twitter",
   "_type": "tweet",
   "_id": "1",
   "_version": 1,
   "found": true,
   "fields": {
      "tags": [
         "red"
      ]
   }
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>Field values fetched from the document it self are always returned as an array.
Since the <literal>counter</literal> field is not stored the get request simply ignores it when trying to get the <literal>stored_fields.</literal></simpara>
<simpara>It is also possible to retrieve metadata fields like <literal>_routing</literal> and <literal>_parent</literal> fields:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT twitter/tweet/2?routing=user1
{
    "counter" : 1,
    "tags" : ["white"]
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<programlisting language="js" linenumbering="unnumbered">GET twitter/tweet/2?routing=user1&amp;stored_fields=tags,counter</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>The result of the above get operation is:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "_index": "twitter",
   "_type": "tweet",
   "_id": "2",
   "_version": 1,
   "_routing": "user1",
   "found": true,
   "fields": {
      "tags": [
         "white"
      ]
   }
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>Also only leaf fields can be returned via the <literal>stored_field</literal> option. So object fields can&#8217;t be returned and such requests
will fail.</simpara>
<bridgehead id="generated-fields" renderas="sect2">Generated fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/get.asciidoc">Edit me</ulink></bridgehead>
<simpara>If no refresh occurred between indexing and refresh, GET will access the transaction log to fetch the document. However, some fields are generated only when indexing.
If you try to access a field that is only generated when indexing, you will get an exception (default). You can choose to ignore field that are generated if the transaction log is accessed by setting <literal>ignore_errors_on_generated_fields=true</literal>.</simpara>
<bridgehead id="_source" renderas="sect2">Getting the _source directly<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/get.asciidoc">Edit me</ulink></bridgehead>
<simpara>Use the <literal>/{index}/{type}/{id}/_source</literal> endpoint to get
just the <literal>_source</literal> field of the document,
without any additional content around it. For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET twitter/tweet/1/_source</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>You can also use the same source filtering parameters to control which parts of the <literal>_source</literal> will be returned:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET twitter/tweet/1/_source?_source_include=*.id&amp;_source_exclude=entities'</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Note, there is also a HEAD variant for the _source endpoint to efficiently test for document _source existence.
An existing document will not have a _source if it is disabled in the <link linkend="mapping-source-field">mapping</link>.</simpara>
<programlisting language="js" linenumbering="unnumbered">HEAD twitter/tweet/1/_source</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<bridgehead id="get-routing" renderas="sect2">Routing<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/get.asciidoc">Edit me</ulink></bridgehead>
<simpara>When indexing using the ability to control the routing, in order to get
a document, the routing value should also be provided. For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET twitter/tweet/2?routing=user1</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>The above will get a tweet with id 2, but will be routed based on the
user. Note, issuing a get without the correct routing, will cause the
document not to be fetched.</simpara>
<bridgehead id="preference" renderas="sect2">Preference<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/get.asciidoc">Edit me</ulink></bridgehead>
<simpara>Controls a <literal>preference</literal> of which shard replicas to execute the get
request on. By default, the operation is randomized between the shard
replicas.</simpara>
<simpara>The <literal>preference</literal> can be set to:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>_primary</literal>
</term>
<listitem>
<simpara>
        The operation will go and be executed only on the primary
        shards.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>_local</literal>
</term>
<listitem>
<simpara>
        The operation will prefer to be executed on a local
        allocated shard if possible.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Custom (string) value
</term>
<listitem>
<simpara>
        A custom value will be used to guarantee that
        the same shards will be used for the same custom value. This can help
        with "jumping values" when hitting different shards in different refresh
        states. A sample value can be something like the web session id, or the
        user name.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="get-refresh" renderas="sect2">Refresh<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/get.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>refresh</literal> parameter can be set to <literal>true</literal> in order to refresh the
relevant shard before the get operation and make it searchable. Setting
it to <literal>true</literal> should be done after careful thought and verification that
this does not cause a heavy load on the system (and slows down
indexing).</simpara>
<bridgehead id="get-distributed" renderas="sect2">Distributed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/get.asciidoc">Edit me</ulink></bridgehead>
<simpara>The get operation gets hashed into a specific shard id. It then gets
redirected to one of the replicas within that shard id and returns the
result. The replicas are the primary shard and its replicas within that
shard id group. This means that the more replicas we will have, the
better GET scaling we will have.</simpara>
<bridgehead id="get-versioning" renderas="sect2">Versioning support<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/get.asciidoc">Edit me</ulink></bridgehead>
<simpara>You can use the <literal>version</literal> parameter to retrieve the document only if
its current version is equal to the specified one. This behavior is the same
for all version types with the exception of version type <literal>FORCE</literal> which always
retrieves the document. Note that <literal>FORCE</literal> version type is deprecated.</simpara>
<simpara>Internally, Elasticsearch has marked the old document as deleted and added an
entirely new document. The old version of the document doesn’t disappear
immediately, although you won’t be able to access it. Elasticsearch cleans up
deleted documents in the background as you continue to index more data.</simpara>
</chapter>
<chapter id="docs-delete">
<title>Delete API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/delete.asciidoc">Edit me</ulink></title>
<simpara>The delete API allows to delete a typed JSON document from a specific
index based on its id. The following example deletes the JSON document
from an index called twitter, under a type called tweet, with id valued
1:</simpara>
<programlisting language="js" linenumbering="unnumbered">$ curl -XDELETE 'http://localhost:9200/twitter/tweet/1'</programlisting>
<simpara>The result of the above delete operation is:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "_shards" : {
        "total" : 10,
        "failed" : 0,
        "successful" : 10
    },
    "found" : true,
    "_index" : "twitter",
    "_type" : "tweet",
    "_id" : "1",
    "_version" : 2,
    "result": "deleted"
}</programlisting>
<bridgehead id="delete-versioning" renderas="sect2">Versioning<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/delete.asciidoc">Edit me</ulink></bridgehead>
<simpara>Each document indexed is versioned. When deleting a document, the
<literal>version</literal> can be specified to make sure the relevant document we are
trying to delete is actually being deleted and it has not changed in the
meantime. Every write operation executed on a document, deletes included,
causes its version to be incremented.</simpara>
<bridgehead id="delete-routing" renderas="sect2">Routing<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/delete.asciidoc">Edit me</ulink></bridgehead>
<simpara>When indexing using the ability to control the routing, in order to
delete a document, the routing value should also be provided. For
example:</simpara>
<programlisting language="js" linenumbering="unnumbered">$ curl -XDELETE 'http://localhost:9200/twitter/tweet/1?routing=kimchy'</programlisting>
<simpara>The above will delete a tweet with id 1, but will be routed based on the
user. Note, issuing a delete without the correct routing, will cause the
document to not be deleted.</simpara>
<simpara>When the <literal>_routing</literal> mapping is set as <literal>required</literal> and no routing value is
specified, the delete api will throw a <literal>RoutingMissingException</literal> and reject
the request.</simpara>
<bridgehead id="delete-parent" renderas="sect2">Parent<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/delete.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>parent</literal> parameter can be set, which will basically be the same as
setting the routing parameter.</simpara>
<simpara>Note that deleting a parent document does not automatically delete its
children. One way of deleting all child documents given a parent&#8217;s id is
to use the <link linkend="docs-delete-by-query">Delete By Query API</link> to perform a
 index with the automatically generated (and indexed)
field _parent, which is in the format parent_type#parent_id.</simpara>
<simpara>When deleting a child document its parent id must be specified, otherwise
the delete request will be rejected and a <literal>RoutingMissingException</literal> will be
thrown instead.</simpara>
<bridgehead id="delete-index-creation" renderas="sect2">Automatic index creation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/delete.asciidoc">Edit me</ulink></bridgehead>
<simpara>The delete operation automatically creates an index if it has not been
created before (check out the <link linkend="indices-create-index">create index API</link>
for manually creating an index), and also automatically creates a
dynamic type mapping for the specific type if it has not been created
before (check out the <link linkend="indices-put-mapping">put mapping</link>
API for manually creating type mapping).</simpara>
<bridgehead id="delete-distributed" renderas="sect2">Distributed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/delete.asciidoc">Edit me</ulink></bridgehead>
<simpara>The delete operation gets hashed into a specific shard id. It then gets
redirected into the primary shard within that id group, and replicated
(if needed) to shard replicas within that id group.</simpara>
<bridgehead id="delete-wait-for-active-shards" renderas="sect2">Wait For Active Shards<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/delete.asciidoc">Edit me</ulink></bridgehead>
<simpara>When making delete requests, you can set the <literal>wait_for_active_shards</literal>
parameter to require a minimum number of shard copies to be active
before starting to process the delete request. See
<link linkend="index-wait-for-active-shards">here</link> for further details and a usage
example.</simpara>
<bridgehead id="delete-refresh" renderas="sect2">Refresh<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/delete.asciidoc">Edit me</ulink></bridgehead>
<simpara>Control when the changes made by this request are visible to search. See
<xref linkend="docs-refresh"/>.</simpara>
<bridgehead id="delete-timeout" renderas="sect2">Timeout<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/delete.asciidoc">Edit me</ulink></bridgehead>
<simpara>The primary shard assigned to perform the delete operation might not be
available when the delete operation is executed. Some reasons for this
might be that the primary shard is currently recovering from a store
or undergoing relocation. By default, the delete operation will wait on
the primary shard to become available for up to 1 minute before failing
and responding with an error. The <literal>timeout</literal> parameter can be used to
explicitly specify how long it waits. Here is an example of setting it
to 5 minutes:</simpara>
<programlisting language="js" linenumbering="unnumbered">$ curl -XDELETE 'http://localhost:9200/twitter/tweet/1?timeout=5m'</programlisting>
</chapter>
<chapter id="docs-delete-by-query">
<title>Delete By Query API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/delete-by-query.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>The delete-by-query API is new and should still be considered experimental.  The API may change in ways that are not backwards compatible.</simpara></warning>
<simpara>The simplest usage of <literal>_delete_by_query</literal> just performs a deletion on every
document that match a query. Here is the API:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST twitter/_delete_by_query
{
  "query": { <co id="CO6-1"/>
    "match": {
      "message": "some message"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:big_twitter]</remark>
<calloutlist>
<callout arearefs="CO6-1">
<para>
The query must be passed as a value to the <literal>query</literal> key, in the same
way as the <link linkend="search-search">Search API</link>. You can also use the <literal>q</literal>
parameter in the same way as the search api.
</para>
</callout>
</calloutlist>
<simpara>That will return something like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "took" : 147,
  "timed_out": false,
  "deleted": 119,
  "batches": 1,
  "version_conflicts": 0,
  "noops": 0,
  "retries": {
    "bulk": 0,
    "search": 0
  },
  "throttled_millis": 0,
  "requests_per_second": -1.0,
  "throttled_until_millis": 0,
  "total": 119,
  "failures" : [ ]
}</programlisting>
<remark> TESTRESPONSE[s/"took" : 147/"took" : "$body.took"/]</remark>
<simpara><literal>_delete_by_query</literal> gets a snapshot of the index when it starts and deletes what
it finds using <literal>internal</literal> versioning. That means that you&#8217;ll get a version
conflict if the document changes between the time when the snapshot was taken
and when the delete request is processed. When the versions match the document
is deleted.</simpara>
<note><simpara>Since <literal>internal</literal> versioning does not support the value 0 as a valid
version number, documents with version equal to zero cannot be deleted using
<literal>_delete_by_query</literal> and will fail the request.</simpara></note>
<simpara>During the <literal>_delete_by_query</literal> execution, multiple search requests are sequentially
executed in order to find all the matching documents to delete. Every time a batch
of documents is found, a corresponding bulk request is executed to delete all
these documents. In case a search or bulk request got rejected, <literal>_delete_by_query</literal>
 relies on a default policy to retry rejected requests (up to 10 times, with
 exponential back off). Reaching the maximum retries limit causes the <literal>_delete_by_query</literal>
 to abort and all failures are returned in the <literal>failures</literal> of the response.
 The deletions that have been performed still stick. In other words, the process
 is not rolled back, only aborted. While the first failure causes the abort, all
 failures that are returned by the failing bulk request are returned in the <literal>failures</literal>
 element; therefore it&#8217;s possible for there to be quite a few failed entities.</simpara>
<simpara>If you&#8217;d like to count version conflicts rather than cause them to abort then
set <literal>conflicts=proceed</literal> on the url or <literal>"conflicts": "proceed"</literal> in the request body.</simpara>
<simpara>Back to the API format, you can limit <literal>_delete_by_query</literal> to a single type. This
will only delete <literal>tweet</literal> documents from the <literal>twitter</literal> index:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST twitter/tweet/_delete_by_query?conflicts=proceed
{
  "query": {
    "match_all": {}
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>It&#8217;s also possible to delete documents of multiple indexes and multiple
types at once, just like the search API:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST twitter,blog/tweet,post/_delete_by_query
{
  "query": {
    "match_all": {}
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT twitter\nPUT blog\n/]</remark>
<simpara>If you provide <literal>routing</literal> then the routing is copied to the scroll query,
limiting the process to the shards that match that routing value:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST twitter/_delete_by_query?routing=1
{
  "query": {
    "range" : {
        "age" : {
           "gte" : 10
        }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>By default <literal>_delete_by_query</literal> uses scroll batches of 1000. You can change the
batch size with the <literal>scroll_size</literal> URL parameter:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST twitter/_delete_by_query?scroll_size=5000
{
  "query": {
    "term": {
      "user": "kimchy"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<bridgehead id="_url_parameters" renderas="sect2">URL Parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/delete-by-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>In addition to the standard parameters like <literal>pretty</literal>, the Delete By Query API
also supports <literal>refresh</literal>, <literal>wait_for_completion</literal>, <literal>wait_for_active_shards</literal>, and <literal>timeout</literal>.</simpara>
<simpara>Sending the <literal>refresh</literal> will refresh all shards involved in the delete by query
once the request completes. This is different than the Delete API&#8217;s <literal>refresh</literal>
parameter which causes just the shard that received the delete request
to be refreshed.</simpara>
<simpara>If the request contains <literal>wait_for_completion=false</literal> then Elasticsearch will
perform some preflight checks, launch the request, and then return a <literal>task</literal>
which can be used with <link linkend="docs-delete-by-query-task-api">Tasks APIs</link>
to cancel or get the status of the task. Elasticsearch will also create a
record of this task as a document at <literal>.tasks/task/${taskId}</literal>. This is yours
to keep or remove as you see fit. When you are done with it, delete it so
Elasticsearch can reclaim the space it uses.</simpara>
<simpara><literal>wait_for_active_shards</literal> controls how many copies of a shard must be active
before proceeding with the request. See <link linkend="index-wait-for-active-shards">here</link>
for details. <literal>timeout</literal> controls how long each write request waits for unavailable
shards to become available. Both work exactly how they work in the
<link linkend="docs-bulk">Bulk API</link>.</simpara>
<simpara><literal>requests_per_second</literal> can be set to any positive decimal number (<literal>1.4</literal>, <literal>6</literal>,
<literal>1000</literal>, etc) and throttles the number of requests per second that the delete-by-query
issues or it can be set to <literal>-1</literal> to disabled throttling. The throttling is done
waiting between bulk batches so that it can manipulate the scroll timeout. The
wait time is the difference between the time it took the batch to complete and
the time <literal>requests_per_second * requests_in_the_batch</literal>. Since the batch isn&#8217;t
broken into multiple bulk requests large batch sizes will cause Elasticsearch
to create many requests and then wait for a while before starting the next set.
This is "bursty" instead of "smooth". The default is <literal>-1</literal>.</simpara>
<bridgehead id="_response_body" renderas="sect2">Response body<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/delete-by-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>The JSON response looks like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "took" : 639,
  "deleted": 0,
  "batches": 1,
  "version_conflicts": 2,
  "retries": 0,
  "throttled_millis": 0,
  "failures" : [ ]
}</programlisting>
<variablelist>
<varlistentry>
<term>
<literal>took</literal>
</term>
<listitem>
<simpara>
The number of milliseconds from start to end of the whole operation.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>deleted</literal>
</term>
<listitem>
<simpara>
The number of documents that were successfully deleted.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>batches</literal>
</term>
<listitem>
<simpara>
The number of scroll responses pulled back by the the delete by query.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>version_conflicts</literal>
</term>
<listitem>
<simpara>
The number of version conflicts that the delete by query hit.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>retries</literal>
</term>
<listitem>
<simpara>
The number of retries that the delete by query did in response to a full queue.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>throttled_millis</literal>
</term>
<listitem>
<simpara>
Number of milliseconds the request slept to conform to <literal>requests_per_second</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>failures</literal>
</term>
<listitem>
<simpara>
Array of all indexing failures. If this is non-empty then the request aborted
because of those failures. See <literal>conflicts</literal> for how to prevent version conflicts
from aborting the operation.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="docs-delete-by-query-task-api" renderas="sect2">Works with the Task API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/delete-by-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>You can fetch the status of any running delete-by-query requests with the
<link linkend="tasks">Task API</link>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _tasks?detailed=true&amp;actions=*/delete/byquery</programlisting>
<remark> CONSOLE</remark>
<simpara>The responses looks like:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "nodes" : {
    "r1A2WoRbTwKZ516z6NEs5A" : {
      "name" : "r1A2WoR",
      "transport_address" : "127.0.0.1:9300",
      "host" : "127.0.0.1",
      "ip" : "127.0.0.1:9300",
      "attributes" : {
        "testattr" : "test",
        "portsfile" : "true"
      },
      "tasks" : {
        "r1A2WoRbTwKZ516z6NEs5A:36619" : {
          "node" : "r1A2WoRbTwKZ516z6NEs5A",
          "id" : 36619,
          "type" : "transport",
          "action" : "indices:data/write/delete/byquery",
          "status" : {    <co id="CO7-1"/>
            "total" : 6154,
            "updated" : 0,
            "created" : 0,
            "deleted" : 3500,
            "batches" : 36,
            "version_conflicts" : 0,
            "noops" : 0,
            "retries": 0,
            "throttled_millis": 0
          },
          "description" : ""
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO7-1">
<para>
this object contains the actual status. It is just like the response json
with the important addition of the <literal>total</literal> field. <literal>total</literal> is the total number
of operations that the reindex expects to perform. You can estimate the
progress by adding the <literal>updated</literal>, <literal>created</literal>, and <literal>deleted</literal> fields. The request
will finish when their sum is equal to the <literal>total</literal> field.
</para>
</callout>
</calloutlist>
<simpara>With the task id you can look up the task directly:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_tasks/taskId:1</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[catch:missing]</remark>
<simpara>The advantage of this API is that it integrates with <literal>wait_for_completion=false</literal>
to transparently return the status of completed tasks. If the task is completed
and <literal>wait_for_completion=false</literal> was set on it them it&#8217;ll come back with a
<literal>results</literal> or an <literal>error</literal> field. The cost of this feature is the document that
<literal>wait_for_completion=false</literal> creates at <literal>.tasks/task/${taskId}</literal>. It is up to
you to delete that document.</simpara>
<bridgehead id="docs-delete-by-query-cancel-task-api" renderas="sect2">Works with the Cancel Task API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/delete-by-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>Any Delete By Query can be canceled using the <link linkend="tasks">Task Cancel API</link>:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _tasks/task_id:1/_cancel</programlisting>
<remark> CONSOLE</remark>
<simpara>The <literal>task_id</literal> can be found using the tasks API above.</simpara>
<simpara>Cancellation should happen quickly but might take a few seconds. The task status
API above will continue to list the task until it is wakes to cancel itself.</simpara>
<bridgehead id="docs-delete-by-query-rethrottle" renderas="sect2">Rethrottling<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/delete-by-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>The value of <literal>requests_per_second</literal> can be changed on a running delete by query
using the <literal>_rethrottle</literal> API:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _delete_by_query/task_id:1/_rethrottle?requests_per_second=-1</programlisting>
<remark> CONSOLE</remark>
<simpara>The <literal>task_id</literal> can be found using the tasks API above.</simpara>
<simpara>Just like when setting it on the <literal>_delete_by_query</literal> API <literal>requests_per_second</literal>
can be either <literal>-1</literal> to disable throttling or any decimal number
like <literal>1.7</literal> or <literal>12</literal> to throttle to that level. Rethrottling that speeds up the
query takes effect immediately but rethrotting that slows down the query will
take effect on after completing the current batch. This prevents scroll
timeouts.</simpara>
<bridgehead id="docs-delete-by-query-manual-slice" renderas="sect2">Manually slicing<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/delete-by-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>Delete-by-query supports <xref linkend="sliced-scroll"/> allowing you to manually parallelize
the process relatively easily:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST twitter/_delete_by_query
{
  "slice": {
    "id": 0,
    "max": 2
  },
  "query": {
    "range": {
      "likes": {
        "lt": 10
      }
    }
  }
}
POST twitter/_delete_by_query
{
  "slice": {
    "id": 1,
    "max": 2
  },
  "query": {
    "range": {
      "likes": {
        "lt": 10
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:big_twitter]</remark>
<simpara>Which you can verify works with:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _refresh
POST twitter/_search?size=0&amp;filter_path=hits.total
{
  "query": {
    "range": {
      "likes": {
        "lt": 10
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Which results in a sensible <literal>total</literal> like this one:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "hits": {
    "total": 0
  }
}</programlisting>
<remark> TESTRESPONSE</remark>
<bridgehead id="docs-delete-by-query-automatic-slice" renderas="sect2">Automatic slicing<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/delete-by-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>You can also let delete-by-query automatically parallelize using
<xref linkend="sliced-scroll"/> to slice on <literal>_uid</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST twitter/_delete_by_query?refresh&amp;slices=5
{
  "query": {
    "range": {
      "likes": {
        "lt": 10
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:big_twitter]</remark>
<simpara>Which you also can verify works with:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST twitter/_search?size=0&amp;filter_path=hits.total
{
  "query": {
    "range": {
      "likes": {
        "lt": 10
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Which results in a sensible <literal>total</literal> like this one:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "hits": {
    "total": 0
  }
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>Adding <literal>slices</literal> to <literal>_delete_by_query</literal> just automates the manual process used in
the section above, creating sub-requests which means it has some quirks:
* You can see these requests in the
<link linkend="docs-delete-by-query-task-api">Tasks APIs</link>. These sub-requests are "child"
tasks of the task for the request with <literal>slices</literal>.
* Fetching the status of the task for the request with <literal>slices</literal> only contains
the status of completed slices.
* These sub-requests are individually addressable for things like cancellation
and rethrottling.
* Rethrottling the request with <literal>slices</literal> will rethrottle the unfinished
sub-request proportionally.
* Canceling the request with <literal>slices</literal> will cancel each sub-request.
* Due to the nature of <literal>slices</literal> each sub-request won&#8217;t get a perfectly even
portion of the documents. All documents will be addressed, but some slices may
be larger than others. Expect larger slices to have a more even distribution.
* Parameters like <literal>requests_per_second</literal> and <literal>size</literal> on a request with <literal>slices</literal>
are distributed proportionally to each sub-request. Combine that with the point
above about distribution being uneven and you should conclude that the using
<literal>size</literal> with <literal>slices</literal> might not result in exactly <literal>size</literal> documents being
`_delete_by_query`ed.
* Each sub-requests gets a slightly different snapshot of the source index
though these are all taken at approximately the same time.</simpara>
<bridgehead id="docs-delete-by-query-picking-slices" renderas="sect2">Picking the number of slices<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/delete-by-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>At this point we have a few recommendations around the number of <literal>slices</literal> to
use (the <literal>max</literal> parameter in the slice API if manually parallelizing):</simpara>
<itemizedlist>
<listitem>
<simpara>
Don&#8217;t use large numbers. <literal>500</literal> creates fairly massive CPU thrash.
</simpara>
</listitem>
<listitem>
<simpara>
It is more efficient from a query performance standpoint to use some multiple
of the number of shards in the source index.
</simpara>
</listitem>
<listitem>
<simpara>
Using exactly as many shards as are in the source index is the most efficient
from a query performance standpoint.
</simpara>
</listitem>
<listitem>
<simpara>
Indexing performance should scale linearly across available resources with
the number of <literal>slices</literal>.
</simpara>
</listitem>
<listitem>
<simpara>
Whether indexing or query performance dominates that process depends on lots
of factors like the documents being reindexed and the cluster doing the
reindexing.
</simpara>
</listitem>
</itemizedlist>
</chapter>
<chapter id="docs-update">
<title>Update API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/update.asciidoc">Edit me</ulink></title>
<simpara>The update API allows to update a document based on a script provided.
The operation gets the document (collocated with the shard) from the
index, runs the script (with optional script language and parameters),
and index back the result (also allows to delete, or ignore the
operation). It uses versioning to make sure no updates have happened
during the "get" and "reindex".</simpara>
<simpara>Note, this operation still means full reindex of the document, it just
removes some network roundtrips and reduces chances of version conflicts
between the get and the index. The <literal>_source</literal> field needs to be enabled
for this feature to work.</simpara>
<simpara>For example, lets index a simple doc:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT test/type1/1
{
    "counter" : 1,
    "tags" : ["red"]
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_scripted_updates" renderas="sect2">Scripted updates<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/update.asciidoc">Edit me</ulink></bridgehead>
<simpara>Now, we can execute a script that would increment the counter:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST test/type1/1/_update
{
    "script" : {
        "inline": "ctx._source.counter += params.count",
        "lang": "painless",
        "params" : {
            "count" : 4
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>We can add a tag to the list of tags (note, if the tag exists, it
will still add it, since its a list):</simpara>
<programlisting language="js" linenumbering="unnumbered">POST test/type1/1/_update
{
    "script" : {
        "inline": "ctx._source.tags.add(params.tag)",
        "lang": "painless",
        "params" : {
            "tag" : "blue"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>In addition to <literal>_source</literal>, the following variables are available through
the <literal>ctx</literal> map: <literal>_index</literal>, <literal>_type</literal>, <literal>_id</literal>, <literal>_version</literal>, <literal>_routing</literal>,
<literal>_parent</literal>, and <literal>_now</literal> (the current timestamp).</simpara>
<simpara>We can also add a new field to the document:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST test/type1/1/_update
{
    "script" : "ctx._source.new_field = \"value_of_new_field\""
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Or remove a field from the document:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST test/type1/1/_update
{
    "script" : "ctx._source.remove(\"new_field\")"
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>And, we can even change the operation that is executed.  This example deletes
the doc if the <literal>tags</literal> field contain <literal>green</literal>, otherwise it does nothing
(<literal>noop</literal>):</simpara>
<programlisting language="js" linenumbering="unnumbered">POST test/type1/1/_update
{
    "script" : {
        "inline": "if (ctx._source.tags.contains(params.tag)) { ctx.op = \"delete\" } else { ctx.op = \"none\" }",
        "lang": "painless",
        "params" : {
            "tag" : "green"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<bridgehead id="_updates_with_a_partial_document" renderas="sect2">Updates with a partial document<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/update.asciidoc">Edit me</ulink></bridgehead>
<simpara>The update API also support passing a partial document,
which will be merged into the existing document (simple recursive merge,
inner merging of objects, replacing core "keys/values" and arrays). For
example:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST test/type1/1/_update
{
    "doc" : {
        "name" : "new_name"
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>If both <literal>doc</literal> and <literal>script</literal> are specified, then <literal>doc</literal> is ignored. Best is
to put your field pairs of the partial document in the script itself.</simpara>
<bridgehead id="_detecting_noop_updates" renderas="sect2">Detecting noop updates<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/update.asciidoc">Edit me</ulink></bridgehead>
<simpara>If <literal>doc</literal> is specified its value is merged with the existing <literal>_source</literal>.
By default updates that don&#8217;t change anything detect that they don&#8217;t change anything and return "result": "noop" like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST test/type1/1/_update
{
    "doc" : {
        "name" : "new_name"
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>If <literal>name</literal> was <literal>new_name</literal> before the request was sent then the entire update
request is ignored. The <literal>result</literal> element in the response returns <literal>noop</literal> if
the request was ignored.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "_shards": {
        "total": 0,
        "successful": 0,
        "failed": 0
   },
   "_index": "test",
   "_type": "type1",
   "_id": "1",
   "_version": 6,
   "result": noop
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>You can disable this behavior by setting "detect_noop": false like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST test/type1/1/_update
{
    "doc" : {
        "name" : "new_name"
    },
    "detect_noop": true
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<bridgehead id="upserts" renderas="sect2">Upserts<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/update.asciidoc">Edit me</ulink></bridgehead>
<simpara>If the document does not already exist, the contents of the <literal>upsert</literal> element
will be inserted as a new document.  If the document does exist, then the
<literal>script</literal> will be executed instead:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST test/type1/1/_update
{
    "script" : {
        "inline": "ctx._source.counter += params.count",
        "lang": "painless",
        "params" : {
            "count" : 4
        }
    },
    "upsert" : {
        "counter" : 1
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<bridgehead id="_literal_scripted_upsert_literal" renderas="sect3"><literal>scripted_upsert</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/update.asciidoc">Edit me</ulink></bridgehead>
<simpara>If you would like your script to run regardless of whether the document exists
or not&#8201;&#8212;&#8201;i.e. the script handles initializing the document instead of the
<literal>upsert</literal> element&#8201;&#8212;&#8201;then set <literal>scripted_upsert</literal> to <literal>true</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST sessions/session/dh3sgudg8gsrgl/_update
{
    "scripted_upsert":true,
    "script" : {
        "id": "my_web_session_summariser",
        "params" : {
            "pageViewEvent" : {
                "url":"foo.com/bar",
                "response":404,
                "time":"2014-01-01 12:32"
            }
        }
    },
    "upsert" : {}
}</programlisting>
<bridgehead id="_literal_doc_as_upsert_literal" renderas="sect3"><literal>doc_as_upsert</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/update.asciidoc">Edit me</ulink></bridgehead>
<simpara>Instead of sending a partial <literal>doc</literal> plus an <literal>upsert</literal> doc, setting
<literal>doc_as_upsert</literal> to <literal>true</literal> will use the contents of <literal>doc</literal> as the <literal>upsert</literal>
value:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST test/type1/1/_update
{
    "doc" : {
        "name" : "new_name"
    },
    "doc_as_upsert" : true
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<bridgehead id="_parameters_2" renderas="sect2">Parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/update.asciidoc">Edit me</ulink></bridgehead>
<simpara>The update operation supports the following query-string parameters:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>retry_on_conflict</literal>
</simpara>
</entry>
<entry>
<simpara>
In between the get and indexing phases of the update, it is possible that
another process might have already updated the same document.  By default, the
update will fail with a version conflict exception.  The <literal>retry_on_conflict</literal>
parameter controls how many times to retry the update before finally throwing
an exception.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>routing</literal>
</simpara>
</entry>
<entry>
<simpara>
Routing is used to route the update request to the right shard and sets the
routing for the upsert request if the document being updated doesn&#8217;t exist.
Can&#8217;t be used to update the routing of an existing document.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>parent</literal>
</simpara>
</entry>
<entry>
<simpara>
Parent is used to route the update request to the right shard and sets the
parent for the upsert request if the document being updated doesn&#8217;t exist.
Can&#8217;t be used to update the <literal>parent</literal> of an existing document.
If an alias index routing is specified then it overrides the parent routing and it is used to route the request.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>timeout</literal>
</simpara>
</entry>
<entry>
<simpara>
Timeout waiting for a shard to become available.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>wait_for_active_shards</literal>
</simpara>
</entry>
<entry>
<simpara>
The number of shard copies required to be active before proceeding with the update operation.
See <link linkend="index-wait-for-active-shards">here</link> for details.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>refresh</literal>
</simpara>
</entry>
<entry>
<simpara>
Control when the changes made by this request are visible to search. See
<xref linkend="docs-refresh"/>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>_source</literal>
</simpara>
</entry>
<entry>
<simpara>
Allows to control if and how the updated source should be returned in the response.
By default the updated source is not returned.
See <link linkend="search-request-source-filtering"><literal>source filtering</literal></link> for details.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>version</literal> &amp; <literal>version_type</literal>
</simpara>
</entry>
<entry>
<simpara>
The update API uses the Elasticsearch&#8217;s versioning support internally to make
sure the document doesn&#8217;t change during the update. You can use the <literal>version</literal>
parameter to specify that the document should only be updated if its version
matches the one specified. By setting version type to <literal>force</literal> you can force
the new version of the document after update (use with care! with <literal>force</literal>
there is no guarantee the document didn&#8217;t change).
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<note>
<title>The update API does not support external versioning</title>
<simpara>External versioning (version types <literal>external</literal> &amp; <literal>external_gte</literal>) is not
supported by the update API as it would result in Elasticsearch version
numbers being out of sync with the external system.  Use the
<link linkend="docs-index_"><literal>index</literal> API</link> instead.</simpara>
</note>
</chapter>
<chapter id="docs-update-by-query">
<title>Update By Query API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/update-by-query.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>The update-by-query API is new and should still be considered experimental.  The API may change in ways that are not backwards compatible.</simpara></warning>
<simpara>The simplest usage of <literal>_update_by_query</literal> just performs an update on every
document in the index without changing the source. This is useful to
<link linkend="picking-up-a-new-property">pick up a new property</link> or some other online
mapping change. Here is the API:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST twitter/_update_by_query?conflicts=proceed</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:big_twitter]</remark>
<simpara>That will return something like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "took" : 147,
  "timed_out": false,
  "updated": 120,
  "deleted": 0,
  "batches": 1,
  "version_conflicts": 0,
  "noops": 0,
  "retries": {
    "bulk": 0,
    "search": 0
  },
  "throttled_millis": 0,
  "requests_per_second": -1.0,
  "throttled_until_millis": 0,
  "total": 120,
  "failures" : [ ]
}</programlisting>
<remark> TESTRESPONSE[s/"took" : 147/"took" : "$body.took"/]</remark>
<simpara><literal>_update_by_query</literal> gets a snapshot of the index when it starts and indexes what
it finds using <literal>internal</literal> versioning. That means that you&#8217;ll get a version
conflict if the document changes between the time when the snapshot was taken
and when the index request is processed. When the versions match the document
is updated and the version number is incremented.</simpara>
<note><simpara>Since <literal>internal</literal> versioning does not support the value 0 as a valid
version number, documents with version equal to zero cannot be updated using
<literal>_update_by_query</literal> and will fail the request.</simpara></note>
<simpara>All update and query failures cause the <literal>_update_by_query</literal> to abort and are
returned in the <literal>failures</literal> of the response. The updates that have been
performed still stick. In other words, the process is not rolled back, only
aborted. While the first failure causes the abort, all failures that are
returned by the failing bulk request are returned in the <literal>failures</literal> element; therefore
it&#8217;s possible for there to be quite a few failed entities.</simpara>
<simpara>If you want to simply count version conflicts not cause the <literal>_update_by_query</literal>
to abort you can set <literal>conflicts=proceed</literal> on the url or <literal>"conflicts": "proceed"</literal>
in the request body. The first example does this because it is just trying to
pick up an online mapping change and a version conflict simply means that the
conflicting document was updated between the start of the <literal>_update_by_query</literal>
and the time when it attempted to update the document. This is fine because
that update will have picked up the online mapping update.</simpara>
<simpara>Back to the API format, you can limit <literal>_update_by_query</literal> to a single type. This
will only update <literal>tweet</literal> documents from the <literal>twitter</literal> index:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST twitter/tweet/_update_by_query?conflicts=proceed</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>You can also limit <literal>_update_by_query</literal> using the
<link linkend="query-dsl">Query DSL</link>. This will update all documents from the
<literal>twitter</literal> index for the user <literal>kimchy</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST twitter/_update_by_query?conflicts=proceed
{
  "query": { <co id="CO8-1"/>
    "term": {
      "user": "kimchy"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<calloutlist>
<callout arearefs="CO8-1">
<para>
The query must be passed as a value to the <literal>query</literal> key, in the same
way as the <link linkend="search-search">Search API</link>. You can also use the <literal>q</literal>
parameter in the same way as the search api.
</para>
</callout>
</calloutlist>
<simpara>So far we&#8217;ve only been updating documents without changing their source. That
is genuinely useful for things like
<link linkend="picking-up-a-new-property">picking up new properties</link> but it&#8217;s only half the
fun. <literal>_update_by_query</literal> supports a <literal>script</literal> object to update the document. This
will increment the <literal>likes</literal> field on all of kimchy&#8217;s tweets:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST twitter/_update_by_query
{
  "script": {
    "inline": "ctx._source.likes++",
    "lang": "painless"
  },
  "query": {
    "term": {
      "user": "kimchy"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>Just as in <link linkend="docs-update">Update API</link> you can set <literal>ctx.op</literal> to change the
operation that is executed:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>noop</literal>
</term>
<listitem>
<simpara>
Set <literal>ctx.op = "noop"</literal> if your script decides that it doesn&#8217;t have to make any
changes. That will cause <literal>_update_by_query</literal> to omit that document from its updates.
 This no operation will be reported in the <literal>noop</literal> counter in the
<link linkend="docs-update-by-query-response-body">response body</link>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>delete</literal>
</term>
<listitem>
<simpara>
Set <literal>ctx.op = "delete"</literal> if your script decides that the document must be
 deleted. The deletion will be reported in the <literal>deleted</literal> counter in the
<link linkend="docs-update-by-query-response-body">response body</link>.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>Setting <literal>ctx.op</literal> to anything else is an error. Setting any
other field in <literal>ctx</literal> is an error.</simpara>
<simpara>Note that we stopped specifying <literal>conflicts=proceed</literal>. In this case we want a
version conflict to abort the process so we can handle the failure.</simpara>
<simpara>This API doesn&#8217;t allow you to move the documents it touches, just modify their
source. This is intentional! We&#8217;ve made no provisions for removing the document
from its original location.</simpara>
<simpara>It&#8217;s also possible to do this whole thing on multiple indexes and multiple
types at once, just like the search API:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST twitter,blog/tweet,post/_update_by_query</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT twitter\nPUT blog\n/]</remark>
<simpara>If you provide <literal>routing</literal> then the routing is copied to the scroll query,
limiting the process to the shards that match that routing value:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST twitter/_update_by_query?routing=1</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>By default <literal>_update_by_query</literal> uses scroll batches of 1000. You can change the
batch size with the <literal>scroll_size</literal> URL parameter:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST twitter/_update_by_query?scroll_size=100</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara><literal>_update_by_query</literal> can also use the <xref linkend="ingest"/> feature by
specifying a <literal>pipeline</literal> like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT _ingest/pipeline/set-foo
{
  "description" : "sets foo",
  "processors" : [ {
      "set" : {
        "field": "foo",
        "value": "bar"
      }
  } ]
}
POST twitter/_update_by_query?pipeline=set-foo</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<bridgehead id="_url_parameters_2" renderas="sect2">URL Parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/update-by-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>In addition to the standard parameters like <literal>pretty</literal>, the Update By Query API
also supports <literal>refresh</literal>, <literal>wait_for_completion</literal>, <literal>wait_for_active_shards</literal>, and <literal>timeout</literal>.</simpara>
<simpara>Sending the <literal>refresh</literal> will update all shards in the index being updated when
the request completes. This is different than the Index API&#8217;s <literal>refresh</literal>
parameter which causes just the shard that received the new data to be indexed.</simpara>
<simpara>If the request contains <literal>wait_for_completion=false</literal> then Elasticsearch will
perform some preflight checks, launch the request, and then return a <literal>task</literal>
which can be used with <link linkend="docs-update-by-query-task-api">Tasks APIs</link>
to cancel or get the status of the task. Elasticsearch will also create a
record of this task as a document at <literal>.tasks/task/${taskId}</literal>. This is yours
to keep or remove as you see fit. When you are done with it, delete it so
Elasticsearch can reclaim the space it uses.</simpara>
<simpara><literal>wait_for_active_shards</literal> controls how many copies of a shard must be active
before proceeding with the request. See <link linkend="index-wait-for-active-shards">here</link>
for details. <literal>timeout</literal> controls how long each write request waits for unavailable
shards to become available. Both work exactly how they work in the
<link linkend="docs-bulk">Bulk API</link>.</simpara>
<simpara><literal>requests_per_second</literal> can be set to any positive decimal number (<literal>1.4</literal>, <literal>6</literal>,
<literal>1000</literal>, etc) and throttles the number of requests per second that the update-by-query
issues or it can be set to <literal>-1</literal> to disabled throttling. The throttling is done
waiting between bulk batches so that it can manipulate the scroll timeout. The
wait time is the difference between the time it took the batch to complete and
the time <literal>requests_per_second * requests_in_the_batch</literal>. Since the batch isn&#8217;t
broken into multiple bulk requests large batch sizes will cause Elasticsearch
to create many requests and then wait for a while before starting the next set.
This is "bursty" instead of "smooth". The default is <literal>-1</literal>.</simpara>
<bridgehead id="docs-update-by-query-response-body" renderas="sect2">Response body<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/update-by-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>The JSON response looks like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "took" : 639,
  "updated": 0,
  "batches": 1,
  "version_conflicts": 2,
  "retries": {
    "bulk": 0,
    "search": 0
  }
  "throttled_millis": 0,
  "failures" : [ ]
}</programlisting>
<variablelist>
<varlistentry>
<term>
<literal>took</literal>
</term>
<listitem>
<simpara>
The number of milliseconds from start to end of the whole operation.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>updated</literal>
</term>
<listitem>
<simpara>
The number of documents that were successfully updated.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>batches</literal>
</term>
<listitem>
<simpara>
The number of scroll responses pulled back by the the update by query.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>version_conflicts</literal>
</term>
<listitem>
<simpara>
The number of version conflicts that the update by query hit.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>retries</literal>
</term>
<listitem>
<simpara>
The number of retries attempted by update-by-query. <literal>bulk</literal> is the number of bulk
actions retried and <literal>search</literal> is the number of search actions retried.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>throttled_millis</literal>
</term>
<listitem>
<simpara>
Number of milliseconds the request slept to conform to <literal>requests_per_second</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>failures</literal>
</term>
<listitem>
<simpara>
Array of all indexing failures. If this is non-empty then the request aborted
because of those failures. See <literal>conflicts</literal> for how to prevent version conflicts
from aborting the operation.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="docs-update-by-query-task-api" renderas="sect2">Works with the Task API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/update-by-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>You can fetch the status of all running update-by-query requests with the
<link linkend="tasks">Task API</link>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _tasks?detailed=true&amp;actions=*byquery</programlisting>
<remark> CONSOLE</remark>
<simpara>The responses looks like:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "nodes" : {
    "r1A2WoRbTwKZ516z6NEs5A" : {
      "name" : "r1A2WoR",
      "transport_address" : "127.0.0.1:9300",
      "host" : "127.0.0.1",
      "ip" : "127.0.0.1:9300",
      "attributes" : {
        "testattr" : "test",
        "portsfile" : "true"
      },
      "tasks" : {
        "r1A2WoRbTwKZ516z6NEs5A:36619" : {
          "node" : "r1A2WoRbTwKZ516z6NEs5A",
          "id" : 36619,
          "type" : "transport",
          "action" : "indices:data/write/update/byquery",
          "status" : {    <co id="CO9-1"/>
            "total" : 6154,
            "updated" : 3500,
            "created" : 0,
            "deleted" : 0,
            "batches" : 4,
            "version_conflicts" : 0,
            "noops" : 0,
            "retries": {
              "bulk": 0,
              "search": 0
            }
            "throttled_millis": 0
          },
          "description" : ""
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO9-1">
<para>
this object contains the actual status. It is just like the response json
with the important addition of the <literal>total</literal> field. <literal>total</literal> is the total number
of operations that the reindex expects to perform. You can estimate the
progress by adding the <literal>updated</literal>, <literal>created</literal>, and <literal>deleted</literal> fields. The request
will finish when their sum is equal to the <literal>total</literal> field.
</para>
</callout>
</calloutlist>
<simpara>With the task id you can look up the task directly:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_tasks/taskId:1</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[catch:missing]</remark>
<simpara>The advantage of this API is that it integrates with <literal>wait_for_completion=false</literal>
to transparently return the status of completed tasks. If the task is completed
and <literal>wait_for_completion=false</literal> was set on it them it&#8217;ll come back with a
<literal>results</literal> or an <literal>error</literal> field. The cost of this feature is the document that
<literal>wait_for_completion=false</literal> creates at <literal>.tasks/task/${taskId}</literal>. It is up to
you to delete that document.</simpara>
<bridgehead id="docs-update-by-query-cancel-task-api" renderas="sect2">Works with the Cancel Task API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/update-by-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>Any Update By Query can be canceled using the <link linkend="tasks">Task Cancel API</link>:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _tasks/task_id:1/_cancel</programlisting>
<remark> CONSOLE</remark>
<simpara>The <literal>task_id</literal> can be found using the tasks API above.</simpara>
<simpara>Cancellation should happen quickly but might take a few seconds. The task status
API above will continue to list the task until it is wakes to cancel itself.</simpara>
<bridgehead id="docs-update-by-query-rethrottle" renderas="sect2">Rethrottling<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/update-by-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>The value of <literal>requests_per_second</literal> can be changed on a running update by query
using the <literal>_rethrottle</literal> API:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _update_by_query/task_id:1/_rethrottle?requests_per_second=-1</programlisting>
<remark> CONSOLE</remark>
<simpara>The <literal>task_id</literal> can be found using the tasks API above.</simpara>
<simpara>Just like when setting it on the <literal>_update_by_query</literal> API <literal>requests_per_second</literal>
can be either <literal>-1</literal> to disable throttling or any decimal number
like <literal>1.7</literal> or <literal>12</literal> to throttle to that level. Rethrottling that speeds up the
query takes effect immediately but rethrotting that slows down the query will
take effect on after completing the current batch. This prevents scroll
timeouts.</simpara>
<bridgehead id="docs-update-by-query-manual-slice" renderas="sect3">Manual slicing<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/update-by-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>Update-by-query supports <xref linkend="sliced-scroll"/> allowing you to manually parallelize
the process relatively easily:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST twitter/_update_by_query
{
  "slice": {
    "id": 0,
    "max": 2
  },
  "script": {
    "inline": "ctx._source['extra'] = 'test'"
  }
}
POST twitter/_update_by_query
{
  "slice": {
    "id": 1,
    "max": 2
  },
  "script": {
    "inline": "ctx._source['extra'] = 'test'"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:big_twitter]</remark>
<simpara>Which you can verify works with:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _refresh
POST twitter/_search?size=0&amp;q=extra:test&amp;filter_path=hits.total</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Which results in a sensible <literal>total</literal> like this one:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "hits": {
    "total": 120
  }
}</programlisting>
<remark> TESTRESPONSE</remark>
<bridgehead id="docs-update-by-query-automatic-slice" renderas="sect2">Automatic slicing<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/update-by-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>You can also let update-by-query automatically parallelize using
<xref linkend="sliced-scroll"/> to slice on <literal>_uid</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST twitter/_update_by_query?refresh&amp;slices=5
{
  "script": {
    "inline": "ctx._source['extra'] = 'test'"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:big_twitter]</remark>
<simpara>Which you also can verify works with:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST twitter/_search?size=0&amp;q=extra:test&amp;filter_path=hits.total</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Which results in a sensible <literal>total</literal> like this one:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "hits": {
    "total": 120
  }
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>Adding <literal>slices</literal> to <literal>_update_by_query</literal> just automates the manual process used in
the section above, creating sub-requests which means it has some quirks:
* You can see these requests in the
<link linkend="docs-update-by-query-task-api">Tasks APIs</link>. These sub-requests are "child"
tasks of the task for the request with <literal>slices</literal>.
* Fetching the status of the task for the request with <literal>slices</literal> only contains
the status of completed slices.
* These sub-requests are individually addressable for things like cancellation
and rethrottling.
* Rethrottling the request with <literal>slices</literal> will rethrottle the unfinished
sub-request proportionally.
* Canceling the request with <literal>slices</literal> will cancel each sub-request.
* Due to the nature of <literal>slices</literal> each sub-request won&#8217;t get a perfectly even
portion of the documents. All documents will be addressed, but some slices may
be larger than others. Expect larger slices to have a more even distribution.
* Parameters like <literal>requests_per_second</literal> and <literal>size</literal> on a request with <literal>slices</literal>
are distributed proportionally to each sub-request. Combine that with the point
above about distribution being uneven and you should conclude that the using
<literal>size</literal> with <literal>slices</literal> might not result in exactly <literal>size</literal> documents being
`_update_by_query`ed.
* Each sub-requests gets a slightly different snapshot of the source index
though these are all taken at approximately the same time.</simpara>
<bridgehead id="docs-update-by-query-picking-slices" renderas="sect2">Picking the number of slices<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/update-by-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>At this point we have a few recommendations around the number of <literal>slices</literal> to
use (the <literal>max</literal> parameter in the slice API if manually parallelizing):</simpara>
<itemizedlist>
<listitem>
<simpara>
Don&#8217;t use large numbers. <literal>500</literal> creates fairly massive CPU thrash.
</simpara>
</listitem>
<listitem>
<simpara>
It is more efficient from a query performance standpoint to use some multiple
of the number of shards in the source index.
</simpara>
</listitem>
<listitem>
<simpara>
Using exactly as many shards as are in the source index is the most efficient
from a query performance standpoint.
</simpara>
</listitem>
<listitem>
<simpara>
Indexing performance should scale linearly across available resources with
the number of <literal>slices</literal>.
</simpara>
</listitem>
<listitem>
<simpara>
Whether indexing or query performance dominates that process depends on lots
of factors like the documents being reindexed and the cluster doing the
reindexing.
</simpara>
</listitem>
</itemizedlist>
<bridgehead id="picking-up-a-new-property" renderas="sect2">Pick up a new property<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/update-by-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>Say you created an index without dynamic mapping, filled it with data, and then
added a mapping value to pick up more fields from the data:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT test
{
  "mappings": {
    "test": {
      "dynamic": false,   <co id="CO10-1"/>
      "properties": {
        "text": {"type": "text"}
      }
    }
  }
}

POST test/test?refresh
{
  "text": "words words",
  "flag": "bar"
}
POST test/test?refresh
{
  "text": "words words",
  "flag": "foo"
}
PUT test/_mapping/test   <co id="CO10-2"/>
{
  "properties": {
    "text": {"type": "text"},
    "flag": {"type": "text", "analyzer": "keyword"}
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO10-1">
<para>
This means that new fields won&#8217;t be indexed, just stored in <literal>_source</literal>.
</para>
</callout>
<callout arearefs="CO10-2">
<para>
This updates the mapping to add the new <literal>flag</literal> field. To pick up the new
field you have to reindex all documents with it.
</para>
</callout>
</calloutlist>
<simpara>Searching for the data won&#8217;t find anything:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST test/_search?filter_path=hits.total
{
  "query": {
    "match": {
      "flag": "foo"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<programlisting language="js" linenumbering="unnumbered">{
  "hits" : {
    "total" : 0
  }
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>But you can issue an <literal>_update_by_query</literal> request to pick up the new mapping:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST test/_update_by_query?refresh&amp;conflicts=proceed
POST test/_search?filter_path=hits.total
{
  "query": {
    "match": {
      "flag": "foo"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<programlisting language="js" linenumbering="unnumbered">{
  "hits" : {
    "total" : 1
  }
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>You can do the exact same thing when adding a field to a multifield.</simpara>
</chapter>
<chapter id="docs-multi-get">
<title>Multi Get API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/multi-get.asciidoc">Edit me</ulink></title>
<simpara>Multi GET API allows to get multiple documents based on an index, type
(optional) and id (and possibly routing). The response includes a <literal>docs</literal>
array with all the fetched documents, each element similar in structure
to a document provided by the <link linkend="docs-get">get</link>
API. Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl 'localhost:9200/_mget' -d '{
    "docs" : [
        {
            "_index" : "test",
            "_type" : "type",
            "_id" : "1"
        },
        {
            "_index" : "test",
            "_type" : "type",
            "_id" : "2"
        }
    ]
}'</programlisting>
<simpara>The <literal>mget</literal> endpoint can also be used against an index (in which case it
is not required in the body):</simpara>
<programlisting language="js" linenumbering="unnumbered">curl 'localhost:9200/test/_mget' -d '{
    "docs" : [
        {
            "_type" : "type",
            "_id" : "1"
        },
        {
            "_type" : "type",
            "_id" : "2"
        }
    ]
}'</programlisting>
<simpara>And type:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl 'localhost:9200/test/type/_mget' -d '{
    "docs" : [
        {
            "_id" : "1"
        },
        {
            "_id" : "2"
        }
    ]
}'</programlisting>
<simpara>In which case, the <literal>ids</literal> element can directly be used to simplify the
request:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl 'localhost:9200/test/type/_mget' -d '{
    "ids" : ["1", "2"]
}'</programlisting>
<bridgehead id="mget-type" renderas="sect2">Optional Type<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/multi-get.asciidoc">Edit me</ulink></bridgehead>
<simpara>The mget API allows for <literal>_type</literal> to be optional. Set it to <literal>_all</literal> or leave it empty in order
to fetch the first document matching the id across all types.</simpara>
<simpara>If you don&#8217;t set the type and have many documents sharing the same <literal>_id</literal>, you will end up
getting only the first matching document.</simpara>
<simpara>For example, if you have a document 1 within typeA and typeB then following request
will give you back only the same document twice:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl 'localhost:9200/test/_mget' -d '{
    "ids" : ["1", "1"]
}'</programlisting>
<simpara>You need in that case to explicitly set the <literal>_type</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /test/_mget/
{
  "docs" : [
        {
            "_type":"typeA",
            "_id" : "1"
        },
        {
            "_type":"typeB",
            "_id" : "1"
        }
    ]
}</programlisting>
<bridgehead id="mget-source-filtering" renderas="sect2">Source filtering<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/multi-get.asciidoc">Edit me</ulink></bridgehead>
<simpara>By default, the <literal>_source</literal> field will be returned for every document (if stored).
Similar to the <link linkend="get-source-filtering">get</link> API, you can retrieve only parts of
the <literal>_source</literal> (or not at all) by using the <literal>_source</literal> parameter. You can also use
the url parameters <literal>_source</literal>,<literal>_source_include</literal> &amp; <literal>_source_exclude</literal> to specify defaults,
which will be used when there are no per-document instructions.</simpara>
<simpara>For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl 'localhost:9200/_mget' -d '{
    "docs" : [
        {
            "_index" : "test",
            "_type" : "type",
            "_id" : "1",
            "_source" : false
        },
        {
            "_index" : "test",
            "_type" : "type",
            "_id" : "2",
            "_source" : ["field3", "field4"]
        },
        {
            "_index" : "test",
            "_type" : "type",
            "_id" : "3",
            "_source" : {
                "include": ["user"],
                "exclude": ["user.location"]
            }
        }
    ]
}'</programlisting>
<bridgehead id="mget-fields" renderas="sect2">Fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/multi-get.asciidoc">Edit me</ulink></bridgehead>
<simpara>Specific stored fields can be specified to be retrieved per document to get, similar to the <link linkend="get-stored-fields">stored_fields</link> parameter of the Get API.
For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl 'localhost:9200/_mget' -d '{
    "docs" : [
        {
            "_index" : "test",
            "_type" : "type",
            "_id" : "1",
            "stored_fields" : ["field1", "field2"]
        },
        {
            "_index" : "test",
            "_type" : "type",
            "_id" : "2",
            "stored_fields" : ["field3", "field4"]
        }
    ]
}'</programlisting>
<simpara>Alternatively, you can specify the <literal>stored_fields</literal> parameter in the query string
as a default to be applied to all documents.</simpara>
<programlisting language="js" linenumbering="unnumbered">curl 'localhost:9200/test/type/_mget?stored_fields=field1,field2' -d '{
    "docs" : [
        {
            "_id" : "1" <co id="CO11-1"/>
        },
        {
            "_id" : "2",
            "stored_fields" : ["field3", "field4"] <co id="CO11-2"/>
        }
    ]
}'</programlisting>
<calloutlist>
<callout arearefs="CO11-1">
<para>
Returns <literal>field1</literal> and <literal>field2</literal>
</para>
</callout>
<callout arearefs="CO11-2">
<para>
Returns <literal>field3</literal> and <literal>field4</literal>
</para>
</callout>
</calloutlist>
<bridgehead id="_generated_fields" renderas="sect2">Generated fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/multi-get.asciidoc">Edit me</ulink></bridgehead>
<simpara>See <xref linkend="generated-fields"/> for fields generated only when indexing.</simpara>
<bridgehead id="mget-routing" renderas="sect2">Routing<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/multi-get.asciidoc">Edit me</ulink></bridgehead>
<simpara>You can also specify routing value as a parameter:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl 'localhost:9200/_mget?routing=key1' -d '{
    "docs" : [
        {
            "_index" : "test",
            "_type" : "type",
            "_id" : "1",
            "_routing" : "key2"
        },
        {
            "_index" : "test",
            "_type" : "type",
            "_id" : "2"
        }
    ]
}'</programlisting>
<simpara>In this example, document <literal>test/type/2</literal> will be fetch from shard corresponding to routing key <literal>key1</literal> but
document <literal>test/type/1</literal> will be fetch from shard corresponding to routing key <literal>key2</literal>.</simpara>
<bridgehead id="mget-security" renderas="sect2">Security<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/multi-get.asciidoc">Edit me</ulink></bridgehead>
<simpara>See <xref linkend="url-access-control"/></simpara>
</chapter>
<chapter id="docs-bulk">
<title>Bulk API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/bulk.asciidoc">Edit me</ulink></title>
<simpara>The bulk API makes it possible to perform many index/delete operations
in a single API call. This can greatly increase the indexing speed.</simpara>
<sidebar>
<title>Client support for bulk requests</title>
<simpara>Some of the officially supported clients provide helpers to assist with
bulk requests and reindexing of documents from one index to another:</simpara>
<variablelist>
<varlistentry>
<term>
Perl
</term>
<listitem>
<simpara>
    See <ulink url="https://metacpan.org/pod/Search::Elasticsearch::Bulk">Search::Elasticsearch::Bulk</ulink>
    and <ulink url="https://metacpan.org/pod/Search::Elasticsearch::Scroll">Search::Elasticsearch::Scroll</ulink>
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Python
</term>
<listitem>
<simpara>
    See <ulink url="http://elasticsearch-py.readthedocs.org/en/master/helpers.html">elasticsearch.helpers.*</ulink>
</simpara>
</listitem>
</varlistentry>
</variablelist>
</sidebar>
<simpara>The REST API endpoint is <literal>/_bulk</literal>, and it expects the following JSON
structure:</simpara>
<programlisting language="js" linenumbering="unnumbered">action_and_meta_data\n
optional_source\n
action_and_meta_data\n
optional_source\n
....
action_and_meta_data\n
optional_source\n</programlisting>
<simpara><emphasis role="strong">NOTE</emphasis>: the final line of data must end with a newline character <literal>\n</literal>.</simpara>
<simpara>The possible actions are <literal>index</literal>, <literal>create</literal>, <literal>delete</literal> and <literal>update</literal>.
<literal>index</literal> and <literal>create</literal> expect a source on the next
line, and have the same semantics as the <literal>op_type</literal> parameter to the
standard index API (i.e. create will fail if a document with the same
index and type exists already, whereas index will add or replace a
document as necessary). <literal>delete</literal> does not expect a source on the
following line, and has the same semantics as the standard delete API.
<literal>update</literal> expects that the partial doc, upsert and script and its options
are specified on the next line.</simpara>
<simpara>If you&#8217;re providing text file input to <literal>curl</literal>, you <emphasis role="strong">must</emphasis> use the
<literal>--data-binary</literal> flag instead of plain <literal>-d</literal>. The latter doesn&#8217;t preserve
newlines. Example:</simpara>
<programlisting language="js" linenumbering="unnumbered">$ cat requests
{ "index" : { "_index" : "test", "_type" : "type1", "_id" : "1" } }
{ "field1" : "value1" }
$ curl -s -XPOST localhost:9200/_bulk --data-binary "@requests"; echo
{"took":7, "errors": false, "items":[{"index":{"_index":"test","_type":"type1","_id":"1","_version":1,"result":"created","forced_refresh":false}}]}</programlisting>
<simpara>Because this format uses literal <literal>\n</literal>'s as delimiters, please be sure
that the JSON actions and sources are not pretty printed. Here is an
example of a correct sequence of bulk commands:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _bulk
{ "index" : { "_index" : "test", "_type" : "type1", "_id" : "1" } }
{ "field1" : "value1" }
{ "delete" : { "_index" : "test", "_type" : "type1", "_id" : "2" } }
{ "create" : { "_index" : "test", "_type" : "type1", "_id" : "3" } }
{ "field1" : "value3" }
{ "update" : {"_id" : "1", "_type" : "type1", "_index" : "test"} }
{ "doc" : {"field2" : "value2"} }</programlisting>
<remark> CONSOLE</remark>
<simpara>The result of this bulk operation is:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "took": 30,
   "errors": false,
   "items": [
      {
         "index": {
            "_index": "test",
            "_type": "type1",
            "_id": "1",
            "_version": 1,
            "result": "created",
            "_shards": {
               "total": 2,
               "successful": 1,
               "failed": 0
            },
            "created": true,
            "status": 201
         }
      },
      {
         "delete": {
            "found": false,
            "_index": "test",
            "_type": "type1",
            "_id": "2",
            "_version": 1,
            "result": "not_found",
            "_shards": {
               "total": 2,
               "successful": 1,
               "failed": 0
            },
            "status": 404
         }
      },
      {
         "create": {
            "_index": "test",
            "_type": "type1",
            "_id": "3",
            "_version": 1,
            "result": "created",
            "_shards": {
               "total": 2,
               "successful": 1,
               "failed": 0
            },
            "created": true,
            "status": 201
         }
      },
      {
         "update": {
            "_index": "test",
            "_type": "type1",
            "_id": "1",
            "_version": 2,
            "result": "updated",
            "_shards": {
                "total": 2,
                "successful": 1,
                "failed": 0
            },
            "status": 200
         }
      }
   ]
}</programlisting>
<remark> TESTRESPONSE[s/"took": 30/"took": $body.took/ s/"index_uuid": .../"index_uuid": $body.items.3.update.error.index_uuid/]</remark>
<simpara>The endpoints are <literal>/_bulk</literal>, <literal>/{index}/_bulk</literal>, and <literal>{index}/{type}/_bulk</literal>.
When the index or the index/type are provided, they will be used by
default on bulk items that don&#8217;t provide them explicitly.</simpara>
<simpara>A note on the format. The idea here is to make processing of this as
fast as possible. As some of the actions will be redirected to other
shards on other nodes, only <literal>action_meta_data</literal> is parsed on the
receiving node side.</simpara>
<simpara>Client libraries using this protocol should try and strive to do
something similar on the client side, and reduce buffering as much as
possible.</simpara>
<simpara>The response to a bulk action is a large JSON structure with the
individual results of each action that was performed. The failure of a
single action does not affect the remaining actions.</simpara>
<simpara>There is no "correct" number of actions to perform in a single bulk
call. You should experiment with different settings to find the optimum
size for your particular workload.</simpara>
<simpara>If using the HTTP API, make sure that the client does not send HTTP
chunks, as this will slow things down.</simpara>
<bridgehead id="bulk-versioning" renderas="sect2">Versioning<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/bulk.asciidoc">Edit me</ulink></bridgehead>
<simpara>Each bulk item can include the version value using the
<literal>_version</literal>/<literal>version</literal> field. It automatically follows the behavior of the
index / delete operation based on the <literal>_version</literal> mapping. It also
support the <literal>version_type</literal>/<literal>_version_type</literal> (see <link linkend="index-versioning">versioning</link>)</simpara>
<bridgehead id="bulk-routing" renderas="sect2">Routing<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/bulk.asciidoc">Edit me</ulink></bridgehead>
<simpara>Each bulk item can include the routing value using the
<literal>_routing</literal>/<literal>routing</literal> field. It automatically follows the behavior of the
index / delete operation based on the <literal>_routing</literal> mapping.</simpara>
<bridgehead id="bulk-parent" renderas="sect2">Parent<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/bulk.asciidoc">Edit me</ulink></bridgehead>
<simpara>Each bulk item can include the parent value using the <literal>_parent</literal>/<literal>parent</literal>
field. It automatically follows the behavior of the index / delete
operation based on the <literal>_parent</literal> / <literal>_routing</literal> mapping.</simpara>
<bridgehead id="bulk-wait-for-active-shards" renderas="sect2">Wait For Active Shards<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/bulk.asciidoc">Edit me</ulink></bridgehead>
<simpara>When making bulk calls, you can set the <literal>wait_for_active_shards</literal>
parameter to require a minimum number of shard copies to be active
before starting to process the bulk request. See
<link linkend="index-wait-for-active-shards">here</link> for further details and a usage
example.</simpara>
<bridgehead id="bulk-refresh" renderas="sect2">Refresh<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/bulk.asciidoc">Edit me</ulink></bridgehead>
<simpara>Control when the changes made by this request are visible to search. See
<link linkend="docs-refresh">refresh</link>.</simpara>
<bridgehead id="bulk-update" renderas="sect2">Update<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/bulk.asciidoc">Edit me</ulink></bridgehead>
<simpara>When using <literal>update</literal> action <literal>_retry_on_conflict</literal> can be used as field in
the action itself (not in the extra payload line), to specify how many
times an update should be retried in the case of a version conflict.</simpara>
<simpara>The <literal>update</literal> action payload, supports the following options: <literal>doc</literal>
(partial document), <literal>upsert</literal>, <literal>doc_as_upsert</literal>, <literal>script</literal>, <literal>params</literal> (for
script), <literal>lang</literal> (for script) and <literal>_source</literal>. See update documentation for details on
the options. Example with update actions:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _bulk
{ "update" : {"_id" : "1", "_type" : "type1", "_index" : "index1", "_retry_on_conflict" : 3} }
{ "doc" : {"field" : "value"} }
{ "update" : { "_id" : "0", "_type" : "type1", "_index" : "index1", "_retry_on_conflict" : 3} }
{ "script" : { "inline": "ctx._source.counter += params.param1", "lang" : "painless", "params" : {"param1" : 1}}, "upsert" : {"counter" : 1}}
{ "update" : {"_id" : "2", "_type" : "type1", "_index" : "index1", "_retry_on_conflict" : 3} }
{ "doc" : {"field" : "value"}, "doc_as_upsert" : true }
{ "update" : {"_id" : "3", "_type" : "type1", "_index" : "index1", "_source" : true} }
{ "doc" : {"field" : "value"} }
{ "update" : {"_id" : "4", "_type" : "type1", "_index" : "index1"} }
{ "doc" : {"field" : "value"}, "_source": true}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<bridgehead id="bulk-security" renderas="sect2">Security<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/bulk.asciidoc">Edit me</ulink></bridgehead>
<simpara>See <xref linkend="url-access-control"/></simpara>
</chapter>
<chapter id="docs-reindex">
<title>Reindex API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/reindex.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>The reindex API is new and should still be considered experimental.  The API may change in ways that are not backwards compatible.</simpara></warning>
<important><simpara>Reindex does not attempt to set up the destination index.  It does
not copy the settings of the source index.  You should set up the destination
index prior to running a <literal>_reindex</literal> action, including setting up mappings, shard
counts, replicas, etc.</simpara></important>
<simpara>The most basic form of <literal>_reindex</literal> just copies documents from one index to another.
This will copy documents from the <literal>twitter</literal> index into the <literal>new_twitter</literal> index:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _reindex
{
  "source": {
    "index": "twitter"
  },
  "dest": {
    "index": "new_twitter"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:big_twitter]</remark>
<simpara>That will return something like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "took" : 147,
  "timed_out": false,
  "created": 120,
  "updated": 0,
  "deleted": 0,
  "batches": 1,
  "version_conflicts": 0,
  "noops": 0,
  "retries": {
    "bulk": 0,
    "search": 0
  },
  "throttled_millis": 0,
  "requests_per_second": -1.0,
  "throttled_until_millis": 0,
  "total": 120,
  "failures" : [ ]
}</programlisting>
<remark> TESTRESPONSE[s/"took" : 147/"took" : "$body.took"/]</remark>
<simpara>Just like <link linkend="docs-update-by-query"><literal>_update_by_query</literal></link>, <literal>_reindex</literal> gets a
snapshot of the source index but its target must be a <emphasis role="strong">different</emphasis> index so
version conflicts are unlikely. The <literal>dest</literal> element can be configured like the
index API to control optimistic concurrency control. Just leaving out
<literal>version_type</literal> (as above) or setting it to <literal>internal</literal> will cause Elasticsearch
to blindly dump documents into the target, overwriting any that happen to have
the same type and id:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _reindex
{
  "source": {
    "index": "twitter"
  },
  "dest": {
    "index": "new_twitter",
    "version_type": "internal"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>Setting <literal>version_type</literal> to <literal>external</literal> will cause Elasticsearch to preserve the
<literal>version</literal> from the source, create any documents that are missing, and update
any documents that have an older version in the destination index than they do
in the source index:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _reindex
{
  "source": {
    "index": "twitter"
  },
  "dest": {
    "index": "new_twitter",
    "version_type": "external"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>Settings <literal>op_type</literal> to <literal>create</literal> will cause <literal>_reindex</literal> to only create missing
documents in the target index. All existing documents will cause a version
conflict:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _reindex
{
  "source": {
    "index": "twitter"
  },
  "dest": {
    "index": "new_twitter",
    "op_type": "create"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>By default version conflicts abort the <literal>_reindex</literal> process but you can just
count them by settings <literal>"conflicts": "proceed"</literal> in the request body:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _reindex
{
  "conflicts": "proceed",
  "source": {
    "index": "twitter"
  },
  "dest": {
    "index": "new_twitter",
    "op_type": "create"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>You can limit the documents by adding a type to the <literal>source</literal> or by adding a
query. This will only copy <literal>tweet</literal>&apos;s made by <literal>kimchy</literal> into <literal>new_twitter</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _reindex
{
  "source": {
    "index": "twitter",
    "type": "tweet",
    "query": {
      "term": {
        "user": "kimchy"
      }
    }
  },
  "dest": {
    "index": "new_twitter"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara><literal>index</literal> and <literal>type</literal> in <literal>source</literal> can both be lists, allowing you to copy from
lots of sources in one request. This will copy documents from the <literal>tweet</literal> and
<literal>post</literal> types in the <literal>twitter</literal> and <literal>blog</literal> index. It&#8217;d include the <literal>post</literal> type in
the <literal>twitter</literal> index and the <literal>tweet</literal> type in the <literal>blog</literal> index. If you want to be
more specific you&#8217;ll need to use the <literal>query</literal>. It also makes no effort to handle
ID collisions. The target index will remain valid but it&#8217;s not easy to predict
which document will survive because the iteration order isn&#8217;t well defined.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _reindex
{
  "source": {
    "index": ["twitter", "blog"],
    "type": ["tweet", "post"]
  },
  "dest": {
    "index": "all_together"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT twitter\nPUT blog\n/]</remark>
<simpara>It&#8217;s also possible to limit the number of processed documents by setting
<literal>size</literal>. This will only copy a single document from <literal>twitter</literal> to
<literal>new_twitter</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _reindex
{
  "size": 1,
  "source": {
    "index": "twitter"
  },
  "dest": {
    "index": "new_twitter"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>If you want a particular set of documents from the twitter index you&#8217;ll
need to sort. Sorting makes the scroll less efficient but in some contexts
it&#8217;s worth it. If possible, prefer a more selective query to <literal>size</literal> and <literal>sort</literal>.
This will copy 10000 documents from <literal>twitter</literal> into <literal>new_twitter</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _reindex
{
  "size": 10000,
  "source": {
    "index": "twitter",
    "sort": { "date": "desc" }
  },
  "dest": {
    "index": "new_twitter"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>The <literal>source</literal> section supports all the elements that are supported in a
<link linkend="search-request-body">search request</link>. For instance only a subset of the
fields from the original documents can be reindexed using source filtering
as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _reindex
{
  "source": {
    "index": "twitter",
    "_source": ["user", "tweet"]
  },
  "dest": {
    "index": "new_twitter"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>Like <literal>_update_by_query</literal>, <literal>_reindex</literal> supports a script that modifies the
document. Unlike <literal>_update_by_query</literal>, the script is allowed to modify the
document&#8217;s metadata. This example bumps the version of the source document:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _reindex
{
  "source": {
    "index": "twitter"
  },
  "dest": {
    "index": "new_twitter",
    "version_type": "external"
  },
  "script": {
    "inline": "if (ctx._source.foo == 'bar') {ctx._version++; ctx._source.remove('foo')}",
    "lang": "painless"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>Just as in <literal>_update_by_query</literal>, you can set <literal>ctx.op</literal> to change the
operation that is executed on the destination index:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>noop</literal>
</term>
<listitem>
<simpara>
Set <literal>ctx.op = "noop"</literal> if your script decides that the document doesn&#8217;t have
to be indexed in the destination index. This no operation will be reported
in the <literal>noop</literal> counter in the <link linkend="docs-reindex-response-body">response body</link>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>delete</literal>
</term>
<listitem>
<simpara>
Set <literal>ctx.op = "delete"</literal> if your script decides that the document must be
 deleted from the destination index. The deletion will be reported in the
 <literal>deleted</literal> counter in the <link linkend="docs-reindex-response-body">response body</link>.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>Setting <literal>ctx.op</literal> to anything else is an error. Setting any
other field in <literal>ctx</literal> is an error.</simpara>
<simpara>Think of the possibilities! Just be careful! With great power&#8230;. You can
change:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>_id</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>_type</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>_index</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>_version</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>_routing</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>_parent</literal>
</simpara>
</listitem>
</itemizedlist>
<simpara>Setting <literal>_version</literal> to <literal>null</literal> or clearing it from the <literal>ctx</literal> map is just like not
sending the version in an indexing request. It will cause that document to be
overwritten in the target index regardless of the version on the target or the
version type you use in the <literal>_reindex</literal> request.</simpara>
<simpara>By default if <literal>_reindex</literal> sees a document with routing then the routing is
preserved unless it&#8217;s changed by the script. You can set <literal>routing</literal> on the
<literal>dest</literal> request to change this:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>keep</literal>
</term>
<listitem>
<simpara>
Sets the routing on the bulk request sent for each match to the routing on
the match. The default.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>discard</literal>
</term>
<listitem>
<simpara>
Sets the routing on the bulk request sent for each match to null.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>=&lt;some text&gt;</literal>
</term>
<listitem>
<simpara>
Sets the routing on the bulk request sent for each match to all text after
the <literal>=</literal>.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>For example, you can use the following request to copy all documents from
the <literal>source</literal> index with the company name <literal>cat</literal> into the <literal>dest</literal> index with
routing set to <literal>cat</literal>.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _reindex
{
  "source": {
    "index": "source",
    "query": {
      "match": {
        "company": "cat"
      }
    }
  },
  "dest": {
    "index": "dest",
    "routing": "=cat"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT source\n/]</remark>
<simpara>By default <literal>_reindex</literal> uses scroll batches of 1000. You can change the
batch size with the <literal>size</literal> field in the <literal>source</literal> element:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _reindex
{
  "source": {
    "index": "source",
    "size": 100
  },
  "dest": {
    "index": "dest",
    "routing": "=cat"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT source\n/]</remark>
<simpara>Reindex can also use the <xref linkend="ingest"/> feature by specifying a
<literal>pipeline</literal> like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _reindex
{
  "source": {
    "index": "source"
  },
  "dest": {
    "index": "dest",
    "pipeline": "some_ingest_pipeline"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT source\n/]</remark>
<bridgehead id="reindex-from-remote" renderas="sect2">Reindex from Remote<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/reindex.asciidoc">Edit me</ulink></bridgehead>
<simpara>Reindex supports reindexing from a remote Elasticsearch cluster:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _reindex
{
  "source": {
    "remote": {
      "host": "http://otherhost:9200",
      "username": "user",
      "password": "pass"
    },
    "index": "source",
    "query": {
      "match": {
        "test": "data"
      }
    }
  },
  "dest": {
    "index": "dest"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:host]</remark>
<remark> TEST[s/^/PUT source\n/]</remark>
<remark> TEST[s/otherhost:9200",/\${host}"/]</remark>
<remark> TEST[s/"username": "user",//]</remark>
<remark> TEST[s/"password": "pass"//]</remark>
<simpara>The <literal>host</literal> parameter must contain a scheme, host, and port (e.g.
<literal>https://otherhost:9200</literal>). The <literal>username</literal> and <literal>password</literal> parameters are
optional and when they are present reindex will connect to the remote
Elasticsearch node using using basic auth. Be sure to use <literal>https</literal> when using
basic auth or the password will be sent in plain text.</simpara>
<simpara>Remote hosts have to be explicitly whitelisted in elasticsearch.yaml using the
<literal>reindex.remote.whitelist</literal> property. It can be set to a comma delimited list
of allowed remote <literal>host</literal> and <literal>port</literal> combinations (e.g.
<literal>otherhost:9200, another:9200, 127.0.10.*:9200, localhost:*</literal>). Scheme is
ignored by the whitelist - only host and port are used.</simpara>
<simpara>This feature should work with remote clusters of any version of Elasticsearch
you are likely to find. This should allow you to upgrade from any version of
Elasticsearch to the current version by reindexing from a cluster of the old
version.</simpara>
<simpara>To enable queries sent to older versions of Elasticsearch the <literal>query</literal> parameter
is sent directly to the remote host without validation or modification.</simpara>
<simpara>Reindexing from a remote server uses an on-heap buffer that defaults to a
maximum size of 200mb. If the remote index includes very large documents you&#8217;ll
need to use a smaller batch size. The example below sets the batch size <literal>10</literal>
which is very, very small.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _reindex
{
  "source": {
    "remote": {
      "host": "http://otherhost:9200",
      "username": "user",
      "password": "pass"
    },
    "index": "source",
    "size": 10,
    "query": {
      "match": {
        "test": "data"
      }
    }
  },
  "dest": {
    "index": "dest"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:host]</remark>
<remark> TEST[s/^/PUT source\n/]</remark>
<remark> TEST[s/otherhost:9200",/\${host}"/]</remark>
<remark> TEST[s/"username": "user",//]</remark>
<remark> TEST[s/"password": "pass"//]</remark>
<bridgehead id="_url_parameters_3" renderas="sect2">URL Parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/reindex.asciidoc">Edit me</ulink></bridgehead>
<simpara>In addition to the standard parameters like <literal>pretty</literal>, the Reindex API also
supports <literal>refresh</literal>, <literal>wait_for_completion</literal>, <literal>wait_for_active_shards</literal>, <literal>timeout</literal>, and
<literal>requests_per_second</literal>.</simpara>
<simpara>Sending the <literal>refresh</literal> url parameter will cause all indexes to which the request
wrote to be refreshed. This is different than the Index API&#8217;s <literal>refresh</literal>
parameter which causes just the shard that received the new data to be refreshed.</simpara>
<simpara>If the request contains <literal>wait_for_completion=false</literal> then Elasticsearch will
perform some preflight checks, launch the request, and then return a <literal>task</literal>
which can be used with <link linkend="docs-reindex-task-api">Tasks APIs</link>
to cancel or get the status of the task. Elasticsearch will also create a
record of this task as a document at <literal>.tasks/task/${taskId}</literal>. This is yours
to keep or remove as you see fit. When you are done with it, delete it so
Elasticsearch can reclaim the space it uses.</simpara>
<simpara><literal>wait_for_active_shards</literal> controls how many copies of a shard must be active
before proceeding with the reindexing. See <link linkend="index-wait-for-active-shards">here</link>
for details. <literal>timeout</literal> controls how long each write request waits for unavailable
shards to become available. Both work exactly how they work in the
<link linkend="docs-bulk">Bulk API</link>.</simpara>
<simpara><literal>requests_per_second</literal> can be set to any positive decimal number (<literal>1.4</literal>, <literal>6</literal>,
<literal>1000</literal>, etc) and throttles the number of requests per second that the reindex
issues or it can be set to <literal>-1</literal> to disabled throttling. The throttling is done
waiting between bulk batches so that it can manipulate the scroll timeout. The
wait time is the difference between the time it took the batch to complete and
the time <literal>requests_per_second * requests_in_the_batch</literal>. Since the batch isn&#8217;t
broken into multiple bulk requests large batch sizes will cause Elasticsearch
to create many requests and then wait for a while before starting the next set.
This is "bursty" instead of "smooth". The default is <literal>-1</literal>.</simpara>
<bridgehead id="docs-reindex-response-body" renderas="sect2">Response body<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/reindex.asciidoc">Edit me</ulink></bridgehead>
<simpara>The JSON response looks like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "took" : 639,
  "updated": 0,
  "created": 123,
  "batches": 1,
  "version_conflicts": 2,
  "retries": {
    "bulk": 0,
    "search": 0
  }
  "throttled_millis": 0,
  "failures" : [ ]
}</programlisting>
<variablelist>
<varlistentry>
<term>
<literal>took</literal>
</term>
<listitem>
<simpara>
The number of milliseconds from start to end of the whole operation.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>updated</literal>
</term>
<listitem>
<simpara>
The number of documents that were successfully updated.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>created</literal>
</term>
<listitem>
<simpara>
The number of documents that were successfully created.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>batches</literal>
</term>
<listitem>
<simpara>
The number of scroll responses pulled back by the the reindex.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>version_conflicts</literal>
</term>
<listitem>
<simpara>
The number of version conflicts that reindex hit.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>retries</literal>
</term>
<listitem>
<simpara>
The number of retries attempted by reindex. <literal>bulk</literal> is the number of bulk
actions retried and <literal>search</literal> is the number of search actions retried.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>throttled_millis</literal>
</term>
<listitem>
<simpara>
Number of milliseconds the request slept to conform to <literal>requests_per_second</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>failures</literal>
</term>
<listitem>
<simpara>
Array of all indexing failures. If this is non-empty then the request aborted
because of those failures. See <literal>conflicts</literal> for how to prevent version conflicts
from aborting the operation.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="docs-reindex-task-api" renderas="sect2">Works with the Task API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/reindex.asciidoc">Edit me</ulink></bridgehead>
<simpara>You can fetch the status of all running reindex requests with the
<link linkend="tasks">Task API</link>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _tasks?detailed=true&amp;actions=*reindex</programlisting>
<remark> CONSOLE</remark>
<simpara>The responses looks like:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "nodes" : {
    "r1A2WoRbTwKZ516z6NEs5A" : {
      "name" : "r1A2WoR",
      "transport_address" : "127.0.0.1:9300",
      "host" : "127.0.0.1",
      "ip" : "127.0.0.1:9300",
      "attributes" : {
        "testattr" : "test",
        "portsfile" : "true"
      },
      "tasks" : {
        "r1A2WoRbTwKZ516z6NEs5A:36619" : {
          "node" : "r1A2WoRbTwKZ516z6NEs5A",
          "id" : 36619,
          "type" : "transport",
          "action" : "indices:data/write/reindex",
          "status" : {    <co id="CO12-1"/>
            "total" : 6154,
            "updated" : 3500,
            "created" : 0,
            "deleted" : 0,
            "batches" : 4,
            "version_conflicts" : 0,
            "noops" : 0,
            "retries": {
              "bulk": 0,
              "search": 0
            },
            "throttled_millis": 0
          },
          "description" : ""
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO12-1">
<para>
this object contains the actual status. It is just like the response json
with the important addition of the <literal>total</literal> field. <literal>total</literal> is the total number
of operations that the reindex expects to perform. You can estimate the
progress by adding the <literal>updated</literal>, <literal>created</literal>, and <literal>deleted</literal> fields. The request
will finish when their sum is equal to the <literal>total</literal> field.
</para>
</callout>
</calloutlist>
<simpara>With the task id you can look up the task directly:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_tasks/taskId:1</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[catch:missing]</remark>
<simpara>The advantage of this API is that it integrates with <literal>wait_for_completion=false</literal>
to transparently return the status of completed tasks. If the task is completed
and <literal>wait_for_completion=false</literal> was set on it them it&#8217;ll come back with a
<literal>results</literal> or an <literal>error</literal> field. The cost of this feature is the document that
<literal>wait_for_completion=false</literal> creates at <literal>.tasks/task/${taskId}</literal>. It is up to
you to delete that document.</simpara>
<bridgehead id="docs-reindex-cancel-task-api" renderas="sect2">Works with the Cancel Task API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/reindex.asciidoc">Edit me</ulink></bridgehead>
<simpara>Any Reindex can be canceled using the <link linkend="tasks">Task Cancel API</link>:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _tasks/task_id:1/_cancel</programlisting>
<remark> CONSOLE</remark>
<simpara>The <literal>task_id</literal> can be found using the tasks API above.</simpara>
<simpara>Cancelation should happen quickly but might take a few seconds. The task status
API above will continue to list the task until it is wakes to cancel itself.</simpara>
<bridgehead id="docs-reindex-rethrottle" renderas="sect2">Rethrottling<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/reindex.asciidoc">Edit me</ulink></bridgehead>
<simpara>The value of <literal>requests_per_second</literal> can be changed on a running reindex using
the <literal>_rethrottle</literal> API:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _reindex/task_id:1/_rethrottle?requests_per_second=-1</programlisting>
<remark> CONSOLE</remark>
<simpara>The <literal>task_id</literal> can be found using the tasks API above.</simpara>
<simpara>Just like when setting it on the <literal>_reindex</literal> API <literal>requests_per_second</literal>
can be either <literal>-1</literal> to disable throttling or any decimal number
like <literal>1.7</literal> or <literal>12</literal> to throttle to that level. Rethrottling that speeds up the
query takes effect immediately but rethrotting that slows down the query will
take effect on after completing the current batch. This prevents scroll
timeouts.</simpara>
<bridgehead id="docs-reindex-change-name" renderas="sect2">Reindex to change the name of a field<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/reindex.asciidoc">Edit me</ulink></bridgehead>
<simpara><literal>_reindex</literal> can be used to build a copy of an index with renamed fields. Say you
create an index containing documents that look like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST test/test/1?refresh
{
  "text": "words words",
  "flag": "foo"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>But you don&#8217;t like the name <literal>flag</literal> and want to replace it with <literal>tag</literal>.
<literal>_reindex</literal> can create the other index for you:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _reindex
{
  "source": {
    "index": "test"
  },
  "dest": {
    "index": "test2"
  },
  "script": {
    "inline": "ctx._source.tag = ctx._source.remove(\"flag\")"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Now you can get the new document:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET test2/test/1</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>and it&#8217;ll look like:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "found": true,
  "_id": "1",
  "_index": "test2",
  "_type": "test",
  "_version": 1,
  "_source": {
    "text": "words words",
    "tag": "foo"
  }
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>Or you can search by <literal>tag</literal> or whatever you want.</simpara>
<bridgehead id="docs-reindex-manual-slice" renderas="sect3">Manual slicing<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/reindex.asciidoc">Edit me</ulink></bridgehead>
<simpara>Reindex supports <xref linkend="sliced-scroll"/>, allowing you to manually parallelize the
process relatively easily:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _reindex
{
  "source": {
    "index": "twitter",
    "slice": {
      "id": 0,
      "max": 2
    }
  },
  "dest": {
    "index": "new_twitter"
  }
}
POST _reindex
{
  "source": {
    "index": "twitter",
    "slice": {
      "id": 1,
      "max": 2
    }
  },
  "dest": {
    "index": "new_twitter"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:big_twitter]</remark>
<simpara>Which you can verify works with:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _refresh
POST new_twitter/_search?size=0&amp;filter_path=hits.total</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Which results in a sensible <literal>total</literal> like this one:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "hits": {
    "total": 120
  }
}</programlisting>
<remark> TESTRESPONSE</remark>
<bridgehead id="docs-reindex-automatic-slice" renderas="sect2">Automatic slicing<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/reindex.asciidoc">Edit me</ulink></bridgehead>
<simpara>You can also let reindex automatically parallelize using <xref linkend="sliced-scroll"/> to
slice on <literal>_uid</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _reindex?slices=5&amp;refresh
{
  "source": {
    "index": "twitter"
  },
  "dest": {
    "index": "new_twitter"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:big_twitter]</remark>
<simpara>Which you also can verify works with:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST new_twitter/_search?size=0&amp;filter_path=hits.total</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Which results in a sensible <literal>total</literal> like this one:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "hits": {
    "total": 120
  }
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>Adding <literal>slices</literal> to <literal>_reindex</literal> just automates the manual process used in the
section above, creating sub-requests which means it has some quirks:
* You can see these requests in the <link linkend="docs-reindex-task-api">Tasks APIs</link>. These
sub-requests are "child" tasks of the task for the request with <literal>slices</literal>.
* Fetching the status of the task for the request with <literal>slices</literal> only contains
the status of completed slices.
* These sub-requests are individually addressable for things like cancellation
and rethrottling.
* Rethrottling the request with <literal>slices</literal> will rethrottle the unfinished
sub-request proportionally.
* Canceling the request with <literal>slices</literal> will cancel each sub-request.
* Due to the nature of <literal>slices</literal> each sub-request won&#8217;t get a perfectly even
portion of the documents. All documents will be addressed, but some slices may
be larger than others. Expect larger slices to have a more even distribution.
* Parameters like <literal>requests_per_second</literal> and <literal>size</literal> on a request with <literal>slices</literal>
are distributed proportionally to each sub-request. Combine that with the point
above about distribution being uneven and you should conclude that the using
<literal>size</literal> with <literal>slices</literal> might not result in exactly <literal>size</literal> documents being
`_reindex`ed.
* Each sub-requests gets a slightly different snapshot of the source index
though these are all taken at approximately the same time.</simpara>
<bridgehead id="docs-reindex-picking-slices" renderas="sect2">Picking the number of slices<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/reindex.asciidoc">Edit me</ulink></bridgehead>
<simpara>At this point we have a few recommendations around the number of <literal>slices</literal> to
use (the <literal>max</literal> parameter in the slice API if manually parallelizing):</simpara>
<itemizedlist>
<listitem>
<simpara>
Don&#8217;t use large numbers. <literal>500</literal> creates fairly massive CPU thrash.
</simpara>
</listitem>
<listitem>
<simpara>
It is more efficient from a query performance standpoint to use some multiple
of the number of shards in the source index.
</simpara>
</listitem>
<listitem>
<simpara>
Using exactly as many shards as are in the source index is the most efficient
from a query performance standpoint.
</simpara>
</listitem>
<listitem>
<simpara>
Indexing performance should scale linearly across available resources with
the number of <literal>slices</literal>.
</simpara>
</listitem>
<listitem>
<simpara>
Whether indexing or query performance dominates that process depends on lots
of factors like the documents being reindexed and the cluster doing the
reindexing.
</simpara>
</listitem>
</itemizedlist>
<bridgehead id="_reindex_daily_indices" renderas="sect2">Reindex daily indices<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/reindex.asciidoc">Edit me</ulink></bridgehead>
<simpara>You can use <literal>_reindex</literal> in combination with <link linkend="modules-scripting-painless">Painless</link>
 to reindex daily indices to apply a new template to the existing documents.</simpara>
<simpara>Assuming you have indices consisting of documents as following:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT metricbeat-2016.05.30/beat/1?refresh
{"system.cpu.idle.pct": 0.908}
PUT metricbeat-2016.05.31/beat/1?refresh
{"system.cpu.idle.pct": 0.105}</programlisting>
<remark> CONSOLE</remark>
<simpara>The new template for the <literal>metricbeat-*</literal> indices is already loaded into elasticsearch
but it applies only to the newly created indices. Painless can be used to reindex
the existing documents and apply the new template.</simpara>
<simpara>The script below extracts the date from the index name and creates a new index
with <literal>-1</literal> appended. All data from <literal>metricbeat-2016.05.31</literal> will be reindex
into <literal>metricbeat-2016.05.31-1</literal>.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _reindex
{
  "source": {
    "index": "metricbeat-*"
  },
  "dest": {
    "index": "metricbeat"
  },
  "script": {
    "lang": "painless",
    "inline": "ctx._index = 'metricbeat-' + (ctx._index.substring('metricbeat-'.length(), ctx._index.length())) + '-1'"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>All documents from the previous metricbeat indices now can be found in the <literal>*-1</literal> indices.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET metricbeat-2016.05.30-1/beat/1
GET metricbeat-2016.05.31-1/beat/1</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>The previous method can also be used in combination with <link linkend="docs-reindex-change-name">change the name of a field</link>
to only load the existing data into the new index, but also rename fields if needed.</simpara>
<bridgehead id="_extracting_a_random_subset_of_an_index" renderas="sect2">Extracting a random subset of an index<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/reindex.asciidoc">Edit me</ulink></bridgehead>
<simpara>Reindex can be used to extract a random subset of an index for testing:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _reindex
{
  "size": 10,
  "source": {
    "index": "twitter",
    "query": {
      "function_score" : {
        "query" : { "match_all": {} },
        "random_score" : {}
      }
    },
    "sort": "_score"    <co id="CO13-1"/>
  },
  "dest": {
    "index": "random_twitter"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:big_twitter]</remark>
<calloutlist>
<callout arearefs="CO13-1">
<para>
Reindex defaults to sorting by <literal>_doc</literal> so <literal>random_score</literal> won&#8217;t have any
effect unless you override the sort to <literal>_score</literal>.
</para>
</callout>
</calloutlist>
</chapter>
<chapter id="docs-termvectors">
<title>Term Vectors<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/termvectors.asciidoc">Edit me</ulink></title>
<simpara>Returns information and statistics on terms in the fields of a particular
document. The document could be stored in the index or artificially provided
by the user. Term vectors are <link linkend="realtime">realtime</link> by default, not near
realtime. This can be changed by setting <literal>realtime</literal> parameter to <literal>false</literal>.</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET 'http://localhost:9200/twitter/tweet/1/_termvectors?pretty=true'</programlisting>
<simpara>Optionally, you can specify the fields for which the information is
retrieved either with a parameter in the url</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET 'http://localhost:9200/twitter/tweet/1/_termvectors?fields=text,...'</programlisting>
<simpara>or by adding the requested fields in the request body (see
example below). Fields can also be specified with wildcards
in similar way to the <link linkend="query-dsl-multi-match-query">multi match query</link></simpara>
<warning><simpara>Note that the usage of <literal>/_termvector</literal> is deprecated in 2.0, and replaced by <literal>/_termvectors</literal>.</simpara></warning>
<bridgehead id="_return_values" renderas="sect2">Return values<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/termvectors.asciidoc">Edit me</ulink></bridgehead>
<simpara>Three types of values can be requested: <emphasis>term information</emphasis>, <emphasis>term statistics</emphasis>
and <emphasis>field statistics</emphasis>. By default, all term information and field
statistics are returned for all fields but no term statistics.</simpara>
<bridgehead id="_term_information" renderas="sect3">Term information<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/termvectors.asciidoc">Edit me</ulink></bridgehead>
<itemizedlist>
<listitem>
<simpara>
term frequency in the field (always returned)
</simpara>
</listitem>
<listitem>
<simpara>
term positions (<literal>positions</literal> : true)
</simpara>
</listitem>
<listitem>
<simpara>
start and end offsets (<literal>offsets</literal> : true)
</simpara>
</listitem>
<listitem>
<simpara>
term payloads (<literal>payloads</literal> : true), as base64 encoded bytes
</simpara>
</listitem>
</itemizedlist>
<simpara>If the requested information wasn&#8217;t stored in the index, it will be
computed on the fly if possible. Additionally, term vectors could be computed
for documents not even existing in the index, but instead provided by the user.</simpara>
<warning>
<simpara>Start and end offsets assume UTF-16 encoding is being used. If you want to use
these offsets in order to get the original text that produced this token, you
should make sure that the string you are taking a sub-string of is also encoded
using UTF-16.</simpara>
</warning>
<bridgehead id="_term_statistics" renderas="sect3">Term statistics<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/termvectors.asciidoc">Edit me</ulink></bridgehead>
<simpara>Setting <literal>term_statistics</literal> to <literal>true</literal> (default is <literal>false</literal>) will
return</simpara>
<itemizedlist>
<listitem>
<simpara>
total term frequency (how often a term occurs in all documents)<?asciidoc-br?>
</simpara>
</listitem>
<listitem>
<simpara>
document frequency (the number of documents containing the current
   term)
</simpara>
</listitem>
</itemizedlist>
<simpara>By default these values are not returned since term statistics can
have a serious performance impact.</simpara>
<bridgehead id="_field_statistics" renderas="sect3">Field statistics<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/termvectors.asciidoc">Edit me</ulink></bridgehead>
<simpara>Setting <literal>field_statistics</literal> to <literal>false</literal> (default is <literal>true</literal>) will
omit :</simpara>
<itemizedlist>
<listitem>
<simpara>
document count (how many documents contain this field)
</simpara>
</listitem>
<listitem>
<simpara>
sum of document frequencies (the sum of document frequencies for all
   terms in this field)
</simpara>
</listitem>
<listitem>
<simpara>
sum of total term frequencies (the sum of total term frequencies of
   each term in this field)
</simpara>
</listitem>
</itemizedlist>
<bridgehead id="_terms_filtering" renderas="sect3">Terms Filtering<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/termvectors.asciidoc">Edit me</ulink></bridgehead>
<simpara>With the parameter <literal>filter</literal>, the terms returned could also be filtered based
on their tf-idf scores. This could be useful in order find out a good
characteristic vector of a document. This feature works in a similar manner to
the <link linkend="mlt-query-term-selection">second phase</link> of the
<link linkend="query-dsl-mlt-query">More Like This Query</link>. See <link linkend="docs-termvectors-terms-filtering">example 5</link>
for usage.</simpara>
<simpara>The following sub-parameters are supported:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>max_num_terms</literal>
</simpara>
</entry>
<entry>
<simpara>
  Maximum number of terms that must be returned per field. Defaults to <literal>25</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>min_term_freq</literal>
</simpara>
</entry>
<entry>
<simpara>
  Ignore words with less than this frequency in the source doc. Defaults to <literal>1</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max_term_freq</literal>
</simpara>
</entry>
<entry>
<simpara>
  Ignore words with more than this frequency in the source doc. Defaults to unbounded.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>min_doc_freq</literal>
</simpara>
</entry>
<entry>
<simpara>
  Ignore terms which do not occur in at least this many docs. Defaults to <literal>1</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max_doc_freq</literal>
</simpara>
</entry>
<entry>
<simpara>
  Ignore words which occur in more than this many docs. Defaults to unbounded.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>min_word_length</literal>
</simpara>
</entry>
<entry>
<simpara>
  The minimum word length below which words will be ignored. Defaults to <literal>0</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max_word_length</literal>
</simpara>
</entry>
<entry>
<simpara>
  The maximum word length above which words will be ignored. Defaults to unbounded (<literal>0</literal>).
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="_behaviour" renderas="sect2">Behaviour<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/termvectors.asciidoc">Edit me</ulink></bridgehead>
<simpara>The term and field statistics are not accurate. Deleted documents
are not taken into account. The information is only retrieved for the
shard the requested document resides in.
The term and field statistics are therefore only useful as relative measures
whereas the absolute numbers have no meaning in this context. By default,
when requesting term vectors of artificial documents, a shard to get the statistics
from is randomly selected. Use <literal>routing</literal> only to hit a particular shard.</simpara>
<example>
<title>Returning stored term vectors</title>
<simpara>First, we create an index that stores term vectors, payloads etc. :</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -s -XPUT 'http://localhost:9200/twitter/' -d '{
  "mappings": {
    "tweet": {
      "properties": {
        "text": {
          "type": "text",
          "term_vector": "with_positions_offsets_payloads",
          "store" : true,
          "analyzer" : "fulltext_analyzer"
         },
         "fullname": {
          "type": "text",
          "term_vector": "with_positions_offsets_payloads",
          "analyzer" : "fulltext_analyzer"
        }
      }
    }
  },
  "settings" : {
    "index" : {
      "number_of_shards" : 1,
      "number_of_replicas" : 0
    },
    "analysis": {
      "analyzer": {
        "fulltext_analyzer": {
          "type": "custom",
          "tokenizer": "whitespace",
          "filter": [
            "lowercase",
            "type_as_payload"
          ]
        }
      }
    }
  }
}'</programlisting>
<simpara>Second, we add some documents:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XPUT 'http://localhost:9200/twitter/tweet/1?pretty=true' -d '{
  "fullname" : "John Doe",
  "text" : "twitter test test test "
}'

curl -XPUT 'http://localhost:9200/twitter/tweet/2?pretty=true' -d '{
  "fullname" : "Jane Doe",
  "text" : "Another twitter test ..."
}'</programlisting>
<simpara>The following request returns all information and statistics for field
<literal>text</literal> in document <literal>1</literal> (John Doe):</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET 'http://localhost:9200/twitter/tweet/1/_termvectors?pretty=true' -d '{
  "fields" : ["text"],
  "offsets" : true,
  "payloads" : true,
  "positions" : true,
  "term_statistics" : true,
  "field_statistics" : true
}'</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "_id": "1",
    "_index": "twitter",
    "_type": "tweet",
    "_version": 1,
    "found": true,
    "term_vectors": {
        "text": {
            "field_statistics": {
                "doc_count": 2,
                "sum_doc_freq": 6,
                "sum_ttf": 8
            },
            "terms": {
                "test": {
                    "doc_freq": 2,
                    "term_freq": 3,
                    "tokens": [
                        {
                            "end_offset": 12,
                            "payload": "d29yZA==",
                            "position": 1,
                            "start_offset": 8
                        },
                        {
                            "end_offset": 17,
                            "payload": "d29yZA==",
                            "position": 2,
                            "start_offset": 13
                        },
                        {
                            "end_offset": 22,
                            "payload": "d29yZA==",
                            "position": 3,
                            "start_offset": 18
                        }
                    ],
                    "ttf": 4
                },
                "twitter": {
                    "doc_freq": 2,
                    "term_freq": 1,
                    "tokens": [
                        {
                            "end_offset": 7,
                            "payload": "d29yZA==",
                            "position": 0,
                            "start_offset": 0
                        }
                    ],
                    "ttf": 2
                }
            }
        }
    }
}</programlisting>
</example>
<example>
<title>Generating term vectors on the fly</title>
<simpara>Term vectors which are not explicitly stored in the index are automatically
computed on the fly. The following request returns all information and statistics for the
fields in document <literal>1</literal>, even though the terms haven&#8217;t been explicitly stored in the index.
Note that for the field <literal>text</literal>, the terms are not re-generated.</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET 'http://localhost:9200/twitter/tweet/1/_termvectors?pretty=true' -d '{
  "fields" : ["text", "some_field_without_term_vectors"],
  "offsets" : true,
  "positions" : true,
  "term_statistics" : true,
  "field_statistics" : true
}'</programlisting>
</example>
<example id="docs-termvectors-artificial-doc">
<title>Artificial documents</title>
<simpara>Term vectors can also be generated for artificial documents,
that is for documents not present in the index.  For example, the following request would
return the same results as in example 1. The mapping used is determined by the
<literal>index</literal> and <literal>type</literal>.</simpara>
<simpara><emphasis role="strong">If dynamic mapping is turned on (default), the document fields not in the original
mapping will be dynamically created.</emphasis></simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET 'http://localhost:9200/twitter/tweet/_termvectors' -d '{
  "doc" : {
    "fullname" : "John Doe",
    "text" : "twitter test test test"
  }
}'</programlisting>
</example>
<example id="docs-termvectors-per-field-analyzer">
<title>Per-field analyzer</title>
<simpara>Additionally, a different analyzer than the one at the field may be provided
by using the <literal>per_field_analyzer</literal> parameter. This is useful in order to
generate term vectors in any fashion, especially when using artificial
documents. When providing an analyzer for a field that already stores term
vectors, the term vectors will be re-generated.</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET 'http://localhost:9200/twitter/tweet/_termvectors' -d '{
  "doc" : {
    "fullname" : "John Doe",
    "text" : "twitter test test test"
  },
  "fields": ["fullname"],
  "per_field_analyzer" : {
    "fullname": "keyword"
  }
}'</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "_index": "twitter",
  "_type": "tweet",
  "_version": 0,
  "found": true,
  "term_vectors": {
    "fullname": {
       "field_statistics": {
          "sum_doc_freq": 1,
          "doc_count": 1,
          "sum_ttf": 1
       },
       "terms": {
          "John Doe": {
             "term_freq": 1,
             "tokens": [
                {
                   "position": 0,
                   "start_offset": 0,
                   "end_offset": 8
                }
             ]
          }
       }
    }
  }
}</programlisting>
</example>
<example id="docs-termvectors-terms-filtering">
<title>Terms filtering</title>
<simpara>Finally, the terms returned could be filtered based on their tf-idf scores. In
the example below we obtain the three most "interesting" keywords from the
artificial document having the given "plot" field value. Notice
that the keyword "Tony" or any stop words are not part of the response, as
their tf-idf must be too low.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /imdb/movies/_termvectors
{
    "doc": {
      "plot": "When wealthy industrialist Tony Stark is forced to build an armored suit after a life-threatening incident, he ultimately decides to use its technology to fight against evil."
    },
    "term_statistics" : true,
    "field_statistics" : true,
    "positions": false,
    "offsets": false,
    "filter" : {
      "max_num_terms" : 3,
      "min_term_freq" : 1,
      "min_doc_freq" : 1
    }
}</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "_index": "imdb",
   "_type": "movies",
   "_version": 0,
   "found": true,
   "term_vectors": {
      "plot": {
         "field_statistics": {
            "sum_doc_freq": 3384269,
            "doc_count": 176214,
            "sum_ttf": 3753460
         },
         "terms": {
            "armored": {
               "doc_freq": 27,
               "ttf": 27,
               "term_freq": 1,
               "score": 9.74725
            },
            "industrialist": {
               "doc_freq": 88,
               "ttf": 88,
               "term_freq": 1,
               "score": 8.590818
            },
            "stark": {
               "doc_freq": 44,
               "ttf": 47,
               "term_freq": 1,
               "score": 9.272792
            }
         }
      }
   }
}</programlisting>
</example>
</chapter>
<chapter id="docs-multi-termvectors">
<title>Multi termvectors API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/multi-termvectors.asciidoc">Edit me</ulink></title>
<simpara>Multi termvectors API allows to get multiple termvectors at once. The
documents from which to retrieve the term vectors are specified by an index,
type and id. But the documents could also be artificially provided in the request itself.</simpara>
<simpara>The response includes a <literal>docs</literal>
array with all the fetched termvectors, each element having the structure
provided by the <link linkend="docs-termvectors">termvectors</link>
API. Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl 'localhost:9200/_mtermvectors' -d '{
   "docs": [
      {
         "_index": "testidx",
         "_type": "test",
         "_id": "2",
         "term_statistics": true
      },
      {
         "_index": "testidx",
         "_type": "test",
         "_id": "1",
         "fields": [
            "text"
         ]
      }
   ]
}'</programlisting>
<simpara>See the <link linkend="docs-termvectors">termvectors</link> API for a description of possible parameters.</simpara>
<simpara>The <literal>_mtermvectors</literal> endpoint can also be used against an index (in which case it
is not required in the body):</simpara>
<programlisting language="js" linenumbering="unnumbered">curl 'localhost:9200/testidx/_mtermvectors' -d '{
   "docs": [
      {
         "_type": "test",
         "_id": "2",
         "fields": [
            "text"
         ],
         "term_statistics": true
      },
      {
         "_type": "test",
         "_id": "1"
      }
   ]
}'</programlisting>
<simpara>And type:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl 'localhost:9200/testidx/test/_mtermvectors' -d '{
   "docs": [
      {
         "_id": "2",
         "fields": [
            "text"
         ],
         "term_statistics": true
      },
      {
         "_id": "1"
      }
   ]
}'</programlisting>
<simpara>If all requested documents are on same index and have same type and also the parameters are the same, the request can be simplified:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl 'localhost:9200/testidx/test/_mtermvectors' -d '{
    "ids" : ["1", "2"],
    "parameters": {
        "fields": [
                "text"
        ],
        "term_statistics": true,
        …
    }
}'</programlisting>
<simpara>Additionally, just like for the <link linkend="docs-termvectors">termvectors</link>
API, term vectors could be generated for user provided documents.  The mapping used is
determined by <literal>_index</literal> and <literal>_type</literal>.</simpara>
<programlisting language="js" linenumbering="unnumbered">curl 'localhost:9200/_mtermvectors' -d '{
   "docs": [
      {
         "_index": "testidx",
         "_type": "test",
         "doc" : {
            "fullname" : "John Doe",
            "text" : "twitter test test test"
         }
      },
      {
         "_index": "testidx",
         "_type": "test",
         "doc" : {
           "fullname" : "Jane Doe",
           "text" : "Another twitter test ..."
         }
      }
   ]
}'</programlisting>
</chapter>
<chapter id="docs-refresh">
<title><literal>?refresh</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/refresh.asciidoc">Edit me</ulink></title>
<simpara>The <link linkend="docs-index_">Index</link>, <link linkend="docs-update">Update</link>, <link linkend="docs-delete">Delete</link>, and
<link linkend="docs-bulk">Bulk</link> APIs support setting <literal>refresh</literal> to control when changes made
by this request are made visible to search. These are the allowed values:</simpara>
<variablelist>
<varlistentry>
<term>
Empty string or <literal>true</literal>
</term>
<listitem>
<simpara>
Refresh the relevant primary and replica shards (not the whole index)
immediately after the operation occurs, so that the updated document appears
in search results immediately. This should <emphasis role="strong">ONLY</emphasis> be done after careful thought
and verification that it does not lead to poor performance, both from an
indexing and a search standpoint.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>wait_for</literal>
</term>
<listitem>
<simpara>
Wait for the changes made by the request to be made visible by a refresh before
replying. This doesn&#8217;t force an immediate refresh, rather, it waits for a
refresh to happen. Elasticsearch automatically refreshes shards that have changed
every <literal>index.refresh_interval</literal> which defaults to one second. That setting is
<link linkend="dynamic-index-settings">dynamic</link>. Calling the <xref linkend="indices-refresh"/> API or
setting <literal>refresh</literal> to <literal>true</literal> on any of the APIs that support it will also
cause a refresh, in turn causing already running requests with <literal>refresh=wait_for</literal>
to return.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>false</literal> (the default)
</term>
<listitem>
<simpara>
Take no refresh related actions. The changes made by this request will be made
visible at some point after the request returns.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_choosing_which_setting_to_use" renderas="sect2">Choosing which setting to use<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/refresh.asciidoc">Edit me</ulink></bridgehead>
<simpara>Unless you have a good reason to wait for the change to become visible always
use <literal>refresh=false</literal>, or, because that is the default, just leave the <literal>refresh</literal>
parameter out of the URL. That is the simplest and fastest choice.</simpara>
<simpara>If you absolutely must have the changes made by a request visible synchronously
with the request then you must pick between putting more load on
Elasticsearch (<literal>true</literal>) and waiting longer for the response (<literal>wait_for</literal>). Here
are a few points that should inform that decision:</simpara>
<itemizedlist>
<listitem>
<simpara>
The more changes being made to the index the more work <literal>wait_for</literal> saves
compared to <literal>true</literal>. In the case that the index is only changed once every
<literal>index.refresh_interval</literal> then it saves no work.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>true</literal> creates less efficient indexes constructs (tiny segments) that must
later be merged into more efficient index constructs (larger segments). Meaning
that the cost of <literal>true</literal> is payed at index time to create the tiny segment, at
search time to search the tiny segment, and at merge time to make the larger
segments.
</simpara>
</listitem>
<listitem>
<simpara>
Never start multiple <literal>refresh=wait_for</literal> requests in a row. Instead batch them
into a single bulk request with <literal>refresh=wait_for</literal> and Elasticsearch will start
them all in parallel and return only when they have all finished.
</simpara>
</listitem>
<listitem>
<simpara>
If the refresh interval is set to <literal>-1</literal>, disabling the automatic refreshes,
then requests with <literal>refresh=wait_for</literal> will wait indefinitely until some action
causes a refresh. Conversely, setting <literal>index.refresh_interval</literal> to something
shorter than the default like <literal>200ms</literal> will make <literal>refresh=wait_for</literal> come back
faster, but it&#8217;ll still generate inefficient segments.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>refresh=wait_for</literal> only affects the request that it is on, but, by forcing a
refresh immediately, <literal>refresh=true</literal> will affect other ongoing request. In
general, if you have a running system you don&#8217;t wish to disturb then
<literal>refresh=wait_for</literal> is a smaller modification.
</simpara>
</listitem>
</itemizedlist>
<bridgehead id="_literal_refresh_wait_for_literal_can_force_a_refresh" renderas="sect2"><literal>refresh=wait_for</literal> Can Force a Refresh<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/refresh.asciidoc">Edit me</ulink></bridgehead>
<simpara>If a <literal>refresh=wait_for</literal> request comes in when there are already
<literal>index.max_refresh_listeners</literal> (defaults to 1000) requests waiting for a refresh
on that shard then that request will behave just as though it had <literal>refresh</literal> set
to <literal>true</literal> instead: it will force a refresh. This keeps the promise that when a
<literal>refresh=wait_for</literal> request returns that its changes are visible for search
while preventing unchecked resource usage for blocked requests. If a request
forced a refresh because it ran out of listener slots then its response will
contain <literal>"forced_refresh": true</literal>.</simpara>
<simpara>Bulk requests only take up one slot on each shard that they touch no matter how
many times they modify the shard.</simpara>
<bridgehead id="_examples" renderas="sect2">Examples<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/docs/refresh.asciidoc">Edit me</ulink></bridgehead>
<simpara>These will create a document and immediately refresh the index so it is visible:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /test/test/1?refresh
{"test": "test"}
PUT /test/test/2?refresh=true
{"test": "test"}</programlisting>
<remark> CONSOLE</remark>
<simpara>These will create a document without doing anything to make it visible for
search:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /test/test/3
{"test": "test"}
PUT /test/test/4?refresh=false
{"test": "test"}</programlisting>
<remark> CONSOLE</remark>
<simpara>This will create a document and wait for it to become visible for search:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /test/test/4?refresh=wait_for
{"test": "test"}</programlisting>
<remark> CONSOLE</remark>
</chapter>
</part>
<part id="search">
<title>Search APIs <ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search.asciidoc">Edit me</ulink></title>
<partintro>
<simpara>Most search APIs are <link linkend="search-multi-index-type">multi-index&#44; multi-type</link>, with the
exception of the <xref linkend="search-explain"/> endpoints.</simpara>
<bridgehead id="search-routing" renderas="sect1">Routing<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search.asciidoc">Edit me</ulink></bridgehead>
<simpara>When executing a search, it will be broadcast to all the index/indices
shards (round robin between replicas). Which shards will be searched on
can be controlled by providing the <literal>routing</literal> parameter. For example,
when indexing tweets, the routing value can be the user name:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /twitter/tweet?routing=kimchy
{
    "user" : "kimchy",
    "postDate" : "2009-11-15T14:12:12",
    "message" : "trying out Elasticsearch"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>In such a case, if we want to search only on the tweets for a specific
user, we can specify it as the routing, resulting in the search hitting
only the relevant shard:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /twitter/tweet/_search?routing=kimchy
{
    "query": {
        "bool" : {
            "must" : {
                "query_string" : {
                    "query" : "some query string here"
                }
            },
            "filter" : {
                "term" : { "user" : "kimchy" }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>The routing parameter can be multi valued represented as a comma
separated string. This will result in hitting the relevant shards where
the routing values match to.</simpara>
<bridgehead id="stats-groups" renderas="sect1">Stats Groups<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search.asciidoc">Edit me</ulink></bridgehead>
<simpara>A search can be associated with stats groups, which maintains a
statistics aggregation per group. It can later be retrieved using the
<link linkend="indices-stats">indices stats</link> API
specifically. For example, here is a search body request that associate
the request with two different groups:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /_search
{
    "query" : {
        "match_all" : {}
    },
    "stats" : ["group1", "group2"]
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<bridgehead id="global-search-timeout" renderas="sect1">Global Search Timeout<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search.asciidoc">Edit me</ulink></bridgehead>
<simpara>Individual searches can have a timeout as part of the
<xref linkend="search-request-body"/>. Since search requests can originate from many
sources, Elasticsearch has a dynamic cluster-level setting for a global
search timeout that applies to all search requests that do not set a
timeout in the <xref linkend="search-request-body"/>. The default value is no global
timeout. The setting key is <literal>search.default_search_timeout</literal> and can be
set using the <xref linkend="cluster-update-settings"/> endpoints. Setting this value
to <literal>-1</literal> resets the global search timeout to no timeout.</simpara>
<bridgehead id="global-search-cancellation" renderas="sect1">Search Cancellation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search.asciidoc">Edit me</ulink></bridgehead>
<simpara>Searches can be cancelled using standard <link linkend="task-cancellation">task cancellation</link>
mechanism. By default, a running search only checks if it is cancelled or
not on segment boundaries, therefore the cancellation can be delayed by large
segments. The search cancellation responsiveness can be improved by setting
the dynamic cluster-level setting <literal>search.low_level_cancellation</literal> to <literal>true</literal>.
However, it comes with an additional overhead of more frequent cancellation
checks that can be noticeable on large fast running search queries. Changing this
setting only affects the searches that start after the change is made.</simpara>
</partintro>
<chapter id="search-search">
<title>Search<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/search.asciidoc">Edit me</ulink></title>
<simpara>The search API allows you to execute a search query and get back search hits
that match the query. The query can either be provided using a simple
<link linkend="search-uri-request">query string as a parameter</link>, or using a
<link linkend="search-request-body">request body</link>.</simpara>
<bridgehead id="search-multi-index-type" renderas="sect2">Multi-Index, Multi-Type<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/search.asciidoc">Edit me</ulink></bridgehead>
<simpara>All search APIs can be applied across multiple types within an index, and
across multiple indices with support for the
<link linkend="multi-index">multi index syntax</link>. For
example, we can search on all documents across all types within the
twitter index:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /twitter/_search?q=user:kimchy</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>We can also search within specific types:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /twitter/tweet,user/_search?q=user:kimchy</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>We can also search all tweets with a certain tag across several indices
(for example, when each user has his own index):</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /kimchy,elasticsearch/tweet/_search?q=tag:wow</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT kimchy\nPUT elasticsearch\n/]</remark>
<simpara>Or we can search all tweets across all available indices using <literal>_all</literal>
placeholder:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_all/tweet/_search?q=tag:wow</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>Or even search across all indices and all types:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search?q=tag:wow</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>By default elasticsearch rejects search requests that would query more than
1000 shards. The reason is that such large numbers of shards make the job of
the coordinating node very CPU and memory intensive. It is usually a better
idea to organize data in such a way that there are fewer larger shards. In
case you would like to bypass this limit, which is discouraged, you can update
the <literal>action.search.shard_count.limit</literal> cluster setting to a greater value.</simpara>
</chapter>
<chapter id="search-uri-request">
<title>URI Search<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/uri-request.asciidoc">Edit me</ulink></title>
<simpara>A search request can be executed purely using a URI by providing request
parameters. Not all search options are exposed when executing a search
using this mode, but it can be handy for quick "curl tests". Here is an
example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET twitter/tweet/_search?q=user:kimchy</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>And here is a sample response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "timed_out": false,
    "took": 62,
    "_shards":{
        "total" : 1,
        "successful" : 1,
        "failed" : 0
    },
    "hits":{
        "total" : 1,
        "max_score": 1.3862944,
        "hits" : [
            {
                "_index" : "twitter",
                "_type" : "tweet",
                "_id" : "0",
                "_score": 1.3862944,
                "_source" : {
                    "user" : "kimchy",
                    "date" : "2009-11-15T14:12:12",
                    "message" : "trying out Elasticsearch",
                    "likes": 0
                }
            }
        ]
    }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 62/"took": "$body.took"/]</remark>
<bridgehead id="_parameters_3" renderas="sect2">Parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/uri-request.asciidoc">Edit me</ulink></bridgehead>
<simpara>The parameters allowed in the URI are:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Name </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>q</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The query string (maps to the <literal>query_string</literal> query, see
<link linkend="query-dsl-query-string-query"><emphasis>Query String Query</emphasis></link> for more details).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>df</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The default field to use when no field prefix is defined within the
query.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>analyzer</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The analyzer name to be used when analyzing the query string.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>analyze_wildcard</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Should wildcard and prefix queries be analyzed or
not. Defaults to <literal>false</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>default_operator</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The default operator to be used, can be <literal>AND</literal> or
<literal>OR</literal>. Defaults to <literal>OR</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>lenient</literal></simpara></entry>
<entry align="left" valign="top"><simpara>If set to true will cause format based failures (like
providing text to a numeric field) to be ignored. Defaults to false.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>explain</literal></simpara></entry>
<entry align="left" valign="top"><simpara>For each hit, contain an explanation of how scoring of the
hits was computed.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>_source</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Set to <literal>false</literal> to disable retrieval of the <literal>_source</literal> field. You can also retrieve
part of the document by using <literal>_source_include</literal> &amp; <literal>_source_exclude</literal> (see the <link linkend="search-request-source-filtering">request body</link>
documentation for more details)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>stored_fields</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The selective stored fields of the document to return for each hit,
comma delimited. Not specifying any value will cause no fields to return.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>sort</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Sorting to perform. Can either be in the form of <literal>fieldName</literal>, or
<literal>fieldName:asc</literal>/<literal>fieldName:desc</literal>. The fieldName can either be an actual
field within the document, or the special <literal>_score</literal> name to indicate
sorting based on scores. There can be several <literal>sort</literal> parameters (order
is important).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>track_scores</literal></simpara></entry>
<entry align="left" valign="top"><simpara>When sorting, set to <literal>true</literal> in order to still track
scores and return them as part of each hit.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>timeout</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A search timeout, bounding the search request to be executed
within the specified time value and bail with the hits accumulated up to
that point when expired. Defaults to no timeout.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>terminate_after</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The maximum number of documents to collect for
each shard, upon reaching which the query execution will terminate early.
If set, the response will have a boolean field <literal>terminated_early</literal> to
indicate whether the query execution has actually terminated_early.
Defaults to no terminate_after.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>from</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The starting from index of the hits to return. Defaults to <literal>0</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>size</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The number of hits to return. Defaults to <literal>10</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>search_type</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The type of the search operation to perform. Can be
<literal>dfs_query_then_fetch</literal> or <literal>query_then_fetch</literal>.
Defaults to <literal>query_then_fetch</literal>. See
<link linkend="search-request-search-type"><emphasis>Search Type</emphasis></link> for
more details on the different types of search that can be performed.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</chapter>
<chapter id="search-request-body">
<title>Request Body Search<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request-body.asciidoc">Edit me</ulink></title>
<simpara>The search request can be executed with a search DSL, which includes the
<link linkend="query-dsl">Query DSL</link>, within its body. Here is an
example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /twitter/tweet/_search
{
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>And here is a sample response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "took": 1,
    "timed_out": false,
    "_shards":{
        "total" : 1,
        "successful" : 1,
        "failed" : 0
    },
    "hits":{
        "total" : 1,
        "max_score": 1.3862944,
        "hits" : [
            {
                "_index" : "twitter",
                "_type" : "tweet",
                "_id" : "0",
                "_score": 1.3862944,
                "_source" : {
                    "user" : "kimchy",
                    "message": "trying out Elasticsearch",
                    "date" : "2009-11-15T14:12:12",
                    "likes" : 0
                }
            }
        ]
    }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 1/"took": $body.took/]</remark>
<bridgehead id="_parameters_4" renderas="sect2">Parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request-body.asciidoc">Edit me</ulink></bridgehead>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>timeout</literal>
</simpara>
</entry>
<entry>
<simpara>
    A search timeout, bounding the search request to be executed within the
    specified time value and bail with the hits accumulated up to that point
    when expired. Defaults to no timeout. See <xref linkend="time-units"/>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>from</literal>
</simpara>
</entry>
<entry>
<simpara>
    To retrieve hits from a certain offset. Defaults to <literal>0</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>size</literal>
</simpara>
</entry>
<entry>
<simpara>
    The number of hits to return. Defaults to <literal>10</literal>. If you do not care about
    getting some hits back but only about the number of matches and/or
    aggregations, setting the value to <literal>0</literal> will help performance.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>search_type</literal>
</simpara>
</entry>
<entry>
<simpara>
    The type of the search operation to perform. Can be
    <literal>dfs_query_then_fetch</literal> or <literal>query_then_fetch</literal>.
    Defaults to <literal>query_then_fetch</literal>.
    See <link linkend="search-request-search-type"><emphasis>Search Type</emphasis></link> for more.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>request_cache</literal>
</simpara>
</entry>
<entry>
<simpara>
    Set to <literal>true</literal> or <literal>false</literal> to enable or disable the caching
    of search results for requests where <literal>size</literal> is 0, ie
    aggregations and suggestions (no top hits returned).
    See <xref linkend="shard-request-cache"/>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>terminate_after</literal>
</simpara>
</entry>
<entry>
<simpara>
    The maximum number of documents to collect for each shard,
    upon reaching which the query execution will terminate early. If set, the
    response will have a boolean field <literal>terminated_early</literal> to indicate whether
    the query execution has actually terminated_early. Defaults to no
    terminate_after.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>Out of the above, the <literal>search_type</literal> and the <literal>request_cache</literal> must be passed as
query-string parameters. The rest of the search request should be passed
within the body itself. The body content can also be passed as a REST
parameter named <literal>source</literal>.</simpara>
<simpara>Both HTTP GET and HTTP POST can be used to execute search with body. Since not
all clients support GET with body, POST is allowed as well.</simpara>
<bridgehead id="_fast_check_for_any_matching_docs" renderas="sect2">Fast check for any matching docs<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request-body.asciidoc">Edit me</ulink></bridgehead>
<simpara>In case we only want to know if there are any documents matching a
specific query, we can set the <literal>size</literal> to <literal>0</literal> to indicate that we are not
interested in the search results. Also we can set <literal>terminate_after</literal> to <literal>1</literal>
to indicate that the query execution can be terminated whenever the first
matching document was found (per shard).</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search?q=message:elasticsearch&amp;size=0&amp;terminate_after=1</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>The response will not contain any hits as the <literal>size</literal> was set to <literal>0</literal>. The
<literal>hits.total</literal> will be either equal to <literal>0</literal>, indicating that there were no
matching documents, or greater than <literal>0</literal> meaning that there were at least
as many documents matching the query when it was early terminated.
Also if the query was terminated early, the <literal>terminated_early</literal> flag will
be set to <literal>true</literal> in the response.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "took": 3,
  "timed_out": false,
  "terminated_early": true,
  "_shards": {
    "total": 1,
    "successful": 1,
    "failed": 0
  },
  "hits": {
    "total": 1,
    "max_score": 0.0,
    "hits": []
  }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 3/"took": $body.took/]</remark>
<section id="search-request-query">
<title>Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/query.asciidoc">Edit me</ulink></title>
<simpara>The query element within the search request body allows to define a
query using the <link linkend="query-dsl">Query DSL</link>.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="search-request-from-size">
<title>From / Size<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/from-size.asciidoc">Edit me</ulink></title>
<simpara>Pagination of results can be done by using the <literal>from</literal> and <literal>size</literal>
parameters. The <literal>from</literal> parameter defines the offset from the first
result you want to fetch. The <literal>size</literal> parameter allows you to configure
the maximum amount of hits to be returned.</simpara>
<simpara>Though <literal>from</literal> and <literal>size</literal> can be set as request parameters, they can also
be set within the search body. <literal>from</literal> defaults to <literal>0</literal>, and <literal>size</literal>
defaults to <literal>10</literal>.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "from" : 0, "size" : 10,
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Note that <literal>from</literal> + <literal>size</literal> can not be more than the <literal>index.max_result_window</literal>
index setting which defaults to 10,000. See the <link linkend="search-request-scroll">Scroll</link> or <link linkend="search-request-search-after">Search After</link>
API for more efficient ways to do deep scrolling.</simpara>
</section>
<section id="search-request-sort">
<title>Sort<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/sort.asciidoc">Edit me</ulink></title>
<simpara>Allows to add one or more sort on specific fields. Each sort can be
reversed as well. The sort is defined on a per field level, with special
field name for <literal>_score</literal> to sort by score, and <literal>_doc</literal> to sort by index order.</simpara>
<simpara>Assuming the following index mapping:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /my_index
{
    "mappings": {
        "my_type": {
            "properties": {
                "post_date": { "type": "date" },
                "user": {
                    "type": "keyword"
                },
                "name": {
                    "type": "keyword"
                },
                "age": { "type": "integer" }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<programlisting language="js" linenumbering="unnumbered">GET /my_index/my_type/_search
{
    "sort" : [
        { "post_date" : {"order" : "asc"}},
        "user",
        { "name" : "desc" },
        { "age" : "desc" },
        "_score"
    ],
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<note><simpara><literal>_doc</literal> has no real use-case besides being the most efficient sort order.
So if you don&#8217;t care about the order in which documents are returned, then you
should sort by <literal>_doc</literal>. This especially helps when <link linkend="search-request-scroll">scrolling</link>.</simpara></note>
<section id="_sort_values">
<title>Sort Values<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/sort.asciidoc">Edit me</ulink></title>
<simpara>The sort values for each document returned are also returned as part of
the response.</simpara>
</section>
<section id="_sort_order">
<title>Sort Order<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/sort.asciidoc">Edit me</ulink></title>
<simpara>The <literal>order</literal> option can have the following values:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>asc</literal>
</simpara>
</entry>
<entry>
<simpara>
Sort in ascending order
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>desc</literal>
</simpara>
</entry>
<entry>
<simpara>
Sort in descending order
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>The order defaults to <literal>desc</literal> when sorting on the <literal>_score</literal>, and defaults
to <literal>asc</literal> when sorting on anything else.</simpara>
</section>
<section id="_sort_mode_option">
<title>Sort mode option<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/sort.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch supports sorting by array or multi-valued fields. The <literal>mode</literal> option
controls what array value is picked for sorting the document it belongs
to. The <literal>mode</literal> option can have the following values:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>min</literal>
</simpara>
</entry>
<entry>
<simpara>
Pick the lowest value.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max</literal>
</simpara>
</entry>
<entry>
<simpara>
Pick the highest value.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>sum</literal>
</simpara>
</entry>
<entry>
<simpara>
Use the sum of all values as sort value. Only applicable for
        number based array fields.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>avg</literal>
</simpara>
</entry>
<entry>
<simpara>
Use the average of all values as sort value. Only applicable
        for number based array fields.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>median</literal>
</simpara>
</entry>
<entry>
<simpara>
Use the median of all values as sort value.  Only applicable
           for number based array fields.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<section id="_sort_mode_example_usage">
<title>Sort mode example usage<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/sort.asciidoc">Edit me</ulink></title>
<simpara>In the example below the field price has multiple prices per document.
In this case the result hits will be sorted by price ascending based on
the average price per document.</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /my_index/my_type/1?refresh
{
   "product": "chocolate",
    "price": [20, 4]
}

POST /_search
{
   "query" : {
      "term" : { "product" : "chocolate" }
   },
   "sort" : [
      {"price" : {"order" : "asc", "mode" : "avg"}}
   ]
}</programlisting>
<remark> CONSOLE</remark>
</section>
</section>
<section id="nested-sorting">
<title>Sorting within nested objects.<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/sort.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch also supports sorting by
fields that are inside one or more nested objects. The sorting by nested
field support has the following parameters on top of the already
existing sort options:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>nested_path</literal>
</term>
<listitem>
<simpara>
    Defines on which nested object to sort. The actual
    sort field must be a direct field inside this nested object.
    When sorting by nested field, this field is mandatory.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>nested_filter</literal>
</term>
<listitem>
<simpara>
    A filter that the inner objects inside the nested path
    should match with in order for its field values to be taken into account
    by sorting. Common case is to repeat the query / filter inside the
    nested filter or query. By default no <literal>nested_filter</literal> is active.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<section id="_nested_sorting_example">
<title>Nested sorting example<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/sort.asciidoc">Edit me</ulink></title>
<simpara>In the below example <literal>offer</literal> is a field of type <literal>nested</literal>.
The <literal>nested_path</literal> needs to be specified; otherwise, elasticsearch doesn&#8217;t know on what nested level sort values need to be captured.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /_search
{
   "query" : {
      "term" : { "product" : "chocolate" }
   },
   "sort" : [
       {
          "offer.price" : {
             "mode" :  "avg",
             "order" : "asc",
             "nested_path" : "offer",
             "nested_filter" : {
                "term" : { "offer.color" : "blue" }
             }
          }
       }
    ]
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Nested sorting is also supported when sorting by
scripts and sorting by geo distance.</simpara>
</section>
</section>
<section id="_missing_values">
<title>Missing Values<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/sort.asciidoc">Edit me</ulink></title>
<simpara>The <literal>missing</literal> parameter specifies how docs which are missing
the field should be treated: The <literal>missing</literal> value can be
set to <literal>_last</literal>, <literal>_first</literal>, or a custom value (that
will be used for missing docs as the sort value). For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "sort" : [
        { "price" : {"missing" : "_last"} }
    ],
    "query" : {
        "term" : { "product" : "chocolate" }
    }
}</programlisting>
<remark> CONSOLE</remark>
<note><simpara>If a nested inner object doesn&#8217;t match with
the <literal>nested_filter</literal> then a missing value is used.</simpara></note>
</section>
<section id="_ignoring_unmapped_fields">
<title>Ignoring Unmapped Fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/sort.asciidoc">Edit me</ulink></title>
<simpara>By default, the search request will fail if there is no mapping
associated with a field. The <literal>unmapped_type</literal> option allows to ignore
fields that have no mapping and not sort by them. The value of this
parameter is used to determine what sort values to emit. Here is an
example of how it can be used:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "sort" : [
        { "price" : {"unmapped_type" : "long"} }
    ],
    "query" : {
        "term" : { "product" : "chocolate" }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>If any of the indices that are queried doesn&#8217;t have a mapping for <literal>price</literal>
then Elasticsearch will handle it as if there was a mapping of type
<literal>long</literal>, with all documents in this index having no value for this field.</simpara>
</section>
<section id="geo-sorting">
<title>Geo Distance Sorting<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/sort.asciidoc">Edit me</ulink></title>
<simpara>Allow to sort by <literal>_geo_distance</literal>. Here is an example, assuming <literal>pin.location</literal> is a field of type <literal>geo_point</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "sort" : [
        {
            "_geo_distance" : {
                "pin.location" : [-70, 40],
                "order" : "asc",
                "unit" : "km",
                "mode" : "min",
                "distance_type" : "sloppy_arc"
            }
        }
    ],
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}</programlisting>
<remark> CONSOLE</remark>
<variablelist>
<varlistentry>
<term>
<literal>distance_type</literal>
</term>
<listitem>
<simpara>
    How to compute the distance. Can either be <literal>sloppy_arc</literal> (default), <literal>arc</literal> (slightly more precise but significantly slower) or <literal>plane</literal> (faster, but inaccurate on long distances and close to the poles).
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>mode</literal>
</term>
<listitem>
<simpara>
    What to do in case a field has several geo points. By default, the shortest
    distance is taken into account when sorting in ascending order and the
    longest distance when sorting in descending order. Supported values are
    <literal>min</literal>, <literal>max</literal>, <literal>median</literal> and <literal>avg</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>unit</literal>
</term>
<listitem>
<simpara>
    The unit to use when computing sort values. The default is <literal>m</literal> (meters).
</simpara>
</listitem>
</varlistentry>
</variablelist>
<note><simpara>geo distance sorting does not support configurable missing values: the
distance will always be considered equal to <literal>Infinity</literal> when a document does not
have values for the field that is used for distance computation.</simpara></note>
<simpara>The following formats are supported in providing the coordinates:</simpara>
<section id="_lat_lon_as_properties">
<title>Lat Lon as Properties<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/sort.asciidoc">Edit me</ulink></title>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "sort" : [
        {
            "_geo_distance" : {
                "pin.location" : {
                    "lat" : 40,
                    "lon" : -70
                },
                "order" : "asc",
                "unit" : "km"
            }
        }
    ],
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="_lat_lon_as_string">
<title>Lat Lon as String<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/sort.asciidoc">Edit me</ulink></title>
<simpara>Format in <literal>lat,lon</literal>.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "sort" : [
        {
            "_geo_distance" : {
                "pin.location" : "40,-70",
                "order" : "asc",
                "unit" : "km"
            }
        }
    ],
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="_geohash">
<title>Geohash<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/sort.asciidoc">Edit me</ulink></title>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "sort" : [
        {
            "_geo_distance" : {
                "pin.location" : "drm3btev3e86",
                "order" : "asc",
                "unit" : "km"
            }
        }
    ],
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="_lat_lon_as_array">
<title>Lat Lon as Array<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/sort.asciidoc">Edit me</ulink></title>
<simpara>Format in <literal>[lon, lat]</literal>, note, the order of lon/lat here in order to
conform with <ulink url="http://geojson.org/">GeoJSON</ulink>.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "sort" : [
        {
            "_geo_distance" : {
                "pin.location" : [-70, 40],
                "order" : "asc",
                "unit" : "km"
            }
        }
    ],
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
</section>
<section id="_multiple_reference_points">
<title>Multiple reference points<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/sort.asciidoc">Edit me</ulink></title>
<simpara>Multiple geo points can be passed as an array containing any <literal>geo_point</literal> format, for example</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "sort" : [
        {
            "_geo_distance" : {
                "pin.location" : [[-70, 40], [-71, 42]],
                "order" : "asc",
                "unit" : "km"
            }
        }
    ],
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>and so forth.</simpara>
<simpara>The final distance for a document will then be <literal>min</literal>/<literal>max</literal>/<literal>avg</literal> (defined via <literal>mode</literal>) distance of all points contained in the document to all points given in the sort request.</simpara>
</section>
<section id="_script_based_sorting">
<title>Script Based Sorting<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/sort.asciidoc">Edit me</ulink></title>
<simpara>Allow to sort based on custom scripts, here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query" : {
        "term" : { "user" : "kimchy" }
    },
    "sort" : {
        "_script" : {
            "type" : "number",
            "script" : {
                "lang": "painless",
                "inline": "doc['field_name'].value * params.factor",
                "params" : {
                    "factor" : 1.1
                }
            },
            "order" : "asc"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="_track_scores">
<title>Track Scores<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/sort.asciidoc">Edit me</ulink></title>
<simpara>When sorting on a field, scores are not computed. By setting
<literal>track_scores</literal> to true, scores will still be computed and tracked.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "track_scores": true,
    "sort" : [
        { "post_date" : {"order" : "desc"} },
        { "name" : "desc" },
        { "age" : "desc" }
    ],
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="_memory_considerations">
<title>Memory Considerations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/sort.asciidoc">Edit me</ulink></title>
<simpara>When sorting, the relevant sorted field values are loaded into memory.
This means that per shard, there should be enough memory to contain
them. For string based types, the field sorted on should not be analyzed
/ tokenized. For numeric types, if possible, it is recommended to
explicitly set the type to narrower types (like <literal>short</literal>, <literal>integer</literal> and
<literal>float</literal>).</simpara>
</section>
</section>
<section id="search-request-source-filtering">
<title>Source filtering<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/source-filtering.asciidoc">Edit me</ulink></title>
<simpara>Allows to control how the <literal>_source</literal> field is returned with every hit.</simpara>
<simpara>By default operations return the contents of the <literal>_source</literal> field unless
you have used the <literal>stored_fields</literal> parameter or if the <literal>_source</literal> field is disabled.</simpara>
<simpara>You can turn off <literal>_source</literal> retrieval by using the <literal>_source</literal> parameter:</simpara>
<simpara>To disable <literal>_source</literal> retrieval set to <literal>false</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "_source": false,
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The <literal>_source</literal> also accepts one or more wildcard patterns to control what parts of the <literal>_source</literal> should be returned:</simpara>
<simpara>For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "_source": "obj.*",
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Or</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "_source": [ "obj1.*", "obj2.*" ],
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Finally, for complete control, you can specify both <literal>includes</literal> and <literal>excludes</literal>
patterns:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "_source": {
        "includes": [ "obj1.*", "obj2.*" ],
        "excludes": [ "*.description" ]
    },
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="search-request-stored-fields">
<title>Fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/stored-fields.asciidoc">Edit me</ulink></title>
<warning><simpara>The <literal>stored_fields</literal> parameter is about fields that are explicitly marked as
stored in the mapping, which is off by default and generally not recommended.
Use <link linkend="search-request-source-filtering">source filtering</link> instead to select
subsets of the original source document to be returned.</simpara></warning>
<simpara>Allows to selectively load specific stored fields for each document represented
by a search hit.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "stored_fields" : ["user", "postDate"],
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara><literal>*</literal> can be used to load all stored fields from the document.</simpara>
<simpara>An empty array will cause only the <literal>_id</literal> and <literal>_type</literal> for each hit to be
returned, for example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "stored_fields" : [],
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>If the requested fields are not stored (<literal>store</literal> mapping set to <literal>false</literal>), they will be ignored.</simpara>
<simpara>Stored field values fetched from the document itself are always returned as an array. On the contrary, metadata fields like <literal>_routing</literal> and
<literal>_parent</literal> fields are never returned as an array.</simpara>
<simpara>Also only leaf fields can be returned via the <literal>field</literal> option. So object fields can&#8217;t be returned and such requests
will fail.</simpara>
<simpara>Script fields can also be automatically detected and used as fields, so
things like <literal>_source.obj1.field1</literal> can be used, though not recommended, as
<literal>obj1.field1</literal> will work as well.</simpara>
<section id="_disable_stored_fields_entirely">
<title>Disable stored fields entirely<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/stored-fields.asciidoc">Edit me</ulink></title>
<simpara>To disable the stored fields (and metadata fields) entirely use: <literal>\_none_</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "stored_fields": "_none_",
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}</programlisting>
<remark> CONSOLE</remark>
<note><simpara><link linkend="search-request-source-filtering"><literal>_source</literal></link> and <link linkend="search-request-version"><literal>version</literal></link> parameters cannot be activated if <literal>_none_</literal> is used.</simpara></note>
</section>
</section>
<section id="search-request-script-fields">
<title>Script Fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/script-fields.asciidoc">Edit me</ulink></title>
<simpara>Allows to return a <link linkend="modules-scripting">script evaluation</link> (based on different fields) for each hit, for example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query" : {
        "match_all": {}
    },
    "script_fields" : {
        "test1" : {
            "script" : {
                "lang": "painless",
                "inline": "doc['my_field_name'].value * 2"
            }
        },
        "test2" : {
            "script" : {
                "lang": "painless",
                "inline": "doc['my_field_name'].value * factor",
                "params" : {
                    "factor"  : 2.0
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Script fields can work on fields that are not stored (<literal>my_field_name</literal> in
the above case), and allow to return custom values to be returned (the
evaluated value of the script).</simpara>
<simpara>Script fields can also access the actual <literal>_source</literal> document indexed and
extract specific elements to be returned from it (can be an "object"
type). Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
    {
        "query" : {
            "match_all": {}
        },
        "script_fields" : {
            "test1" : {
                "script" : "_source.obj1.obj2"
            }
        }
    }</programlisting>
<remark> CONSOLE</remark>
<simpara>Note the <literal>_source</literal> keyword here to navigate the json-like model.</simpara>
<simpara>It&#8217;s important to understand the difference between
<literal>doc['my_field'].value</literal> and <literal>_source.my_field</literal>. The first, using the doc
keyword, will cause the terms for that field to be loaded to memory
(cached), which will result in faster execution, but more memory
consumption. Also, the <literal>doc[...]</literal> notation only allows for simple valued
fields (can&#8217;t return a json object from it) and make sense only on
non-analyzed or single term based fields.</simpara>
<simpara>The <literal>_source</literal> on the other hand causes the source to be loaded, parsed,
and then only the relevant part of the json is returned.</simpara>
</section>
<section id="search-request-docvalue-fields">
<title>Doc value Fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/docvalue-fields.asciidoc">Edit me</ulink></title>
<simpara>Allows to return the <link linkend="doc-values">doc value</link> representation of a field for each hit, for
example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query" : {
        "match_all": {}
    },
    "docvalue_fields" : ["test1", "test2"]
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Doc value fields can work on fields that are not stored.</simpara>
<simpara>Note that if the fields parameter specifies fields without docvalues it will try to load the value from the fielddata cache
causing the terms for that field to be loaded to memory (cached), which will result in more memory consumption.</simpara>
</section>
<section id="search-request-post-filter">
<title>Post filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/post-filter.asciidoc">Edit me</ulink></title>
<simpara>The <literal>post_filter</literal> is applied to the search <literal>hits</literal> at the very end of a search
request,  after aggregations have already been calculated. Its purpose is
best explained by example:</simpara>
<simpara>Imagine that you are selling shirts that have the following properties:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /shirts
{
    "mappings": {
        "item": {
            "properties": {
                "brand": { "type": "keyword"},
                "color": { "type": "keyword"},
                "model": { "type": "keyword"}
            }
        }
    }
}

PUT /shirts/item/1?refresh
{
    "brand": "gucci",
    "color": "red",
    "model": "slim"
}</programlisting>
<remark> CONSOLE</remark>
<remark> TESTSETUP</remark>
<simpara>Imagine a user has specified two filters:</simpara>
<simpara><literal>color:red</literal> and <literal>brand:gucci</literal>.  You only want to show them red shirts made by
Gucci in the search results.  Normally you would do this with a
<link linkend="query-dsl-bool-query"><literal>bool</literal> query</link>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /shirts/_search
{
  "query": {
    "bool": {
      "filter": [
        { "term": { "color": "red"   }},
        { "term": { "brand": "gucci" }}
      ]
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>However, you would also like to use <emphasis>faceted navigation</emphasis> to display a list of
other options that the user could click on.  Perhaps you have a <literal>model</literal> field
that would allow the user to limit their search results to red Gucci
<literal>t-shirts</literal> or <literal>dress-shirts</literal>.</simpara>
<simpara>This can be done with a
<link linkend="search-aggregations-bucket-terms-aggregation"><literal>terms</literal> aggregation</link>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /shirts/_search
{
  "query": {
    "bool": {
      "filter": [
        { "term": { "color": "red"   }},
        { "term": { "brand": "gucci" }}
      ]
    }
  },
  "aggs": {
    "models": {
      "terms": { "field": "model" } <co id="CO14-1"/>
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO14-1">
<para>
Returns the most popular models of red shirts by Gucci.
</para>
</callout>
</calloutlist>
<simpara>But perhaps you would also like to tell the user how many Gucci shirts are
available in <emphasis role="strong">other colors</emphasis>. If you just add a <literal>terms</literal> aggregation on the
<literal>color</literal> field, you will only get back the color <literal>red</literal>, because your query
returns only red shirts by Gucci.</simpara>
<simpara>Instead, you want to include shirts of all colors during aggregation, then
apply the <literal>colors</literal> filter only to the search results.  This is the purpose of
the <literal>post_filter</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /shirts/_search
{
  "query": {
    "bool": {
      "filter": {
        "term": { "brand": "gucci" } <co id="CO15-1"/>
      }
    }
  },
  "aggs": {
    "colors": {
      "terms": { "field": "color" } <co id="CO15-2"/>
    },
    "color_red": {
      "filter": {
        "term": { "color": "red" } <co id="CO15-3"/>
      },
      "aggs": {
        "models": {
          "terms": { "field": "model" } <co id="CO15-4"/>
        }
      }
    }
  },
  "post_filter": { <co id="CO15-5"/>
    "term": { "color": "red" }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO15-1">
<para>
The main query now finds all shirts by Gucci, regardless of color.
</para>
</callout>
<callout arearefs="CO15-2">
<para>
The <literal>colors</literal> agg returns popular colors for shirts by Gucci.
</para>
</callout>
<callout arearefs="CO15-3 CO15-4">
<para>
The <literal>color_red</literal> agg limits the <literal>models</literal> sub-aggregation
    to <emphasis role="strong">red</emphasis> Gucci shirts.
</para>
</callout>
<callout arearefs="CO15-5">
<para>
Finally, the <literal>post_filter</literal> removes colors other than red
    from the search <literal>hits</literal>.
</para>
</callout>
</calloutlist>
</section>
<section id="search-request-highlighting">
<title>Highlighting<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/highlighting.asciidoc">Edit me</ulink></title>
<simpara>Allows to highlight search results on one or more fields. The
implementation uses either the lucene <literal>plain</literal> highlighter, the
fast vector highlighter (<literal>fvh</literal>) or <literal>postings</literal> highlighter.
The following is an example of the search request body:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query" : {
        "match": { "user": "kimchy" }
    },
    "highlight" : {
        "fields" : {
            "content" : {}
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>In the above case, the <literal>content</literal> field will be highlighted for each
search hit (there will be another element in each search hit, called
<literal>highlight</literal>, which includes the highlighted fields and the highlighted
fragments).</simpara>
<note>
<simpara>In order to perform highlighting, the actual content of the field is
required. If the field in question is stored (has <literal>store</literal> set to <literal>true</literal>
in the mapping) it will be used, otherwise, the actual <literal>_source</literal> will
be loaded and the relevant field will be extracted from it.</simpara>
<simpara>The <literal>_all</literal> field cannot be extracted from <literal>_source</literal>, so it can only
be used for highlighting if it mapped to have <literal>store</literal> set to <literal>true</literal>.</simpara>
</note>
<simpara>The field name supports wildcard notation. For example, using <literal>comment_*</literal>
will cause all <link linkend="text">text</link> and <link linkend="keyword">keyword</link> fields (and <link linkend="string">string</link>
from versions before 5.0) that match the expression to be highlighted.
Note that all other fields will not be highlighted. If you use a custom mapper and want to
highlight on a field anyway, you have to provide the field name explicitly.</simpara>
<section id="plain-highlighter">
<title>Plain highlighter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/highlighting.asciidoc">Edit me</ulink></title>
<simpara>The default choice of highlighter is of type <literal>plain</literal> and uses the Lucene highlighter.
It tries hard to reflect the query matching logic in terms of understanding word importance and any word positioning criteria in phrase queries.</simpara>
<warning><simpara>If you want to highlight a lot of fields in a lot of documents with complex queries this highlighter will not be fast.
In its efforts to accurately reflect query logic it creates a tiny in-memory index and re-runs the original query criteria through
Lucene&#8217;s query execution planner to get access to low-level match information on the current document.
This is repeated for every field and every document that needs highlighting. If this presents a performance issue in your system consider using an alternative highlighter.</simpara></warning>
</section>
<section id="postings-highlighter">
<title>Postings highlighter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/highlighting.asciidoc">Edit me</ulink></title>
<simpara>If <literal>index_options</literal> is set to <literal>offsets</literal> in the mapping the postings highlighter
will be used instead of the plain highlighter. The postings highlighter:</simpara>
<itemizedlist>
<listitem>
<simpara>
Is faster since it doesn&#8217;t require to reanalyze the text to be highlighted:
the larger the documents the better the performance gain should be
</simpara>
</listitem>
<listitem>
<simpara>
Requires less disk space than term_vectors, needed for the fast vector
highlighter
</simpara>
</listitem>
<listitem>
<simpara>
Breaks the text into sentences and highlights them. Plays really well with
natural languages, not as well with fields containing for instance html markup
</simpara>
</listitem>
<listitem>
<simpara>
Treats the document as the whole corpus, and scores individual sentences as
if they were documents in this corpus, using the  BM25 algorithm
</simpara>
</listitem>
</itemizedlist>
<simpara>Here is an example of setting the <literal>content</literal> field in the index mapping to allow for
highlighting using the postings highlighter on it:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "type_name" : {
        "content" : {"index_options" : "offsets"}
    }
}</programlisting>
<note><simpara>Note that the postings highlighter is meant to perform simple query terms
highlighting, regardless of their positions. That means that when used for
instance in combination with a phrase query, it will highlight all the terms
that the query is composed of, regardless of whether they are actually part of
a query match, effectively ignoring their positions.</simpara></note>
<warning><simpara>The postings highlighter doesn&#8217;t support highlighting some complex queries,
like a <literal>match</literal> query with <literal>type</literal> set to <literal>match_phrase_prefix</literal>. No highlighted
snippets will be returned in that case.</simpara></warning>
</section>
<section id="fast-vector-highlighter">
<title>Fast vector highlighter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/highlighting.asciidoc">Edit me</ulink></title>
<simpara>If <literal>term_vector</literal> information is provided by setting <literal>term_vector</literal> to
<literal>with_positions_offsets</literal> in the mapping then the fast vector highlighter
will be used instead of the plain highlighter.  The fast vector highlighter:</simpara>
<itemizedlist>
<listitem>
<simpara>
Is faster especially for large fields (&gt; <literal>1MB</literal>)
</simpara>
</listitem>
<listitem>
<simpara>
Can be customized with <literal>boundary_chars</literal>, <literal>boundary_max_scan</literal>, and
 <literal>fragment_offset</literal> (see <link linkend="boundary-characters">below</link>)
</simpara>
</listitem>
<listitem>
<simpara>
Requires setting <literal>term_vector</literal> to <literal>with_positions_offsets</literal> which
  increases the size of the index
</simpara>
</listitem>
<listitem>
<simpara>
Can combine matches from multiple fields into one result.  See
  <literal>matched_fields</literal>
</simpara>
</listitem>
<listitem>
<simpara>
Can assign different weights to matches at different positions allowing
  for things like phrase matches being sorted above term matches when
  highlighting a Boosting Query that boosts phrase matches over term matches
</simpara>
</listitem>
</itemizedlist>
<simpara>Here is an example of setting the <literal>content</literal> field to allow for
highlighting using the fast vector highlighter on it (this will cause
the index to be bigger):</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "type_name" : {
        "content" : {"term_vector" : "with_positions_offsets"}
    }
}</programlisting>
</section>
<section id="_force_highlighter_type">
<title>Force highlighter type<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/highlighting.asciidoc">Edit me</ulink></title>
<simpara>The <literal>type</literal> field allows to force a specific highlighter type. This is useful
for instance when needing to use the plain highlighter on a field that has
<literal>term_vectors</literal> enabled. The allowed values are: <literal>plain</literal>, <literal>postings</literal> and <literal>fvh</literal>.
The following is an example that forces the use of the plain highlighter:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query" : {
        "match": { "user": "kimchy" }
    },
    "highlight" : {
        "fields" : {
            "content" : {"type" : "plain"}
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="_force_highlighting_on_source">
<title>Force highlighting on source<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/highlighting.asciidoc">Edit me</ulink></title>
<simpara>Forces the highlighting to highlight fields based on the source even if fields are
stored separately. Defaults to <literal>false</literal>.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query" : {
        "match": { "user": "kimchy" }
    },
    "highlight" : {
        "fields" : {
            "content" : {"force_source" : true}
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="tags">
<title>Highlighting Tags<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/highlighting.asciidoc">Edit me</ulink></title>
<simpara>By default, the highlighting will wrap highlighted text in <literal>&lt;em&gt;</literal> and
<literal>&lt;/em&gt;</literal>. This can be controlled by setting <literal>pre_tags</literal> and <literal>post_tags</literal>,
for example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query" : {
        "match": { "user": "kimchy" }
    },
    "highlight" : {
        "pre_tags" : ["&lt;tag1&gt;"],
        "post_tags" : ["&lt;/tag1&gt;"],
        "fields" : {
            "_all" : {}
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Using the fast vector highlighter there can be more tags, and the "importance"
is ordered.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query" : {
        "match": { "user": "kimchy" }
    },
    "highlight" : {
        "pre_tags" : ["&lt;tag1&gt;", "&lt;tag2&gt;"],
        "post_tags" : ["&lt;/tag1&gt;", "&lt;/tag2&gt;"],
        "fields" : {
            "_all" : {}
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>There are also built in "tag" schemas, with currently a single schema
called <literal>styled</literal> with the following <literal>pre_tags</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">&lt;em class="hlt1"&gt;, &lt;em class="hlt2"&gt;, &lt;em class="hlt3"&gt;,
&lt;em class="hlt4"&gt;, &lt;em class="hlt5"&gt;, &lt;em class="hlt6"&gt;,
&lt;em class="hlt7"&gt;, &lt;em class="hlt8"&gt;, &lt;em class="hlt9"&gt;,
&lt;em class="hlt10"&gt;</programlisting>
<simpara>and <literal>&lt;/em&gt;</literal> as <literal>post_tags</literal>. If you think of more nice to have built in tag
schemas, just send an email to the mailing list or open an issue. Here
is an example of switching tag schemas:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query" : {
        "match": { "user": "kimchy" }
    },
    "highlight" : {
        "tags_schema" : "styled",
        "fields" : {
            "content" : {}
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="_encoder">
<title>Encoder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/highlighting.asciidoc">Edit me</ulink></title>
<simpara>An <literal>encoder</literal> parameter can be used to define how highlighted text will
be encoded. It can be either <literal>default</literal> (no encoding) or <literal>html</literal> (will
escape html, if you use html highlighting tags).</simpara>
</section>
<section id="_highlighted_fragments">
<title>Highlighted Fragments<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/highlighting.asciidoc">Edit me</ulink></title>
<simpara>Each field highlighted can control the size of the highlighted fragment
in characters (defaults to <literal>100</literal>), and the maximum number of fragments
to return (defaults to <literal>5</literal>).
For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query" : {
        "match": { "user": "kimchy" }
    },
    "highlight" : {
        "fields" : {
            "content" : {"fragment_size" : 150, "number_of_fragments" : 3}
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The <literal>fragment_size</literal> is ignored when using the postings highlighter, as it
outputs sentences regardless of their length.</simpara>
<simpara>On top of this it is possible to specify that highlighted fragments need
to be sorted by score:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query" : {
        "match": { "user": "kimchy" }
    },
    "highlight" : {
        "order" : "score",
        "fields" : {
            "content" : {"fragment_size" : 150, "number_of_fragments" : 3}
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>If the <literal>number_of_fragments</literal> value is set to <literal>0</literal> then no fragments are
produced, instead the whole content of the field is returned, and of
course it is highlighted. This can be very handy if short texts (like
document title or address) need to be highlighted but no fragmentation
is required. Note that <literal>fragment_size</literal> is ignored in this case.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query" : {
        "match": { "user": "kimchy" }
    },
    "highlight" : {
        "fields" : {
            "_all" : {},
            "bio.title" : {"number_of_fragments" : 0}
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>When using <literal>fvh</literal> one can use <literal>fragment_offset</literal>
parameter to control the margin to start highlighting from.</simpara>
<simpara>In the case where there is no matching fragment to highlight, the default is
to not return anything. Instead, we can return a snippet of text from the
beginning of the field by setting <literal>no_match_size</literal> (default <literal>0</literal>) to the length
of the text that you want returned. The actual length may be shorter than
specified as it tries to break on a word boundary. When using the postings
highlighter it is not possible to control the actual size of the snippet,
therefore the first sentence gets returned whenever <literal>no_match_size</literal> is
greater than <literal>0</literal>.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query" : {
        "match": { "user": "kimchy" }
    },
    "highlight" : {
        "fields" : {
            "content" : {
                "fragment_size" : 150,
                "number_of_fragments" : 3,
                "no_match_size": 150
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="_highlight_query">
<title>Highlight query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/highlighting.asciidoc">Edit me</ulink></title>
<simpara>It is also possible to highlight against a query other than the search
query by setting <literal>highlight_query</literal>.  This is especially useful if you
use a rescore query because those are not taken into account by
highlighting by default.  Elasticsearch does not validate that
<literal>highlight_query</literal> contains the search query in any way so it is possible
to define it so legitimate query results aren&#8217;t highlighted at all.
Generally it is better to include the search query in the
<literal>highlight_query</literal>.  Here is an example of including both the search
query and the rescore query in <literal>highlight_query</literal>.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "stored_fields": [ "_id" ],
    "query" : {
        "match": {
            "content": {
                "query": "foo bar"
            }
        }
    },
    "rescore": {
        "window_size": 50,
        "query": {
            "rescore_query" : {
                "match_phrase": {
                    "content": {
                        "query": "foo bar",
                        "slop": 1
                    }
                }
            },
            "rescore_query_weight" : 10
        }
    },
    "highlight" : {
        "order" : "score",
        "fields" : {
            "content" : {
                "fragment_size" : 150,
                "number_of_fragments" : 3,
                "highlight_query": {
                    "bool": {
                        "must": {
                            "match": {
                                "content": {
                                    "query": "foo bar"
                                }
                            }
                        },
                        "should": {
                            "match_phrase": {
                                "content": {
                                    "query": "foo bar",
                                    "slop": 1,
                                    "boost": 10.0
                                }
                            }
                        },
                        "minimum_should_match": 0
                    }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Note that the score of text fragment in this case is calculated by the Lucene
highlighting framework. For implementation details you can check the
<literal>ScoreOrderFragmentsBuilder.java</literal> class. On the other hand when using the
postings highlighter the fragments are scored using, as mentioned above,
the BM25 algorithm.</simpara>
</section>
<section id="highlighting-settings">
<title>Global Settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/highlighting.asciidoc">Edit me</ulink></title>
<simpara>Highlighting settings can be set on a global level and then overridden
at the field level.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query" : {
        "match": { "user": "kimchy" }
    },
    "highlight" : {
        "number_of_fragments" : 3,
        "fragment_size" : 150,
        "fields" : {
            "_all" : { "pre_tags" : ["&lt;em&gt;"], "post_tags" : ["&lt;/em&gt;"] },
            "bio.title" : { "number_of_fragments" : 0 },
            "bio.author" : { "number_of_fragments" : 0 },
            "bio.content" : { "number_of_fragments" : 5, "order" : "score" }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="field-match">
<title>Require Field Match<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/highlighting.asciidoc">Edit me</ulink></title>
<simpara><literal>require_field_match</literal> can be set to <literal>false</literal> which will cause any field to
be highlighted regardless of whether the query matched specifically on them.
The default behaviour is <literal>true</literal>, meaning that only fields that hold a query
match will be highlighted.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query" : {
        "match": { "user": "kimchy" }
    },
    "highlight" : {
        "require_field_match": false,
        "fields": {
                "_all" : { "pre_tags" : ["&lt;em&gt;"], "post_tags" : ["&lt;/em&gt;"] }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="boundary-characters">
<title>Boundary Characters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/highlighting.asciidoc">Edit me</ulink></title>
<simpara>When highlighting a field using the fast vector highlighter,
<literal>boundary_chars</literal> can be configured to define what constitutes a boundary
for highlighting. It&#8217;s a single string with each boundary character
defined in it. It defaults to <literal>.,!? \t\n</literal>.</simpara>
<simpara>The <literal>boundary_max_scan</literal> allows to control how far to look for boundary
characters, and defaults to <literal>20</literal>.</simpara>
</section>
<section id="matched-fields">
<title>Matched Fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/highlighting.asciidoc">Edit me</ulink></title>
<simpara>The Fast Vector Highlighter can combine matches on multiple fields to
highlight a single field using <literal>matched_fields</literal>.  This is most
intuitive for multifields that analyze the same string in different
ways.  All <literal>matched_fields</literal> must have <literal>term_vector</literal> set to
<literal>with_positions_offsets</literal> but only the field to which the matches are
combined is loaded so only that field would benefit from having
<literal>store</literal> set to <literal>yes</literal>.</simpara>
<simpara>In the following examples <literal>content</literal> is analyzed by the <literal>english</literal>
analyzer and <literal>content.plain</literal> is analyzed by the <literal>standard</literal> analyzer.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "query_string": {
            "query": "content.plain:running scissors",
            "fields": ["content"]
        }
    },
    "highlight": {
        "order": "score",
        "fields": {
            "content": {
                "matched_fields": ["content", "content.plain"],
                "type" : "fvh"
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above matches both "run with scissors" and "running with scissors"
and would highlight "running" and "scissors" but not "run". If both
phrases appear in a large document then "running with scissors" is
sorted above "run with scissors" in the fragments list because there
are more matches in that fragment.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "query_string": {
            "query": "running scissors",
            "fields": ["content", "content.plain^10"]
        }
    },
    "highlight": {
        "order": "score",
        "fields": {
            "content": {
                "matched_fields": ["content", "content.plain"],
                "type" : "fvh"
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above highlights "run" as well as "running" and "scissors" but
still sorts "running with scissors" above "run with scissors" because
the plain match ("running") is boosted.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "query_string": {
            "query": "running scissors",
            "fields": ["content", "content.plain^10"]
        }
    },
    "highlight": {
        "order": "score",
        "fields": {
            "content": {
                "matched_fields": ["content.plain"],
                "type" : "fvh"
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above query wouldn&#8217;t highlight "run" or "scissor" but shows that
it is just fine not to list the field to which the matches are combined
(<literal>content</literal>) in the matched fields.</simpara>
<note><simpara>Technically it is also fine to add fields to <literal>matched_fields</literal> that
don&#8217;t share the same underlying string as the field to which the matches
are combined.  The results might not make much sense and if one of the
matches is off the end of the text then the whole query will fail.</simpara></note>
<note>
<simpara>There is a small amount of overhead involved with setting
<literal>matched_fields</literal> to a non-empty array so always prefer</simpara>
<programlisting language="js" linenumbering="unnumbered">    "highlight": {
        "fields": {
            "content": {}
        }
    }</programlisting>
<simpara>to</simpara>
<programlisting language="js" linenumbering="unnumbered">    "highlight": {
        "fields": {
            "content": {
                "matched_fields": ["content"],
                "type" : "fvh"
            }
        }
    }</programlisting>
</note>
</section>
<section id="phrase-limit">
<title>Phrase Limit<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/highlighting.asciidoc">Edit me</ulink></title>
<simpara>The fast vector highlighter has a <literal>phrase_limit</literal> parameter that prevents
it from analyzing too many phrases and eating tons of memory.  It defaults
to 256 so only the first 256 matching phrases in the document scored
considered.  You can raise the limit with the <literal>phrase_limit</literal> parameter but
keep in mind that scoring more phrases consumes more time and memory.</simpara>
<simpara>If using <literal>matched_fields</literal> keep in mind that <literal>phrase_limit</literal> phrases per
matched field are considered.</simpara>
<bridgehead id="explicit-field-order" renderas="sect2">Field Highlight Order<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/highlighting.asciidoc">Edit me</ulink></bridgehead>
<simpara>Elasticsearch highlights the fields in the order that they are sent.  Per the
json spec objects are unordered but if you need to be explicit about the order
that fields are highlighted then you can use an array for <literal>fields</literal> like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">    "highlight": {
        "fields": [
            {"title":{ /*params*/ }},
            {"text":{ /*params*/ }}
        ]
    }</programlisting>
<simpara>None of the highlighters built into Elasticsearch care about the order that the
fields are highlighted but a plugin may.</simpara>
</section>
</section>
<section id="search-request-rescore">
<title>Rescoring<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/rescore.asciidoc">Edit me</ulink></title>
<simpara>Rescoring can help to improve precision by reordering just the top (eg
100 - 500) documents returned by the
<link linkend="search-request-query"><literal>query</literal></link> and
<link linkend="search-request-post-filter"><literal>post_filter</literal></link> phases, using a
secondary (usually more costly) algorithm, instead of applying the
costly algorithm to all documents in the index.</simpara>
<simpara>A <literal>rescore</literal> request is executed on each shard before it returns its
results to be sorted by the node handling the overall search request.</simpara>
<simpara>Currently the rescore API has only one implementation: the query
rescorer, which uses a query to tweak the scoring. In the future,
alternative rescorers may be made available, for example, a pair-wise rescorer.</simpara>
<note><simpara>the <literal>rescore</literal> phase is not executed when <link linkend="search-request-sort"><literal>sort</literal></link> is used.</simpara></note>
<note><simpara>when exposing pagination to your users, you should not change
<literal>window_size</literal> as you step through each page (by passing different
<literal>from</literal> values) since that can alter the top hits causing results to
confusingly shift as the user steps through pages.</simpara></note>
<section id="_query_rescorer">
<title>Query rescorer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/rescore.asciidoc">Edit me</ulink></title>
<simpara>The query rescorer executes a second query only on the Top-K results
returned by the <link linkend="search-request-query"><literal>query</literal></link> and
<link linkend="search-request-post-filter"><literal>post_filter</literal></link> phases. The
number of docs which will be examined on each shard can be controlled by
the <literal>window_size</literal> parameter, which defaults to
<link linkend="search-request-from-size"><literal>from</literal> and <literal>size</literal></link>.</simpara>
<simpara>By default the scores from the original query and the rescore query are
combined linearly to produce the final <literal>_score</literal> for each document. The
relative importance of the original query and of the rescore query can
be controlled with the <literal>query_weight</literal> and <literal>rescore_query_weight</literal>
respectively. Both default to <literal>1</literal>.</simpara>
<simpara>For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -s -XPOST 'localhost:9200/_search' -d '{
   "query" : {
      "match" : {
         "field1" : {
            "operator" : "or",
            "query" : "the quick brown",
            "type" : "boolean"
         }
      }
   },
   "rescore" : {
      "window_size" : 50,
      "query" : {
         "rescore_query" : {
            "match" : {
               "field1" : {
                  "query" : "the quick brown",
                  "type" : "phrase",
                  "slop" : 2
               }
            }
         },
         "query_weight" : 0.7,
         "rescore_query_weight" : 1.2
      }
   }
}
'</programlisting>
<simpara>The way the scores are combined can be controlled with the <literal>score_mode</literal>:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Score Mode </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>total</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Add the original score and the rescore query score.  The default.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>multiply</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Multiply the original score by the rescore query score.  Useful
for <link linkend="query-dsl-function-score-query"><literal>function query</literal></link> rescores.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>avg</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Average the original score and the rescore query score.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>max</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Take the max of original score and the rescore query score.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>min</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Take the min of the original score and the rescore query score.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section id="_multiple_rescores">
<title>Multiple Rescores<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/rescore.asciidoc">Edit me</ulink></title>
<simpara>It is also possible to execute multiple rescores in sequence:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -s -XPOST 'localhost:9200/_search' -d '{
   "query" : {
      "match" : {
         "field1" : {
            "operator" : "or",
            "query" : "the quick brown",
            "type" : "boolean"
         }
      }
   },
   "rescore" : [ {
      "window_size" : 100,
      "query" : {
         "rescore_query" : {
            "match" : {
               "field1" : {
                  "query" : "the quick brown",
                  "type" : "phrase",
                  "slop" : 2
               }
            }
         },
         "query_weight" : 0.7,
         "rescore_query_weight" : 1.2
      }
   }, {
      "window_size" : 10,
      "query" : {
         "score_mode": "multiply",
         "rescore_query" : {
            "function_score" : {
               "script_score": {
                  "script": {
                    "lang": "painless",
                    "inline": "Math.log10(doc['numeric'].value + 2)"
                  }
               }
            }
         }
      }
   } ]
}
'</programlisting>
<simpara>The first one gets the results of the query then the second one gets the
results of the first, etc.  The second rescore will "see" the sorting done
by the first rescore so it is possible to use a large window on the first
rescore to pull documents into a smaller window for the second rescore.</simpara>
</section>
</section>
<section id="search-request-search-type">
<title>Search Type<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/search-type.asciidoc">Edit me</ulink></title>
<simpara>There are different execution paths that can be done when executing a
distributed search. The distributed search operation needs to be
scattered to all the relevant shards and then all the results are
gathered back. When doing scatter/gather type execution, there are
several ways to do that, specifically with search engines.</simpara>
<simpara>One of the questions when executing a distributed search is how much
results to retrieve from each shard. For example, if we have 10 shards,
the 1st shard might hold the most relevant results from 0 till 10, with
other shards results ranking below it. For this reason, when executing a
request, we will need to get results from 0 till 10 from all shards,
sort them, and then return the results if we want to ensure correct
results.</simpara>
<simpara>Another question, which relates to the search engine, is the fact that each
shard stands on its own. When a query is executed on a specific shard,
it does not take into account term frequencies and other search engine
information from the other shards. If we want to support accurate
ranking, we would need to first gather the term frequencies from all
shards to calculate global term frequencies, then execute the query on
each shard using these global frequencies.</simpara>
<simpara>Also, because of the need to sort the results, getting back a large
document set, or even scrolling it, while maintaining the correct sorting
behavior can be a very expensive operation. For large result set
scrolling, it is best to sort by <literal>_doc</literal> if the order in which documents
are returned is not important.</simpara>
<simpara>Elasticsearch is very flexible and allows to control the type of search
to execute on a <emphasis role="strong">per search request</emphasis> basis. The type can be configured
by setting the <emphasis role="strong">search_type</emphasis> parameter in the query string. The types
are:</simpara>
<section id="query-then-fetch">
<title>Query Then Fetch<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/search-type.asciidoc">Edit me</ulink></title>
<simpara>Parameter value: <emphasis role="strong">query_then_fetch</emphasis>.</simpara>
<simpara>The request is processed in two phases. In the first phase, the query
is forwarded to <emphasis role="strong">all involved shards</emphasis>. Each shard executes the search
and generates a sorted list of results, local to that shard. Each
shard returns <emphasis role="strong">just enough information</emphasis> to the coordinating node
to allow it merge and re-sort the shard level results into a globally
sorted set of results, of maximum length <literal>size</literal>.</simpara>
<simpara>During the second phase, the coordinating node requests the document
content (and highlighted snippets, if any) from <emphasis role="strong">only the relevant
shards</emphasis>.</simpara>
<note><simpara>This is the default setting, if you do not specify a <literal>search_type</literal>
      in your request.</simpara></note>
</section>
<section id="dfs-query-then-fetch">
<title>Dfs, Query Then Fetch<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/search-type.asciidoc">Edit me</ulink></title>
<simpara>Parameter value: <emphasis role="strong">dfs_query_then_fetch</emphasis>.</simpara>
<simpara>Same as "Query Then Fetch", except for an initial scatter phase which
goes and computes the distributed term frequencies for more accurate
scoring.</simpara>
</section>
</section>
<section id="search-request-scroll">
<title>Scroll<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/scroll.asciidoc">Edit me</ulink></title>
<simpara>While a <literal>search</literal> request returns a single &#8220;page&#8221; of results, the <literal>scroll</literal>
API can be used to retrieve large numbers of results (or even all results)
from a single search request, in much the same way as you would use a cursor
on a traditional database.</simpara>
<simpara>Scrolling is not intended for real time user requests, but rather for
processing large amounts of data, e.g. in order to reindex the contents of one
index into a new index with a different configuration.</simpara>
<sidebar>
<title>Client support for scrolling and reindexing</title>
<simpara>Some of the officially supported clients provide helpers to assist with
scrolled searches and reindexing of documents from one index to another:</simpara>
<variablelist>
<varlistentry>
<term>
Perl
</term>
<listitem>
<simpara>
    See <ulink url="https://metacpan.org/pod/Search::Elasticsearch::Bulk">Search::Elasticsearch::Bulk</ulink>
    and <ulink url="https://metacpan.org/pod/Search::Elasticsearch::Scroll">Search::Elasticsearch::Scroll</ulink>
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Python
</term>
<listitem>
<simpara>
    See <ulink url="http://elasticsearch-py.readthedocs.org/en/master/helpers.html">elasticsearch.helpers.*</ulink>
</simpara>
</listitem>
</varlistentry>
</variablelist>
</sidebar>
<note><simpara>The results that are returned from a scroll request reflect the state of
the index at the time that the initial <literal>search</literal> request was  made, like a
snapshot in time. Subsequent changes to documents (index, update or delete)
will only affect later search requests.</simpara></note>
<simpara>In order to use scrolling, the initial search request should specify the
<literal>scroll</literal> parameter in the query string, which tells Elasticsearch how long it
should keep the &#8220;search context&#8221; alive (see <xref linkend="scroll-search-context"/>), eg <literal>?scroll=1m</literal>.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /twitter/tweet/_search?scroll=1m
{
    "size": 100,
    "query": {
        "match" : {
            "title" : "elasticsearch"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>The result from the above request includes a <literal>_scroll_id</literal>, which should
be passed to the <literal>scroll</literal> API in order to retrieve the next batch of
results.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST <co id="CO16-1"/> /_search/scroll <co id="CO16-2"/>
{
    "scroll" : "1m", <co id="CO16-3"/>
    "scroll_id" : "DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ==" <co id="CO16-4"/>
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued s/DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ==/$body._scroll_id/]</remark>
<calloutlist>
<callout arearefs="CO16-1">
<para>
<literal>GET</literal> or <literal>POST</literal> can be used.
</para>
</callout>
<callout arearefs="CO16-2">
<para>
The URL should not include the <literal>index</literal> or <literal>type</literal> name&#8201;&#8212;&#8201;these
    are specified in the original <literal>search</literal> request instead.
</para>
</callout>
<callout arearefs="CO16-3">
<para>
The <literal>scroll</literal> parameter tells Elasticsearch to keep the search context open
    for another <literal>1m</literal>.
</para>
</callout>
<callout arearefs="CO16-4">
<para>
The <literal>scroll_id</literal> parameter
</para>
</callout>
</calloutlist>
<simpara>The <literal>size</literal> parameter allows you to configure the maximum number of hits to be
returned with each batch of results.  Each call to the <literal>scroll</literal> API returns the
next batch of results until there are no more results left to return, ie the
<literal>hits</literal> array is empty.</simpara>
<important><simpara>The initial search request and each subsequent scroll request
returns a new <literal>_scroll_id</literal>&#8201;&#8212;&#8201;only the most recent <literal>_scroll_id</literal> should be
used.</simpara></important>
<note><simpara>If the request specifies aggregations, only the initial search response
will contain the aggregations results.</simpara></note>
<note><simpara>Scroll requests have optimizations that make them faster when the sort
order is <literal>_doc</literal>. If you want to iterate over all documents regardless of the
order, this is the most efficient option:</simpara></note>
<programlisting language="js" linenumbering="unnumbered">GET /_search?scroll=1m
{
  "sort": [
    "_doc"
  ]
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<section id="scroll-search-context">
<title>Keeping the search context alive<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/scroll.asciidoc">Edit me</ulink></title>
<simpara>The <literal>scroll</literal> parameter (passed to the <literal>search</literal> request and to every <literal>scroll</literal>
request) tells Elasticsearch how long it should keep the search context alive.
Its value (e.g. <literal>1m</literal>, see <xref linkend="time-units"/>) does not need to be long enough to
process all data&#8201;&#8212;&#8201;it just needs to be long enough to process the previous
batch of results. Each <literal>scroll</literal> request (with the <literal>scroll</literal> parameter) sets a
new  expiry time.</simpara>
<simpara>Normally, the background merge process optimizes the
index by merging together smaller segments to create new bigger segments, at
which time the smaller segments are deleted. This process continues during
scrolling, but an open search context prevents the old segments from being
deleted while they are still in use.  This is how Elasticsearch is able to
return the results of the initial search request, regardless of subsequent
changes to documents.</simpara>
<tip><simpara>Keeping older segments alive means that more file handles are needed.
Ensure that you have configured your nodes to have ample free file handles.
See <xref linkend="file-descriptors"/>.</simpara></tip>
<simpara>You can check how many search contexts are open with the
<link linkend="cluster-nodes-stats">nodes stats API</link>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_nodes/stats/indices/search</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="_clear_scroll_api">
<title>Clear scroll API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/scroll.asciidoc">Edit me</ulink></title>
<simpara>Search context are automatically removed when the <literal>scroll</literal> timeout has been
exceeded. However keeping scrolls open has a cost, as discussed in the
<link linkend="scroll-search-context">previous section</link> so scrolls should be explicitly
cleared as soon as the scroll is not being used anymore using the
<literal>clear-scroll</literal> API:</simpara>
<programlisting language="js" linenumbering="unnumbered">DELETE /_search/scroll
{
    "scroll_id" : ["DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ=="]
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[catch:missing]</remark>
<simpara>Multiple scroll IDs can be passed as array:</simpara>
<programlisting language="js" linenumbering="unnumbered">DELETE /_search/scroll
{
    "scroll_id" : [
      "DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ==",
      "DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAABFmtSWWRRWUJrU2o2ZExpSGJCVmQxYUEAAAAAAAAAAxZrUllkUVlCa1NqNmRMaUhiQlZkMWFBAAAAAAAAAAIWa1JZZFFZQmtTajZkTGlIYkJWZDFhQQAAAAAAAAAFFmtSWWRRWUJrU2o2ZExpSGJCVmQxYUEAAAAAAAAABBZrUllkUVlCa1NqNmRMaUhiQlZkMWFB"
    ]
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[catch:missing]</remark>
<simpara>All search contexts can be cleared with the <literal>_all</literal> parameter:</simpara>
<programlisting language="js" linenumbering="unnumbered">DELETE /_search/scroll/_all</programlisting>
<remark> CONSOLE</remark>
<simpara>The <literal>scroll_id</literal> can also be passed as a query string parameter or in the request body.
Multiple scroll IDs can be passed as comma separated values:</simpara>
<programlisting language="js" linenumbering="unnumbered">DELETE /_search/scroll/DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ==,DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAABFmtSWWRRWUJrU2o2ZExpSGJCVmQxYUEAAAAAAAAAAxZrUllkUVlCa1NqNmRMaUhiQlZkMWFBAAAAAAAAAAIWa1JZZFFZQmtTajZkTGlIYkJWZDFhQQAAAAAAAAAFFmtSWWRRWUJrU2o2ZExpSGJCVmQxYUEAAAAAAAAABBZrUllkUVlCa1NqNmRMaUhiQlZkMWFB</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[catch:missing]</remark>
</section>
<section id="sliced-scroll">
<title>Sliced Scroll<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/scroll.asciidoc">Edit me</ulink></title>
<simpara>For scroll queries that return a lot of documents it is possible to split the scroll in multiple slices which
can be consumed independently:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /twitter/tweet/_search?scroll=1m
{
    "slice": {
        "id": 0, <co id="CO17-1"/>
        "max": 2 <co id="CO17-2"/>
    },
    "query": {
        "match" : {
            "title" : "elasticsearch"
        }
    }
}
GET /twitter/tweet/_search?scroll=1m
{
    "slice": {
        "id": 1,
        "max": 2
    },
    "query": {
        "match" : {
            "title" : "elasticsearch"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:big_twitter]</remark>
<calloutlist>
<callout arearefs="CO17-1">
<para>
The id of the slice
</para>
</callout>
<callout arearefs="CO17-2">
<para>
The maximum number of slices
</para>
</callout>
</calloutlist>
<simpara>The result from the first request returned documents that belong to the first slice (id: 0) and the result from the
second request returned documents that belong to the second slice. Since the maximum number of slices is set to 2
 the union of the results of the two requests is equivalent to the results of a scroll query without slicing.
By default the splitting is done on the shards first and then locally on each shard using the _uid field
with the following formula:
<literal>slice(doc) = floorMod(hashCode(doc._uid), max)</literal>
For instance if the number of shards is equal to 2 and the user requested 4 slices then the slices 0 and 2 are assigned
to the first shard and the slices 1 and 3 are assigned to the second shard.</simpara>
<simpara>Each scroll is independent and can be processed in parallel like any scroll request.</simpara>
<note><simpara>If the number of slices is bigger than the number of shards the slice filter is very slow on the first calls, it has a complexity of O(N) and a memory cost equals
to N bits per slice where N is the total number of documents in the shard.
After few calls the filter should be cached and subsequent calls should be faster but you should limit the number of
 sliced query you perform in parallel to avoid the memory explosion.</simpara></note>
<simpara>To avoid this cost entirely it is possible to use the <literal>doc_values</literal> of another field to do the slicing
but the user must ensure that the field has the following properties:</simpara>
<itemizedlist>
<listitem>
<simpara>
The field is numeric.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>doc_values</literal> are enabled on that field
</simpara>
</listitem>
<listitem>
<simpara>
Every document should contain a single value. If a document has multiple values for the specified field, the first value is used.
</simpara>
</listitem>
<listitem>
<simpara>
The value for each document should be set once when the document is created and never updated. This ensures that each
slice gets deterministic results.
</simpara>
</listitem>
<listitem>
<simpara>
The cardinality of the field should be high. This ensures that each slice gets approximately the same amount of documents.
</simpara>
</listitem>
</itemizedlist>
<programlisting language="js" linenumbering="unnumbered">GET /twitter/tweet/_search?scroll=1m
{
    "slice": {
        "field": "date",
        "id": 0,
        "max": 10
    },
    "query": {
        "match" : {
            "title" : "elasticsearch"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:big_twitter]</remark>
<simpara>For append only time-based indices, the <literal>timestamp</literal> field can be used safely.</simpara>
<note><simpara>By default the maximum number of slices allowed per scroll is limited to 1024.
You can update the <literal>index.max_slices_per_scroll</literal> index setting to bypass this limit.</simpara></note>
</section>
</section>
<section id="search-request-preference">
<title>Preference<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/preference.asciidoc">Edit me</ulink></title>
<simpara>Controls a <literal>preference</literal> of which shard replicas to execute the search
request on. By default, the operation is randomized between the shard
replicas.</simpara>
<simpara>The <literal>preference</literal> is a query string parameter which can be set to:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>_primary</literal>
</simpara>
</entry>
<entry>
<simpara>
        The operation will go and be executed only on the primary
        shards.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>_primary_first</literal>
</simpara>
</entry>
<entry>
<simpara>
        The operation will go and be executed on the primary
        shard, and if not available (failover), will execute on other shards.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>_replica</literal>
</simpara>
</entry>
<entry>
<simpara>
  The operation will go and be executed only on a replica shard.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>_replica_first</literal>
</simpara>
</entry>
<entry>
<simpara>
  The operation will go and be executed only on a replica shard, and if
  not available (failover), will execute on other shards.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>_local</literal>
</simpara>
</entry>
<entry>
<simpara>
        The operation will prefer to be executed on a local
        allocated shard if possible.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>_prefer_nodes:abc,xyz</literal>
</simpara>
</entry>
<entry>
<simpara>
        Prefers execution on the nodes with the provided
        node ids (<literal>abc</literal> or <literal>xyz</literal> in this case) if applicable.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>_shards:2,3</literal>
</simpara>
</entry>
<entry>
<simpara>
        Restricts the operation to the specified shards. (<literal>2</literal>
        and <literal>3</literal> in this case). This preference can be combined with other
        preferences but it has to appear first: <literal>_shards:2,3|_primary</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>_only_nodes</literal>
</simpara>
</entry>
<entry>
<simpara>
    Restricts the operation to nodes specified in node specification
    <ulink url="https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster.html">https://www.elastic.co/guide/en/elasticsearch/reference/current/cluster.html</ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Custom (string) value
</simpara>
</entry>
<entry>
<simpara>
        A custom value will be used to guarantee that
        the same shards will be used for the same custom value. This can help
        with "jumping values" when hitting different shards in different refresh
        states. A sample value can be something like the web session id, or the
        user name.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>For instance, use the user&#8217;s session ID to ensure consistent ordering of results
for the user:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search?preference=xyzabc123
{
    "query": {
        "match": {
            "title": "elasticsearch"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="search-request-explain">
<title>Explain<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/explain.asciidoc">Edit me</ulink></title>
<simpara>Enables explanation for each hit on how its score was computed.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "explain": true,
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="search-request-version">
<title>Version<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/version.asciidoc">Edit me</ulink></title>
<simpara>Returns a version for each search hit.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "version": true,
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="search-request-index-boost">
<title>Index Boost<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/index-boost.asciidoc">Edit me</ulink></title>
<simpara>Allows to configure different boost level per index when searching
across more than one indices. This is very handy when hits coming from
one index matter more than hits coming from another index (think social
graph where each user has an index).</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "indices_boost" : {
        "index1" : 1.4,
        "index2" : 1.3
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="search-request-min-score">
<title>min_score<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/min-score.asciidoc">Edit me</ulink></title>
<simpara>Exclude documents which have a <literal>_score</literal> less than the minimum specified
in <literal>min_score</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "min_score": 0.5,
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Note, most times, this does not make much sense, but is provided for
advanced use cases.</simpara>
</section>
<section id="search-request-named-queries-and-filters">
<title>Named Queries<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/named-queries-and-filters.asciidoc">Edit me</ulink></title>
<simpara>Each filter and query can accept a <literal>_name</literal> in its top level definition.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "bool" : {
            "should" : [
                {"match" : { "name.first" : {"query" : "shay", "_name" : "first"} }},
                {"match" : { "name.last" : {"query" : "banon", "_name" : "last"} }}
            ],
            "filter" : {
                "terms" : {
                    "name.last" : ["banon", "kimchy"],
                    "_name" : "test"
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The search response will include for each hit the <literal>matched_queries</literal> it matched on. The tagging of queries and filters
only make sense for the <literal>bool</literal> query.</simpara>
</section>
<section id="search-request-inner-hits">
<title>Inner hits<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/inner-hits.asciidoc">Edit me</ulink></title>
<simpara>The <link linkend="mapping-parent-field">parent/child</link> and <link linkend="nested">nested</link> features allow the return of documents that
have matches in a different scope. In the parent/child case, parent documents are returned based on matches in child
documents or child documents are returned based on matches in parent documents. In the nested case, documents are returned
based on matches in nested inner objects.</simpara>
<simpara>In both cases, the actual matches in the different scopes that caused a document to be returned is hidden. In many cases,
it&#8217;s very useful to know which inner nested objects (in the case of nested) or children/parent documents (in the case
of parent/child) caused certain information to be returned. The inner hits feature can be used for this. This feature
returns per search hit in the search response additional nested hits that caused a search hit to match in a different scope.</simpara>
<simpara>Inner hits can be used by defining an <literal>inner_hits</literal> definition on a <literal>nested</literal>, <literal>has_child</literal> or <literal>has_parent</literal> query and filter.
The structure looks like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">"&lt;query&gt;" : {
    "inner_hits" : {
        &lt;inner_hits_options&gt;
    }
}</programlisting>
<simpara>If <literal>inner_hits</literal> is defined on a query that supports it then each search hit will contain an <literal>inner_hits</literal> json object with the following structure:</simpara>
<programlisting language="js" linenumbering="unnumbered">"hits": [
     {
        "_index": ...,
        "_type": ...,
        "_id": ...,
        "inner_hits": {
           "&lt;inner_hits_name&gt;": {
              "hits": {
                 "total": ...,
                 "hits": [
                    {
                       "_type": ...,
                       "_id": ...,
                       ...
                    },
                    ...
                 ]
              }
           }
        },
        ...
     },
     ...
]</programlisting>
<section id="_options">
<title>Options<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/inner-hits.asciidoc">Edit me</ulink></title>
<simpara>Inner hits support the following options:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>from</literal>
</simpara>
</entry>
<entry>
<simpara>
The offset from where the first hit to fetch for each <literal>inner_hits</literal> in the returned regular search hits.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>size</literal>
</simpara>
</entry>
<entry>
<simpara>
The maximum number of hits to return per <literal>inner_hits</literal>. By default the top three matching hits are returned.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>sort</literal>
</simpara>
</entry>
<entry>
<simpara>
How the inner hits should be sorted per <literal>inner_hits</literal>. By default the hits are sorted by the score.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>name</literal>
</simpara>
</entry>
<entry>
<simpara>
The name to be used for the particular inner hit definition in the response. Useful when multiple inner hits
         have been defined in a single search request. The default depends in which query the inner hit is defined.
         For <literal>has_child</literal> query and filter this is the child type, <literal>has_parent</literal> query and filter this is the parent type
         and the nested query and filter this is the nested path.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>Inner hits also supports the following per document features:</simpara>
<itemizedlist>
<listitem>
<simpara>
<link linkend="search-request-highlighting">Highlighting</link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="search-request-explain">Explain</link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="search-request-source-filtering">Source filtering</link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="search-request-script-fields">Script fields</link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="search-request-docvalue-fields">Doc value fields</link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="search-request-version">Include versions</link>
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="nested-inner-hits">
<title>Nested inner hits<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/inner-hits.asciidoc">Edit me</ulink></title>
<simpara>The nested <literal>inner_hits</literal> can be used to include nested inner objects as inner hits to a search hit.</simpara>
<simpara>The example below assumes that there is a nested object field defined with the name <literal>comments</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "query" : {
        "nested" : {
            "path" : "comments",
            "query" : {
                "match" : {"comments.message" : "[actual query]"}
            },
            "inner_hits" : {} <co id="CO18-1"/>
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO18-1">
<para>
The inner hit definition in the nested query. No other options need to be defined.
</para>
</callout>
</calloutlist>
<simpara>An example of a response snippet that could be generated from the above search request:</simpara>
<programlisting language="js" linenumbering="unnumbered">...
"hits": {
  ...
  "hits": [
     {
        "_index": "my-index",
        "_type": "question",
        "_id": "1",
        "_source": ...,
        "inner_hits": {
           "comments": { <co id="CO19-1"/>
              "hits": {
                 "total": ...,
                 "hits": [
                    {
                       "_nested": {
                          "field": "comments",
                          "offset": 2
                       },
                       "_source": ...
                    },
                    ...
                 ]
              }
           }
        }
     },
     ...</programlisting>
<calloutlist>
<callout arearefs="CO19-1">
<para>
The name used in the inner hit definition in the search request. A custom key can be used via the <literal>name</literal> option.
</para>
</callout>
</calloutlist>
<simpara>The <literal>_nested</literal> metadata is crucial in the above example, because it defines from what inner nested object this inner hit
came from. The <literal>field</literal> defines the object array field the nested hit is from and the <literal>offset</literal> relative to its location
in the <literal>_source</literal>. Due to sorting and scoring the actual location of the hit objects in the <literal>inner_hits</literal> is usually
different than the location a nested inner object was defined.</simpara>
<simpara>By default the <literal>_source</literal> is returned also for the hit objects in <literal>inner_hits</literal>, but this can be changed. Either via
<literal>_source</literal> filtering feature part of the source can be returned or be disabled. If stored fields are defined on the
nested level these can also be returned via the <literal>fields</literal> feature.</simpara>
<simpara>An important default is that the <literal>_source</literal> returned in hits inside <literal>inner_hits</literal> is relative to the <literal>_nested</literal> metadata.
So in the above example only the comment part is returned per nested hit and not the entire source of the top level
document that contained the comment.</simpara>
</section>
<section id="hierarchical-nested-inner-hits">
<title>Hierarchical levels of nested object fields and inner hits.<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/inner-hits.asciidoc">Edit me</ulink></title>
<simpara>If a mapping has multiple levels of hierarchical nested object fields each level can be accessed via dot notated path.
For example if there is a <literal>comments</literal> nested field that contains a <literal>votes</literal> nested field and votes should directly be returned
with the root hits then the following path can be defined:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "query" : {
      "nested" : {
         "path" : "comments.votes",
         "query" : { ... },
         "inner_hits" : {}
      }
    }
}</programlisting>
<simpara>This indirect referencing is only supported for nested inner hits.</simpara>
</section>
<section id="parent-child-inner-hits">
<title>Parent/child inner hits<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/inner-hits.asciidoc">Edit me</ulink></title>
<simpara>The parent/child <literal>inner_hits</literal> can be used to include parent or child</simpara>
<simpara>The examples below assumes that there is a <literal>_parent</literal> field mapping in the <literal>comment</literal> type:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "query" : {
        "has_child" : {
            "type" : "comment",
            "query" : {
                "match" : {"message" : "[actual query]"}
            },
            "inner_hits" : {} <co id="CO20-1"/>
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO20-1">
<para>
The inner hit definition like in the nested example.
</para>
</callout>
</calloutlist>
<simpara>An example of a response snippet that could be generated from the above search request:</simpara>
<programlisting language="js" linenumbering="unnumbered">...
"hits": {
  ...
  "hits": [
     {
        "_index": "my-index",
        "_type": "question",
        "_id": "1",
        "_source": ...,
        "inner_hits": {
           "comment": {
              "hits": {
                 "total": ...,
                 "hits": [
                    {
                       "_type": "comment",
                       "_id": "5",
                       "_source": ...
                    },
                    ...
                 ]
              }
           }
        }
     },
     ...</programlisting>
</section>
</section>
<section id="search-request-search-after">
<title>Search After<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/request/search-after.asciidoc">Edit me</ulink></title>
<simpara>Pagination of results can be done by using the <literal>from</literal> and <literal>size</literal> but the cost becomes prohibitive when the deep pagination is reached.
The <literal>index.max_result_window</literal> which defaults to 10,000 is a safeguard, search requests take heap memory and time proportional to <literal>from + size</literal>.
The <link linkend="search-request-scroll">Scroll</link> api is recommended for efficient deep scrolling but scroll contexts are costly and it is not
recommended to use it for real time user requests.
The <literal>search_after</literal> parameter circumvents this problem by providing a live cursor.
The idea is to use the results from the previous page to help the retrieval of the next page.</simpara>
<simpara>Suppose that the query to retrieve the first page looks like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET twitter/tweet/_search
{
    "size": 10,
    "query": {
        "match" : {
            "title" : "elasticsearch"
        }
    },
    "sort": [
        {"date": "asc"},
        {"_uid": "desc"}
    ]
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<note><simpara>A field with one unique value per document should be used as the tiebreaker of the sort specification.
Otherwise the sort order for documents that have the same sort values would be undefined. The recommended way is to use
the field <literal>_uid</literal> which is certain to contain one unique value for each document.</simpara></note>
<simpara>The result from the above request includes an array of <literal>sort values</literal> for each document.
These <literal>sort values</literal> can be used in conjunction with the <literal>search_after</literal> parameter to start returning results "after" any
document in the result list.
For instance we can use the <literal>sort values</literal> of the last document and pass it to <literal>search_after</literal> to retrieve the next page of results:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET twitter/tweet/_search
{
    "size": 10,
    "query": {
        "match" : {
            "title" : "elasticsearch"
        }
    },
    "search_after": [1463538857, "tweet#654323"],
    "sort": [
        {"date": "asc"},
        {"_uid": "desc"}
    ]
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<note><simpara>The parameter <literal>from</literal> must be set to 0 (or -1) when <literal>search_after</literal> is used.</simpara></note>
<simpara><literal>search_after</literal> is not a solution to jump freely to a random page but rather to scroll many queries in parallel.
It is very similar to the <literal>scroll</literal> API but unlike it, the <literal>search_after</literal> parameter is stateless, it is always resolved against the latest
 version of the searcher. For this reason the sort order may change during a walk depending on the updates and deletes of your index.</simpara>
</section>
</chapter>
<chapter id="search-template">
<title>Search Template<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/search-template.asciidoc">Edit me</ulink></title>
<simpara>The <literal>/_search/template</literal> endpoint allows to use the mustache language to pre render search requests,
before they are executed and fill existing templates with template parameters.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search/template
{
    "inline" : {
      "query": { "match" : { "{{my_field}}" : "{{my_value}}" } },
      "size" : "{{my_size}}"
    },
    "params" : {
        "my_field" : "foo",
        "my_value" : "bar",
        "my_size" : 5
    }
}</programlisting>
<simpara>For more information on how Mustache templating and what kind of templating you
can do with it check out the <ulink url="http://mustache.github.io/mustache.5.html">online
documentation of the mustache project</ulink>.</simpara>
<note><simpara>The mustache language is implemented in elasticsearch as a sandboxed
scripting language, hence it obeys settings that may be used to enable or
disable scripts per language, source and operation as described in
<link linkend="enable-dynamic-scripting">scripting docs</link></simpara></note>
<bridgehead id="_more_template_examples" renderas="sect3">More template examples<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/search-template.asciidoc">Edit me</ulink></bridgehead>
<bridgehead id="_filling_in_a_query_string_with_a_single_value" renderas="sect4">Filling in a query string with a single value<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/search-template.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">GET /_search/template
{
    "inline": {
        "query": {
            "match": {
                "title": "{{query_string}}"
            }
        }
    },
    "params": {
        "query_string": "search for these words"
    }
}</programlisting>
<bridgehead id="_converting_parameters_to_json" renderas="sect4">Converting parameters to JSON<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/search-template.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>{{#toJson}}parameter{{/toJson}}</literal> function can be used to convert parameters
like maps and array to their JSON representation:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search/template
{
  "inline": "{ \"query\": { \"terms\": { \"status\": {{#toJson}}status{{/toJson}} }}}",
  "params": {
    "status": [ "pending", "published" ]
  }
}</programlisting>
<simpara>which is rendered as:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "query": {
    "terms": {
      "status": [
        "pending",
        "published"
      ]
    }
  }
}</programlisting>
<simpara>A more complex example substitutes an array of JSON objects:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "inline": "{\"query\":{\"bool\":{\"must\": {{#toJson}}clauses{{/toJson}} }}}",
    "params": {
        "clauses": [
            { "term": "foo" },
            { "term": "bar" }
        ]
   }
}</programlisting>
<simpara>which is rendered as:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "query" : {
      "bool" : {
        "must" : [
          {
            "term" : "foo"
          },
          {
            "term" : "bar"
          }
        ]
      }
    }
}</programlisting>
<bridgehead id="_concatenating_array_of_values" renderas="sect4">Concatenating array of values<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/search-template.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>{{#join}}array{{/join}}</literal> function can be used to concatenate the
values of an array as a comma delimited string:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search/template
{
  "inline": {
    "query": {
      "match": {
        "emails": "{{#join}}emails{{/join}}"
      }
    }
  },
  "params": {
    "emails": [ "username@email.com", "lastname@email.com" ]
  }
}</programlisting>
<simpara>which is rendered as:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "query" : {
        "match" : {
            "emails" : "username@email.com,lastname@email.com"
        }
    }
}</programlisting>
<simpara>The function also accepts a custom delimiter:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search/template
{
  "inline": {
    "query": {
      "range": {
        "born": {
            "gte"   : "{{date.min}}",
            "lte"   : "{{date.max}}",
            "format": "{{#join delimiter='||'}}date.formats{{/join delimiter='||'}}"
            }
      }
    }
  },
  "params": {
    "date": {
        "min": "2016",
        "max": "31/12/2017",
        "formats": ["dd/MM/yyyy", "yyyy"]
    }
  }
}</programlisting>
<simpara>which is rendered as:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "query" : {
      "range" : {
        "born" : {
          "gte" : "2016",
          "lte" : "31/12/2017",
          "format" : "dd/MM/yyyy||yyyy"
        }
      }
    }
}</programlisting>
<bridgehead id="_default_values" renderas="sect4">Default values<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/search-template.asciidoc">Edit me</ulink></bridgehead>
<simpara>A default value is written as <literal>{{var}}{{^var}}default{{/var}}</literal> for instance:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "inline": {
    "query": {
      "range": {
        "line_no": {
          "gte": "{{start}}",
          "lte": "{{end}}{{^end}}20{{/end}}"
        }
      }
    }
  },
  "params": { ... }
}</programlisting>
<simpara>When <literal>params</literal> is <literal>{ "start": 10, "end": 15 }</literal> this query would be rendered as:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "range": {
        "line_no": {
            "gte": "10",
            "lte": "15"
        }
  }
}</programlisting>
<simpara>But when <literal>params</literal> is <literal>{ "start": 10 }</literal> this query would use the default value
for <literal>end</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "range": {
        "line_no": {
            "gte": "10",
            "lte": "20"
        }
    }
}</programlisting>
<bridgehead id="_conditional_clauses" renderas="sect4">Conditional clauses<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/search-template.asciidoc">Edit me</ulink></bridgehead>
<simpara>Conditional clauses cannot be expressed using the JSON form of the template.
Instead, the template <emphasis role="strong">must</emphasis> be passed as a string.  For instance, let&#8217;s say
we wanted to run a <literal>match</literal> query on the <literal>line</literal> field, and optionally wanted
to filter by line numbers, where <literal>start</literal> and <literal>end</literal> are optional.</simpara>
<simpara>The <literal>params</literal> would look like:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "params": {
        "text":      "words to search for",
        "line_no": { <co id="CO21-1"/>
            "start": 10, <co id="CO21-2"/>
            "end":   20  <co id="CO21-3"/>
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO21-1 CO21-2 CO21-3">
<para>
All three of these elements are optional.
</para>
</callout>
</calloutlist>
<simpara>We could write the query as:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "query": {
    "bool": {
      "must": {
        "match": {
          "line": "{{text}}" <co id="CO22-1"/>
        }
      },
      "filter": {
        {{#line_no}} <co id="CO22-2"/>
          "range": {
            "line_no": {
              {{#start}} <co id="CO22-3"/>
                "gte": "{{start}}" <co id="CO22-4"/>
                {{#end}},{{/end}} <co id="CO22-5"/>
              {{/start}} <co id="CO22-6"/>
              {{#end}} <co id="CO22-7"/>
                "lte": "{{end}}" <co id="CO22-8"/>
              {{/end}} <co id="CO22-9"/>
            }
          }
        {{/line_no}} <co id="CO22-10"/>
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO22-1">
<para>
Fill in the value of param <literal>text</literal>
</para>
</callout>
<callout arearefs="CO22-2 CO22-10">
<para>
Include the <literal>range</literal> filter only if <literal>line_no</literal> is specified
</para>
</callout>
<callout arearefs="CO22-3 CO22-6">
<para>
Include the <literal>gte</literal> clause only if <literal>line_no.start</literal> is specified
</para>
</callout>
<callout arearefs="CO22-4">
<para>
Fill in the value of param <literal>line_no.start</literal>
</para>
</callout>
<callout arearefs="CO22-5">
<para>
Add a comma after the <literal>gte</literal> clause only if <literal>line_no.start</literal>
    AND <literal>line_no.end</literal> are specified
</para>
</callout>
<callout arearefs="CO22-7 CO22-9">
<para>
Include the <literal>lte</literal> clause only if <literal>line_no.end</literal> is specified
</para>
</callout>
<callout arearefs="CO22-8">
<para>
Fill in the value of param <literal>line_no.end</literal>
</para>
</callout>
</calloutlist>
<note>
<simpara>As written above, this template is not valid JSON because it includes the
<emphasis>section</emphasis> markers like <literal>{{#line_no}}</literal>.  For this reason, the template should
either be stored in a file (see <xref linkend="pre-registered-templates"/>) or, when used
via the REST API, should be written as a string:</simpara>
<programlisting language="js" linenumbering="unnumbered">"inline": "{\"query\":{\"bool\":{\"must\":{\"match\":{\"line\":\"{{text}}\"}},\"filter\":{{{#line_no}}\"range\":{\"line_no\":{{{#start}}\"gte\":\"{{start}}\"{{#end}},{{/end}}{{/start}}{{#end}}\"lte\":\"{{end}}\"{{/end}}}}{{/line_no}}}}}}"</programlisting>
</note>
<bridgehead id="pre-registered-templates" renderas="sect4">Pre-registered template<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/search-template.asciidoc">Edit me</ulink></bridgehead>
<simpara>You can register search templates by storing it in the <literal>config/scripts</literal> directory, in a file using the <literal>.mustache</literal> extension.
In order to execute the stored template, reference it by it&#8217;s name under the <literal>template</literal> key:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search/template
{
    "file": "storedTemplate", <co id="CO23-1"/>
    "params": {
        "query_string": "search for these words"
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO23-1">
<para>
Name of the query template in <literal>config/scripts/</literal>, i.e., <literal>storedTemplate.mustache</literal>.
</para>
</callout>
</calloutlist>
<simpara>You can also register search templates by storing it in the cluster state.
There are REST APIs to manage these indexed templates.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /_search/template/&lt;templatename&gt;
{
    "template": {
        "query": {
            "match": {
                "title": "{{query_string}}"
            }
        }
    }
}</programlisting>
<simpara>This template can be retrieved by</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search/template/&lt;templatename&gt;</programlisting>
<simpara>which is rendered as:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "template": {
        "query": {
            "match": {
                "title": "{{query_string}}"
            }
        }
    }
}</programlisting>
<simpara>This template can be deleted by</simpara>
<programlisting language="js" linenumbering="unnumbered">DELETE /_search/template/&lt;templatename&gt;</programlisting>
<simpara>To use an indexed template at search time use:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search/template
{
    "id": "templateName", <co id="CO24-1"/>
    "params": {
        "query_string": "search for these words"
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO24-1">
<para>
Name of the query template stored in the <literal>.scripts</literal> index.
</para>
</callout>
</calloutlist>
<bridgehead id="_validating_templates" renderas="sect3">Validating templates<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/search-template.asciidoc">Edit me</ulink></bridgehead>
<simpara>A template can be rendered in a response with given parameters using</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_render/template
{
  "inline": {
    "query": {
      "terms": {
        "status": [
          "{{#status}}",
          "{{.}}",
          "{{/status}}"
        ]
      }
    }
  },
  "params": {
    "status": [ "pending", "published" ]
  }
}</programlisting>
<simpara>This call will return the rendered template:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "template_output": {
    "query": {
      "terms": {
        "status": [ <co id="CO25-1"/>
          "pending",
          "published"
        ]
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO25-1">
<para>
<literal>status</literal> array has been populated with values from the <literal>params</literal> object.
</para>
</callout>
</calloutlist>
<simpara>File and indexed templates can also be rendered by replacing <literal>inline</literal> with
<literal>file</literal> or <literal>id</literal> respectively. For example, to render a file template</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_render/template
{
  "file": "my_template",
  "params": {
    "status": [ "pending", "published" ]
  }
}</programlisting>
<simpara>Pre-registered templates can also be rendered using</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_render/template/&lt;template_name&gt;
{
  "params": {
    "..."
  }
}</programlisting>
<bridgehead id="_explain" renderas="sect4">Explain<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/search-template.asciidoc">Edit me</ulink></bridgehead>
<simpara>You can use <literal>explain</literal> parameter when running a template:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search/template
{
  "file": "my_template",
  "params": {
    "status": [ "pending", "published" ]
  },
  "explain": true
}</programlisting>
<bridgehead id="_profiling" renderas="sect4">Profiling<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/search-template.asciidoc">Edit me</ulink></bridgehead>
<simpara>You can use <literal>profile</literal> parameter when running a template:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search/template
{
  "file": "my_template",
  "params": {
    "status": [ "pending", "published" ]
  },
  "profile": true
}</programlisting>
</chapter>
<chapter id="multi-search-template">
<title>Multi Search Template<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/search-template.asciidoc">Edit me</ulink></title>
<simpara>The multi search template API allows to execute several search template
requests within the same API using the <literal>_msearch/template</literal> endpoint.</simpara>
<simpara>The format of the request is similar to the <link linkend="search-multi-search">Multi Search API</link> format:</simpara>
<programlisting language="js" linenumbering="unnumbered">header\n
body\n
header\n
body\n</programlisting>
<simpara>The header part supports the same <literal>index</literal>, <literal>types</literal>, <literal>search_type</literal>,
<literal>preference</literal>, and <literal>routing</literal> options as the usual Multi Search API.</simpara>
<simpara>The body includes a search template body request and supports inline,
stored and file templates. Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">$ cat requests
{"index": "test"}
{"inline": {"query": {"match":  {"user" : "{{username}}" }}}, "params": {"username": "john"}} <co id="CO26-1"/>
{"index": "_all", "types": "accounts"}
{"inline": {"query": {"{{query_type}}": {"name": "{{name}}" }}}, "params": {"query_type": "match_phrase_prefix", "name": "Smith"}}
{"index": "_all"}
{"id": "template_1", "params": {"query_string": "search for these words" }} <co id="CO26-2"/>
{"types": "users"}
{"file": "template_2", "params": {"field_name": "fullname", "field_value": "john smith" }} <co id="CO26-3"/>

$ curl -XGET localhost:9200/_msearch/template --data-binary "@requests"; echo</programlisting>
<calloutlist>
<callout arearefs="CO26-1">
<para>
Inline search template request
</para>
</callout>
<callout arearefs="CO26-2">
<para>
Search template request based on a stored template
</para>
</callout>
<callout arearefs="CO26-3">
<para>
Search template request based on a file template
</para>
</callout>
</calloutlist>
<simpara>The response returns a <literal>responses</literal> array, which includes the search template
response for each search template request matching its order in the original
multi search template request. If there was a complete failure for that specific
search template request, an object with <literal>error</literal> message will be returned in place
of the actual search response.</simpara>
</chapter>
<chapter id="search-shards">
<title>Search Shards API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/search-shards.asciidoc">Edit me</ulink></title>
<simpara>The search shards api returns the indices and shards that a search request would
be executed against. This can give useful feedback for working out issues or
planning optimizations with routing and shard preferences. When filtered aliases
are used, the filter is returned as part of the <literal>indices</literal> section <phrase revisionflag="added" revision="5.1.0">Added in 5.1.0.</phrase>.</simpara>
<simpara>The <literal>index</literal> and <literal>type</literal> parameters may be single values, or comma-separated.</simpara>
<simpara>The <literal>type</literal> parameter is deprecated <phrase revisionflag="deleted" revision="5.1.0">Deprecated in 5.1.0. was ignored in previous versions.</phrase>.</simpara>
<bridgehead id="_usage" renderas="sect2">Usage<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/search-shards.asciidoc">Edit me</ulink></bridgehead>
<simpara>Full example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /twitter/_search_shards</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT twitter\n/]</remark>
<simpara>This will yield the following result:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "nodes": ...,
  "indices" : {
    "twitter": { }
  },
  "shards": [
    [
      {
        "index": "twitter",
        "node": "JklnKbD7Tyqi9TP3_Q_tBg",
        "primary": true,
        "shard": 0,
        "state": "STARTED",
        "allocation_id": {"id":"0TvkCyF7TAmM1wHP4a42-A"},
        "relocating_node": null
      }
    ],
    [
      {
        "index": "twitter",
        "node": "JklnKbD7Tyqi9TP3_Q_tBg",
        "primary": true,
        "shard": 1,
        "state": "STARTED",
        "allocation_id": {"id":"fMju3hd1QHWmWrIgFnI4Ww"},
        "relocating_node": null
      }
    ],
    [
      {
        "index": "twitter",
        "node": "JklnKbD7Tyqi9TP3_Q_tBg",
        "primary": true,
        "shard": 2,
        "state": "STARTED",
        "allocation_id": {"id":"Nwl0wbMBTHCWjEEbGYGapg"},
        "relocating_node": null
      }
    ],
    [
      {
        "index": "twitter",
        "node": "JklnKbD7Tyqi9TP3_Q_tBg",
        "primary": true,
        "shard": 3,
        "state": "STARTED",
        "allocation_id": {"id":"bU_KLGJISbW0RejwnwDPKw"},
        "relocating_node": null
      }
    ],
    [
      {
        "index": "twitter",
        "node": "JklnKbD7Tyqi9TP3_Q_tBg",
        "primary": true,
        "shard": 4,
        "state": "STARTED",
        "allocation_id": {"id":"DMs7_giNSwmdqVukF7UydA"},
        "relocating_node": null
      }
    ]
  ]
}</programlisting>
<remark> TESTRESPONSE[s/"nodes": ...,/"nodes": $body.nodes,/]</remark>
<remark> TESTRESPONSE[s/JklnKbD7Tyqi9TP3_Q_tBg/$body.shards.0.0.node/]</remark>
<remark> TESTRESPONSE[s/0TvkCyF7TAmM1wHP4a42-A/$body.shards.0.0.allocation_id.id/]</remark>
<remark> TESTRESPONSE[s/fMju3hd1QHWmWrIgFnI4Ww/$body.shards.1.0.allocation_id.id/]</remark>
<remark> TESTRESPONSE[s/Nwl0wbMBTHCWjEEbGYGapg/$body.shards.2.0.allocation_id.id/]</remark>
<remark> TESTRESPONSE[s/bU_KLGJISbW0RejwnwDPKw/$body.shards.3.0.allocation_id.id/]</remark>
<remark> TESTRESPONSE[s/DMs7_giNSwmdqVukF7UydA/$body.shards.4.0.allocation_id.id/]</remark>
<simpara>And specifying the same request, this time with a routing value:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /twitter/_search_shards?routing=foo,baz</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT twitter\n/]</remark>
<simpara>This will yield the following result:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "nodes": ...,
  "indices" : {
      "twitter": { }
  },
  "shards": [
    [
      {
        "index": "twitter",
        "node": "JklnKbD7Tyqi9TP3_Q_tBg",
        "primary": true,
        "shard": 0,
        "state": "STARTED",
        "allocation_id": {"id":"0TvkCyF7TAmM1wHP4a42-A"},
        "relocating_node": null
      }
    ],
    [
      {
        "index": "twitter",
        "node": "JklnKbD7Tyqi9TP3_Q_tBg",
        "primary": true,
        "shard": 1,
        "state": "STARTED",
        "allocation_id": {"id":"fMju3hd1QHWmWrIgFnI4Ww"},
        "relocating_node": null
      }
    ]
  ]
}</programlisting>
<remark> TESTRESPONSE[s/"nodes": ...,/"nodes": $body.nodes,/]</remark>
<remark> TESTRESPONSE[s/JklnKbD7Tyqi9TP3_Q_tBg/$body.shards.0.0.node/]</remark>
<remark> TESTRESPONSE[s/0TvkCyF7TAmM1wHP4a42-A/$body.shards.0.0.allocation_id.id/]</remark>
<remark> TESTRESPONSE[s/fMju3hd1QHWmWrIgFnI4Ww/$body.shards.1.0.allocation_id.id/]</remark>
<simpara>This time the search will only be executed against two of the shards, because
routing values have been specified.</simpara>
<bridgehead id="_all_parameters" renderas="sect2">All parameters:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/search-shards.asciidoc">Edit me</ulink></bridgehead>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>routing</literal>
</simpara>
</entry>
<entry>
<simpara>
    A comma-separated list of routing values to take into account when
    determining which shards a request would be executed against.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>preference</literal>
</simpara>
</entry>
<entry>
<simpara>
    Controls a <literal>preference</literal> of which shard replicas to execute the search
    request on. By default, the operation is randomized between the shard
    replicas. See the <ulink url="search-request-preference.html">preference</ulink>
    documentation for a list of all acceptable values.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>local</literal>
</simpara>
</entry>
<entry>
<simpara>
    A boolean value whether to read the cluster state locally in order to
    determine where shards are allocated instead of using the Master node&#8217;s
    cluster state.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</chapter>
<chapter id="search-suggesters">
<title>Suggesters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/suggesters.asciidoc">Edit me</ulink></title>
<simpara>The suggest feature suggests similar looking terms based on a provided
text by using a suggester. Parts of the suggest feature are still under
development.</simpara>
<simpara>The suggest request part is either defined alongside the query part in a
<literal>_search</literal> request or via the REST <literal>_suggest</literal> endpoint.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST twitter/_search
{
  "query" : {
    "match": {
      "message": "tring out Elasticsearch"
    }
  },
  "suggest" : {
    "my-suggestion" : {
      "text" : "trying out Elasticsearch",
      "term" : {
        "field" : "message"
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>Suggest requests executed against the <literal>_suggest</literal> endpoint should omit
the surrounding <literal>suggest</literal> element which is only used if the suggest
request is part of a search.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _suggest
{
  "my-suggestion" : {
    "text" : "tring out Elasticsearch",
    "term" : {
      "field" : "message"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>Several suggestions can be specified per request. Each suggestion is
identified with an arbitrary name. In the example below two suggestions
are requested. Both <literal>my-suggest-1</literal> and <literal>my-suggest-2</literal> suggestions use
the <literal>term</literal> suggester, but have a different <literal>text</literal>.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _suggest
{
  "my-suggest-1" : {
    "text" : "tring out Elasticsearch",
    "term" : {
      "field" : "message"
    }
  },
  "my-suggest-2" : {
    "text" : "kmichy",
    "term" : {
      "field" : "user"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>The below suggest response example includes the suggestion response for
<literal>my-suggest-1</literal> and <literal>my-suggest-2</literal>. Each suggestion part contains
entries. Each entry is effectively a token from the suggest text and
contains the suggestion entry text, the original start offset and length
in the suggest text and if found an arbitrary number of options.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "_shards": ...
  "my-suggest-1": [ {
    "text": "tring",
    "offset": 0,
    "length": 5,
    "options": [ {"text": "trying", "score": 0.8, "freq": 1 } ]
  }, {
    "text": "out",
    "offset": 6,
    "length": 3,
    "options": []
  }, {
    "text": "elasticsearch",
    "offset": 10,
    "length": 13,
    "options": []
  } ],
  "my-suggest-2": ...
}</programlisting>
<remark> TESTRESPONSE[s/"_shards": \.\.\./"_shards": "$body._shards",/]</remark>
<remark> TESTRESPONSE[s/"my-suggest-2": \.\.\./"my-suggest-2": "$body.my-suggest-2"/]</remark>
<simpara>Each options array contains an option object that includes the
suggested text, its document frequency and score compared to the suggest
entry text. The meaning of the score depends on the used suggester. The
term suggester&#8217;s score is based on the edit distance.</simpara>
<bridgehead id="global-suggest" renderas="sect2">Global suggest text<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/suggesters.asciidoc">Edit me</ulink></bridgehead>
<simpara>To avoid repetition of the suggest text, it is possible to define a
global text. In the example below the suggest text is defined globally
and applies to the <literal>my-suggest-1</literal> and <literal>my-suggest-2</literal> suggestions.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _suggest
{
  "text" : "tring out Elasticsearch",
  "my-suggest-1" : {
    "term" : {
      "field" : "message"
    }
  },
  "my-suggest-2" : {
    "term" : {
      "field" : "user"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The suggest text can in the above example also be specified as
suggestion specific option. The suggest text specified on suggestion
level override the suggest text on the global level.</simpara>
<section id="search-suggesters-term">
<title>Term suggester<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/suggesters/term-suggest.asciidoc">Edit me</ulink></title>
<note><simpara>In order to understand the format of suggestions, please
read the <xref linkend="search-suggesters"/> page first.</simpara></note>
<simpara>The <literal>term</literal> suggester suggests terms based on edit distance. The provided
suggest text is analyzed before terms are suggested. The suggested terms
are provided per analyzed suggest text token. The <literal>term</literal> suggester
doesn&#8217;t take the query into account that is part of request.</simpara>
<section id="_common_suggest_options">
<title>Common suggest options:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/suggesters/term-suggest.asciidoc">Edit me</ulink></title>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>text</literal>
</simpara>
</entry>
<entry>
<simpara>
    The suggest text. The suggest text is a required option that
    needs to be set globally or per suggestion.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>field</literal>
</simpara>
</entry>
<entry>
<simpara>
    The field to fetch the candidate suggestions from. This is
    an required option that either needs to be set globally or per
    suggestion.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>analyzer</literal>
</simpara>
</entry>
<entry>
<simpara>
    The analyzer to analyse the suggest text with. Defaults
    to the search analyzer of the suggest field.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>size</literal>
</simpara>
</entry>
<entry>
<simpara>
    The maximum corrections to be returned per suggest text
    token.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>sort</literal>
</simpara>
</entry>
<entry>
<simpara>
    Defines how suggestions should be sorted per suggest text
    term. Two possible values:
</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>score</literal>:     Sort by score first, then document frequency and
                    then the term itself.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>frequency</literal>: Sort by document frequency first, then similarity
                    score and then the term itself.
</simpara>
</listitem>
</itemizedlist>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>suggest_mode</literal>
</simpara>
</entry>
<entry>
<simpara>
    The suggest mode controls what suggestions are
    included or controls for what suggest text terms, suggestions should be
    suggested. Three possible values can be specified:
</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>missing</literal>:  Only provide suggestions for suggest text terms that are
                    not in the index. This is the default.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>popular</literal>:  Only suggest suggestions that occur in more docs than
                    the original suggest text term.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>always</literal>:   Suggest any matching suggestions based on terms in the
                    suggest text.
</simpara>
</listitem>
</itemizedlist>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
<section id="_other_term_suggest_options">
<title>Other term suggest options:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/suggesters/term-suggest.asciidoc">Edit me</ulink></title>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>lowercase_terms</literal>
</simpara>
</entry>
<entry>
<simpara>
    Lower cases the suggest text terms after text analysis.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max_edits</literal>
</simpara>
</entry>
<entry>
<simpara>
    The maximum edit distance candidate suggestions can
    have in order to be considered as a suggestion. Can only be a value
    between 1 and 2. Any other value result in an bad request error being
    thrown. Defaults to 2.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>prefix_length</literal>
</simpara>
</entry>
<entry>
<simpara>
    The number of minimal prefix characters that must
    match in order be a candidate suggestions. Defaults to 1. Increasing
    this number improves spellcheck performance. Usually misspellings don&#8217;t
    occur in the beginning of terms. (Old name "prefix_len" is deprecated)
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>min_word_length</literal>
</simpara>
</entry>
<entry>
<simpara>
    The minimum length a suggest text term must have in
    order to be included. Defaults to 4. (Old name "min_word_len" is deprecated)
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>shard_size</literal>
</simpara>
</entry>
<entry>
<simpara>
    Sets the maximum number of suggestions to be retrieved
    from each individual shard. During the reduce phase only the top N
    suggestions are returned based on the <literal>size</literal> option. Defaults to the
    <literal>size</literal> option. Setting this to a value higher than the <literal>size</literal> can be
    useful in order to get a more accurate document frequency for spelling
    corrections at the cost of performance. Due to the fact that terms are
    partitioned amongst shards, the shard level document frequencies of
    spelling corrections may not be precise. Increasing this will make these
    document frequencies more precise.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max_inspections</literal>
</simpara>
</entry>
<entry>
<simpara>
    A factor that is used to multiply with the
    <literal>shards_size</literal> in order to inspect more candidate spell corrections on
    the shard level. Can improve accuracy at the cost of performance.
    Defaults to 5.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>min_doc_freq</literal>
</simpara>
</entry>
<entry>
<simpara>
    The minimal threshold in number of documents a
    suggestion should appear in. This can be specified as an absolute number
    or as a relative percentage of number of documents. This can improve
    quality by only suggesting high frequency terms. Defaults to 0f and is
    not enabled. If a value higher than 1 is specified then the number
    cannot be fractional. The shard level document frequencies are used for
    this option.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max_term_freq</literal>
</simpara>
</entry>
<entry>
<simpara>
    The maximum threshold in number of documents a
    suggest text token can exist in order to be included. Can be a relative
    percentage number (e.g 0.4) or an absolute number to represent document
    frequencies. If an value higher than 1 is specified then fractional can
    not be specified. Defaults to 0.01f. This can be used to exclude high
    frequency terms from being spellchecked. High frequency terms are
    usually spelled correctly on top of this also improves the spellcheck
    performance. The shard level document frequencies are used for this
    option.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>string_distance</literal>
</simpara>
</entry>
<entry>
<simpara>
    Which string distance implementation to use for comparing how similar
    suggested terms are. Five possible values can be specified:
    <literal>internal</literal> - The default based on damerau_levenshtein but highly optimized
    for comparing string distance for terms inside the index.
    <literal>damerau_levenshtein</literal> - String distance algorithm based on
    Damerau-Levenshtein algorithm.
    <literal>levenstein</literal> - String distance algorithm based on Levenstein edit distance
    algorithm.
    <literal>jarowinkler</literal> - String distance algorithm based on Jaro-Winkler algorithm.
    <literal>ngram</literal> - String distance algorithm based on character n-grams.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
</section>
<section id="search-suggesters-phrase">
<title>Phrase Suggester<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/suggesters/phrase-suggest.asciidoc">Edit me</ulink></title>
<note><simpara>In order to understand the format of suggestions, please
read the <xref linkend="search-suggesters"/> page first.</simpara></note>
<simpara>The <literal>term</literal> suggester provides a very convenient API to access word
alternatives on a per token basis within a certain string distance. The API
allows accessing each token in the stream individually while
suggest-selection is left to the API consumer. Yet, often pre-selected
suggestions are required in order to present to the end-user. The
<literal>phrase</literal> suggester adds additional logic on top of the <literal>term</literal> suggester
to select entire corrected phrases instead of individual tokens weighted
based on <literal>ngram-language</literal> models. In practice this suggester will be
able to make better decisions about which tokens to pick based on
co-occurrence and frequencies.</simpara>
<section id="_api_example">
<title>API Example<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/suggesters/phrase-suggest.asciidoc">Edit me</ulink></title>
<simpara>In general the <literal>phrase</literal> suggester requires special mapping up front to work.
The <literal>phrase</literal> suggester examples on this page need the following mapping to
work. The <literal>reverse</literal> analyzer is used only in the last example.</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT test
{
  "settings": {
    "index": {
      "number_of_shards": 1,
      "analysis": {
        "analyzer": {
          "trigram": {
            "type": "custom",
            "tokenizer": "standard",
            "filter": ["standard", "shingle"]
          },
          "reverse": {
            "type": "custom",
            "tokenizer": "standard",
            "filter": ["standard", "reverse"]
          }
        },
        "filter": {
          "shingle": {
            "type": "shingle",
            "min_shingle_size": 2,
            "max_shingle_size": 3
          }
        }
      }
    }
  },
  "mappings": {
    "test": {
      "properties": {
        "title": {
          "type": "text",
          "fields": {
            "trigram": {
              "type": "text",
              "analyzer": "trigram"
            },
            "reverse": {
              "type": "text",
              "analyzer": "reverse"
            }
          }
        }
      }
    }
  }
}
POST test/test?refresh=true
{"title": "noble warriors"}
POST test/test?refresh=true
{"title": "nobel prize"}</programlisting>
<remark> CONSOLE</remark>
<remark> TESTSETUP</remark>
<simpara>Once you have the analyzers and mappings set up you can use the <literal>phrase</literal>
suggester in the same spot you&#8217;d use the <literal>term</literal> suggester:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _suggest
{
  "text": "noble prize",
  "simple_phrase": {
    "phrase": {
      "field": "title.trigram",
      "size": 1,
      "gram_size": 3,
      "direct_generator": [ {
        "field": "title.trigram",
        "suggest_mode": "always"
      } ],
      "highlight": {
        "pre_tag": "&lt;em&gt;",
        "post_tag": "&lt;/em&gt;"
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The response contains suggestions scored by the most likely spell correction first. In this case we received the expected correction "nobel prize".</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "_shards": ...
  "simple_phrase" : [
    {
      "text" : "noble prize",
      "offset" : 0,
      "length" : 11,
      "options" : [ {
        "text" : "nobel prize",
        "highlighted": "&lt;em&gt;nobel&lt;/em&gt; prize",
        "score" : 0.5962314
      }]
    }
  ]
}</programlisting>
<remark> TESTRESPONSE[s/"_shards": .../"_shards": "$body._shards",/]</remark>
</section>
<section id="_basic_phrase_suggest_api_parameters">
<title>Basic Phrase suggest API parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/suggesters/phrase-suggest.asciidoc">Edit me</ulink></title>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>field</literal>
</simpara>
</entry>
<entry>
<simpara>
    the name of the field used to do n-gram lookups for the
    language model, the suggester will use this field to gain statistics to
    score corrections. This field is mandatory.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>gram_size</literal>
</simpara>
</entry>
<entry>
<simpara>
    sets max size of the n-grams (shingles) in the <literal>field</literal>.
    If the field doesn&#8217;t contain n-grams (shingles) this should be omitted
    or set to <literal>1</literal>. Note that Elasticsearch tries to detect the gram size
    based on the specified <literal>field</literal>. If the field uses a <literal>shingle</literal> filter the
    <literal>gram_size</literal> is set to the <literal>max_shingle_size</literal> if not explicitly set.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>real_word_error_likelihood</literal>
</simpara>
</entry>
<entry>
<simpara>
    the likelihood of a term being a
    misspelled even if the term exists in the dictionary. The default is
    <literal>0.95</literal> corresponding to 5% of the real words are misspelled.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>confidence</literal>
</simpara>
</entry>
<entry>
<simpara>
    The confidence level defines a factor applied to the
    input phrases score which is used as a threshold for other suggest
    candidates. Only candidates that score higher than the threshold will be
    included in the result. For instance a confidence level of <literal>1.0</literal> will
    only return suggestions that score higher than the input phrase. If set
    to <literal>0.0</literal> the top N candidates are returned. The default is <literal>1.0</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max_errors</literal>
</simpara>
</entry>
<entry>
<simpara>
    the maximum percentage of the terms that at most
    considered to be misspellings in order to form a correction. This method
    accepts a float value in the range <literal>[0..1)</literal> as a fraction of the actual
    query terms or a number <literal>&gt;=1</literal> as an absolute number of query terms. The
    default is set to <literal>1.0</literal> which corresponds to that only corrections with
    at most 1 misspelled term are returned.  Note that setting this too high
    can negatively impact performance. Low values like <literal>1</literal> or <literal>2</literal> are recommended
    otherwise the time spend in suggest calls might exceed the time spend in
    query execution.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>separator</literal>
</simpara>
</entry>
<entry>
<simpara>
    the separator that is used to separate terms in the
    bigram field. If not set the whitespace character is used as a
    separator.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>size</literal>
</simpara>
</entry>
<entry>
<simpara>
    the number of candidates that are generated for each
    individual query term Low numbers like <literal>3</literal> or <literal>5</literal> typically produce good
    results. Raising this can bring up terms with higher edit distances. The
    default is <literal>5</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>analyzer</literal>
</simpara>
</entry>
<entry>
<simpara>
    Sets the analyzer to analyse to suggest text with.
    Defaults to the search analyzer of the suggest field passed via <literal>field</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>shard_size</literal>
</simpara>
</entry>
<entry>
<simpara>
    Sets the maximum number of suggested term to be
    retrieved from each individual shard. During the reduce phase, only the
    top N suggestions are returned based on the <literal>size</literal> option. Defaults to
    <literal>5</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>text</literal>
</simpara>
</entry>
<entry>
<simpara>
    Sets the text / query to provide suggestions for.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>highlight</literal>
</simpara>
</entry>
<entry>
<simpara>
    Sets up suggestion highlighting.  If not provided then
    no <literal>highlighted</literal> field is returned.  If provided must
    contain exactly <literal>pre_tag</literal> and <literal>post_tag</literal> which are
    wrapped around the changed tokens.  If multiple tokens
    in a row are changed the entire phrase of changed tokens
    is wrapped rather than each token.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>collate</literal>
</simpara>
</entry>
<entry>
<simpara>
    Checks each suggestion against the specified <literal>query</literal> to prune suggestions
    for which no matching docs exist in the index. The collate query for a
    suggestion is run only on the local shard from which the suggestion has
    been generated from. The <literal>query</literal> must be specified, and it is run as
    a <link linkend="query-dsl-template-query"><literal>template</literal> query</link>.
    The current suggestion is automatically made available as the <literal>{{suggestion}}</literal>
    variable, which should be used in your query.  You can still specify
    your own template <literal>params</literal>&#8201;&#8212;&#8201;the <literal>suggestion</literal> value will be added to the
    variables you specify. Additionally, you can specify a <literal>prune</literal> to control
    if all phrase suggestions will be returned, when set to <literal>true</literal> the suggestions
    will have an additional option <literal>collate_match</literal>, which will be <literal>true</literal> if
    matching documents for the phrase was found, <literal>false</literal> otherwise.
    The default value for <literal>prune</literal> is <literal>false</literal>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<programlisting language="js" linenumbering="unnumbered">POST _suggest
{
  "text" : "noble prize",
  "simple_phrase" : {
    "phrase" : {
      "field" :  "title.trigram",
      "size" :   1,
      "direct_generator" : [ {
        "field" :            "title.trigram",
        "suggest_mode" :     "always",
        "min_word_length" :  1
      } ],
      "collate": {
        "query": { <co id="CO27-1"/>
          "inline" : {
            "match": {
              "{{field_name}}" : "{{suggestion}}" <co id="CO27-2"/>
            }
          }
        },
        "params": {"field_name" : "title"}, <co id="CO27-3"/>
        "prune": true <co id="CO27-4"/>
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO27-1">
<para>
This query will be run once for every suggestion.
</para>
</callout>
<callout arearefs="CO27-2">
<para>
The <literal>{{suggestion}}</literal> variable will be replaced by the text
    of each suggestion.
</para>
</callout>
<callout arearefs="CO27-3">
<para>
An additional <literal>field_name</literal> variable has been specified in
    <literal>params</literal> and is used by the <literal>match</literal> query.
</para>
</callout>
<callout arearefs="CO27-4">
<para>
All suggestions will be returned with an extra <literal>collate_match</literal>
    option indicating whether the generated phrase matched any
    document.
</para>
</callout>
</calloutlist>
</section>
<section id="_smoothing_models">
<title>Smoothing Models<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/suggesters/phrase-suggest.asciidoc">Edit me</ulink></title>
<simpara>The <literal>phrase</literal> suggester supports multiple smoothing models to balance
weight between infrequent grams (grams (shingles) are not existing in
the index) and frequent grams (appear at least once in the index).</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>stupid_backoff</literal>
</simpara>
</entry>
<entry>
<simpara>
    a simple backoff model that backs off to lower
    order n-gram models if the higher order count is <literal>0</literal> and discounts the
    lower order n-gram model by a constant factor. The default <literal>discount</literal> is
    <literal>0.4</literal>. Stupid Backoff is the default model.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>laplace</literal>
</simpara>
</entry>
<entry>
<simpara>
    a smoothing model that uses an additive smoothing where a
    constant (typically <literal>1.0</literal> or smaller) is added to all counts to balance
    weights, The default <literal>alpha</literal> is <literal>0.5</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>linear_interpolation</literal>
</simpara>
</entry>
<entry>
<simpara>
    a smoothing model that takes the weighted
    mean of the unigrams, bigrams and trigrams based on user supplied
    weights (lambdas). Linear Interpolation doesn&#8217;t have any default values.
    All parameters (<literal>trigram_lambda</literal>, <literal>bigram_lambda</literal>, <literal>unigram_lambda</literal>)
    must be supplied.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
<section id="_candidate_generators">
<title>Candidate Generators<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/suggesters/phrase-suggest.asciidoc">Edit me</ulink></title>
<simpara>The <literal>phrase</literal> suggester uses candidate generators to produce a list of
possible terms per term in the given text. A single candidate generator
is similar to a <literal>term</literal> suggester called for each individual term in the
text. The output of the generators is subsequently scored in combination
with the candidates from the other terms to for suggestion candidates.</simpara>
<simpara>Currently only one type of candidate generator is supported, the
<literal>direct_generator</literal>. The Phrase suggest API accepts a list of generators
under the key <literal>direct_generator</literal> each of the generators in the list are
called per term in the original text.</simpara>
</section>
<section id="_direct_generators">
<title>Direct Generators<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/suggesters/phrase-suggest.asciidoc">Edit me</ulink></title>
<simpara>The direct generators support the following parameters:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>field</literal>
</simpara>
</entry>
<entry>
<simpara>
    The field to fetch the candidate suggestions from. This is
    a required option that either needs to be set globally or per
    suggestion.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>size</literal>
</simpara>
</entry>
<entry>
<simpara>
    The maximum corrections to be returned per suggest text token.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>suggest_mode</literal>
</simpara>
</entry>
<entry>
<simpara>
    The suggest mode controls what suggestions are included on the suggestions
    generated on each shard. All values other than <literal>always</literal> can be thought of
    as an optimization to generate fewer suggestions to test on each shard and
    are not rechecked when combining the suggestions generated on each
    shard. Thus <literal>missing</literal> will generate suggestions for terms on shards that do
    not contain them even other shards do contain them. Those should be
    filtered out using <literal>confidence</literal>. Three possible values can be specified:
</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>missing</literal>: Only generate suggestions for terms that are not in the
                 shard. This is the default.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>popular</literal>: Only suggest terms that occur in more docs on the shard than
                 the original term.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>always</literal>: Suggest any matching suggestions based on terms in the
                 suggest text.
</simpara>
</listitem>
</itemizedlist>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max_edits</literal>
</simpara>
</entry>
<entry>
<simpara>
    The maximum edit distance candidate suggestions can have
    in order to be considered as a suggestion. Can only be a value between 1
    and 2. Any other value result in an bad request error being thrown.
    Defaults to 2.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>prefix_length</literal>
</simpara>
</entry>
<entry>
<simpara>
    The number of minimal prefix characters that must
    match in order be a candidate suggestions. Defaults to 1. Increasing
    this number improves spellcheck performance. Usually misspellings don&#8217;t
    occur in the beginning of terms. (Old name "prefix_len" is deprecated)
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>min_word_length</literal>
</simpara>
</entry>
<entry>
<simpara>
    The minimum length a suggest text term must have in
    order to be included. Defaults to 4. (Old name "min_word_len" is deprecated)
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max_inspections</literal>
</simpara>
</entry>
<entry>
<simpara>
    A factor that is used to multiply with the
    <literal>shards_size</literal> in order to inspect more candidate spell corrections on
    the shard level. Can improve accuracy at the cost of performance.
    Defaults to 5.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>min_doc_freq</literal>
</simpara>
</entry>
<entry>
<simpara>
    The minimal threshold in number of documents a
    suggestion should appear in. This can be specified as an absolute number
    or as a relative percentage of number of documents. This can improve
    quality by only suggesting high frequency terms. Defaults to 0f and is
    not enabled. If a value higher than 1 is specified then the number
    cannot be fractional. The shard level document frequencies are used for
    this option.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max_term_freq</literal>
</simpara>
</entry>
<entry>
<simpara>
    The maximum threshold in number of documents a
    suggest text token can exist in order to be included. Can be a relative
    percentage number (e.g 0.4) or an absolute number to represent document
    frequencies. If an value higher than 1 is specified then fractional can
    not be specified. Defaults to 0.01f. This can be used to exclude high
    frequency terms from being spellchecked. High frequency terms are
    usually spelled correctly on top of this also improves the spellcheck
    performance. The shard level document frequencies are used for this
    option.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>pre_filter</literal>
</simpara>
</entry>
<entry>
<simpara>
    a filter (analyzer) that is applied to each of the
    tokens passed to this candidate generator. This filter is applied to the
    original token before candidates are generated.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>post_filter</literal>
</simpara>
</entry>
<entry>
<simpara>
    a filter (analyzer) that is applied to each of the
    generated tokens before they are passed to the actual phrase scorer.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>The following example shows a <literal>phrase</literal> suggest call with two generators,
the first one is using a field containing ordinary indexed terms and the
second one uses a field that uses terms indexed with a <literal>reverse</literal> filter
(tokens are index in reverse order). This is used to overcome the limitation
of the direct generators to require a constant prefix to provide
high-performance suggestions. The <literal>pre_filter</literal> and <literal>post_filter</literal> options
accept ordinary analyzer names.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _suggest
{
  "text" : "obel prize",
  "simple_phrase" : {
    "phrase" : {
      "field" : "title.trigram",
      "size" : 1,
      "direct_generator" : [ {
        "field" : "title.trigram",
        "suggest_mode" : "always"
      }, {
        "field" : "title.reverse",
        "suggest_mode" : "always",
        "pre_filter" : "reverse",
        "post_filter" : "reverse"
      } ]
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara><literal>pre_filter</literal> and <literal>post_filter</literal> can also be used to inject synonyms after
candidates are generated. For instance for the query <literal>captain usq</literal> we
might generate a candidate <literal>usa</literal> for term <literal>usq</literal> which is a synonym for
<literal>america</literal> which allows to present <literal>captain america</literal> to the user if this
phrase scores high enough.</simpara>
</section>
</section>
<section id="search-suggesters-completion">
<title>Completion Suggester<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/suggesters/completion-suggest.asciidoc">Edit me</ulink></title>
<note><simpara>In order to understand the format of suggestions, please
read the <xref linkend="search-suggesters"/> page first.</simpara></note>
<simpara>The <literal>completion</literal> suggester provides auto-complete/search-as-you-type
functionality. This is a navigational feature to guide users to
relevant results as they are typing, improving search precision.
It is not meant for spell correction or did-you-mean functionality
like the <literal>term</literal> or <literal>phrase</literal> suggesters.</simpara>
<simpara>Ideally, auto-complete functionality should be as fast as a user
types to provide instant feedback relevant to what a user has already
typed in. Hence, <literal>completion</literal> suggester is optimized for speed.
The suggester uses data structures that enable fast lookups,
but are costly to build and are stored in-memory.</simpara>
<section id="completion-suggester-mapping">
<title>Mapping<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/suggesters/completion-suggest.asciidoc">Edit me</ulink></title>
<simpara>To use this feature, specify a special mapping for this field,
which indexes the field values for fast completions.</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT music
{
    "mappings": {
        "song" : {
            "properties" : {
                "suggest" : {
                    "type" : "completion"
                },
                "title" : {
                    "type": "keyword"
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TESTSETUP</remark>
<simpara>Mapping supports the following parameters:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>analyzer</literal>
</term>
<listitem>
<simpara>
    The index analyzer to use, defaults to <literal>simple</literal>.
    In case you are wondering why we did not opt for the <literal>standard</literal>
    analyzer: We try to have easy to understand behaviour here, and if you
    index the field content <literal>At the Drive-in</literal>, you will not get any
    suggestions for <literal>a</literal>, nor for <literal>d</literal> (the first non stopword).
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>search_analyzer</literal>
</term>
<listitem>
<simpara>
    The search analyzer to use, defaults to value of <literal>analyzer</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>preserve_separators</literal>
</term>
<listitem>
<simpara>
    Preserves the separators, defaults to <literal>true</literal>.
    If disabled, you could find a field starting with <literal>Foo Fighters</literal>, if you
    suggest for <literal>foof</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>preserve_position_increments</literal>
</term>
<listitem>
<simpara>
    Enables position increments, defaults to <literal>true</literal>.
    If disabled and using stopwords analyzer, you could get a
    field starting with <literal>The Beatles</literal>, if you suggest for <literal>b</literal>. <emphasis role="strong">Note</emphasis>: You
    could also achieve this by indexing two inputs, <literal>Beatles</literal> and
    <literal>The Beatles</literal>, no need to change a simple analyzer, if you are able to
    enrich your data.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>max_input_length</literal>
</term>
<listitem>
<simpara>
    Limits the length of a single input, defaults to <literal>50</literal> UTF-16 code points.
    This limit is only used at index time to reduce the total number of
    characters per input string in order to prevent massive inputs from
    bloating the underlying datastructure. Most usecases won&#8217;t be influenced
    by the default value since prefix completions seldom grow beyond prefixes longer
    than a handful of characters.
</simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
<section id="indexing">
<title>Indexing<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/suggesters/completion-suggest.asciidoc">Edit me</ulink></title>
<simpara>You index suggestions like any other field. A suggestion is made of an
<literal>input</literal> and an optional <literal>weight</literal> attribute. An <literal>input</literal> is the expected
text to be matched by a suggestion query and the <literal>weight</literal> determines how
the suggestions will be scored. Indexing a suggestion is as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT music/song/1?refresh
{
    "suggest" : {
        "input": [ "Nevermind", "Nirvana" ],
        "weight" : 34
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST</remark>
<simpara>The following parameters are supported:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>input</literal>
</term>
<listitem>
<simpara>
    The input to store, this can be an array of strings or just
    a string. This field is mandatory.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>weight</literal>
</term>
<listitem>
<simpara>
    A positive integer or a string containing a positive integer,
    which defines a weight and allows you to rank your suggestions.
    This field is optional.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>You can index multiple suggestions for a document as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT music/song/1?refresh
{
    "suggest" : [
        {
            "input": "Nevermind",
            "weight" : 10
        },
        {
            "input": "Nirvana",
            "weight" : 3
        }
    ]
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>You can use the following shorthand form. Note that you can not specify
a weight with suggestion(s).</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT music/song/1?refresh
{
  "suggest" : [ "Nevermind", "Nirvana" ]
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
</section>
<section id="querying">
<title>Querying<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/suggesters/completion-suggest.asciidoc">Edit me</ulink></title>
<simpara>Suggesting works as usual, except that you have to specify the suggest
type as <literal>completion</literal>. Suggestions are near real-time, which means
new suggestions can be made visible by <link linkend="indices-refresh">refresh</link> and
documents once deleted are never shown. This request:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST music/_suggest?pretty
{
    "song-suggest" : {
        "prefix" : "nir",
        "completion" : {
            "field" : "suggest"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>returns this response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "_shards" : {
    "total" : 5,
    "successful" : 5,
    "failed" : 0
  },
  "song-suggest" : [ {
    "text" : "nir",
    "offset" : 0,
    "length" : 3,
    "options" : [ {
      "text" : "Nirvana",
      "_index": "music",
      "_type": "song",
      "_id": "1",
      "_score": 1.0,
      "_source": {
        "suggest": ["Nevermind", "Nirvana"]
      }
    } ]
  } ]
}</programlisting>
<remark> TESTRESPONSE</remark>
<important><simpara><literal>_source</literal> meta-field must be enabled, which is the default
behavior, to enable returning <literal>_source</literal> with suggestions.</simpara></important>
<simpara>The configured weight for a suggestion is returned as <literal>_score</literal>. The
<literal>text</literal> field uses the <literal>input</literal> of your indexed suggestion. Suggestions
return the full document <literal>_source</literal> by default. The size of the <literal>_source</literal>
can impact performance due to disk fetch and network transport overhead.
To save some network overhead, filter out unnecessary fields from the <literal>_source</literal>
using <link linkend="search-request-source-filtering">source filtering</link> to minimize
<literal>_source</literal> size. Note that the _suggest endpoint doesn&#8217;t support source
filtering but using suggest on the <literal>_search</literal> endpoint does:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST music/_search?size=0
{
    "_source": "suggest",
    "suggest": {
        "song-suggest" : {
            "prefix" : "nir",
            "completion" : {
                "field" : "suggest"
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Which should look like:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "took": 6,
    "timed_out": false,
    "_shards" : {
        "total" : 5,
        "successful" : 5,
        "failed" : 0
    },
    "hits": {
        "total" : 0,
        "max_score" : 0.0,
        "hits" : []
    },
    "suggest": {
        "song-suggest" : [ {
            "text" : "nir",
            "offset" : 0,
            "length" : 3,
            "options" : [ {
                "text" : "Nirvana",
                "_index": "music",
                "_type": "song",
                "_id": "1",
                "_score": 1.0,
                "_source": {
                    "suggest": ["Nevermind", "Nirvana"]
                }
            } ]
        } ]
    }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 6,/"took": $body.took,/]</remark>
<simpara>The basic completion suggester query supports the following parameters:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>field</literal>
</term>
<listitem>
<simpara>
The name of the field on which to run the query (required).
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>size</literal>
</term>
<listitem>
<simpara>
The number of suggestions to return (defaults to <literal>5</literal>).
</simpara>
</listitem>
</varlistentry>
</variablelist>
<note><simpara>The completion suggester considers all documents in the index.
See <xref linkend="suggester-context"/> for an explanation of how to query a subset of
documents instead.</simpara></note>
<note><simpara>In case of completion queries spanning more than one shard, the suggest
is executed in two phases, where the last phase fetches the relevant documents
from shards, implying executing completion requests against a single shard is
more performant due to the document fetch overhead when the suggest spans
multiple shards. To get best performance for completions, it is recommended to
index completions into a single shard index. In case of high heap usage due to
shard size, it is still recommended to break index into multiple shards instead
of optimizing for completion performance.</simpara></note>
</section>
<section id="fuzzy">
<title>Fuzzy queries<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/suggesters/completion-suggest.asciidoc">Edit me</ulink></title>
<simpara>The completion suggester also supports fuzzy queries - this means,
you can have a typo in your search and still get results back.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST music/_suggest?pretty
{
    "song-suggest" : {
        "prefix" : "nor",
        "completion" : {
            "field" : "suggest",
            "fuzzy" : {
                "fuzziness" : 2
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Suggestions that share the longest prefix to the query <literal>prefix</literal> will
be scored higher.</simpara>
<simpara>The fuzzy query can take specific fuzzy parameters.
The following parameters are supported:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>fuzziness</literal>
</simpara>
</entry>
<entry>
<simpara>
    The fuzziness factor, defaults to <literal>AUTO</literal>.
    See  <xref linkend="fuzziness"/> for allowed settings.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>transpositions</literal>
</simpara>
</entry>
<entry>
<simpara>
    if set to <literal>true</literal>, transpositions are counted
    as one change instead of two, defaults to <literal>true</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>min_length</literal>
</simpara>
</entry>
<entry>
<simpara>
    Minimum length of the input before fuzzy
    suggestions are returned, defaults <literal>3</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>prefix_length</literal>
</simpara>
</entry>
<entry>
<simpara>
    Minimum length of the input, which is not
    checked for fuzzy alternatives, defaults to <literal>1</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>unicode_aware</literal>
</simpara>
</entry>
<entry>
<simpara>
    If <literal>true</literal>, all measurements (like fuzzy edit
    distance, transpositions, and lengths) are
    measured in Unicode code points instead of
    in bytes.  This is slightly slower than raw
    bytes, so it is set to <literal>false</literal> by default.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<note><simpara>If you want to stick with the default values, but
      still use fuzzy, you can either use <literal>fuzzy: {}</literal>
      or <literal>fuzzy: true</literal>.</simpara></note>
</section>
<section id="regex">
<title>Regex queries<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/suggesters/completion-suggest.asciidoc">Edit me</ulink></title>
<simpara>The completion suggester also supports regex queries meaning
you can express a prefix as a regular expression</simpara>
<programlisting language="js" linenumbering="unnumbered">POST music/_suggest?pretty
{
    "song-suggest" : {
        "regex" : "n[ever|i]r",
        "completion" : {
            "field" : "suggest"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The regex query can take specific regex parameters.
The following parameters are supported:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>flags</literal>
</simpara>
</entry>
<entry>
<simpara>
    Possible flags are <literal>ALL</literal> (default), <literal>ANYSTRING</literal>, <literal>COMPLEMENT</literal>,
    <literal>EMPTY</literal>, <literal>INTERSECTION</literal>, <literal>INTERVAL</literal>, or <literal>NONE</literal>. See <link linkend="query-dsl-regexp-query">regexp-syntax</link>
    for their meaning
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max_determinized_states</literal>
</simpara>
</entry>
<entry>
<simpara>
    Regular expressions are dangerous because it&#8217;s easy to accidentally
    create an innocuous looking one that requires an exponential number of
    internal determinized automaton states (and corresponding RAM and CPU)
    for Lucene to execute.  Lucene prevents these using the
    <literal>max_determinized_states</literal> setting (defaults to 10000).  You can raise
    this limit to allow more complex regular expressions to execute.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
</section>
<section id="suggester-context">
<title>Context Suggester<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/suggesters/context-suggest.asciidoc">Edit me</ulink></title>
<simpara>The completion suggester considers all documents in the index, but it is often
desirable to serve suggestions filtered and/or boosted by some criteria.
For example, you want to suggest song titles filtered by certain artists or
you want to boost song titles based on their genre.</simpara>
<simpara>To achieve suggestion filtering and/or boosting, you can add context mappings while
configuring a completion field. You can define multiple context mappings for a
completion field.
Every context mapping has a unique name and a type. There are two types: <literal>category</literal>
and <literal>geo</literal>. Context mappings are configured under the <literal>contexts</literal> parameter in
the field mapping.</simpara>
<simpara>The following defines types, each with two context mappings for a completion
field:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT place
{
    "mappings": {
        "shops" : {
            "properties" : {
                "suggest" : {
                    "type" : "completion",
                    "contexts": [
                        { <co id="CO28-1"/>
                            "name": "place_type",
                            "type": "category",
                            "path": "cat"
                        },
                        { <co id="CO28-2"/>
                            "name": "location",
                            "type": "geo",
                            "precision": 4
                        }
                    ]
                }
            }
        }
    }
}
PUT place_path_category
{
    "mappings": {
        "shops" : {
            "properties" : {
                "suggest" : {
                    "type" : "completion",
                    "contexts": [
                        { <co id="CO28-3"/>
                            "name": "place_type",
                            "type": "category",
                            "path": "cat"
                        },
                        { <co id="CO28-4"/>
                            "name": "location",
                            "type": "geo",
                            "precision": 4,
                            "path": "loc"
                        }
                    ]
                },
                "loc": {
                    "type": "geo_point"
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TESTSETUP</remark>
<calloutlist>
<callout arearefs="CO28-1">
<para>
Defines a <literal>category</literal> context named <emphasis>place_type</emphasis> where the categories must be
    sent with the suggestions.
</para>
</callout>
<callout arearefs="CO28-2">
<para>
Defines a <literal>geo</literal> context named <emphasis>location</emphasis> where the categories must be sent
    with the suggestions.
</para>
</callout>
<callout arearefs="CO28-3">
<para>
Defines a <literal>category</literal> context named <emphasis>place_type</emphasis> where the categories are
    read from the <literal>cat</literal> field.
</para>
</callout>
<callout arearefs="CO28-4">
<para>
Defines a <literal>geo</literal> context named <emphasis>location</emphasis> where the categories are read from
    the <literal>loc</literal> field.
</para>
</callout>
</calloutlist>
<note><simpara>Adding context mappings increases the index size for completion field. The completion index
is entirely heap resident, you can monitor the completion field index size using <xref linkend="indices-stats"/>.</simpara></note>
<bridgehead id="suggester-context-category" renderas="sect3">Category Context<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/suggesters/context-suggest.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>category</literal> context allows you to associate one or more categories with suggestions at index
time. At query time, suggestions can be filtered and boosted by their associated categories.</simpara>
<simpara>The mappings are set up like the <literal>place_type</literal> fields above. If <literal>path</literal> is defined
then the categories are read from that path in the document, otherwise they must
be sent in the suggest field like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT place/shops/1
{
    "suggest": {
        "input": ["timmy's", "starbucks", "dunkin donuts"],
        "contexts": {
            "place_type": ["cafe", "food"] <co id="CO29-1"/>
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO29-1">
<para>
These suggestions will be associated with <emphasis>cafe</emphasis> and <emphasis>food</emphasis> category.
</para>
</callout>
</calloutlist>
<simpara>If the mapping had a <literal>path</literal> then the following index request would be enough to
add the categories:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT place_path_category/shops/1
{
    "suggest": ["timmy's", "starbucks", "dunkin donuts"],
    "cat": ["cafe", "food"] <co id="CO30-1"/>
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO30-1">
<para>
These suggestions will be associated with <emphasis>cafe</emphasis> and <emphasis>food</emphasis> category.
</para>
</callout>
</calloutlist>
<note><simpara>If context mapping references another field and the categories
are explicitly indexed, the suggestions are indexed with both set
of categories.</simpara></note>
<bridgehead id="_category_query" renderas="sect4">Category Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/suggesters/context-suggest.asciidoc">Edit me</ulink></bridgehead>
<simpara>Suggestions can be filtered by one or more categories. The following
filters suggestions by multiple categories:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST place/_suggest?pretty
{
    "suggest" : {
        "prefix" : "tim",
        "completion" : {
            "field" : "suggest",
            "size": 10,
            "contexts": {
                "place_type": [ "cafe", "restaurants" ]
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<note><simpara>When no categories are provided at query-time, all indexed documents are considered.
Querying with no categories on a category enabled completion field should be avoided, as it
will degrade search performance.</simpara></note>
<simpara>Suggestions with certain categories can be boosted higher than others.
The following filters suggestions by categories and additionally boosts
suggestions associated with some categories:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST place/_suggest?pretty
{
    "suggest" : {
        "prefix" : "tim",
        "completion" : {
            "field" : "suggest",
            "size": 10,
            "contexts": {
                "place_type": [ <co id="CO31-1"/>
                    { "context" : "cafe" },
                    { "context" : "restaurants", "boost": 2 }
                 ]
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<calloutlist>
<callout arearefs="CO31-1">
<para>
The context query filter suggestions associated with
    categories <emphasis>cafe</emphasis> and <emphasis>restaurants</emphasis> and boosts the
    suggestions associated with <emphasis>restaurants</emphasis> by a
    factor of <literal>2</literal>
</para>
</callout>
</calloutlist>
<simpara>In addition to accepting category values, a context query can be composed of
multiple category context clauses. The following parameters are supported for a
<literal>category</literal> context clause:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>context</literal>
</simpara>
</entry>
<entry>
<simpara>
    The value of the category to filter/boost on.
    This is mandatory.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>boost</literal>
</simpara>
</entry>
<entry>
<simpara>
    The factor by which the score of the suggestion
    should be boosted, the score is computed by
    multiplying the boost with the suggestion weight,
    defaults to <literal>1</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>prefix</literal>
</simpara>
</entry>
<entry>
<simpara>
    Whether the category value should be treated as a
    prefix or not. For example, if set to <literal>true</literal>,
    you can filter category of <emphasis>type1</emphasis>, <emphasis>type2</emphasis> and
    so on, by specifying a category prefix of <emphasis>type</emphasis>.
    Defaults to <literal>false</literal>
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="suggester-context-geo" renderas="sect3">Geo location Context<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/suggesters/context-suggest.asciidoc">Edit me</ulink></bridgehead>
<simpara>A <literal>geo</literal> context allows you to associate one or more geo points or geohashes with suggestions
at index time. At query time, suggestions can be filtered and boosted if they are within
a certain distance of a specified geo location.</simpara>
<simpara>Internally, geo points are encoded as geohashes with the specified precision.</simpara>
<bridgehead id="_geo_mapping" renderas="sect4">Geo Mapping<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/suggesters/context-suggest.asciidoc">Edit me</ulink></bridgehead>
<simpara>In addition to the <literal>path</literal> setting, <literal>geo</literal> context mapping accepts the following settings:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>precision</literal>
</simpara>
</entry>
<entry>
<simpara>
    This defines the precision of the geohash to be indexed and can be specified
    as a distance value (<literal>5m</literal>, <literal>10km</literal> etc.), or as a raw geohash precision (<literal>1</literal>..<literal>12</literal>).
    Defaults to a raw geohash precision value of <literal>6</literal>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<note><simpara>The index time <literal>precision</literal> setting sets the maximum geohash precision that
can be used at query time.</simpara></note>
<bridgehead id="_indexing_geo_contexts" renderas="sect4">Indexing geo contexts<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/suggesters/context-suggest.asciidoc">Edit me</ulink></bridgehead>
<simpara><literal>geo</literal> contexts can be explicitly set with suggestions or be indexed from a geo point field in the
document via the <literal>path</literal> parameter, similar to <literal>category</literal> contexts. Associating multiple geo location context
with a suggestion, will index the suggestion for every geo location. The following indexes a suggestion
with two geo location contexts:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT place/shops/1
{
    "suggest": {
        "input": "timmy's",
        "contexts": {
            "location": [
                {
                    "lat": 43.6624803,
                    "lon": -79.3863353
                },
                {
                    "lat": 43.6624718,
                    "lon": -79.3873227
                }
            ]
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_geo_location_query" renderas="sect4">Geo location Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/suggesters/context-suggest.asciidoc">Edit me</ulink></bridgehead>
<simpara>Suggestions can be filtered and boosted with respect to how close they are to one or
more geo points. The following filters suggestions that fall within the area represented by
the encoded geohash of a geo point:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST place/_suggest
{
    "suggest" : {
        "prefix" : "tim",
        "completion" : {
            "field" : "suggest",
            "size": 10,
            "contexts": {
                "location": {
                    "lat": 43.662,
                    "lon": -79.380
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<note><simpara>When a location with a lower precision at query time is specified, all suggestions
that fall within the area will be considered.</simpara></note>
<simpara>Suggestions that are within an area represented by a geohash can also be boosted higher
than others, as shown by the following:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST place/_suggest?pretty
{
    "suggest" : {
        "prefix" : "tim",
        "completion" : {
            "field" : "suggest",
            "size": 10,
            "contexts": {
                "location": [ <co id="CO32-1"/>
                    {
                        "lat": 43.6624803,
                        "lon": -79.3863353,
                        "precision": 2
                    },
                    {
                        "context": {
                            "lat": 43.6624803,
                            "lon": -79.3863353
                        },
                        "boost": 2
                    }
                 ]
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<calloutlist>
<callout arearefs="CO32-1">
<para>
The context query filters for suggestions that fall under
    the geo location represented by a geohash of <emphasis>(43.662, -79.380)</emphasis>
    with a precision of <emphasis>2</emphasis> and boosts suggestions
    that fall under the geohash representation of <emphasis>(43.6624803, -79.3863353)</emphasis>
    with a default precision of <emphasis>6</emphasis> by a factor of <literal>2</literal>
</para>
</callout>
</calloutlist>
<simpara>In addition to accepting context values, a context query can be composed of
multiple context clauses. The following parameters are supported for a
<literal>category</literal> context clause:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>context</literal>
</simpara>
</entry>
<entry>
<simpara>
    A geo point object or a geo hash string to filter or
    boost the suggestion by. This is mandatory.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>boost</literal>
</simpara>
</entry>
<entry>
<simpara>
    The factor by which the score of the suggestion
    should be boosted, the score is computed by
    multiplying the boost with the suggestion weight,
    defaults to <literal>1</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>precision</literal>
</simpara>
</entry>
<entry>
<simpara>
    The precision of the geohash to encode the query geo point.
    This can be specified as a distance value (<literal>5m</literal>, <literal>10km</literal> etc.),
    or as a raw geohash precision (<literal>1</literal>..<literal>12</literal>).
    Defaults to index time precision level.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>neighbours</literal>
</simpara>
</entry>
<entry>
<simpara>
    Accepts an array of precision values at which
    neighbouring geohashes should be taken into account.
    precision value can be a distance value (<literal>5m</literal>, <literal>10km</literal> etc.)
    or a raw geohash precision (<literal>1</literal>..<literal>12</literal>). Defaults to
    generating neighbours for index time precision level.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
</chapter>
<chapter id="search-multi-search">
<title>Multi Search API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/multi-search.asciidoc">Edit me</ulink></title>
<simpara>The multi search API allows to execute several search requests within
the same API. The endpoint for it is <literal>_msearch</literal>.</simpara>
<simpara>The format of the request is similar to the bulk API format, and the
structure is as follows (the structure is specifically optimized to
reduce parsing if a specific search ends up redirected to another node):</simpara>
<programlisting language="js" linenumbering="unnumbered">header\n
body\n
header\n
body\n</programlisting>
<simpara>The header part includes which index / indices to search on, optional
(mapping) types to search on, the <literal>search_type</literal>, <literal>preference</literal>, and
<literal>routing</literal>. The body includes the typical search body request (including
the <literal>query</literal>, <literal>aggregations</literal>, <literal>from</literal>, <literal>size</literal>, and so on). Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">$ cat requests
{"index" : "test"}
{"query" : {"match_all" : {}}, "from" : 0, "size" : 10}
{"index" : "test", "search_type" : "dfs_query_then_fetch"}
{"query" : {"match_all" : {}}}
{}
{"query" : {"match_all" : {}}}

{"query" : {"match_all" : {}}}
{"search_type" : "dfs_query_then_fetch"}
{"query" : {"match_all" : {}}}

$ curl -XGET localhost:9200/_msearch --data-binary "@requests"; echo</programlisting>
<simpara>Note, the above includes an example of an empty header (can also be just
without any content) which is supported as well.</simpara>
<simpara>The response returns a <literal>responses</literal> array, which includes the search
response and status code for each search request matching its order in
the original multi search request. If there was a complete failure for that
specific search request, an object with <literal>error</literal> message and corresponding
status code will be returned in place of the actual search response.</simpara>
<simpara>The endpoint allows to also search against an index/indices and
type/types in the URI itself, in which case it will be used as the
default unless explicitly defined otherwise in the header. For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">$ cat requests
{}
{"query" : {"match_all" : {}}, "from" : 0, "size" : 10}
{}
{"query" : {"match_all" : {}}}
{"index" : "test2"}
{"query" : {"match_all" : {}}}

$ curl -XGET localhost:9200/test/_msearch --data-binary @requests; echo</programlisting>
<simpara>The above will execute the search against the <literal>test</literal> index for all the
requests that don&#8217;t define an index, and the last one will be executed
against the <literal>test2</literal> index.</simpara>
<simpara>The <literal>search_type</literal> can be set in a similar manner to globally apply to
all search requests.</simpara>
<simpara>The msearch&#8217;s <literal>max_concurrent_searches</literal> request parameter can be used to control
the maximum number of concurrent searches the multi search api will execute.
This default is based on the number of data nodes and the default search thread pool size.</simpara>
<bridgehead id="msearch-security" renderas="sect2">Security<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/multi-search.asciidoc">Edit me</ulink></bridgehead>
<simpara>See <xref linkend="url-access-control"/></simpara>
</chapter>
<chapter id="search-count">
<title>Count API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/count.asciidoc">Edit me</ulink></title>
<simpara>The count API allows to easily execute a query and get the number of
matches for that query. It can be executed across one or more indices
and across one or more types. The query can either be provided using a
simple query string as a parameter, or using the
<link linkend="query-dsl">Query DSL</link> defined within the request
body. Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /twitter/tweet/1?refresh
{
    "user": "kimchy"
}

GET /twitter/tweet/_count?q=user:kimchy

GET /twitter/tweet/_count
{
    "query" : {
        "term" : { "user" : "kimchy" }
    }
}</programlisting>
<remark>CONSOLE</remark>
<note><simpara>The query being sent in the body must be nested in a <literal>query</literal> key, same as
the <link linkend="search-search">search api</link> works</simpara></note>
<simpara>Both examples above do the same thing, which is count the number of
tweets from the twitter index for a certain user. The result is:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "count" : 1,
    "_shards" : {
        "total" : 5,
        "successful" : 5,
        "failed" : 0
    }
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>The query is optional, and when not provided, it will use <literal>match_all</literal> to
count all the docs.</simpara>
<bridgehead id="_multi_index_multi_type" renderas="sect2">Multi index, Multi type<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/count.asciidoc">Edit me</ulink></bridgehead>
<simpara>The count API can be applied to <link linkend="search-multi-index-type">multiple types in multiple indices</link>.</simpara>
<bridgehead id="_request_parameters" renderas="sect2">Request Parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/count.asciidoc">Edit me</ulink></bridgehead>
<simpara>When executing count using the query parameter <literal>q</literal>, the query passed is
a query string using Lucene query parser. There are additional
parameters that can be passed:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Name </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>df</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The default field to use when no field prefix is defined within the
query.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>analyzer</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The analyzer name to be used when analyzing the query string.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>default_operator</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The default operator to be used, can be <literal>AND</literal> or
<literal>OR</literal>. Defaults to <literal>OR</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>lenient</literal></simpara></entry>
<entry align="left" valign="top"><simpara>If set to true will cause format based failures (like
providing text to a numeric field) to be ignored. Defaults to false.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>analyze_wildcard</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Should wildcard and prefix queries be analyzed or
not. Defaults to <literal>false</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>terminate_after</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The maximum count for each shard, upon
reaching which the query execution will terminate early.
If set, the response will have a boolean field <literal>terminated_early</literal> to
indicate whether the query execution has actually terminated_early.
Defaults to no terminate_after.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<bridgehead id="_request_body" renderas="sect2">Request Body<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/count.asciidoc">Edit me</ulink></bridgehead>
<simpara>The count can use the <link linkend="query-dsl">Query DSL</link> within
its body in order to express the query that should be executed. The body
content can also be passed as a REST parameter named <literal>source</literal>.</simpara>
<simpara>Both HTTP GET and HTTP POST can be used to execute count with body.
Since not all clients support GET with body, POST is allowed as well.</simpara>
<bridgehead id="_distributed" renderas="sect2">Distributed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/count.asciidoc">Edit me</ulink></bridgehead>
<simpara>The count operation is broadcast across all shards. For each shard id
group, a replica is chosen and executed against it. This means that
replicas increase the scalability of count.</simpara>
<bridgehead id="_routing" renderas="sect2">Routing<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/count.asciidoc">Edit me</ulink></bridgehead>
<simpara>The routing value (a comma separated list of the routing values) can be
specified to control which shards the count request will be executed on.</simpara>
</chapter>
<chapter id="search-validate">
<title>Validate API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/validate.asciidoc">Edit me</ulink></title>
<simpara>The validate API allows a user to validate a potentially expensive query
without executing it. We&#8217;ll use the following test data to explain _validate:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT twitter/tweet/_bulk?refresh
{"index":{"_id":1}}
{"user" : "kimchy", "post_date" : "2009-11-15T14:12:12", "message" : "trying out Elasticsearch"}
{"index":{"_id":2}}
{"user" : "kimchi", "post_date" : "2009-11-15T14:12:13", "message" : "My username is similar to @kimchy!"}</programlisting>
<remark> CONSOLE</remark>
<remark> TESTSETUP</remark>
<simpara>When sent a valid query:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET twitter/_validate/query?q=user:foo</programlisting>
<remark> CONSOLE</remark>
<simpara>The response contains <literal>valid:true</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">{"valid":true,"_shards":{"total":1,"successful":1,"failed":0}}</programlisting>
<remark> TESTRESPONSE</remark>
<bridgehead id="_request_parameters_2" renderas="sect2">Request Parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/validate.asciidoc">Edit me</ulink></bridgehead>
<simpara>When executing exists using the query parameter <literal>q</literal>, the query passed is
a query string using Lucene query parser. There are additional
parameters that can be passed:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Name </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>df</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The default field to use when no field prefix is defined within the
query.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>analyzer</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The analyzer name to be used when analyzing the query string.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>default_operator</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The default operator to be used, can be <literal>AND</literal> or
<literal>OR</literal>. Defaults to <literal>OR</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>lenient</literal></simpara></entry>
<entry align="left" valign="top"><simpara>If set to true will cause format based failures (like
providing text to a numeric field) to be ignored. Defaults to false.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>analyze_wildcard</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Should wildcard and prefix queries be analyzed or
not. Defaults to <literal>false</literal>.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>The query may also be sent in the request body:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET twitter/tweet/_validate/query
{
  "query" : {
    "bool" : {
      "must" : {
        "query_string" : {
          "query" : "*:*"
        }
      },
      "filter" : {
        "term" : { "user" : "kimchy" }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<note><simpara>The query being sent in the body must be nested in a <literal>query</literal> key, same as
the <link linkend="search-search">search api</link> works</simpara></note>
<simpara>If the query is invalid, <literal>valid</literal> will be <literal>false</literal>. Here the query is
invalid because Elasticsearch knows the post_date field should be a date
due to dynamic mapping, and <emphasis>foo</emphasis> does not correctly parse into a date:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET twitter/tweet/_validate/query?q=post_date:foo</programlisting>
<remark> CONSOLE</remark>
<programlisting language="js" linenumbering="unnumbered">{"valid":false,"_shards":{"total":1,"successful":1,"failed":0}}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>An <literal>explain</literal> parameter can be specified to get more detailed information
about why a query failed:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET twitter/tweet/_validate/query?q=post_date:foo&amp;explain=true</programlisting>
<remark> CONSOLE</remark>
<simpara>responds with:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "valid" : false,
  "_shards" : {
    "total" : 1,
    "successful" : 1,
    "failed" : 0
  },
  "explanations" : [ {
    "index" : "twitter",
    "valid" : false,
    "error" : "twitter/IAEc2nIXSSunQA_suI0MLw] QueryShardException[failed to create query:...failed to parse date field [foo]"
  } ]
}</programlisting>
<remark> TESTRESPONSE[s/"error" : "[^\"]+"/"error": "$body.explanations.0.error"/]</remark>
<simpara>When the query is valid, the explanation defaults to the string
representation of that query. With <literal>rewrite</literal> set to <literal>true</literal>, the explanation
is more detailed showing the actual Lucene query that will be executed.</simpara>
<simpara>For Fuzzy Queries:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET twitter/tweet/_validate/query?rewrite=true
{
  "query": {
    "match": {
      "user": {
        "query": "kimchy",
        "fuzziness": "auto"
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[skip:https://github.com/elastic/elasticsearch/issues/18254]</remark>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "valid": true,
   "_shards": {
      "total": 1,
      "successful": 1,
      "failed": 0
   },
   "explanations": [
      {
         "index": "twitter",
         "valid": true,
         "explanation": "+user:kimchy +user:kimchi^0.75 #(ConstantScore(_type:tweet))^0.0"
      }
   ]
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>For More Like This:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET twitter/tweet/_validate/query?rewrite=true
{
  "query": {
    "more_like_this": {
      "like": {
        "_id": "2"
      },
      "boost_terms": 1
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[skip:https://github.com/elastic/elasticsearch/issues/18254]</remark>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "valid": true,
   "_shards": {
      "total": 1,
      "successful": 1,
      "failed": 0
   },
   "explanations": [
      {
         "index": "twitter",
         "valid": true,
         "explanation": "((user:terminator^3.71334 plot:future^2.763601 plot:human^2.8415773 plot:sarah^3.4193945 plot:kyle^3.8244398 plot:cyborg^3.9177752 plot:connor^4.040236 plot:reese^4.7133346 ... )~6) -ConstantScore(_uid:tweet#2)) #(ConstantScore(_type:tweet))^0.0"
      }
   ]
}</programlisting>
<remark> TESTRESPONSE</remark>
<caution><simpara>The request is executed on a single shard only, which is randomly
selected. The detailed explanation of the query may depend on which shard is
being hit, and therefore may vary from one request to another.</simpara></caution>
</chapter>
<chapter id="search-explain">
<title>Explain API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/explain.asciidoc">Edit me</ulink></title>
<simpara>The explain api computes a score explanation for a query and a specific
document. This can give useful feedback whether a document matches or
didn&#8217;t match a specific query.</simpara>
<simpara>The <literal>index</literal> and <literal>type</literal> parameters expect a single index and a single
type respectively.</simpara>
<bridgehead id="_usage_2" renderas="sect2">Usage<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/explain.asciidoc">Edit me</ulink></bridgehead>
<simpara>Full query example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /twitter/tweet/0/_explain
{
      "query" : {
        "match" : { "message" : "elasticsearch" }
      }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>This will yield the following result:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "_index" : "twitter",
  "_type" : "tweet",
  "_id" : "0",
  "matched" : true,
  "explanation" : {
    "value" : 1.55077,
    "description" : "sum of:",
    "details" : [ {
      "value" : 1.55077,
      "description" : "weight(message:elasticsearch in 0) [PerFieldSimilarity], result of:",
      "details" : [ {
        "value" : 1.55077,
        "description" : "score(doc=0,freq=1.0 = termFreq=1.0\n), product of:",
        "details" : [ {
          "value" : 1.3862944,
          "description" : "idf(docFreq=1, docCount=5)",
          "details" : [ ]
        }, {
          "value" : 1.1186441,
          "description" : "tfNorm, computed from:",
          "details" : [
            { "value" : 1.0, "description" : "termFreq=1.0", "details" : [ ] },
            { "value" : 1.2, "description" : "parameter k1", "details" : [ ] },
            { "value" : 0.75, "description" : "parameter b", "details" : [ ] },
            { "value" : 5.4, "description" : "avgFieldLength", "details" : [ ] },
            { "value" : 4.0, "description" : "fieldLength", "details" : [ ] }
          ]
        } ]
      } ]
    }, {
      "value" : 0.0,
      "description" : "match on required clause, product of:",
      "details" : [ {
        "value" : 0.0,
        "description" : "# clause",
        "details" : [ ]
      }, {
        "value" : 1.0,
        "description" : "*:*, product of:",
        "details" : [
          { "value" : 1.0, "description" : "boost", "details" : [ ] },
          { "value" : 1.0, "description" : "queryNorm", "details" : [ ] }
        ]
      } ]
    } ]
  }
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>There is also a simpler way of specifying the query via the <literal>q</literal>
parameter. The specified <literal>q</literal> parameter value is then parsed as if the
<literal>query_string</literal> query was used. Example usage of the <literal>q</literal> parameter in the
explain api:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /twitter/tweet/0/_explain?q=message:search</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>This will yield the same result as the previous request.</simpara>
<bridgehead id="_all_parameters_2" renderas="sect2">All parameters:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/explain.asciidoc">Edit me</ulink></bridgehead>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>_source</literal>
</simpara>
</entry>
<entry>
<simpara>
    Set to <literal>true</literal> to retrieve the <literal>_source</literal> of the document explained. You can also
    retrieve part of the document by using <literal>_source_include</literal> &amp; <literal>_source_exclude</literal> (see <link linkend="get-source-filtering">Get API</link> for more details)
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>stored_fields</literal>
</simpara>
</entry>
<entry>
<simpara>
    Allows to control which stored fields to return as part of the
    document explained.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>routing</literal>
</simpara>
</entry>
<entry>
<simpara>
    Controls the routing in the case the routing was used
    during indexing.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>parent</literal>
</simpara>
</entry>
<entry>
<simpara>
    Same effect as setting the routing parameter.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>preference</literal>
</simpara>
</entry>
<entry>
<simpara>
    Controls on which shard the explain is executed.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>source</literal>
</simpara>
</entry>
<entry>
<simpara>
    Allows the data of the request to be put in the query
    string of the url.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>q</literal>
</simpara>
</entry>
<entry>
<simpara>
    The query string (maps to the query_string query).
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>df</literal>
</simpara>
</entry>
<entry>
<simpara>
    The default field to use when no field prefix is defined within
    the query. Defaults to _all field.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>analyzer</literal>
</simpara>
</entry>
<entry>
<simpara>
    The analyzer name to be used when analyzing the query
    string. Defaults to the analyzer of the _all field.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>analyze_wildcard</literal>
</simpara>
</entry>
<entry>
<simpara>
    Should wildcard and prefix queries be analyzed or
    not. Defaults to false.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>lenient</literal>
</simpara>
</entry>
<entry>
<simpara>
    If set to true will cause format based failures (like
    providing text to a numeric field) to be ignored. Defaults to false.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>default_operator</literal>
</simpara>
</entry>
<entry>
<simpara>
    The default operator to be used, can be AND or
    OR. Defaults to OR.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</chapter>
<chapter id="search-profile">
<title>Profile API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/profile.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This functionality is experimental and may be changed or removed completely in a future release.</simpara></warning>
<simpara>The Profile API provides detailed timing information about the execution of individual components
in a search request.  It gives the user insight into how search requests are executed at a low level so that
the user can understand why certain requests are slow, and take steps to improve them.</simpara>
<simpara>The output from the Profile API is <emphasis role="strong">very</emphasis> verbose, especially for complicated requests executed across
many shards. Pretty-printing the response is recommended to help understand the output</simpara>
<bridgehead id="_usage_3" renderas="sect2">Usage<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/profile.asciidoc">Edit me</ulink></bridgehead>
<simpara>Any <literal>_search</literal> request can be profiled by adding a top-level <literal>profile</literal> parameter:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
  "profile": true,<co id="CO33-1"/>
  "query" : {
    "match" : { "message" : "message number" }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<calloutlist>
<callout arearefs="CO33-1">
<para>
Setting the top-level <literal>profile</literal> parameter to <literal>true</literal> will enable profiling
for the search
</para>
</callout>
</calloutlist>
<simpara>This will yield the following result:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "took": 25,
   "timed_out": false,
   "_shards": {
      "total": 1,
      "successful": 1,
      "failed": 0
   },
   "hits": {
      "total": 4,
      "max_score": 0.5093388,
      "hits": [...] <co id="CO34-1"/>
   },
   "profile": {
     "shards": [
        {
           "id": "[2aE02wS1R8q_QFnYu6vDVQ][twitter][1]",
           "searches": [
              {
                 "query": [
                    {
                       "type": "BooleanQuery",
                       "description": "message:message message:number",
                       "time": "1.873811000ms",
                       "breakdown": {
                          "score": 51306,
                          "score_count": 4,
                          "build_scorer": 2935582,
                          "build_scorer_count": 1,
                          "match": 0,
                          "match_count": 0,
                          "create_weight": 919297,
                          "create_weight_count": 1,
                          "next_doc": 53876,
                          "next_doc_count": 5,
                          "advance": 0,
                          "advance_count": 0
                       },
                       "children": [
                          {
                             "type": "TermQuery",
                             "description": "message:message",
                             "time": "0.3919430000ms",
                             "breakdown": {
                                "score": 28776,
                                "score_count": 4,
                                "build_scorer": 784451,
                                "build_scorer_count": 1,
                                "match": 0,
                                "match_count": 0,
                                "create_weight": 1669564,
                                "create_weight_count": 1,
                                "next_doc": 10111,
                                "next_doc_count": 5,
                                "advance": 0,
                                "advance_count": 0
                             }
                          },
                          {
                             "type": "TermQuery",
                             "description": "message:number",
                             "time": "0.2106820000ms",
                             "breakdown": {
                                "score": 4552,
                                "score_count": 4,
                                "build_scorer": 42602,
                                "build_scorer_count": 1,
                                "match": 0,
                                "match_count": 0,
                                "create_weight": 89323,
                                "create_weight_count": 1,
                                "next_doc": 2852,
                                "next_doc_count": 5,
                                "advance": 0,
                                "advance_count": 0
                             }
                          }
                       ]
                    }
                 ],
                 "rewrite_time": 51443,
                 "collector": [
                    {
                       "name": "CancellableCollector",
                       "reason": "search_cancelled",
                       "time": "0.3043110000ms",
                       "children": [
                         {
                           "name": "SimpleTopScoreDocCollector",
                           "reason": "search_top_hits",
                           "time": "0.03227300000ms"
                         }
                       ]
                    }
                 ]
              }
           ],
           "aggregations": []
        }
     ]
   }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 25/"took": $body.took/]</remark>
<remark> TESTRESPONSE[s/"hits": \[...\]/"hits": $body.hits.hits/]</remark>
<remark> TESTRESPONSE[s/"id": "\[2aE02wS1R8q_QFnYu6vDVQ\]\[twitter\]\[1\]"/"id": $body.profile.shards.0.id/]</remark>
<remark> TESTRESPONSE[s/"rewrite_time": 51443/"rewrite_time": $body.profile.shards.0.searches.0.rewrite_time/]</remark>
<remark> TESTRESPONSE[s/"score": 51306/"score": $body.profile.shards.0.searches.0.query.0.breakdown.score/]</remark>
<remark> TESTRESPONSE[s/"time": "1.873811000ms"/"time": $body.profile.shards.0.searches.0.query.0.time/]</remark>
<remark> TESTRESPONSE[s/"build_scorer": 2935582/"build_scorer": $body.profile.shards.0.searches.0.query.0.breakdown.build_scorer/]</remark>
<remark> TESTRESPONSE[s/"create_weight": 919297/"create_weight": $body.profile.shards.0.searches.0.query.0.breakdown.create_weight/]</remark>
<remark> TESTRESPONSE[s/"next_doc": 53876/"next_doc": $body.profile.shards.0.searches.0.query.0.breakdown.next_doc/]</remark>
<remark> TESTRESPONSE[s/"time": "0.3919430000ms"/"time": $body.profile.shards.0.searches.0.query.0.children.0.time/]</remark>
<remark> TESTRESPONSE[s/"score": 28776/"score": $body.profile.shards.0.searches.0.query.0.children.0.breakdown.score/]</remark>
<remark> TESTRESPONSE[s/"build_scorer": 784451/"build_scorer": $body.profile.shards.0.searches.0.query.0.children.0.breakdown.build_scorer/]</remark>
<remark> TESTRESPONSE[s/"create_weight": 1669564/"create_weight": $body.profile.shards.0.searches.0.query.0.children.0.breakdown.create_weight/]</remark>
<remark> TESTRESPONSE[s/"next_doc": 10111/"next_doc": $body.profile.shards.0.searches.0.query.0.children.0.breakdown.next_doc/]</remark>
<remark> TESTRESPONSE[s/"time": "0.2106820000ms"/"time": $body.profile.shards.0.searches.0.query.0.children.1.time/]</remark>
<remark> TESTRESPONSE[s/"score": 4552/"score": $body.profile.shards.0.searches.0.query.0.children.1.breakdown.score/]</remark>
<remark> TESTRESPONSE[s/"build_scorer": 42602/"build_scorer": $body.profile.shards.0.searches.0.query.0.children.1.breakdown.build_scorer/]</remark>
<remark> TESTRESPONSE[s/"create_weight": 89323/"create_weight": $body.profile.shards.0.searches.0.query.0.children.1.breakdown.create_weight/]</remark>
<remark> TESTRESPONSE[s/"next_doc": 2852/"next_doc": $body.profile.shards.0.searches.0.query.0.children.1.breakdown.next_doc/]</remark>
<remark> TESTRESPONSE[s/"time": "0.3043110000ms"/"time": $body.profile.shards.0.searches.0.collector.0.time/]</remark>
<remark> TESTRESPONSE[s/"time": "0.03227300000ms"/"time": $body.profile.shards.0.searches.0.collector.0.children.0.time/]</remark>
<remark> Sorry for this mess....</remark>
<calloutlist>
<callout arearefs="CO34-1">
<para>
Search results are returned, but were omitted here for brevity
</para>
</callout>
</calloutlist>
<simpara>Even for a simple query, the response is relatively complicated.  Let&#8217;s break it down piece-by-piece before moving
to more complex examples.</simpara>
<simpara>First, the overall structure of the profile response is as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "profile": {
        "shards": [
           {
              "id": "[2aE02wS1R8q_QFnYu6vDVQ][twitter][1]",  <co id="CO35-1"/>
              "searches": [
                 {
                    "query": [...],             <co id="CO35-2"/>
                    "rewrite_time": 51443,      <co id="CO35-3"/>
                    "collector": [...]          <co id="CO35-4"/>
                 }
              ],
              "aggregations": [...]             <co id="CO35-5"/>
           }
        ]
     }
}</programlisting>
<remark> TESTRESPONSE[s/"profile": /"took": $body.took, "timed_out": $body.timed_out, "_shards": $body._shards, "hits": $body.hits, "profile": /]</remark>
<remark> TESTRESPONSE[s/"id": "\[2aE02wS1R8q_QFnYu6vDVQ\]\[twitter\]\[1\]"/"id": $body.profile.shards.0.id/]</remark>
<remark> TESTRESPONSE[s/"query": \[...\]/"query": $body.profile.shards.0.searches.0.query/]</remark>
<remark> TESTRESPONSE[s/"rewrite_time": 51443/"rewrite_time": $body.profile.shards.0.searches.0.rewrite_time/]</remark>
<remark> TESTRESPONSE[s/"collector": \[...\]/"collector": $body.profile.shards.0.searches.0.collector/]</remark>
<remark> TESTRESPONSE[s/"aggregations": \[...\]/"aggregations": []/]</remark>
<calloutlist>
<callout arearefs="CO35-1">
<para>
A profile is returned for each shard that participated in the response, and is identified
by a unique ID
</para>
</callout>
<callout arearefs="CO35-2">
<para>
Each profile contains a section which holds details about the query execution
</para>
</callout>
<callout arearefs="CO35-3">
<para>
Each profile has a single time representing the cumulative rewrite time
</para>
</callout>
<callout arearefs="CO35-4">
<para>
Each profile also contains a section about the Lucene Collectors which run the search
</para>
</callout>
<callout arearefs="CO35-5">
<para>
Each profile contains a section which holds the details about the aggregation execution
</para>
</callout>
</calloutlist>
<simpara>Because a search request may be executed against one or more shards in an index, and a search may cover
one or more indices, the top level element in the profile response is an array of <literal>shard</literal> objects.
Each shard object lists it&#8217;s <literal>id</literal> which uniquely identifies the shard.  The ID&#8217;s format is
<literal>[nodeID][indexName][shardID]</literal>.</simpara>
<simpara>The profile itself may consist of one or more "searches", where a search is a query executed against the underlying
Lucene index.  Most Search Requests submitted by the user will only execute a single <literal>search</literal> against the Lucene index.
But occasionally multiple searches will be executed, such as including a global aggregation (which needs to execute
a secondary "match_all" query for the global context).</simpara>
<simpara>Inside each <literal>search</literal> object there will be two arrays of profiled information:
a <literal>query</literal> array and a <literal>collector</literal> array.  Alongside the <literal>search</literal> object is an <literal>aggregations</literal> object that contains the profile information for the aggregations. In the future, more sections may be added, such as <literal>suggest</literal>, <literal>highlight</literal>, etc</simpara>
<simpara>There will also be a <literal>rewrite</literal> metric showing the total time spent rewriting the query (in nanoseconds).</simpara>
<section id="_profiling_queries">
<title>Profiling Queries<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/profile.asciidoc">Edit me</ulink></title>
<note>
<simpara>The details provided by the Profile API directly expose Lucene class names and concepts, which means
that complete interpretation of the results require fairly advanced knowledge of Lucene.  This
page attempts to give a crash-course in how Lucene executes queries so that you can use the Profile API to successfully
diagnose and debug queries, but it is only an overview.  For complete understanding, please refer
to Lucene&#8217;s documentation and, in places, the code.</simpara>
<simpara>With that said, a complete understanding is often not required to fix a slow query.  It is usually
sufficient to see that a particular component of a query is slow, and not necessarily understand why
the <literal>advance</literal> phase of that query is the cause, for example.</simpara>
</note>
<section id="_literal_query_literal_section">
<title><literal>query</literal> Section<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/profile.asciidoc">Edit me</ulink></title>
<simpara>The <literal>query</literal> section contains detailed timing of the query tree executed by Lucene on a particular shard.
The overall structure of this query tree will resemble your original Elasticsearch query, but may be slightly
(or sometimes very) different.  It will also use similar but not always identical naming.  Using our previous
<literal>match</literal> query example, let&#8217;s analyze the <literal>query</literal> section:</simpara>
<programlisting language="js" linenumbering="unnumbered">"query": [
    {
       "type": "BooleanQuery",
       "description": "message:message message:number",
       "time": "1.873811000ms",
       "breakdown": {...},               <co id="CO36-1"/>
       "children": [
          {
             "type": "TermQuery",
             "description": "message:message",
             "time": "0.3919430000ms",
             "breakdown": {...}
          },
          {
             "type": "TermQuery",
             "description": "message:number",
             "time": "0.2106820000ms",
             "breakdown": {...}
          }
       ]
    }
]</programlisting>
<remark> TESTRESPONSE[s/^/{\n"took": $body.took,\n"timed_out": $body.timed_out,\n"_shards": $body._shards,\n"hits": $body.hits,\n"profile": {\n"shards": [ {\n"id": "$body.profile.shards.0.id",\n"searches": [{\n/]</remark>
<remark> TESTRESPONSE[s/]$/],"rewrite_time": $body.profile.shards.0.searches.0.rewrite_time, "collector": $body.profile.shards.0.searches.0.collector}], "aggregations": []}]}}/]</remark>
<remark> TESTRESPONSE[s/"time": "1.873811000ms",\n.+"breakdown": \{...\}/"time": $body.profile.shards.0.searches.0.query.0.time, "breakdown": $body.profile.shards.0.searches.0.query.0.breakdown/]</remark>
<remark> TESTRESPONSE[s/"time": "0.3919430000ms",\n.+"breakdown": \{...\}/"time": $body.profile.shards.0.searches.0.query.0.children.0.time, "breakdown": $body.profile.shards.0.searches.0.query.0.children.0.breakdown/]</remark>
<remark> TESTRESPONSE[s/"time": "0.2106820000ms",\n.+"breakdown": \{...\}/"time": $body.profile.shards.0.searches.0.query.0.children.1.time, "breakdown": $body.profile.shards.0.searches.0.query.0.children.1.breakdown/]</remark>
<calloutlist>
<callout arearefs="CO36-1">
<para>
The breakdown timings are omitted for simplicity
</para>
</callout>
</calloutlist>
<simpara>Based on the profile structure, we can see that our <literal>match</literal> query was rewritten by Lucene into a BooleanQuery with two
clauses (both holding a TermQuery).  The <literal>"type"</literal> field displays the Lucene class name, and often aligns with
the equivalent name in Elasticsearch.  The <literal>"description"</literal> field displays the Lucene explanation text for the query, and
is made available to help differentiating between parts of your query (e.g. both <literal>"message:search"</literal> and <literal>"message:test"</literal>
are TermQuery&#8217;s and would appear identical otherwise.</simpara>
<simpara>The <literal>"time"</literal> field shows that this query took ~15ms for the entire BooleanQuery to execute.  The recorded time is inclusive
of all children.</simpara>
<simpara>The <literal>"breakdown"</literal> field will give detailed stats about how the time was spent, we&#8217;ll look at
that in a moment.  Finally, the <literal>"children"</literal> array lists any sub-queries that may be present.  Because we searched for two
values ("search test"), our BooleanQuery holds two children TermQueries.  They have identical information (type, time,
breakdown, etc).  Children are allowed to have their own children.</simpara>
<section id="_timing_breakdown">
<title>Timing Breakdown<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/profile.asciidoc">Edit me</ulink></title>
<simpara>The <literal>"breakdown"</literal> component lists detailed timing statistics about low-level Lucene execution:</simpara>
<programlisting language="js" linenumbering="unnumbered">"breakdown": {
   "score": 51306,
   "score_count": 4,
   "build_scorer": 2935582,
   "build_scorer_count": 1,
   "match": 0,
   "match_count": 0,
   "create_weight": 919297,
   "create_weight_count": 1,
   "next_doc": 53876,
   "next_doc_count": 5,
   "advance": 0,
   "advance_count": 0
}</programlisting>
<remark> TESTRESPONSE[s/^/{\n"took": $body.took,\n"timed_out": $body.timed_out,\n"_shards": $body._shards,\n"hits": $body.hits,\n"profile": {\n"shards": [ {\n"id": "$body.profile.shards.0.id",\n"searches": [{\n"query": [{\n"type": "BooleanQuery",\n"description": "message:message message:number",\n"time": $body.profile.shards.0.searches.0.query.0.time,/]</remark>
<remark> TESTRESPONSE[s/}$/},\n"children": $body.profile.shards.0.searches.0.query.0.children}],\n"rewrite_time": $body.profile.shards.0.searches.0.rewrite_time, "collector": $body.profile.shards.0.searches.0.collector}], "aggregations": []}]}}/]</remark>
<remark> TESTRESPONSE[s/"score": 51306/"score": $body.profile.shards.0.searches.0.query.0.breakdown.score/]</remark>
<remark> TESTRESPONSE[s/"time": "1.873811000ms"/"time": $body.profile.shards.0.searches.0.query.0.time/]</remark>
<remark> TESTRESPONSE[s/"build_scorer": 2935582/"build_scorer": $body.profile.shards.0.searches.0.query.0.breakdown.build_scorer/]</remark>
<remark> TESTRESPONSE[s/"create_weight": 919297/"create_weight": $body.profile.shards.0.searches.0.query.0.breakdown.create_weight/]</remark>
<remark> TESTRESPONSE[s/"next_doc": 53876/"next_doc": $body.profile.shards.0.searches.0.query.0.breakdown.next_doc/]</remark>
<simpara>Timings are listed in wall-clock nanoseconds and are not normalized at all.  All caveats about the overall
<literal>"time"</literal> apply here.  The intention of the breakdown is to give you a feel for A) what machinery in Lucene is
actually eating time, and B) the magnitude of differences in times between the various components.  Like the overall time,
the breakdown is inclusive of all children times.</simpara>
<simpara>The meaning of the stats are as follows:</simpara>
<bridgehead id="_all_parameters_3" renderas="sect3">All parameters:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/profile.asciidoc">Edit me</ulink></bridgehead>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>create_weight</literal>
</simpara>
</entry>
<entry>
<simpara>
    A Query in Lucene must be capable of reuse across multiple IndexSearchers (think of it as the engine that
    executes a search against a specific Lucene Index).  This puts Lucene in a tricky spot, since many queries
    need to accumulate temporary state/statistics associated with the index it is being used against, but the
    Query contract mandates that it must be immutable.
    <?asciidoc-br?>
    <?asciidoc-br?>
    To get around this, Lucene asks each query to generate a Weight object which acts as a temporary context
    object to hold state associated with this particular (IndexSearcher, Query) tuple.  The <literal>weight</literal> metric
    shows how long this process takes
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>build_scorer</literal>
</simpara>
</entry>
<entry>
<simpara>
    This parameter shows how long it takes to build a Scorer for the query.  A Scorer is the mechanism that
    iterates over matching documents generates a score per-document (e.g. how well does "foo" match the document?).
    Note, this records the time required to generate the Scorer object, not actually score the documents.  Some
    queries have faster or slower initialization of the Scorer, depending on optimizations, complexity, etc.
    <?asciidoc-br?>
    <?asciidoc-br?>
    This may also showing timing associated with caching, if enabled and/or applicable for the query
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>next_doc</literal>
</simpara>
</entry>
<entry>
<simpara>
    The Lucene method <literal>next_doc</literal> returns Doc ID of the next document matching the query.  This statistic shows
    the time it takes to determine which document is the next match, a process that varies considerably depending
    on the nature of the query.   Next_doc is a specialized form of advance() which is more convenient for many
    queries in Lucene.  It is equivalent to advance(docId() + 1)
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>advance</literal>
</simpara>
</entry>
<entry>
<simpara>
    <literal>advance</literal> is the "lower level" version of next_doc: it serves the same purpose of finding the next matching
    doc, but requires the calling query to perform extra tasks such as identifying and moving past skips, etc.
    However,  not all queries can use next_doc, so <literal>advance</literal> is also timed for those queries.
    <?asciidoc-br?>
    <?asciidoc-br?>
    Conjunctions (e.g. <literal>must</literal> clauses in a boolean) are typical consumers of <literal>advance</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>matches</literal>
</simpara>
</entry>
<entry>
<simpara>
    Some queries, such as phrase queries, match documents using a "Two Phase" process.  First, the document is
    "approximately" matched, and if it matches approximately, it is checked a second time with a more rigorous
    (and expensive) process.  The second phase verification is what the <literal>matches</literal> statistic measures.
    <?asciidoc-br?>
    <?asciidoc-br?>
    For example, a phrase query first checks a document approximately by ensuring all terms in the phrase are
    present in the doc.  If all the terms are present, it then executes the second phase verification to ensure
    the terms are in-order to form the phrase, which is relatively more expensive than just checking for presence
    of the terms.
    <?asciidoc-br?>
    <?asciidoc-br?>
    Because this two-phase process is only used by a handful of queries, the <literal>metric</literal> statistic will often be zero
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>score</literal>
</simpara>
</entry>
<entry>
<simpara>
    This records the time taken to score a particular document via it&#8217;s Scorer
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>*_count</literal>
</simpara>
</entry>
<entry>
<simpara>
    Records the number of invocations of the particular method.  For example, <literal>"next_doc_count": 2,</literal>
    means the <literal>nextDoc()</literal> method was called on two different documents.  This can be used to help judge
    how selective queries are, by comparing counts between different query components.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
</section>
<section id="_literal_collectors_literal_section">
<title><literal>collectors</literal> Section<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/profile.asciidoc">Edit me</ulink></title>
<simpara>The Collectors portion of the response shows high-level execution details. Lucene works by defining a "Collector"
which is responsible for coordinating the traversal, scoring and collection of matching documents.  Collectors
are also how a single query can record aggregation results, execute unscoped "global" queries, execute post-query
filters, etc.</simpara>
<simpara>Looking at the previous example:</simpara>
<programlisting language="js" linenumbering="unnumbered">"collector": [
   {
      "name": "CancellableCollector",
      "reason": "search_cancelled",
      "time": "0.3043110000ms",
      "children": [
        {
          "name": "SimpleTopScoreDocCollector",
          "reason": "search_top_hits",
          "time": "0.03227300000ms"
        }
      ]
   }
]</programlisting>
<remark> TESTRESPONSE[s/^/{\n"took": $body.took,\n"timed_out": $body.timed_out,\n"_shards": $body._shards,\n"hits": $body.hits,\n"profile": {\n"shards": [ {\n"id": "$body.profile.shards.0.id",\n"searches": [{\n"query": $body.profile.shards.0.searches.0.query,\n"rewrite_time": $body.profile.shards.0.searches.0.rewrite_time,/]</remark>
<remark> TESTRESPONSE[s/]$/]}], "aggregations": []}]}}/]</remark>
<remark> TESTRESPONSE[s/"time": "0.3043110000ms"/"time": $body.profile.shards.0.searches.0.collector.0.time/]</remark>
<remark> TESTRESPONSE[s/"time": "0.03227300000ms"/"time": $body.profile.shards.0.searches.0.collector.0.children.0.time/]</remark>
<simpara>We see a single collector named <literal>SimpleTopScoreDocCollector</literal> wrapped into <literal>CancellableCollector</literal>. <literal>SimpleTopScoreDocCollector</literal> is the default "scoring and sorting"
<literal>Collector</literal> used by Elasticsearch.  The <literal>"reason"</literal> field attempts to give a plain english description of the class name.  The
<literal>"time"</literal> is similar to the time in the Query tree: a wall-clock time inclusive of all children.  Similarly, <literal>children</literal> lists
all sub-collectors. The <literal>CancellableCollector</literal> that wraps <literal>SimpleTopScoreDocCollector</literal> is used by elasticsearch to detect if the current
search was cancelled and stop collecting documents as soon as it occurs.</simpara>
<simpara>It should be noted that Collector times are <emphasis role="strong">independent</emphasis> from the Query times.  They are calculated, combined
and normalized independently!  Due to the nature of Lucene&#8217;s execution, it is impossible to "merge" the times
from the Collectors into the Query section, so they are displayed in separate portions.</simpara>
<simpara>For reference, the various collector reason&#8217;s are:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>search_sorted</literal>
</simpara>
</entry>
<entry>
<simpara>
    A collector that scores and sorts documents.  This is the most common collector and will be seen in most
    simple searches
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>search_count</literal>
</simpara>
</entry>
<entry>
<simpara>
    A collector that only counts the number of documents that match the query, but does not fetch the source.
    This is seen when <literal>size: 0</literal> is specified
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>search_terminate_after_count</literal>
</simpara>
</entry>
<entry>
<simpara>
    A collector that terminates search execution after <literal>n</literal> matching documents have been found.  This is seen
    when the <literal>terminate_after_count</literal> query parameter has been specified
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>search_min_score</literal>
</simpara>
</entry>
<entry>
<simpara>
    A collector that only returns matching documents that have a score greater than <literal>n</literal>.  This is seen when
    the top-level parameter <literal>min_score</literal> has been specified.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>search_multi</literal>
</simpara>
</entry>
<entry>
<simpara>
    A collector that wraps several other collectors.  This is seen when combinations of search, aggregations,
    global aggs and post_filters are combined in a single search.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>search_timeout</literal>
</simpara>
</entry>
<entry>
<simpara>
    A collector that halts execution after a specified period of time.  This is seen when a <literal>timeout</literal> top-level
    parameter has been specified.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>aggregation</literal>
</simpara>
</entry>
<entry>
<simpara>
    A collector that Elasticsearch uses to run aggregations against the query scope.  A single <literal>aggregation</literal>
    collector is used to collect documents for <emphasis role="strong">all</emphasis> aggregations, so you will see a list of aggregations
    in the name rather.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>global_aggregation</literal>
</simpara>
</entry>
<entry>
<simpara>
    A collector that executes an aggregation against the global query scope, rather than the specified query.
    Because the global scope is necessarily different from the executed query, it must execute it&#8217;s own
    match_all query (which you will see added to the Query section) to collect your entire dataset
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
<section id="_literal_rewrite_literal_section">
<title><literal>rewrite</literal> Section<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/profile.asciidoc">Edit me</ulink></title>
<simpara>All queries in Lucene undergo a "rewriting" process.  A query (and its sub-queries) may be rewritten one or
more times, and the process continues until the query stops changing.  This process allows Lucene to perform
optimizations, such as removing redundant clauses, replacing one query for a more efficient execution path,
etc.  For example a Boolean &#8594; Boolean &#8594; TermQuery can be rewritten to a TermQuery, because all the Booleans
are unnecessary in this case.</simpara>
<simpara>The rewriting process is complex and difficult to display, since queries can change drastically.  Rather than
showing the intermediate results, the total rewrite time is simply displayed as a value (in nanoseconds).  This
value is cumulative and contains the total time for all queries being rewritten.</simpara>
</section>
<section id="_a_more_complex_example">
<title>A more complex example<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/profile.asciidoc">Edit me</ulink></title>
<simpara>To demonstrate a slightly more complex query and the associated results, we can profile the following query:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /test/_search
{
  "profile": true,
  "query": {
    "term": {
      "message": {
        "value": "search"
      }
    }
  },
  "aggs": {
    "non_global_term": {
      "terms": {
        "field": "agg"
      },
      "aggs": {
        "second_term": {
          "terms": {
            "field": "sub_agg"
          }
        }
      }
    },
    "another_agg": {
      "cardinality": {
        "field": "aggB"
      }
    },
    "global_agg": {
      "global": {},
      "aggs": {
        "my_agg2": {
          "terms": {
            "field": "globalAgg"
          }
        }
      }
    }
  },
  "post_filter": {
    "term": {
      "my_field": "foo"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT test\n/]</remark>
<simpara>This example has:</simpara>
<itemizedlist>
<listitem>
<simpara>
A query
</simpara>
</listitem>
<listitem>
<simpara>
A scoped aggregation
</simpara>
</listitem>
<listitem>
<simpara>
A global aggregation
</simpara>
</listitem>
<listitem>
<simpara>
A post_filter
</simpara>
</listitem>
</itemizedlist>
<simpara>And the response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "profile": {
         "shards": [
            {
               "id": "[P6-vulHtQRWuD4YnubWb7A][test][0]",
               "searches": [
                  {
                     "query": [
                        {
                           "type": "TermQuery",
                           "description": "my_field:foo",
                           "time": "0.4094560000ms",
                           "breakdown": {
                              "score": 0,
                              "score_count": 1,
                              "next_doc": 0,
                              "next_doc_count": 2,
                              "match": 0,
                              "match_count": 0,
                              "create_weight": 31584,
                              "create_weight_count": 1,
                              "build_scorer": 377872,
                              "build_scorer_count": 1,
                              "advance": 0,
                              "advance_count": 0
                           }
                        },
                        {
                           "type": "TermQuery",
                           "description": "message:search",
                           "time": "0.3037020000ms",
                           "breakdown": {
                              "score": 0,
                              "score_count": 1,
                              "next_doc": 5936,
                              "next_doc_count": 2,
                              "match": 0,
                              "match_count": 0,
                              "create_weight": 185215,
                              "create_weight_count": 1,
                              "build_scorer": 112551,
                              "build_scorer_count": 1,
                              "advance": 0,
                              "advance_count": 0
                           }
                        }
                     ],
                     "rewrite_time": 7208,
                     "collector": [
                        {
                           "name": "MultiCollector",
                           "reason": "search_multi",
                           "time": "1.378943000ms",
                           "children": [
                              {
                                 "name": "FilteredCollector",
                                 "reason": "search_post_filter",
                                 "time": "0.4036590000ms",
                                 "children": [
                                    {
                                       "name": "SimpleTopScoreDocCollector",
                                       "reason": "search_top_hits",
                                       "time": "0.006391000000ms"
                                    }
                                 ]
                              },
                              {
                                 "name": "BucketCollector: [[non_global_term, another_agg]]",
                                 "reason": "aggregation",
                                 "time": "0.9546020000ms"
                              }
                           ]
                        }
                     ]
                  },
                  {
                     "query": [
                        {
                           "type": "MatchAllDocsQuery",
                           "description": "*:*",
                           "time": "0.04829300000ms",
                           "breakdown": {
                              "score": 0,
                              "score_count": 1,
                              "next_doc": 3672,
                              "next_doc_count": 2,
                              "match": 0,
                              "match_count": 0,
                              "create_weight": 6311,
                              "create_weight_count": 1,
                              "build_scorer": 38310,
                              "build_scorer_count": 1,
                              "advance": 0,
                              "advance_count": 0
                           }
                        }
                     ],
                     "rewrite_time": 1067,
                     "collector": [
                        {
                           "name": "GlobalAggregator: [global_agg]",
                           "reason": "aggregation_global",
                           "time": "0.1226310000ms"
                        }
                     ]
                  }
               ]
            }
         ]
      }
}</programlisting>
<simpara>As you can see, the output is significantly verbose from before.  All the major portions of the query are
represented:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>
The first <literal>TermQuery</literal> (message:search) represents the main <literal>term</literal> query
</simpara>
</listitem>
<listitem>
<simpara>
The second <literal>TermQuery</literal> (my_field:foo) represents the <literal>post_filter</literal> query
</simpara>
</listitem>
<listitem>
<simpara>
There is a  <literal>MatchAllDocsQuery</literal> (*:*) query which is being executed as a second, distinct search.  This was
not part of the query specified by the user, but is auto-generated by the global aggregation to provide a global query scope
</simpara>
</listitem>
</orderedlist>
<simpara>The Collector tree is fairly straightforward, showing how a single MultiCollector wraps a FilteredCollector
to execute the post_filter (and in turn wraps the normal scoring SimpleCollector), a BucketCollector to run
all scoped aggregations.  In the MatchAll search, there is a single GlobalAggregator to run the global aggregation.</simpara>
</section>
<section id="_understanding_multitermquery_output">
<title>Understanding MultiTermQuery output<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/profile.asciidoc">Edit me</ulink></title>
<simpara>A special note needs to be made about the <literal>MultiTermQuery</literal> class of queries.  This includes wildcards, regex and fuzzy
queries.  These queries emit very verbose responses, and are not overly structured.</simpara>
<simpara>Essentially, these queries rewrite themselves on a per-segment basis.  If you imagine the wildcard query <literal>b*</literal>, it technically
can match any token that begins with the letter "b".  It would be impossible to enumerate all possible combinations,
so Lucene rewrites the query in context of the segment being evaluated.  E.g. one segment may contain the tokens
<literal>[bar, baz]</literal>, so the query rewrites to a BooleanQuery combination of "bar" and "baz".  Another segment may only have the
token <literal>[bakery]</literal>, so query rewrites to a single TermQuery for "bakery".</simpara>
<simpara>Due to this dynamic, per-segment rewriting, the clean tree structure becomes distorted and no longer follows a clean
"lineage" showing how one query rewrites into the next.  At present time, all we can do is apologize, and suggest you
collapse the details for that query&#8217;s children if it is too confusing.  Luckily, all the timing statistics are correct,
just not the physical layout in the response, so it is sufficient to just analyze the top-level MultiTermQuery and
ignore it&#8217;s children if you find the details too tricky to interpret.</simpara>
<simpara>Hopefully this will be fixed in future iterations, but it is a tricky problem to solve and still in-progress :)</simpara>
</section>
</section>
<section id="_profiling_aggregations">
<title>Profiling Aggregations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/profile.asciidoc">Edit me</ulink></title>
<section id="_literal_aggregations_literal_section">
<title><literal>aggregations</literal> Section<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/profile.asciidoc">Edit me</ulink></title>
<simpara>The <literal>aggregations</literal> section contains detailed timing of the aggregation tree executed by a particular shard.
The overall structure of this aggregation tree will resemble your original Elasticsearch request.  Let&#8217;s consider
the following example aggregations request:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /house-prices/_search
{
  "profile": true,
  "size": 0,
  "aggs": {
    "property_type": {
      "terms": {
        "field": "propertyType"
      },
      "aggs": {
        "avg_price": {
          "avg": {
            "field": "price"
          }
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT house-prices\n/]</remark>
<simpara>Which yields the following aggregation profile output</simpara>
<programlisting language="js" linenumbering="unnumbered">"aggregations": [
  {
    "type": "org.elasticsearch.search.aggregations.bucket.terms.GlobalOrdinalsStringTermsAggregator",
    "description": "property_type",
    "time": "4280.456978ms",
    "breakdown": {
      "reduce": 0,
      "reduce_count": 0,
      "build_aggregation": 49765,
      "build_aggregation_count": 300,
      "initialise": 52785,
      "initialize_count": 300,
      "collect": 3155490036,
      "collect_count": 1800
    },
    "children": [
      {
        "type": "org.elasticsearch.search.aggregations.metrics.avg.AvgAggregator",
        "description": "avg_price",
        "time": "1124.864392ms",
        "breakdown": {
          "reduce": 0,
          "reduce_count": 0,
          "build_aggregation": 1394,
          "build_aggregation_count": 150,
          "initialise": 2883,
          "initialize_count": 150,
          "collect": 1124860115,
          "collect_count": 900
        }
      }
    ]
  }
]</programlisting>
<simpara>From the profile structure we can see our <literal>property_type</literal> terms aggregation which is internally represented by the
<literal>GlobalOrdinalsStringTermsAggregator</literal> class and the sub aggregator <literal>avg_price</literal> which is internally represented by the <literal>AvgAggregator</literal> class. The <literal>type</literal> field displays the class used internally to represent the aggregation. The <literal>description</literal> field displays the name of the aggregation.</simpara>
<simpara>The <literal>"time"</literal> field shows that it took ~4 seconds for the entire aggregation to execute.  The recorded time is inclusive
of all children.</simpara>
<simpara>The <literal>"breakdown"</literal> field will give detailed stats about how the time was spent, we&#8217;ll look at
that in a moment.  Finally, the <literal>"children"</literal> array lists any sub-aggregations that may be present.  Because we have an <literal>avg_price</literal> aggregation as a sub-aggregation to the <literal>property_type</literal> aggregation we see it listed as a child of the <literal>property_type</literal> aggregation.  the two aggregation outputs have identical information (type, time,
breakdown, etc).  Children are allowed to have their own children.</simpara>
<section id="_timing_breakdown_2">
<title>Timing Breakdown<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/profile.asciidoc">Edit me</ulink></title>
<simpara>The <literal>"breakdown"</literal> component lists detailed timing statistics about low-level Lucene execution:</simpara>
<programlisting language="js" linenumbering="unnumbered">"breakdown": {
  "reduce": 0,
  "reduce_count": 0,
  "build_aggregation": 49765,
  "build_aggregation_count": 300,
  "initialise": 52785,
  "initialize_count": 300,
  "collect": 3155490036,
  "collect_count": 1800
}</programlisting>
<simpara>Timings are listed in wall-clock nanoseconds and are not normalized at all.  All caveats about the overall
<literal>time</literal> apply here.  The intention of the breakdown is to give you a feel for A) what machinery in Elasticsearch is
actually eating time, and B) the magnitude of differences in times between the various components.  Like the overall time,
the breakdown is inclusive of all children times.</simpara>
<simpara>The meaning of the stats are as follows:</simpara>
<bridgehead id="_all_parameters_4" renderas="sect3">All parameters:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/profile.asciidoc">Edit me</ulink></bridgehead>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>initialise</literal>
</simpara>
</entry>
<entry>
<simpara>
    This times how long it takes to create and initialise the aggregation before starting to collect documents.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>collect</literal>
</simpara>
</entry>
<entry>
<simpara>
    This represents the cumulative time spent in the collect phase of the aggregation. This is where matching documents are passed to the aggregation and the state of the aggregator is updated based on the information contained in the documents.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>build_aggregation</literal>
</simpara>
</entry>
<entry>
<simpara>
    This represents the time spent creating the shard level results of the aggregation ready to pass back to the reducing node after the collection of documents is finished.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>reduce</literal>
</simpara>
</entry>
<entry>
<simpara>
    This is not currently used and will always report <literal>0</literal>. Currently aggregation profiling only times the shard level parts of the aggregation execution. Timing of the reduce phase will be added later.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>*_count</literal>
</simpara>
</entry>
<entry>
<simpara>
    Records the number of invocations of the particular method.  For example, <literal>"collect_count": 2,</literal>
    means the <literal>collect()</literal> method was called on two different documents.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
</section>
</section>
<section id="_profiling_considerations">
<title>Profiling Considerations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/profile.asciidoc">Edit me</ulink></title>
<section id="_performance_notes">
<title>Performance Notes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/profile.asciidoc">Edit me</ulink></title>
<simpara>Like any profiler, the Profile API introduces a non-negligible overhead to search execution.  The act of instrumenting
low-level method calls such as <literal>collect</literal>, <literal>advance</literal> and <literal>next_doc</literal> can be fairly expensive, since these methods are called
in tight loops.  Therefore, profiling should not be enabled in production settings by default, and should not
be compared against non-profiled query times.  Profiling is just a diagnostic tool.</simpara>
<simpara>There are also cases where special Lucene optimizations are disabled, since they are not amenable to profiling.  This
could cause some queries to report larger relative times than their non-profiled counterparts, but in general should
not have a drastic effect compared to other components in the profiled query.</simpara>
</section>
<section id="_limitations">
<title>Limitations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/profile.asciidoc">Edit me</ulink></title>
<itemizedlist>
<listitem>
<simpara>
Profiling statistics are currently not available for suggestions, highlighting, <literal>dfs_query_then_fetch</literal>
</simpara>
</listitem>
<listitem>
<simpara>
Profiling of the reduce phase of aggregation is currently not available
</simpara>
</listitem>
<listitem>
<simpara>
The Profiler is still highly experimental. The Profiler is instrumenting parts of Lucene that were
never designed to be exposed in this manner, and so all results should be viewed as a best effort to provide detailed
diagnostics.  We hope to improve this over time. If you find obviously wrong numbers, strange query structures or
other bugs, please report them!
</simpara>
</listitem>
</itemizedlist>
</section>
</section>
</chapter>
<chapter id="search-percolate">
<title>Percolator<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/percolate.asciidoc">Edit me</ulink></title>
<warning revisionflag="deleted" revision="5.0.0"><title>Deprecated in 5.0.0.</title><simpara>Percolate and multi percolate APIs are deprecated and have been replaced by the new <link linkend="query-dsl-percolate-query"><literal>percolate</literal> query</link>.</simpara></warning>
<simpara>For indices created on or after version 5.0.0-alpha1 the percolator automatically indexes the query terms with the percolator queries. This allows the percolator to percolate documents more quickly. It is advisable to reindex any pre 5.0.0 indices to take advantage of this new optimization.</simpara>
</chapter>
<chapter id="search-field-stats">
<title>Field stats API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/field-stats.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This functionality is experimental and may be changed or removed completely in a future release.</simpara></warning>
<simpara>The field stats api allows one to find statistical properties of a field
without executing a search, but looking up measurements that are natively
available in the Lucene index. This can be useful to explore a dataset which
you don&#8217;t know much about. For example, this allows creating a histogram
aggregation with meaningful intervals based on the min/max range of values.</simpara>
<simpara>The field stats api by defaults executes on all indices, but can execute on
specific indices too.</simpara>
<simpara>All indices:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET "http://localhost:9200/_field_stats?fields=rating"</programlisting>
<simpara>Specific indices:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET "http://localhost:9200/index1,index2/_field_stats?fields=rating"</programlisting>
<simpara>Supported request options:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>fields</literal>
</simpara>
</entry>
<entry>
<simpara>
A list of fields to compute stats for. The field name supports wildcard notation. For example, using <literal>text_*</literal>
            will cause all fields that match the expression to be returned.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>level</literal>
</simpara>
</entry>
<entry>
<simpara>
Defines if field stats should be returned on a per index level or on a
            cluster wide level. Valid values are <literal>indices</literal> and <literal>cluster</literal> (default).
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>Alternatively the <literal>fields</literal> option can also be defined in the request body:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XPOST "http://localhost:9200/_field_stats?level=indices" -d '{
   "fields" : ["rating"]
}'</programlisting>
<simpara>This is equivalent to the previous request.</simpara>
<bridgehead id="_field_statistics_2" renderas="sect2">Field statistics<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/field-stats.asciidoc">Edit me</ulink></bridgehead>
<simpara>The field stats api is supported on string based, number based and date based fields and can return the following statistics per field:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>max_doc</literal>
</simpara>
</entry>
<entry>
<simpara>
The total number of documents.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>doc_count</literal>
</simpara>
</entry>
<entry>
<simpara>
The number of documents that have at least one term for this field, or -1 if
this measurement isn&#8217;t available on one or more shards.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>density</literal>
</simpara>
</entry>
<entry>
<simpara>
The percentage of documents that have at least one value for this field. This
is a derived statistic and is based on the <literal>max_doc</literal> and <literal>doc_count</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>sum_doc_freq</literal>
</simpara>
</entry>
<entry>
<simpara>
The sum of each term&#8217;s document frequency in this field, or -1 if this
measurement isn&#8217;t available on one or more shards.
Document frequency is the number of documents containing a particular term.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>sum_total_term_freq</literal>
</simpara>
</entry>
<entry>
<simpara>
The sum of the term frequencies of all terms in this field across all
documents, or -1 if this measurement isn&#8217;t available on one or more shards.
Term frequency is the total number of occurrences of a term in a particular
document and field.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara><literal>is_searchable</literal></simpara>
<simpara>True if any of the instances of the field is searchable, false otherwise.</simpara>
<simpara><literal>is_aggregatable</literal></simpara>
<simpara>True if any of the instances of the field is aggregatable, false otherwise.</simpara>
<variablelist>
<varlistentry>
<term>
<literal>min_value</literal>
</term>
<listitem>
<simpara>
The lowest value in the field.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>min_value_as_string</literal>
</term>
<listitem>
<simpara>
The lowest value in the field represented in a displayable form. All fields,
but string fields returns this. (since string fields, represent values already as strings)
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>max_value</literal>
</term>
<listitem>
<simpara>
The highest value in the field.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>max_value_as_string</literal>
</term>
<listitem>
<simpara>
The highest value in the field represented in a displayable form. All fields,
but string fields returns this. (since string fields, represent values already as strings)
</simpara>
</listitem>
</varlistentry>
</variablelist>
<note><simpara>Documents marked as deleted (but not yet removed by the merge process)
still affect all the mentioned statistics.</simpara></note>
<bridgehead id="_cluster_level_field_statistics_example" renderas="sect2">Cluster level field statistics example<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/field-stats.asciidoc">Edit me</ulink></bridgehead>
<simpara>Request:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET "http://localhost:9200/_field_stats?fields=rating,answer_count,creation_date,display_name"</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "_shards": {
      "total": 1,
      "successful": 1,
      "failed": 0
   },
   "indices": {
      "_all": { <co id="CO37-1"/>
         "fields": {
            "creation_date": {
               "max_doc": 1326564,
               "doc_count": 564633,
               "density": 42,
               "sum_doc_freq": 2258532,
               "sum_total_term_freq": -1,
               "min_value": "2008-08-01T16:37:51.513Z",
               "max_value": "2013-06-02T03:23:11.593Z",
               "is_searchable": "true",
               "is_aggregatable": "true"
            },
            "display_name": {
               "max_doc": 1326564,
               "doc_count": 126741,
               "density": 9,
               "sum_doc_freq": 166535,
               "sum_total_term_freq": 166616,
               "min_value": "0",
               "max_value": "정혜선",
               "is_searchable": "true",
               "is_aggregatable": "false"
            },
            "answer_count": {
               "max_doc": 1326564,
               "doc_count": 139885,
               "density": 10,
               "sum_doc_freq": 559540,
               "sum_total_term_freq": -1,
               "min_value": 0,
               "max_value": 160,
               "is_searchable": "true",
               "is_aggregatable": "true"
            },
            "rating": {
               "max_doc": 1326564,
               "doc_count": 437892,
               "density": 33,
               "sum_doc_freq": 1751568,
               "sum_total_term_freq": -1,
               "min_value": -14,
               "max_value": 1277,
               "is_searchable": "true",
               "is_aggregatable": "true"
            }
         }
      }
   }
}</programlisting>
<calloutlist>
<callout arearefs="CO37-1">
<para>
The <literal>_all</literal> key indicates that it contains the field stats of all indices in the cluster.
</para>
</callout>
</calloutlist>
<note><simpara>When using the cluster level field statistics it is possible to have conflicts if the same field is used in
different indices with incompatible types. For instance a field of type <literal>long</literal> is not compatible with a field of
type <literal>float</literal> or <literal>string</literal>. A section named <literal>conflicts</literal> is added to the response if one or more conflicts are raised.
It contains all the fields with conflicts and the reason of the incompatibility.</simpara></note>
<programlisting language="js" linenumbering="unnumbered">{
   "_shards": {
      "total": 1,
      "successful": 1,
      "failed": 0
   },
   "indices": {
      "_all": {
         "fields": {
            "creation_date": {
               "max_doc": 1326564,
               "doc_count": 564633,
               "density": 42,
               "sum_doc_freq": 2258532,
               "sum_total_term_freq": -1,
               "min_value": "2008-08-01T16:37:51.513Z",
               "max_value": "2013-06-02T03:23:11.593Z",
               "is_searchable": "true",
               "is_aggregatable": "true"
            }
         }
      }
   },
   "conflicts": {
        "field_name_in_conflict1": "reason1",
        "field_name_in_conflict2": "reason2"
   }
}</programlisting>
<bridgehead id="_indices_level_field_statistics_example" renderas="sect3">Indices level field statistics example<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/field-stats.asciidoc">Edit me</ulink></bridgehead>
<simpara>Request:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET "http://localhost:9200/_field_stats?fields=rating,answer_count,creation_date,display_name&amp;level=indices"</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "_shards": {
      "total": 1,
      "successful": 1,
      "failed": 0
   },
   "indices": {
      "stack": { <co id="CO38-1"/>
         "fields": {
            "creation_date": {
               "max_doc": 1326564,
               "doc_count": 564633,
               "density": 42,
               "sum_doc_freq": 2258532,
               "sum_total_term_freq": -1,
               "min_value": "2008-08-01T16:37:51.513Z",
               "max_value": "2013-06-02T03:23:11.593Z",
               "is_searchable": "true",
               "is_aggregatable": "true"
            },
            "display_name": {
               "max_doc": 1326564,
               "doc_count": 126741,
               "density": 9,
               "sum_doc_freq": 166535,
               "sum_total_term_freq": 166616,
               "min_value": "0",
               "max_value": "정혜선",
               "is_searchable": "true",
               "is_aggregatable": "false"
            },
            "answer_count": {
               "max_doc": 1326564,
               "doc_count": 139885,
               "density": 10,
               "sum_doc_freq": 559540,
               "sum_total_term_freq": -1,
               "min_value": 0,
               "max_value": 160,
               "is_searchable": "true",
               "is_aggregatable": "true"
            },
            "rating": {
               "max_doc": 1326564,
               "doc_count": 437892,
               "density": 33,
               "sum_doc_freq": 1751568,
               "sum_total_term_freq": -1,
               "min_value": -14,
               "max_value": 1277,
               "is_searchable": "true",
               "is_aggregatable": "true"
            }
         }
      }
   }
}</programlisting>
<calloutlist>
<callout arearefs="CO38-1">
<para>
The <literal>stack</literal> key means it contains all field stats for the <literal>stack</literal> index.
</para>
</callout>
</calloutlist>
<bridgehead id="_field_stats_index_constraints" renderas="sect2">Field stats index constraints<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/search/field-stats.asciidoc">Edit me</ulink></bridgehead>
<simpara>Field stats index constraints allows to omit all field stats for indices that don&#8217;t match with the constraint. An index
constraint can exclude indices' field stats based on the <literal>min_value</literal> and <literal>max_value</literal> statistic. This option is only
useful if the <literal>level</literal> option is set to <literal>indices</literal>.</simpara>
<simpara>For example index constraints can be useful to find out the min and max value of a particular property of your data in
a time based scenario. The following request only returns field stats for the <literal>answer_count</literal> property for indices
holding questions created in the year 2014:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XPOST "http://localhost:9200/_field_stats?level=indices" -d '{
   "fields" : ["answer_count"] <co id="CO39-1"/>
   "index_constraints" : { <co id="CO39-2"/>
      "creation_date" : { <co id="CO39-3"/>
         "max_value" : { <co id="CO39-4"/>
            "gte" : "2014-01-01T00:00:00.000Z"
         },
         "min_value" : { <co id="CO39-5"/>
            "lt" : "2015-01-01T00:00:00.000Z"
         }
      }
   }
}'</programlisting>
<calloutlist>
<callout arearefs="CO39-1">
<para>
The fields to compute and return field stats for.
</para>
</callout>
<callout arearefs="CO39-2">
<para>
The set index constraints. Note that index constrains can be defined for fields that aren&#8217;t defined in the <literal>fields</literal> option.
</para>
</callout>
<callout arearefs="CO39-3">
<para>
Index constraints for the field <literal>creation_date</literal>.
</para>
</callout>
<callout arearefs="CO39-4 CO39-5">
<para>
Index constraints on the <literal>max_value</literal> and <literal>min_value</literal> property of a field statistic.
</para>
</callout>
</calloutlist>
<simpara>For a field, index constraints can be defined on the <literal>min_value</literal> statistic, <literal>max_value</literal> statistic or both.
Each index constraint support the following comparisons:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>gte</literal>
</simpara>
</entry>
<entry>
<simpara>
Greater-than or equal to
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>gt</literal>
</simpara>
</entry>
<entry>
<simpara>
Greater-than
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>lte</literal>
</simpara>
</entry>
<entry>
<simpara>
Less-than or equal to
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>lt</literal>
</simpara>
</entry>
<entry>
<simpara>
Less-than
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>Field stats index constraints on date fields optionally accept a <literal>format</literal> option, used to parse the constraint&#8217;s value.
If missing, the format configured in the field&#8217;s mapping is used.</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XPOST "http://localhost:9200/_field_stats?level=indices" -d '{
   "fields" : ["answer_count"]
   "index_constraints" : {
      "creation_date" : {
         "max_value" : {
            "gte" : "2014-01-01",
            "format" : "date_optional_time" <co id="CO40-1"/>
         },
         "min_value" : {
            "lt" : "2015-01-01",
            "format" : "date_optional_time"
         }
      }
   }
}'</programlisting>
<calloutlist>
<callout arearefs="CO40-1">
<para>
Custom date format
</para>
</callout>
</calloutlist>
</chapter>
</part>
<part id="search-aggregations">
<title>Aggregations <ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations.asciidoc">Edit me</ulink></title>
<partintro>
<simpara>The aggregations framework helps provide aggregated data based on a search query. It is based on simple building blocks
called aggregations, that can be composed in order to build complex summaries of the data.</simpara>
<simpara>An aggregation can be seen as a <emphasis>unit-of-work</emphasis> that builds analytic information over a set of documents. The context of
the execution defines what this document set is (e.g. a top-level aggregation executes within the context of the executed
query/filters of the search request).</simpara>
<simpara>There are many different types of aggregations, each with its own purpose and output. To better understand these types,
it is often easier to break them into three main families:</simpara>
<variablelist>
<varlistentry>
<term>
<link linkend="search-aggregations-bucket"><emphasis>Bucketing</emphasis></link>
</term>
<listitem>
<simpara>
                                A family of aggregations that build buckets, where each bucket is associated with a <emphasis>key</emphasis> and a document
                                criterion. When the aggregation is executed, all the buckets criteria are evaluated on every document in
                                the context and when a criterion matches, the document is considered to "fall in" the relevant bucket.
                                By the end of the aggregation process, we&#8217;ll end up with a list of buckets - each one with a set of
                                documents that "belong" to it.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="search-aggregations-metrics"><emphasis>Metric</emphasis></link>
</term>
<listitem>
<simpara>
                                Aggregations that keep track and compute metrics over a set of documents.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="search-aggregations-matrix"><emphasis>Matrix</emphasis></link>
</term>
<listitem>
<simpara>
                A family of aggregations that operate on multiple fields and produce a matrix result based on the
                values extracted from the requested document fields. Unlike metric and bucket aggregations, this
                aggregation family does not yet support scripting.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="search-aggregations-pipeline"><emphasis>Pipeline</emphasis></link>
</term>
<listitem>
<simpara>
                                Aggregations that aggregate the output of other aggregations and their associated metrics
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>The interesting part comes next. Since each bucket effectively defines a document set (all documents belonging to
the bucket), one can potentially associate aggregations on the bucket level, and those will execute within the context
of that bucket. This is where the real power of aggregations kicks in: <emphasis role="strong">aggregations can be nested!</emphasis></simpara>
<note><simpara>Bucketing aggregations can have sub-aggregations (bucketing or metric). The sub-aggregations will be computed for
                the buckets which their parent aggregation generates. There is no hard limit on the level/depth of nested
                aggregations (one can nest an aggregation under a "parent" aggregation, which is itself a sub-aggregation of
                another higher-level aggregation).</simpara></note>
<bridgehead id="_structuring_aggregations" renderas="sect1">Structuring Aggregations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations.asciidoc">Edit me</ulink></bridgehead>
<simpara>The following snippet captures the basic structure of aggregations:</simpara>
<programlisting language="js" linenumbering="unnumbered">"aggregations" : {
    "&lt;aggregation_name&gt;" : {
        "&lt;aggregation_type&gt;" : {
            &lt;aggregation_body&gt;
        }
        [,"meta" : {  [&lt;meta_data_body&gt;] } ]?
        [,"aggregations" : { [&lt;sub_aggregation&gt;]+ } ]?
    }
    [,"&lt;aggregation_name_2&gt;" : { ... } ]*
}</programlisting>
<remark> NOTCONSOLE</remark>
<simpara>The <literal>aggregations</literal> object (the key <literal>aggs</literal> can also be used) in the JSON holds the aggregations to be computed. Each aggregation
is associated with a logical name that the user defines (e.g. if the aggregation computes the average price, then it would
make sense to name it <literal>avg_price</literal>). These logical names will also be used to uniquely identify the aggregations in the
response. Each aggregation has a specific type (<literal>&lt;aggregation_type&gt;</literal> in the above snippet) and is typically the first
key within the named aggregation body. Each type of aggregation defines its own body, depending on the nature of the
aggregation (e.g. an <literal>avg</literal> aggregation on a specific field will define the field on which the average will be calculated).
At the same level of the aggregation type definition, one can optionally define a set of additional aggregations,
though this only makes sense if the aggregation you defined is of a bucketing nature. In this scenario, the
sub-aggregations you define on the bucketing aggregation level will be computed for all the buckets built by the
bucketing aggregation. For example, if you define a set of aggregations under the <literal>range</literal> aggregation, the
sub-aggregations will be computed for the range buckets that are defined.</simpara>
<bridgehead id="_values_source" renderas="sect2">Values Source<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations.asciidoc">Edit me</ulink></bridgehead>
<simpara>Some aggregations work on values extracted from the aggregated documents. Typically, the values will be extracted from
a specific document field which is set using the <literal>field</literal> key for the aggregations. It is also possible to define a
<link linkend="modules-scripting"><literal>script</literal></link> which will generate the values (per document).</simpara>
<simpara>When both <literal>field</literal> and <literal>script</literal> settings are configured for the aggregation, the script will be treated as a
<literal>value script</literal>.  While normal scripts are evaluated on a document level (i.e. the script has access to all the data
associated with the document), value scripts are evaluated on the <emphasis role="strong">value</emphasis> level. In this mode, the values are extracted
from the configured <literal>field</literal> and the <literal>script</literal> is used to apply a "transformation" over these value/s.</simpara>
<note id="aggs-script-note">
<simpara>When working with scripts, the <literal>lang</literal> and <literal>params</literal> settings can also be defined. The former defines the scripting
language which is used (assuming the proper language is available in Elasticsearch, either by default or as a plugin). The latter
enables defining all the "dynamic" expressions in the script as parameters, which enables the script to keep itself static
between calls (this will ensure the use of the cached compiled scripts in Elasticsearch).</simpara>
</note>
<simpara>Scripts can generate a single value or multiple values per document. When generating multiple values, one can use the
<literal>script_values_sorted</literal> settings to indicate whether these values are sorted or not. Internally, Elasticsearch can
perform optimizations when dealing with sorted values (for example, with the <literal>min</literal> aggregations, knowing the values are
sorted, Elasticsearch will skip the iterations over all the values and rely on the first value in the list to be the
minimum value among all other values associated with the same document).</simpara>
</partintro>
<chapter id="search-aggregations-metrics">
<title>Metrics Aggregations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics.asciidoc">Edit me</ulink></title>
<simpara>The aggregations in this family compute metrics based on values extracted in one way or another from the documents that
are being aggregated. The values are typically extracted from the fields of the document (using the field data), but
can also be generated using scripts.</simpara>
<simpara>Numeric metrics aggregations are a special type of metrics aggregation which output numeric values. Some aggregations output
a single numeric metric (e.g. <literal>avg</literal>) and are called <literal>single-value numeric metrics aggregation</literal>, others generate multiple
metrics (e.g. <literal>stats</literal>) and are called <literal>multi-value numeric metrics aggregation</literal>. The distinction between single-value and
multi-value numeric metrics aggregations plays a role when these aggregations serve as direct sub-aggregations of some
bucket aggregations (some bucket aggregations enable you to sort the returned buckets based on the numeric metrics in each bucket).</simpara>
<section id="search-aggregations-metrics-avg-aggregation">
<title>Avg Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/avg-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A <literal>single-value</literal> metrics aggregation that computes the average of numeric values that are extracted from the aggregated documents. These values can be extracted either from specific numeric fields in the documents, or be generated by a provided script.</simpara>
<simpara>Assuming the data consists of documents representing exams grades (between 0 and 100) of students</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "avg_grade" : { "avg" : { "field" : "grade" } }
    }
}</programlisting>
<simpara>The above aggregation computes the average grade over all documents. The aggregation type is <literal>avg</literal> and the <literal>field</literal> setting defines the numeric field of the documents the average will be computed on. The above will return the following:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

    "aggregations": {
        "avg_grade": {
            "value": 75
        }
    }
}</programlisting>
<simpara>The name of the aggregation (<literal>avg_grade</literal> above) also serves as the key by which the aggregation result can be retrieved from the returned response.</simpara>
<section id="_script">
<title>Script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/avg-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Computing the average grade based on a script:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...,

    "aggs" : {
        "avg_grade" : {
            "avg" : {
                "script" : {
                    "inline" : "doc['grade'].value",
                    "lang" : "painless"
                }
            }
        }
    }
}</programlisting>
<simpara>This will interpret the <literal>script</literal> parameter as an <literal>inline</literal> script with the <literal>painless</literal> script language and no script parameters. To use a file script use the following syntax:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...,

    "aggs" : {
        "avg_grade" : {
            "avg" : {
                "script" : {
                    "file": "my_script",
                    "params": {
                        "field": "grade"
                    }
                }
            }
        }
    }
}</programlisting>
<tip><simpara>for indexed scripts replace the <literal>file</literal> parameter with an <literal>id</literal> parameter.</simpara></tip>
<section id="_value_script">
<title>Value Script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/avg-aggregation.asciidoc">Edit me</ulink></title>
<simpara>It turned out that the exam was way above the level of the students and a grade correction needs to be applied. We can use value script to get the new average:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        ...

        "aggs" : {
            "avg_corrected_grade" : {
                "avg" : {
                    "field" : "grade",
                    "script" : {
                        "lang": "painless",
                        "inline": "_value * params.correction",
                        "params" : {
                            "correction" : 1.2
                        }
                    }
                }
            }
        }
    }
}</programlisting>
</section>
</section>
<section id="_missing_value">
<title>Missing value<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/avg-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>missing</literal> parameter defines how documents that are missing a value should be treated.
By default they will be ignored but it is also possible to treat them as if they
had a value.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "grade_avg" : {
            "avg" : {
                "field" : "grade",
                "missing": 10 <co id="CO41-1"/>
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO41-1">
<para>
Documents without a value in the <literal>grade</literal> field will fall into the same bucket as documents that have the value <literal>10</literal>.
</para>
</callout>
</calloutlist>
</section>
</section>
<section id="search-aggregations-metrics-cardinality-aggregation">
<title>Cardinality Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/cardinality-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A <literal>single-value</literal> metrics aggregation that calculates an approximate count of
distinct values. Values can be extracted either from specific fields in the
document or generated by a script.</simpara>
<simpara>Assume you are indexing books and would like to count the unique authors that
match a query:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "author_count" : {
            "cardinality" : {
                "field" : "author"
            }
        }
    }
}</programlisting>
<section id="_precision_control">
<title>Precision control<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/cardinality-aggregation.asciidoc">Edit me</ulink></title>
<simpara>This aggregation also supports the <literal>precision_threshold</literal> option:</simpara>
<warning role="experimental"><simpara>The <literal>precision_threshold</literal> option is specific to the current internal implementation of the <literal>cardinality</literal> agg, which may change in the future.</simpara></warning>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "author_count" : {
            "cardinality" : {
                "field" : "author_hash",
                "precision_threshold": 100 <co id="CO42-1"/>
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO42-1">
<para>
The <literal>precision_threshold</literal> options allows to trade memory for accuracy, and
defines a unique count below which counts are expected to be close to
accurate. Above this value, counts might become a bit more fuzzy. The maximum
supported value is 40000, thresholds above this number will have the same
effect as a threshold of 40000. The default values is <literal>3000</literal>.
</para>
</callout>
</calloutlist>
</section>
<section id="_counts_are_approximate">
<title>Counts are approximate<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/cardinality-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Computing exact counts requires loading values into a hash set and returning its
size. This doesn&#8217;t scale when working on high-cardinality sets and/or large
values as the required memory usage and the need to communicate those
per-shard sets between nodes would utilize too many resources of the cluster.</simpara>
<simpara>This <literal>cardinality</literal> aggregation is based on the
<ulink url="http://static.googleusercontent.com/media/research.google.com/fr//pubs/archive/40671.pdf">HyperLogLog++</ulink>
algorithm, which counts based on the hashes of the values with some interesting
properties:</simpara>
<itemizedlist>
<listitem>
<simpara>
configurable precision, which decides on how to trade memory for accuracy,
</simpara>
</listitem>
<listitem>
<simpara>
excellent accuracy on low-cardinality sets,
</simpara>
</listitem>
<listitem>
<simpara>
fixed memory usage: no matter if there are tens or billions of unique values,
   memory usage only depends on the configured precision.
</simpara>
</listitem>
</itemizedlist>
<simpara>For a precision threshold of <literal>c</literal>, the implementation that we are using requires
about <literal>c * 8</literal> bytes.</simpara>
<simpara>The following chart shows how the error varies before and after the threshold:</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/cardinality_error.png"/>
  </imageobject>
  <textobject><phrase>images/cardinality_error.png</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>For all 3 thresholds, counts have been accurate up to the configured threshold
(although not guaranteed, this is likely to be the case). Please also note that
even with a threshold as low as 100, the error remains very low, even when
counting millions of items.</simpara>
</section>
<section id="_pre_computed_hashes">
<title>Pre-computed hashes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/cardinality-aggregation.asciidoc">Edit me</ulink></title>
<simpara>On string fields that have a high cardinality, it might be faster to store the
hash of your field values in your index and then run the cardinality aggregation
on this field. This can either be done by providing hash values from client-side
or by letting elasticsearch compute hash values for you by using the
<ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/mapper-murmur3.html"><literal>mapper-murmur3</literal></ulink> plugin.</simpara>
<note><simpara>Pre-computing hashes is usually only useful on very large and/or
high-cardinality fields as it saves CPU and memory. However, on numeric
fields, hashing is very fast and storing the original values requires as much
or less memory than storing the hashes. This is also true on low-cardinality
string fields, especially given that those have an optimization in order to
make sure that hashes are computed at most once per unique value per segment.</simpara></note>
</section>
<section id="_script_2">
<title>Script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/cardinality-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>cardinality</literal> metric supports scripting, with a noticeable performance hit
however since hashes need to be computed on the fly.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "author_count" : {
            "cardinality" : {
                "script": {
                    "lang": "painless",
                    "inline": "doc['author.first_name'].value + ' ' + doc['author.last_name'].value"
                }
            }
        }
    }
}</programlisting>
<simpara>This will interpret the <literal>script</literal> parameter as an <literal>inline</literal> script with the <literal>painless</literal> script language and no script parameters. To use a file script use the following syntax:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "author_count" : {
            "cardinality" : {
                "script" : {
                    "file": "my_script",
                    "params": {
                        "first_name_field": "author.first_name",
                        "last_name_field": "author.last_name"
                    }
                }
            }
        }
    }
}</programlisting>
<tip><simpara>for indexed scripts replace the <literal>file</literal> parameter with an <literal>id</literal> parameter.</simpara></tip>
</section>
<section id="_missing_value_2">
<title>Missing value<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/cardinality-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>missing</literal> parameter defines how documents that are missing a value should be treated.
By default they will be ignored but it is also possible to treat them as if they
had a value.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "tag_cardinality" : {
            "cardinality" : {
                "field" : "tag",
                "missing": "N/A" <co id="CO43-1"/>
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO43-1">
<para>
Documents without a value in the <literal>tag</literal> field will fall into the same bucket as documents that have the value <literal>N/A</literal>.
</para>
</callout>
</calloutlist>
</section>
</section>
<section id="search-aggregations-metrics-extendedstats-aggregation">
<title>Extended Stats Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/extendedstats-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A <literal>multi-value</literal> metrics aggregation that computes stats over numeric values extracted from the aggregated documents. These values can be extracted either from specific numeric fields in the documents, or be generated by a provided script.</simpara>
<simpara>The <literal>extended_stats</literal> aggregations is an extended version of the <link linkend="search-aggregations-metrics-stats-aggregation"><literal>stats</literal></link> aggregation, where additional metrics are added such as <literal>sum_of_squares</literal>, <literal>variance</literal>, <literal>std_deviation</literal> and <literal>std_deviation_bounds</literal>.</simpara>
<simpara>Assuming the data consists of documents representing exams grades (between 0 and 100) of students</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "grades_stats" : { "extended_stats" : { "field" : "grade" } }
    }
}</programlisting>
<simpara>The above aggregation computes the grades statistics over all documents. The aggregation type is <literal>extended_stats</literal> and the <literal>field</literal> setting defines the numeric field of the documents the stats will be computed on. The above will return the following:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

    "aggregations": {
        "grade_stats": {
           "count": 9,
           "min": 72,
           "max": 99,
           "avg": 86,
           "sum": 774,
           "sum_of_squares": 67028,
           "variance": 51.55555555555556,
           "std_deviation": 7.180219742846005,
           "std_deviation_bounds": {
            "upper": 100.36043948569201,
            "lower": 71.63956051430799
           }
        }
    }
}</programlisting>
<simpara>The name of the aggregation (<literal>grades_stats</literal> above) also serves as the key by which the aggregation result can be retrieved from the returned response.</simpara>
<section id="_standard_deviation_bounds">
<title>Standard Deviation Bounds<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/extendedstats-aggregation.asciidoc">Edit me</ulink></title>
<simpara>By default, the <literal>extended_stats</literal> metric will return an object called <literal>std_deviation_bounds</literal>, which provides an interval of plus/minus two standard
deviations from the mean.  This can be a useful way to visualize variance of your data.  If you want a different boundary, for example
three standard deviations, you can set <literal>sigma</literal> in the request:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "grades_stats" : {
            "extended_stats" : {
                "field" : "grade",
                "sigma" : 3 <co id="CO44-1"/>
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO44-1">
<para>
<literal>sigma</literal> controls how many standard deviations +/- from the mean should be displayed
</para>
</callout>
</calloutlist>
<simpara><literal>sigma</literal> can be any non-negative double, meaning you can request non-integer values such as <literal>1.5</literal>.  A value of <literal>0</literal> is valid, but will simply
return the average for both <literal>upper</literal> and <literal>lower</literal> bounds.</simpara>
<note>
<title>Standard Deviation and Bounds require normality</title>
<simpara>The standard deviation and its bounds are displayed by default, but they are not always applicable to all data-sets.  Your data must
be normally distributed for the metrics to make sense.  The statistics behind standard deviations assumes normally distributed data, so
if your data is skewed heavily left or right, the value returned will be misleading.</simpara>
</note>
</section>
<section id="_script_3">
<title>Script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/extendedstats-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Computing the grades stats based on a script:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...,

    "aggs" : {
        "grades_stats" : {
            "extended_stats" : {
                "script" : {
                    "inline" : "doc['grade'].value",
                    "lang" : "painless"
                 }
             }
         }
    }
}</programlisting>
<simpara>This will interpret the <literal>script</literal> parameter as an <literal>inline</literal> script with the <literal>painless</literal> script language and no script parameters. To use a file script use the following syntax:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...,

    "aggs" : {
        "grades_stats" : {
            "extended_stats" : {
                "script" : {
                    "file": "my_script",
                    "params": {
                        "field": "grade"
                    }
                }
            }
        }
    }
}</programlisting>
<tip><simpara>for indexed scripts replace the <literal>file</literal> parameter with an <literal>id</literal> parameter.</simpara></tip>
<section id="_value_script_2">
<title>Value Script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/extendedstats-aggregation.asciidoc">Edit me</ulink></title>
<simpara>It turned out that the exam was way above the level of the students and a grade correction needs to be applied. We can use value script to get the new stats:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        ...

        "aggs" : {
            "grades_stats" : {
                "extended_stats" : {
                    "field" : "grade",
                    "script" : {
                        "lang" : "painless",
                        "inline": "_value * params.correction",
                        "params" : {
                            "correction" : 1.2
                        }
                    }
                }
            }
        }
    }
}</programlisting>
</section>
</section>
<section id="_missing_value_3">
<title>Missing value<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/extendedstats-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>missing</literal> parameter defines how documents that are missing a value should be treated.
By default they will be ignored but it is also possible to treat them as if they
had a value.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "grades_stats" : {
            "extended_stats" : {
                "field" : "grade",
                "missing": 0 <co id="CO45-1"/>
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO45-1">
<para>
Documents without a value in the <literal>grade</literal> field will fall into the same bucket as documents that have the value <literal>0</literal>.
</para>
</callout>
</calloutlist>
</section>
</section>
<section id="search-aggregations-metrics-geobounds-aggregation">
<title>Geo Bounds Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/geobounds-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A metric aggregation that computes the bounding box containing all geo_point values for a field.</simpara>
<simpara>Example:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "query" : {
        "match" : { "business_type" : "shop" }
    },
    "aggs" : {
        "viewport" : {
            "geo_bounds" : {
                "field" : "location", <co id="CO46-1"/>
                "wrap_longitude" : true <co id="CO46-2"/>
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO46-1">
<para>
The <literal>geo_bounds</literal> aggregation specifies the field to use to obtain the bounds
</para>
</callout>
<callout arearefs="CO46-2">
<para>
<literal>wrap_longitude</literal> is an optional parameter which specifies whether the bounding box should be allowed to overlap the international date line. The default value is <literal>true</literal>
</para>
</callout>
</calloutlist>
<simpara>The above aggregation demonstrates how one would compute the bounding box of the location field for all documents with a business type of shop</simpara>
<simpara>The response for the above aggregation:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

    "aggregations": {
        "viewport": {
            "bounds": {
                "top_left": {
                    "lat": 80.45,
                    "lon": -160.22
                },
                "bottom_right": {
                    "lat": 40.65,
                    "lon": 42.57
                }
            }
        }
    }
}</programlisting>
</section>
<section id="search-aggregations-metrics-geocentroid-aggregation">
<title>Geo Centroid Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/geocentroid-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A metric aggregation that computes the weighted centroid from all coordinate values for a <xref linkend="geo-point"/> field.</simpara>
<simpara>Example:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "query" : {
        "match" : { "crime" : "burglary" }
    },
    "aggs" : {
        "centroid" : {
            "geo_centroid" : {
                "field" : "location" <co id="CO47-1"/>
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO47-1">
<para>
The <literal>geo_centroid</literal> aggregation specifies the field to use for computing the centroid. (NOTE: field must be a <xref linkend="geo-point"/> type)
</para>
</callout>
</calloutlist>
<simpara>The above aggregation demonstrates how one would compute the centroid of the location field for all documents with a crime type of burglary</simpara>
<simpara>The response for the above aggregation:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

    "aggregations": {
        "centroid": {
            "location": {
                "lat": 80.45,
                "lon": -160.22
            }
        }
    }
}</programlisting>
<simpara>The <literal>geo_centroid</literal> aggregation is more interesting when combined as a sub-aggregation to other bucket aggregations.</simpara>
<simpara>Example:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "query" : {
        "match" : { "crime" : "burglary" }
    },
    "aggs" : {
        "towns" : {
            "terms" : { "field" : "town" },
            "aggs" : {
                "centroid" : {
                    "geo_centroid" : { "field" : "location" }
                }
            }
        }
    }
}</programlisting>
<simpara>The above example uses <literal>geo_centroid</literal> as a sub-aggregation to a <link linkend="search-aggregations-bucket-terms-aggregation">terms</link> bucket aggregation
for finding the central location for all crimes of type burglary in each town.</simpara>
<simpara>The response for the above aggregation:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

    "buckets": [
       {
           "key": "Los Altos",
           "doc_count": 113,
           "centroid": {
              "location": {
                 "lat": 37.3924582824111,
                 "lon": -122.12104808539152
              }
           }
       },
       {
           "key": "Mountain View",
           "doc_count": 92,
           "centroid": {
              "location": {
                 "lat": 37.382152481004596,
                 "lon": -122.08116559311748
              }
           }
        }
    ]
}</programlisting>
</section>
<section id="search-aggregations-metrics-max-aggregation">
<title>Max Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/max-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A <literal>single-value</literal> metrics aggregation that keeps track and returns the maximum value among the numeric values extracted from the aggregated documents. These values can be extracted either from specific numeric fields in the documents, or be generated by a provided script.</simpara>
<note><simpara>The <literal>min</literal> and <literal>max</literal> aggregation operate on the <literal>double</literal> representation of
the data. As a consequence, the result may be approximate when running on longs
whose absolute value is greater than <literal>2^53</literal>.</simpara></note>
<simpara>Computing the max price value across all documents</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "max_price" : { "max" : { "field" : "price" } }
    }
}</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

    "aggregations": {
        "max_price": {
            "value": 35
        }
    }
}</programlisting>
<simpara>As can be seen, the name of the aggregation (<literal>max_price</literal> above) also serves as the key by which the aggregation result can be retrieved from the returned response.</simpara>
<section id="_script_4">
<title>Script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/max-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Computing the max price value across all document, this time using a script:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "max_price" : {
            "max" : {
                "script" : {
                    "inline" : "doc['price'].value",
                    "lang" : "painless"
                }
            }
        }
    }
}</programlisting>
<simpara>This will interpret the <literal>script</literal> parameter as an <literal>inline</literal> script with the <literal>painless</literal> script language and no script parameters. To use a file script use the following syntax:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "max_price" : {
            "max" : {
                "script" : {
                    "file": "my_script",
                    "params": {
                        "field": "price"
                    }
                }
            }
        }
    }
}</programlisting>
<tip><simpara>for indexed scripts replace the <literal>file</literal> parameter with an <literal>id</literal> parameter.</simpara></tip>
</section>
<section id="_value_script_3">
<title>Value Script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/max-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Let&#8217;s say that the prices of the documents in our index are in USD, but we would like to compute the max in EURO (and for the sake of this example, lets say the conversion rate is 1.2). We can use a value script to apply the conversion rate to every value before it is aggregated:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "max_price_in_euros" : {
            "max" : {
                "field" : "price",
                "script" : {
                    "lang": "painless",
                    "inline": "_value * params.conversion_rate",
                    "params" : {
                        "conversion_rate" : 1.2
                    }
                }
            }
        }
    }
}</programlisting>
</section>
<section id="_missing_value_4">
<title>Missing value<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/max-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>missing</literal> parameter defines how documents that are missing a value should be treated.
By default they will be ignored but it is also possible to treat them as if they
had a value.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "grade_max" : {
            "max" : {
                "field" : "grade",
                "missing": 10 <co id="CO48-1"/>
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO48-1">
<para>
Documents without a value in the <literal>grade</literal> field will fall into the same bucket as documents that have the value <literal>10</literal>.
</para>
</callout>
</calloutlist>
</section>
</section>
<section id="search-aggregations-metrics-min-aggregation">
<title>Min Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/min-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A <literal>single-value</literal> metrics aggregation that keeps track and returns the minimum value among numeric values extracted from the aggregated documents. These values can be extracted either from specific numeric fields in the documents, or be generated by a provided script.</simpara>
<note><simpara>The <literal>min</literal> and <literal>max</literal> aggregation operate on the <literal>double</literal> representation of
the data. As a consequence, the result may be approximate when running on longs
whose absolute value is greater than <literal>2^53</literal>.</simpara></note>
<simpara>Computing the min price value across all documents:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "min_price" : { "min" : { "field" : "price" } }
    }
}</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

    "aggregations": {
        "min_price": {
            "value": 10
        }
    }
}</programlisting>
<simpara>As can be seen, the name of the aggregation (<literal>min_price</literal> above) also serves as the key by which the aggregation result can be retrieved from the returned response.</simpara>
<section id="_script_5">
<title>Script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/min-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Computing the min price value across all document, this time using a script:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "min_price" : {
            "min" : {
                "script" : {
                    "inline" : "doc['price'].value",
                    "lang" : "painless"
                }
            }
        }
    }
}</programlisting>
<simpara>This will interpret the <literal>script</literal> parameter as an <literal>inline</literal> script with the <literal>painless</literal> script language and no script parameters. To use a file script use the following syntax:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "min_price" : {
            "min" : {
                "script" : {
                    "file": "my_script",
                    "params": {
                        "field": "price"
                    }
                }
            }
        }
    }
}</programlisting>
<tip><simpara>for indexed scripts replace the <literal>file</literal> parameter with an <literal>id</literal> parameter.</simpara></tip>
</section>
<section id="_value_script_4">
<title>Value Script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/min-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Let&#8217;s say that the prices of the documents in our index are in USD, but we would like to compute the min in EURO (and for the sake of this example, lets say the conversion rate is 1.2). We can use a value script to apply the conversion rate to every value before it is aggregated:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "min_price_in_euros" : {
            "min" : {
                "field" : "price",
                "script" :
                    "lang" : "painless",
                    "inline": "_value * params.conversion_rate",
                    "params" : {
                        "conversion_rate" : 1.2
                    }
                }
            }
        }
    }
}</programlisting>
</section>
<section id="_missing_value_5">
<title>Missing value<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/min-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>missing</literal> parameter defines how documents that are missing a value should be treated.
By default they will be ignored but it is also possible to treat them as if they
had a value.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "grade_min" : {
            "min" : {
                "field" : "grade",
                "missing": 10 <co id="CO49-1"/>
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO49-1">
<para>
Documents without a value in the <literal>grade</literal> field will fall into the same bucket as documents that have the value <literal>10</literal>.
</para>
</callout>
</calloutlist>
</section>
</section>
<section id="search-aggregations-metrics-percentile-aggregation">
<title>Percentiles Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/percentile-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A <literal>multi-value</literal> metrics aggregation that calculates one or more percentiles
over numeric values extracted from the aggregated documents.  These values
can be extracted either from specific numeric fields in the documents, or
be generated by a provided script.</simpara>
<simpara>Percentiles show the point at which a certain percentage of observed values
occur.  For example, the 95th percentile is the value which is greater than 95%
of the observed values.</simpara>
<simpara>Percentiles are often used to find outliers.  In normal distributions, the
0.13th and 99.87th percentiles represents three standard deviations from the
mean.  Any data which falls outside three standard deviations is often considered
an anomaly.</simpara>
<simpara>When a range of percentiles are retrieved, they can be used to estimate the
data distribution and determine if the data is skewed, bimodal, etc.</simpara>
<simpara>Assume your data consists of website load times.  The average and median
load times are not overly useful to an administrator.  The max may be interesting,
but it can be easily skewed by a single slow response.</simpara>
<simpara>Let&#8217;s look at a range of percentiles representing load time:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "load_time_outlier" : {
            "percentiles" : {
                "field" : "load_time" <co id="CO50-1"/>
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO50-1">
<para>
The field <literal>load_time</literal> must be a numeric field
</para>
</callout>
</calloutlist>
<simpara>By default, the <literal>percentile</literal> metric will generate a range of
percentiles: <literal>[ 1, 5, 25, 50, 75, 95, 99 ]</literal>.  The response will look like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

   "aggregations": {
      "load_time_outlier": {
         "values" : {
            "1.0": 15,
            "5.0": 20,
            "25.0": 23,
            "50.0": 25,
            "75.0": 29,
            "95.0": 60,
            "99.0": 150
         }
      }
   }
}</programlisting>
<simpara>As you can see, the aggregation will return a calculated value for each percentile
in the default range.  If we assume response times are in milliseconds, it is
immediately obvious that the webpage normally loads in 15-30ms, but occasionally
spikes to 60-150ms.</simpara>
<simpara>Often, administrators are only interested in outliers&#8201;&#8212;&#8201;the extreme percentiles.
We can specify just the percents we are interested in (requested percentiles
must be a value between 0-100 inclusive):</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "load_time_outlier" : {
            "percentiles" : {
                "field" : "load_time",
                "percents" : [95, 99, 99.9] <co id="CO51-1"/>
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO51-1">
<para>
Use the <literal>percents</literal> parameter to specify particular percentiles to calculate
</para>
</callout>
</calloutlist>
<section id="_script_6">
<title>Script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/percentile-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The percentile metric supports scripting.  For example, if our load times
are in milliseconds but we want percentiles calculated in seconds, we could use
a script to convert them on-the-fly:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "load_time_outlier" : {
            "percentiles" : {
                "script" : {
                    "lang": "painless",
                    "inline": "doc['load_time'].value / params.timeUnit", <co id="CO52-1"/>
                    "params" : {
                        "timeUnit" : 1000   <co id="CO52-2"/>
                    }
                }
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO52-1">
<para>
The <literal>field</literal> parameter is replaced with a <literal>script</literal> parameter, which uses the
script to generate values which percentiles are calculated on
</para>
</callout>
<callout arearefs="CO52-2">
<para>
Scripting supports parameterized input just like any other script
</para>
</callout>
</calloutlist>
<simpara>This will interpret the <literal>script</literal> parameter as an <literal>inline</literal> script with the <literal>painless</literal> script language and no script parameters. To use a file script use the following syntax:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "load_time_outlier" : {
            "percentiles" : {
                "script" : {
                    "file": "my_script",
                    "params" : {
                        "timeUnit" : 1000
                    }
                }
            }
        }
    }
}</programlisting>
<tip><simpara>for indexed scripts replace the <literal>file</literal> parameter with an <literal>id</literal> parameter.</simpara></tip>
</section>
<section id="search-aggregations-metrics-percentile-aggregation-approximation">
<title>Percentiles are (usually) approximate<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/percentile-aggregation.asciidoc">Edit me</ulink></title>
<simpara>There are many different algorithms to calculate percentiles.  The naive
implementation simply stores all the values in a sorted array.  To find the 50th
percentile, you simply find the value that is at <literal>my_array[count(my_array) * 0.5]</literal>.</simpara>
<simpara>Clearly, the naive implementation does not scale&#8201;&#8212;&#8201;the sorted array grows
linearly with the number of values in your dataset.  To calculate percentiles
across potentially billions of values in an Elasticsearch cluster, <emphasis>approximate</emphasis>
percentiles are calculated.</simpara>
<simpara>The algorithm used by the <literal>percentile</literal> metric is called TDigest (introduced by
Ted Dunning in
<ulink url="https://github.com/tdunning/t-digest/blob/master/docs/t-digest-paper/histo.pdf">Computing Accurate Quantiles using T-Digests</ulink>).</simpara>
<simpara>When using this metric, there are a few guidelines to keep in mind:</simpara>
<itemizedlist>
<listitem>
<simpara>
Accuracy is proportional to <literal>q(1-q)</literal>.  This means that extreme percentiles (e.g. 99%)
are more accurate than less extreme percentiles, such as the median
</simpara>
</listitem>
<listitem>
<simpara>
For small sets of values, percentiles are highly accurate (and potentially
100% accurate if the data is small enough).
</simpara>
</listitem>
<listitem>
<simpara>
As the quantity of values in a bucket grows, the algorithm begins to approximate
the percentiles.  It is effectively trading accuracy for memory savings.  The
exact level of inaccuracy is difficult to generalize, since it depends on your
data distribution and volume of data being aggregated
</simpara>
</listitem>
</itemizedlist>
<simpara>The following chart shows the relative error on a uniform distribution depending
on the number of collected values and the requested percentile:</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/percentiles_error.png"/>
  </imageobject>
  <textobject><phrase>images/percentiles_error.png</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>It shows how precision is better for extreme percentiles. The reason why error diminishes
for large number of values is that the law of large numbers makes the distribution of
values more and more uniform and the t-digest tree can do a better job at summarizing
it. It would not be the case on more skewed distributions.</simpara>
</section>
<section id="search-aggregations-metrics-percentile-aggregation-compression">
<title>Compression<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/percentile-aggregation.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>The <literal>compression</literal> parameter is specific to the current internal implementation of percentiles, and may change in the future.</simpara></warning>
<simpara>Approximate algorithms must balance memory utilization with estimation accuracy.
This balance can be controlled using a <literal>compression</literal> parameter:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "load_time_outlier" : {
            "percentiles" : {
                "field" : "load_time",
                "tdigest": {
                  "compression" : 200 <co id="CO53-1"/>
                }
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO53-1">
<para>
Compression controls memory usage and approximation error
</para>
</callout>
</calloutlist>
<simpara>The TDigest algorithm uses a number of "nodes" to approximate percentiles&#8201;&#8212;&#8201;the
more nodes available, the higher the accuracy (and large memory footprint) proportional
to the volume of data.  The <literal>compression</literal> parameter limits the maximum number of
nodes to <literal>20 * compression</literal>.</simpara>
<simpara>Therefore, by increasing the compression value, you can increase the accuracy of
your percentiles at the cost of more memory.  Larger compression values also
make the algorithm slower since the underlying tree data structure grows in size,
resulting in more expensive operations.  The default compression value is
<literal>100</literal>.</simpara>
<simpara>A "node" uses roughly 32 bytes of memory, so under worst-case scenarios (large amount
of data which arrives sorted and in-order) the default settings will produce a
TDigest roughly 64KB in size.  In practice data tends to be more random and
the TDigest will use less memory.</simpara>
</section>
<section id="_hdr_histogram">
<title>HDR Histogram<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/percentile-aggregation.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This functionality is experimental and may be changed or removed completely in a future release.</simpara></warning>
<simpara><ulink url="https://github.com/HdrHistogram/HdrHistogram">HDR Histogram</ulink> (High Dynamic Range Histogram) is an alternative implementation
that can be useful when calculating percentiles for latency measurements as it can be faster than the t-digest implementation
with the trade-off of a larger memory footprint. This implementation maintains a fixed worse-case percentage error (specified
as a number of significant digits). This means that if data is recorded with values from 1 microsecond up to 1 hour
(3,600,000,000 microseconds) in a histogram set to 3 significant digits, it will maintain a value resolution of 1 microsecond
for values up to 1 millisecond and 3.6 seconds (or better) for the maximum tracked value (1 hour).</simpara>
<simpara>The HDR Histogram can be used by specifying the <literal>method</literal> parameter in the request:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "load_time_outlier" : {
            "percentiles" : {
                "field" : "load_time",
                "percents" : [95, 99, 99.9],
                "hdr": { <co id="CO54-1"/>
                  "number_of_significant_value_digits" : 3 <co id="CO54-2"/>
                }
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO54-1">
<para>
<literal>hdr</literal> object indicates that HDR Histogram should be used to calculate the percentiles and specific settings for this algorithm can be specified inside the object
</para>
</callout>
<callout arearefs="CO54-2">
<para>
<literal>number_of_significant_value_digits</literal> specifies the resolution of values for the histogram in number of significant digits
</para>
</callout>
</calloutlist>
<simpara>The HDRHistogram only supports positive values and will error if it is passed a negative value. It is also not a good idea to use
the HDRHistogram if the range of values is unknown as this could lead to high memory usage.</simpara>
</section>
<section id="_missing_value_6">
<title>Missing value<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/percentile-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>missing</literal> parameter defines how documents that are missing a value should be treated.
By default they will be ignored but it is also possible to treat them as if they
had a value.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "grade_percentiles" : {
            "percentiles" : {
                "field" : "grade",
                "missing": 10 <co id="CO55-1"/>
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO55-1">
<para>
Documents without a value in the <literal>grade</literal> field will fall into the same bucket as documents that have the value <literal>10</literal>.
</para>
</callout>
</calloutlist>
</section>
</section>
<section id="search-aggregations-metrics-percentile-rank-aggregation">
<title>Percentile Ranks Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/percentile-rank-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A <literal>multi-value</literal> metrics aggregation that calculates one or more percentile ranks
over numeric values extracted from the aggregated documents.  These values
can be extracted either from specific numeric fields in the documents, or
be generated by a provided script.</simpara>
<note>
<simpara>Please see <xref linkend="search-aggregations-metrics-percentile-aggregation-approximation"/>
and <xref linkend="search-aggregations-metrics-percentile-aggregation-compression"/> for advice
regarding approximation and memory use of the percentile ranks aggregation</simpara>
</note>
<simpara>Percentile rank show the percentage of observed values which are below certain
value.  For example, if a value is greater than or equal to 95% of the observed values
it is said to be at the 95th percentile rank.</simpara>
<simpara>Assume your data consists of website load times.  You may have a service agreement that
95% of page loads completely within 15ms and 99% of page loads complete within 30ms.</simpara>
<simpara>Let&#8217;s look at a range of percentiles representing load time:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "load_time_outlier" : {
            "percentile_ranks" : {
                "field" : "load_time", <co id="CO56-1"/>
                "values" : [15, 30]
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO56-1">
<para>
The field <literal>load_time</literal> must be a numeric field
</para>
</callout>
</calloutlist>
<simpara>The response will look like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

   "aggregations": {
      "load_time_outlier": {
         "values" : {
            "15": 92,
            "30": 100
         }
      }
   }
}</programlisting>
<simpara>From this information you can determine you are hitting the 99% load time target but not quite
hitting the 95% load time target</simpara>
<section id="_script_7">
<title>Script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/percentile-rank-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The percentile rank metric supports scripting.  For example, if our load times
are in milliseconds but we want to specify values in seconds, we could use
a script to convert them on-the-fly:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "load_time_outlier" : {
            "percentile_ranks" : {
                "values" : [3, 5],
                "script" : {
                    "lang": "painless",
                    "inline": "doc['load_time'].value / params.timeUnit", <co id="CO57-1"/>
                    "params" : {
                        "timeUnit" : 1000   <co id="CO57-2"/>
                    }
                }
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO57-1">
<para>
The <literal>field</literal> parameter is replaced with a <literal>script</literal> parameter, which uses the
script to generate values which percentile ranks are calculated on
</para>
</callout>
<callout arearefs="CO57-2">
<para>
Scripting supports parameterized input just like any other script
</para>
</callout>
</calloutlist>
<simpara>This will interpret the <literal>script</literal> parameter as an <literal>inline</literal> script with the <literal>painless</literal> script language and no script parameters. To use a file script use the following syntax:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "load_time_outlier" : {
            "percentile_ranks" : {
                "values" : [3, 5],
                "script" : {
                    "file": "my_script",
                    "params" : {
                        "timeUnit" : 1000
                    }
                }
            }
        }
    }
}</programlisting>
<tip><simpara>for indexed scripts replace the <literal>file</literal> parameter with an <literal>id</literal> parameter.</simpara></tip>
</section>
<section id="_hdr_histogram_2">
<title>HDR Histogram<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/percentile-rank-aggregation.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This functionality is experimental and may be changed or removed completely in a future release.</simpara></warning>
<simpara><ulink url="https://github.com/HdrHistogram/HdrHistogram">HDR Histogram</ulink> (High Dynamic Range Histogram) is an alternative implementation
that can be useful when calculating percentile ranks for latency measurements as it can be faster than the t-digest implementation
with the trade-off of a larger memory footprint. This implementation maintains a fixed worse-case percentage error (specified as a
number of significant digits). This means that if data is recorded with values from 1 microsecond up to 1 hour (3,600,000,000
microseconds) in a histogram set to 3 significant digits, it will maintain a value resolution of 1 microsecond for values up to
1 millisecond and 3.6 seconds (or better) for the maximum tracked value (1 hour).</simpara>
<simpara>The HDR Histogram can be used by specifying the <literal>method</literal> parameter in the request:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "load_time_outlier" : {
            "percentile_ranks" : {
                "field" : "load_time",
                "values" : [15, 30],
                "hdr": { <co id="CO58-1"/>
                  "number_of_significant_value_digits" : 3 <co id="CO58-2"/>
                }
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO58-1">
<para>
<literal>hdr</literal> object indicates that HDR Histogram should be used to calculate the percentiles and specific settings for this algorithm can be specified inside the object
</para>
</callout>
<callout arearefs="CO58-2">
<para>
<literal>number_of_significant_value_digits</literal> specifies the resolution of values for the histogram in number of significant digits
</para>
</callout>
</calloutlist>
<simpara>The HDRHistogram only supports positive values and will error if it is passed a negative value. It is also not a good idea to use
the HDRHistogram if the range of values is unknown as this could lead to high memory usage.</simpara>
</section>
<section id="_missing_value_7">
<title>Missing value<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/percentile-rank-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>missing</literal> parameter defines how documents that are missing a value should be treated.
By default they will be ignored but it is also possible to treat them as if they
had a value.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "grade_ranks" : {
            "percentile_ranks" : {
                "field" : "grade",
                "missing": 10 <co id="CO59-1"/>
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO59-1">
<para>
Documents without a value in the <literal>grade</literal> field will fall into the same bucket as documents that have the value <literal>10</literal>.
</para>
</callout>
</calloutlist>
</section>
</section>
<section id="search-aggregations-metrics-scripted-metric-aggregation">
<title>Scripted Metric Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/scripted-metric-aggregation.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This functionality is experimental and may be changed or removed completely in a future release.</simpara></warning>
<simpara>A metric aggregation that executes using scripts to provide a metric output.</simpara>
<simpara>Example:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST ledger/_search?size=0
{
    "query" : {
        "match_all" : {}
    },
    "aggs": {
        "profit": {
            "scripted_metric": {
                "init_script" : "params._agg.transactions = []",
                "map_script" : "params._agg.transactions.add(doc.type.value == 'sale' ? doc.amount.value : -1 * doc.amount.value)", <co id="CO60-1"/>
                "combine_script" : "double profit = 0; for (t in params._agg.transactions) { profit += t } return profit",
                "reduce_script" : "double profit = 0; for (a in params._aggs) { profit += a } return profit"
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:ledger]</remark>
<calloutlist>
<callout arearefs="CO60-1">
<para>
<literal>map_script</literal> is the only required  parameter
</para>
</callout>
</calloutlist>
<simpara>The above aggregation demonstrates how one would use the script aggregation compute the total profit from sale and cost transactions.</simpara>
<simpara>The response for the above aggregation:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "took": 218,
    ...
    "aggregations": {
        "profit": {
            "value": 240.0
        }
   }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 218/"took": $body.took/]</remark>
<remark> TESTRESPONSE[s/\.\.\./"_shards": $body._shards, "hits": $body.hits, "timed_out": false,/]</remark>
<simpara>The above example can also be specified using file scripts as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST ledger/_search?size=0
{
    "aggs": {
        "profit": {
            "scripted_metric": {
                "init_script" : {
                    "file": "my_init_script"
                },
                "map_script" : {
                    "file": "my_map_script"
                },
                "combine_script" : {
                    "file": "my_combine_script"
                },
                "params": {
                    "field": "amount", <co id="CO61-1"/>
                    "_agg": {}        <co id="CO61-2"/>
                },
                "reduce_script" : {
                    "file": "my_reduce_script"
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:ledger]</remark>
<calloutlist>
<callout arearefs="CO61-1">
<para>
script parameters for <literal>init</literal>, <literal>map</literal> and <literal>combine</literal> scripts must be specified
in a global <literal>params</literal> object so that it can be share between the scripts.
</para>
</callout>
<callout arearefs="CO61-2">
<para>
if you specify script parameters then you must specify <literal>"_agg": {}</literal>.
</para>
</callout>
</calloutlist>
<simpara>For more details on specifying scripts see <link linkend="modules-scripting">script documentation</link>.</simpara>
<section id="_allowed_return_types">
<title>Allowed return types<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/scripted-metric-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Whilst any valid script object can be used within a single script, the scripts must return or store in the <literal>_agg</literal> object only the following types:</simpara>
<itemizedlist>
<listitem>
<simpara>
primitive types
</simpara>
</listitem>
<listitem>
<simpara>
String
</simpara>
</listitem>
<listitem>
<simpara>
Map (containing only keys and values of the types listed here)
</simpara>
</listitem>
<listitem>
<simpara>
Array (containing elements of only the types listed here)
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_scope_of_scripts">
<title>Scope of scripts<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/scripted-metric-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The scripted metric aggregation uses scripts at 4 stages of its execution:</simpara>
<variablelist>
<varlistentry>
<term>
init_script
</term>
<listitem>
<simpara>
Executed prior to any collection of documents. Allows the aggregation to set up any initial state.
</simpara>
<simpara>In the above example, the <literal>init_script</literal> creates an array <literal>transactions</literal> in the <literal>_agg</literal> object.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
map_script
</term>
<listitem>
<simpara>
Executed once per document collected. This is the only required script. If no combine_script is specified, the resulting state
                    needs to be stored in an object named <literal>_agg</literal>.
</simpara>
<simpara>In the above example, the <literal>map_script</literal> checks the value of the type field. If the value is <emphasis>sale</emphasis> the value of the amount field
is added to the transactions array. If the value of the type field is not <emphasis>sale</emphasis> the negated value of the amount field is added
to transactions.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
combine_script
</term>
<listitem>
<simpara>
Executed once on each shard after document collection is complete. Allows the aggregation to consolidate the state returned from
                    each shard. If a combine_script is not provided the combine phase will return the aggregation variable.
</simpara>
<simpara>In the above example, the <literal>combine_script</literal> iterates through all the stored transactions, summing the values in the <literal>profit</literal> variable
and finally returns <literal>profit</literal>.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
reduce_script
</term>
<listitem>
<simpara>
Executed once on the coordinating node after all shards have returned their results. The script is provided with access to a
                    variable <literal>_aggs</literal> which is an array of the result of the combine_script on each shard. If a reduce_script is not provided
                    the reduce phase will return the <literal>_aggs</literal> variable.
</simpara>
<simpara>In the above example, the <literal>reduce_script</literal> iterates through the <literal>profit</literal> returned by each shard summing the values before returning the
final combined profit which will be returned in the response of the aggregation.</simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
<section id="_worked_example">
<title>Worked Example<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/scripted-metric-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Imagine a situation where you index the following documents into and index with 2 shards:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /transactions/stock/_bulk?refresh
{"index":{"_id":1}}
{"type": "sale","amount": 80}
{"index":{"_id":2}}
{"type": "cost","amount": 10}
{"index":{"_id":2}}
{"type": "cost","amount": 30}
{"index":{"_id":2}}
{"type": "sale","amount": 130}</programlisting>
<remark> CONSOLE</remark>
<simpara>Lets say that documents 1 and 3 end up on shard A and documents 2 and 4 end up on shard B. The following is a breakdown of what the aggregation result is
at each stage of the example above.</simpara>
<section id="_before_init_script">
<title>Before init_script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/scripted-metric-aggregation.asciidoc">Edit me</ulink></title>
<simpara>No params object was specified so the default params object is used:</simpara>
<programlisting language="js" linenumbering="unnumbered">"params" : {
    "_agg" : {}
}</programlisting>
</section>
<section id="_after_init_script">
<title>After init_script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/scripted-metric-aggregation.asciidoc">Edit me</ulink></title>
<simpara>This is run once on each shard before any document collection is performed, and so we will have a copy on each shard:</simpara>
<variablelist>
<varlistentry>
<term>
Shard A
</term>
<listitem>
<programlisting language="js" linenumbering="unnumbered">"params" : {
    "_agg" : {
        "transactions" : []
    }
}</programlisting>
</listitem>
</varlistentry>
<varlistentry>
<term>
Shard B
</term>
<listitem>
<programlisting language="js" linenumbering="unnumbered">"params" : {
    "_agg" : {
        "transactions" : []
    }
}</programlisting>
</listitem>
</varlistentry>
</variablelist>
</section>
<section id="_after_map_script">
<title>After map_script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/scripted-metric-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Each shard collects its documents and runs the map_script on each document that is collected:</simpara>
<variablelist>
<varlistentry>
<term>
Shard A
</term>
<listitem>
<programlisting language="js" linenumbering="unnumbered">"params" : {
    "_agg" : {
        "transactions" : [ 80, -30 ]
    }
}</programlisting>
</listitem>
</varlistentry>
<varlistentry>
<term>
Shard B
</term>
<listitem>
<programlisting language="js" linenumbering="unnumbered">"params" : {
    "_agg" : {
        "transactions" : [ -10, 130 ]
    }
}</programlisting>
</listitem>
</varlistentry>
</variablelist>
</section>
<section id="_after_combine_script">
<title>After combine_script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/scripted-metric-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The combine_script is executed on each shard after document collection is complete and reduces all the transactions down to a single profit figure for each
shard (by summing the values in the transactions array) which is passed back to the coordinating node:</simpara>
<variablelist>
<varlistentry>
<term>
Shard A
</term>
<listitem>
<simpara>
50
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Shard B
</term>
<listitem>
<simpara>
120
</simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
<section id="_after_reduce_script">
<title>After reduce_script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/scripted-metric-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The reduce_script receives an <literal>_aggs</literal> array containing the result of the combine script for each shard:</simpara>
<programlisting language="js" linenumbering="unnumbered">"_aggs" : [
    50,
    120
]</programlisting>
<simpara>It reduces the responses for the shards down to a final overall profit figure (by summing the values) and returns this as the result of the aggregation to
produce the response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

    "aggregations": {
        "profit": {
            "value": 170
        }
   }
}</programlisting>
</section>
</section>
<section id="_other_parameters">
<title>Other Parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/scripted-metric-aggregation.asciidoc">Edit me</ulink></title>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
params
</simpara>
</entry>
<entry>
<simpara>
Optional. An object whose contents will be passed as variables to the  <literal>init_script</literal>, <literal>map_script</literal> and <literal>combine_script</literal>. This can be
                   useful to allow the user to control the behavior of the aggregation and for storing state between the scripts. If this is not specified,
                   the default is the equivalent of providing:
</simpara>
<programlisting language="js" linenumbering="unnumbered">"params" : {
    "_agg" : {}
}</programlisting>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
</section>
<section id="search-aggregations-metrics-stats-aggregation">
<title>Stats Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/stats-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A <literal>multi-value</literal> metrics aggregation that computes stats over numeric values extracted from the aggregated documents. These values can be extracted either from specific numeric fields in the documents, or be generated by a provided script.</simpara>
<simpara>The stats that are returned consist of: <literal>min</literal>, <literal>max</literal>, <literal>sum</literal>, <literal>count</literal> and <literal>avg</literal>.</simpara>
<simpara>Assuming the data consists of documents representing exams grades (between 0 and 100) of students</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "grades_stats" : { "stats" : { "field" : "grade" } }
    }
}</programlisting>
<simpara>The above aggregation computes the grades statistics over all documents. The aggregation type is <literal>stats</literal> and the <literal>field</literal> setting defines the numeric field of the documents the stats will be computed on. The above will return the following:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

    "aggregations": {
        "grades_stats": {
            "count": 6,
            "min": 60,
            "max": 98,
            "avg": 78.5,
            "sum": 471
        }
    }
}</programlisting>
<simpara>The name of the aggregation (<literal>grades_stats</literal> above) also serves as the key by which the aggregation result can be retrieved from the returned response.</simpara>
<section id="_script_8">
<title>Script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/stats-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Computing the grades stats based on a script:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...,

    "aggs" : {
        "grades_stats" : {
             "stats" : {
                 "script" : {
                     "lang": "painless",
                     "inline": "doc['grade'].value"
                 }
             }
         }
    }
}</programlisting>
<simpara>This will interpret the <literal>script</literal> parameter as an <literal>inline</literal> script with the <literal>painless</literal> script language and no script parameters. To use a file script use the following syntax:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...,

    "aggs" : {
        "grades_stats" : {
            "stats" : {
                "script" : {
                    "file": "my_script",
                    "params" : {
                        "field" : "grade"
                    }
                }
            }
        }
    }
}</programlisting>
<tip><simpara>for indexed scripts replace the <literal>file</literal> parameter with an <literal>id</literal> parameter.</simpara></tip>
<section id="_value_script_5">
<title>Value Script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/stats-aggregation.asciidoc">Edit me</ulink></title>
<simpara>It turned out that the exam was way above the level of the students and a grade correction needs to be applied. We can use a value script to get the new stats:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        ...

        "aggs" : {
            "grades_stats" : {
                "stats" : {
                    "field" : "grade",
                    "script" :
                        "lang": "painless",
                        "inline": "_value * params.correction",
                        "params" : {
                            "correction" : 1.2
                        }
                    }
                }
            }
        }
    }
}</programlisting>
</section>
</section>
<section id="_missing_value_8">
<title>Missing value<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/stats-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>missing</literal> parameter defines how documents that are missing a value should be treated.
By default they will be ignored but it is also possible to treat them as if they
had a value.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "grades_stats" : {
            "stats" : {
                "field" : "grade",
                "missing": 0 <co id="CO62-1"/>
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO62-1">
<para>
Documents without a value in the <literal>grade</literal> field will fall into the same bucket as documents that have the value <literal>0</literal>.
</para>
</callout>
</calloutlist>
</section>
</section>
<section id="search-aggregations-metrics-sum-aggregation">
<title>Sum Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/sum-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A <literal>single-value</literal> metrics aggregation that sums up numeric values that are extracted from the aggregated documents. These values can be extracted either from specific numeric fields in the documents, or be generated by a provided script.</simpara>
<simpara>Assuming the data consists of documents representing stock ticks, where each tick holds the change in the stock price from the previous tick.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "query" : {
        "constant_score" : {
            "filter" : {
                "range" : { "timestamp" : { "from" : "now/1d+9.5h", "to" : "now/1d+16h" }}
            }
        }
    },
    "aggs" : {
        "intraday_return" : { "sum" : { "field" : "change" } }
    }
}</programlisting>
<simpara>The above aggregation sums up all changes in the today&#8217;s trading stock ticks which accounts for the intraday return. The aggregation type is <literal>sum</literal> and the <literal>field</literal> setting defines the numeric field of the documents of which values will be summed up. The above will return the following:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

    "aggregations": {
        "intraday_return": {
           "value": 2.18
        }
    }
}</programlisting>
<simpara>The name of the aggregation (<literal>intraday_return</literal> above) also serves as the key by which the aggregation result can be retrieved from the returned response.</simpara>
<section id="_script_9">
<title>Script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/sum-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Computing the intraday return based on a script:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...,

    "aggs" : {
        "intraday_return" : {
            "sum" : {
                "script" : {
                   "lang": "painless",
                   "inline": "doc['change'].value"
                }
            }
        }
    }
}</programlisting>
<simpara>This will interpret the <literal>script</literal> parameter as an <literal>inline</literal> script with the <literal>painless</literal> script language and no script parameters. To use a file script use the following syntax:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...,

    "aggs" : {
        "intraday_return" : {
            "sum" : {
                "script" : {
                    "file": "my_script",
                    "params" : {
                        "field" : "change"
                    }
                }
            }
        }
    }
}</programlisting>
<tip><simpara>for indexed scripts replace the <literal>file</literal> parameter with an <literal>id</literal> parameter.</simpara></tip>
<section id="_value_script_6">
<title>Value Script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/sum-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Computing the sum of squares over all stock tick changes:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        ...

        "aggs" : {
            "daytime_return" : {
                "sum" : {
                    "field" : "change",
                    "script" : {
                        "lang": "painless",
                        "inline": "_value * _value"
                    }
                }
            }
        }
    }
}</programlisting>
</section>
</section>
<section id="_missing_value_9">
<title>Missing value<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/sum-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>missing</literal> parameter defines how documents that are missing a value should be treated.
By default they will be ignored but it is also possible to treat them as if they
had a value.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "total_time" : {
            "sum" : {
                "field" : "took",
                "missing": 100 <co id="CO63-1"/>
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO63-1">
<para>
Documents without a value in the <literal>took</literal> field will fall into the same bucket as documents that have the value <literal>100</literal>.
</para>
</callout>
</calloutlist>
</section>
</section>
<section id="search-aggregations-metrics-top-hits-aggregation">
<title>Top hits Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/tophits-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A <literal>top_hits</literal> metric aggregator keeps track of the most relevant document being aggregated. This aggregator is intended
to be used as a sub aggregator, so that the top matching documents can be aggregated per bucket.</simpara>
<simpara>The <literal>top_hits</literal> aggregator can effectively be used to group result sets by certain fields via a bucket aggregator.
One or more bucket aggregators determines by which properties a result set get sliced into.</simpara>
<section id="_options_2">
<title>Options<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/tophits-aggregation.asciidoc">Edit me</ulink></title>
<itemizedlist>
<listitem>
<simpara>
<literal>from</literal> - The offset from the first result you want to fetch.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>size</literal> - The maximum number of top matching hits to return per bucket. By default the top three matching hits are returned.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>sort</literal> - How the top matching hits should be sorted. By default the hits are sorted by the score of the main query.
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_supported_per_hit_features">
<title>Supported per hit features<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/tophits-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The top_hits aggregation returns regular search hits, because of this many per hit features can be supported:</simpara>
<itemizedlist>
<listitem>
<simpara>
<link linkend="search-request-highlighting">Highlighting</link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="search-request-explain">Explain</link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="search-request-named-queries-and-filters">Named filters and queries</link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="search-request-source-filtering">Source filtering</link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="search-request-stored-fields">Stored fields</link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="search-request-script-fields">Script fields</link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="search-request-docvalue-fields">Doc value fields</link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="search-request-version">Include versions</link>
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_example">
<title>Example<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/tophits-aggregation.asciidoc">Edit me</ulink></title>
<simpara>In the following example we group the questions by tag and per tag we show the last active question. For each question
only the title field is being included in the source.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs": {
        "top-tags": {
            "terms": {
                "field": "tags",
                "size": 3
            },
            "aggs": {
                "top_tag_hits": {
                    "top_hits": {
                        "sort": [
                            {
                                "last_activity_date": {
                                    "order": "desc"
                                }
                            }
                        ],
                        "_source": {
                            "includes": [
                                "title"
                            ]
                        },
                        "size" : 1
                    }
                }
            }
        }
    }
}</programlisting>
<simpara>Possible response snippet:</simpara>
<programlisting language="js" linenumbering="unnumbered">"aggregations": {
  "top-tags": {
     "buckets": [
        {
           "key": "windows-7",
           "doc_count": 25365,
           "top_tags_hits": {
              "hits": {
                 "total": 25365,
                 "max_score": 1,
                 "hits": [
                    {
                       "_index": "stack",
                       "_type": "question",
                       "_id": "602679",
                       "_score": 1,
                       "_source": {
                          "title": "Windows port opening"
                       },
                       "sort": [
                          1370143231177
                       ]
                    }
                 ]
              }
           }
        },
        {
           "key": "linux",
           "doc_count": 18342,
           "top_tags_hits": {
              "hits": {
                 "total": 18342,
                 "max_score": 1,
                 "hits": [
                    {
                       "_index": "stack",
                       "_type": "question",
                       "_id": "602672",
                       "_score": 1,
                       "_source": {
                          "title": "Ubuntu RFID Screensaver lock-unlock"
                       },
                       "sort": [
                          1370143379747
                       ]
                    }
                 ]
              }
           }
        },
        {
           "key": "windows",
           "doc_count": 18119,
           "top_tags_hits": {
              "hits": {
                 "total": 18119,
                 "max_score": 1,
                 "hits": [
                    {
                       "_index": "stack",
                       "_type": "question",
                       "_id": "602678",
                       "_score": 1,
                       "_source": {
                          "title": "If I change my computers date / time, what could be affected?"
                       },
                       "sort": [
                          1370142868283
                       ]
                    }
                 ]
              }
           }
        }
     ]
  }
}</programlisting>
</section>
<section id="_field_collapse_example">
<title>Field collapse example<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/tophits-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Field collapsing or result grouping is a feature that logically groups a result set into groups and per group returns
top documents. The ordering of the groups is determined by the relevancy of the first document in a group. In
Elasticsearch this can be implemented via a bucket aggregator that wraps a <literal>top_hits</literal> aggregator as sub-aggregator.</simpara>
<simpara>In the example below we search across crawled webpages. For each webpage we store the body and the domain the webpage
belong to. By defining a <literal>terms</literal> aggregator on the <literal>domain</literal> field we group the result set of webpages by domain. The
<literal>top_hits</literal> aggregator is then defined as sub-aggregator, so that the top matching hits are collected per bucket.</simpara>
<simpara>Also a <literal>max</literal> aggregator is defined which is used by the <literal>terms</literal> aggregator&#8217;s order feature the return the buckets by
relevancy order of the most relevant document in a bucket.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "query": {
    "match": {
      "body": "elections"
    }
  },
  "aggs": {
    "top-sites": {
      "terms": {
        "field": "domain",
        "order": {
          "top_hit": "desc"
        }
      },
      "aggs": {
        "top_tags_hits": {
          "top_hits": {}
        },
        "top_hit" : {
          "max": {
            "script": {
              "lang": "painless",
              "inline": "_score"
            }
          }
        }
      }
    }
  }
}</programlisting>
<simpara>At the moment the <literal>max</literal> (or <literal>min</literal>) aggregator is needed to make sure the buckets from the <literal>terms</literal> aggregator are
ordered according to the score of the most relevant webpage per domain. Unfortunately the <literal>top_hits</literal> aggregator
can&#8217;t be used in the <literal>order</literal> option of the <literal>terms</literal> aggregator yet.</simpara>
</section>
<section id="_top_hits_support_in_a_nested_or_reverse_nested_aggregator">
<title>top_hits support in a nested or reverse_nested aggregator<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/tophits-aggregation.asciidoc">Edit me</ulink></title>
<simpara>If the <literal>top_hits</literal> aggregator is wrapped in a <literal>nested</literal> or <literal>reverse_nested</literal> aggregator then nested hits are being returned.
Nested hits are in a sense hidden mini documents that are part of regular document where in the mapping a nested field type
has been configured. The <literal>top_hits</literal> aggregator has the ability to un-hide these documents if it is wrapped in a <literal>nested</literal>
or <literal>reverse_nested</literal> aggregator. Read more about nested in the <link linkend="nested">nested type mapping</link>.</simpara>
<simpara>If nested type has been configured a single document is actually indexed as multiple Lucene documents and they share
the same id. In order to determine the identity of a nested hit there is more needed than just the id, so that is why
nested hits also include their nested identity. The nested identity is kept under the <literal>_nested</literal> field in the search hit
and includes the array field and the offset in the array field the nested hit belongs to. The offset is zero based.</simpara>
<simpara>Top hits response snippet with a nested hit, which resides in the third slot of array field <literal>nested_field1</literal> in document with id <literal>1</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">...
"hits": {
 "total": 25365,
 "max_score": 1,
 "hits": [
   {
     "_index": "a",
     "_type": "b",
     "_id": "1",
     "_score": 1,
     "_nested" : {
       "field" : "nested_field1",
       "offset" : 2
     }
     "_source": ...
   },
   ...
 ]
}
...</programlisting>
<simpara>If <literal>_source</literal> is requested then just the part of the source of the nested object is returned, not the entire source of the document.
Also stored fields on the <emphasis role="strong">nested</emphasis> inner object level are accessible via <literal>top_hits</literal> aggregator residing in a <literal>nested</literal> or <literal>reverse_nested</literal> aggregator.</simpara>
<simpara>Only nested hits will have a <literal>_nested</literal> field in the hit, non nested (regular) hits will not have a <literal>_nested</literal> field.</simpara>
<simpara>The information in <literal>_nested</literal> can also be used to parse the original source somewhere else if <literal>_source</literal> isn&#8217;t enabled.</simpara>
<simpara>If there are multiple levels of nested object types defined in mappings then the <literal>_nested</literal> information can also be hierarchical
in order to express the identity of nested hits that are two layers deep or more.</simpara>
<simpara>In the example below a nested hit resides in the first slot of the field <literal>nested_grand_child_field</literal> which then resides in
the second slow of the <literal>nested_child_field</literal> field:</simpara>
<programlisting language="js" linenumbering="unnumbered">...
"hits": {
 "total": 2565,
 "max_score": 1,
 "hits": [
   {
     "_index": "a",
     "_type": "b",
     "_id": "1",
     "_score": 1,
     "_nested" : {
       "field" : "nested_child_field",
       "offset" : 1,
       "_nested" : {
         "field" : "nested_grand_child_field",
         "offset" : 0
       }
     }
     "_source": ...
   },
   ...
 ]
}
...</programlisting>
</section>
</section>
<section id="search-aggregations-metrics-valuecount-aggregation">
<title>Value Count Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/valuecount-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A <literal>single-value</literal> metrics aggregation that counts the number of values that are extracted from the aggregated documents.
These values can be extracted either from specific fields in the documents, or be generated by a provided script. Typically,
this aggregator will be used in conjunction with other single-value aggregations. For example, when computing the <literal>avg</literal>
one might be interested in the number of values the average is computed over.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "grades_count" : { "value_count" : { "field" : "grade" } }
    }
}</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

    "aggregations": {
        "grades_count": {
            "value": 10
        }
    }
}</programlisting>
<simpara>The name of the aggregation (<literal>grades_count</literal> above) also serves as the key by which the aggregation result can be
retrieved from the returned response.</simpara>
<section id="_script_10">
<title>Script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/metrics/valuecount-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Counting the values generated by a script:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...,

    "aggs" : {
        "grades_count" : {
            "value_count" : {
                "script" : {
                    "inline" : "doc['grade'].value",
                    "lang" : "painless"
                }
            }
        }
    }
}</programlisting>
<simpara>This will interpret the <literal>script</literal> parameter as an <literal>inline</literal> script with the <literal>painless</literal> script language and no script parameters. To use a file script use the following syntax:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...,

    "aggs" : {
        "grades_count" : {
            "value_count" : {
                "script" : {
                    "file": "my_script",
                    "params" : {
                        "field" : "grade"
                    }
                }
            }
        }
    }
}</programlisting>
<tip><simpara>for indexed scripts replace the <literal>file</literal> parameter with an <literal>id</literal> parameter.</simpara></tip>
</section>
</section>
</chapter>
<chapter id="search-aggregations-bucket">
<title>Bucket Aggregations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket.asciidoc">Edit me</ulink></title>
<simpara>Bucket aggregations don&#8217;t calculate metrics over fields like the metrics aggregations do, but instead, they create
buckets of documents. Each bucket is associated with a criterion (depending on the aggregation type) which determines
whether or not a document in the current context "falls" into it. In other words, the buckets effectively define document
sets. In addition to the buckets themselves, the <literal>bucket</literal> aggregations also compute and return the number of documents
that "fell into" each bucket.</simpara>
<simpara>Bucket aggregations, as opposed to <literal>metrics</literal> aggregations, can hold sub-aggregations. These sub-aggregations will be
aggregated for the buckets created by their "parent" bucket aggregation.</simpara>
<simpara>There are different bucket aggregators, each with a different "bucketing" strategy. Some define a single bucket, some
define fixed number of multiple buckets, and others dynamically create the buckets during the aggregation process.</simpara>
<section id="search-aggregations-bucket-children-aggregation">
<title>Children Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/children-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A special single bucket aggregation that enables aggregating from buckets on parent document types to buckets on child documents.</simpara>
<simpara>This aggregation relies on the <link linkend="mapping-parent-field">_parent field</link> in the mapping. This aggregation has a single option:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>type</literal> - The what child type the buckets in the parent space should be mapped to.
</simpara>
</listitem>
</itemizedlist>
<simpara>For example, let&#8217;s say we have an index of questions and answers. The answer type has the following <literal>_parent</literal> field in the mapping:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT child_example
{
    "mappings": {
        "answer" : {
            "_parent" : {
                "type" : "question"
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The question typed document contain a tag field and the answer typed documents contain an owner field. With the <literal>children</literal>
aggregation the tag buckets can be mapped to the owner buckets in a single request even though the two fields exist in
two different kinds of documents.</simpara>
<simpara>An example of a question typed document:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT child_example/question/1
{
    "body": "&lt;p&gt;I have Windows 2003 server and i bought a new Windows 2008 server...",
    "title": "Whats the best way to file transfer my site from server to a newer one?",
    "tags": [
        "windows-server-2003",
        "windows-server-2008",
        "file-transfer"
    ]
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Examples of <literal>answer</literal> typed documents:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT child_example/answer/1?parent=1&amp;refresh
{
    "owner": {
        "location": "Norfolk, United Kingdom",
        "display_name": "Sam",
        "id": 48
    },
    "body": "&lt;p&gt;Unfortunately you're pretty much limited to FTP...",
    "creation_date": "2009-05-04T13:45:37.030"
}
PUT child_example/answer/2?parent=1&amp;refresh
{
    "owner": {
        "location": "Norfolk, United Kingdom",
        "display_name": "Troll",
        "id": 49
    },
    "body": "&lt;p&gt;Use Linux...",
    "creation_date": "2009-05-05T13:45:37.030"
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>The following request can be built that connects the two together:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST child_example/_search?size=0
{
  "aggs": {
    "top-tags": {
      "terms": {
        "field": "tags.keyword",
        "size": 10
      },
      "aggs": {
        "to-answers": {
          "children": {
            "type" : "answer" <co id="CO64-1"/>
          },
          "aggs": {
            "top-names": {
              "terms": {
                "field": "owner.display_name.keyword",
                "size": 10
              }
            }
          }
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<calloutlist>
<callout arearefs="CO64-1">
<para>
The <literal>type</literal> points to type / mapping with the name <literal>answer</literal>.
</para>
</callout>
</calloutlist>
<simpara>The above example returns the top question tags and per tag the top answer owners.</simpara>
<simpara>Possible response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "timed_out": false,
  "took": 25,
  "_shards": { "total": 5, "successful": 5, "failed": 0 },
  "hits": { "total": 3, "max_score": 0.0, hits: [] },
  "aggregations": {
    "top-tags": {
      "doc_count_error_upper_bound": 0,
      "sum_other_doc_count": 0,
      "buckets": [
        {
          "key": "file-transfer",
          "doc_count": 1, <co id="CO65-1"/>
          "to-answers": {
            "doc_count": 2, <co id="CO65-2"/>
            "top-names": {
              "doc_count_error_upper_bound": 0,
              "sum_other_doc_count": 0,
              "buckets": [
                {
                  "key": "Sam",
                  "doc_count": 1
                },
                {
                  "key": "Troll",
                  "doc_count": 1
                }
              ]
            }
          }
        },
        {
          "key": "windows-server-2003",
          "doc_count": 1, <co id="CO65-3"/>
          "to-answers": {
            "doc_count": 2, <co id="CO65-4"/>
            "top-names": {
              "doc_count_error_upper_bound": 0,
              "sum_other_doc_count": 0,
              "buckets": [
                {
                  "key": "Sam",
                  "doc_count": 1
                },
                {
                  "key": "Troll",
                  "doc_count": 1
                }
              ]
            }
          }
        },
        {
          "key": "windows-server-2008",
          "doc_count": 1, <co id="CO65-5"/>
          "to-answers": {
            "doc_count": 2, <co id="CO65-6"/>
            "top-names": {
              "doc_count_error_upper_bound": 0,
              "sum_other_doc_count": 0,
              "buckets": [
                {
                  "key": "Sam",
                  "doc_count": 1
                },
                {
                  "key": "Troll",
                  "doc_count": 1
                }
              ]
            }
          }
        }
      ]
    }
  }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 25/"took": $body.took/]</remark>
<calloutlist>
<callout arearefs="CO65-1 CO65-3 CO65-5">
<para>
The number of question documents with the tag <literal>file-transfer</literal>, <literal>windows-server-2003</literal>, etc.
</para>
</callout>
<callout arearefs="CO65-2 CO65-4 CO65-6">
<para>
The number of answer documents that are related to question documents with the tag <literal>file-transfer</literal>, <literal>windows-server-2003</literal>, etc.
</para>
</callout>
</calloutlist>
</section>
<section id="search-aggregations-bucket-datehistogram-aggregation">
<title>Date Histogram Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/datehistogram-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A multi-bucket aggregation similar to the <link linkend="search-aggregations-bucket-histogram-aggregation">histogram</link> except it can
only be applied on date values. Since dates are represented in elasticsearch internally as long values, it is possible
to use the normal <literal>histogram</literal> on dates as well, though accuracy will be compromised. The reason for this is in the fact
that time based intervals are not fixed (think of leap years and on the number of days in a month). For this reason,
we need special support for time based data. From a functionality perspective, this histogram supports the same features
as the normal <link linkend="search-aggregations-bucket-histogram-aggregation">histogram</link>. The main difference is that the interval can be specified by date/time expressions.</simpara>
<simpara>Requesting bucket intervals of a month.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "articles_over_time" : {
            "date_histogram" : {
                "field" : "date",
                "interval" : "month"
            }
        }
    }
}</programlisting>
<simpara>Available expressions for interval: <literal>year</literal>, <literal>quarter</literal>, <literal>month</literal>, <literal>week</literal>, <literal>day</literal>, <literal>hour</literal>, <literal>minute</literal>, <literal>second</literal></simpara>
<simpara>Time values can also be specified via abbreviations supported by <link linkend="time-units">time units</link> parsing.
Note that fractional time values are not supported, but you can address this by shifting to another
time unit (e.g., <literal>1.5h</literal> could instead be specified as <literal>90m</literal>).</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "articles_over_time" : {
            "date_histogram" : {
                "field" : "date",
                "interval" : "90m"
            }
        }
    }
}</programlisting>
<section id="_keys">
<title>Keys<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/datehistogram-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Internally, a date is represented as a 64 bit number representing a timestamp
in milliseconds-since-the-epoch. These timestamps are returned as the bucket
<literal>key</literal>s. The <literal>key_as_string</literal> is the same timestamp converted to a formatted
date string using the format specified with the <literal>format</literal> parameter:</simpara>
<tip><simpara>If no <literal>format</literal> is specified, then it will use the first date
<link linkend="mapping-date-format">format</link> specified in the field mapping.</simpara></tip>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "articles_over_time" : {
            "date_histogram" : {
                "field" : "date",
                "interval" : "1M",
                "format" : "yyyy-MM-dd" <co id="CO66-1"/>
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO66-1">
<para>
Supports expressive date <link linkend="date-format-pattern">format pattern</link>
</para>
</callout>
</calloutlist>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggregations": {
        "articles_over_time": {
            "buckets": [
                {
                    "key_as_string": "2013-02-02",
                    "key": 1328140800000,
                    "doc_count": 1
                },
                {
                    "key_as_string": "2013-03-02",
                    "key": 1330646400000,
                    "doc_count": 2
                },
                ...
            ]
        }
    }
}</programlisting>
</section>
<section id="_time_zone">
<title>Time Zone<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/datehistogram-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Date-times are stored in Elasticsearch in UTC.  By default, all bucketing and
rounding is also done in UTC. The <literal>time_zone</literal> parameter can be used to indicate
that bucketing should use a different time zone.</simpara>
<simpara>Time zones may either be specified as an ISO 8601 UTC offset (e.g. <literal>+01:00</literal> or
<literal>-08:00</literal>)  or as a timezone id, an identifier used in the TZ database like
<literal>America/Los_Angeles</literal>.</simpara>
<simpara>Consider the following example:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index/log/1
{
  "date": "2015-10-01T00:30:00Z"
}

PUT my_index/log/2
{
  "date": "2015-10-01T01:30:00Z"
}

GET my_index/_search?size=0
{
  "aggs": {
    "by_day": {
      "date_histogram": {
        "field":     "date",
        "interval":  "day"
      }
    }
  }
}</programlisting>
<simpara>UTC is used if no time zone is specified, which would result in both of these
documents being placed into the same day bucket, which starts at midnight UTC
on 1 October 2015:</simpara>
<programlisting language="js" linenumbering="unnumbered">"aggregations": {
  "by_day": {
    "buckets": [
      {
        "key_as_string": "2015-10-01T00:00:00.000Z",
        "key":           1443657600000,
        "doc_count":     2
      }
    ]
  }
}</programlisting>
<simpara>If a <literal>time_zone</literal> of <literal>-01:00</literal> is specified, then midnight starts at one hour before
midnight UTC:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET my_index/_search?size=0
{
  "aggs": {
    "by_day": {
      "date_histogram": {
        "field":     "date",
        "interval":  "day",
        "time_zone": "-01:00"
      }
    }
  }
}</programlisting>
<simpara>Now the first document falls into the bucket for 30 September 2015, while the
second document falls into the bucket for 1 October 2015:</simpara>
<programlisting language="js" linenumbering="unnumbered">"aggregations": {
  "by_day": {
    "buckets": [
      {
        "key_as_string": "2015-09-30T00:00:00.000-01:00", <co id="CO67-1"/>
        "key": 1443571200000,
        "doc_count": 1
      },
      {
        "key_as_string": "2015-10-01T00:00:00.000-01:00", <co id="CO67-2"/>
        "key": 1443657600000,
        "doc_count": 1
      }
    ]
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO67-1 CO67-2">
<para>
The <literal>key_as_string</literal> value represents midnight on each day
    in the specified time zone.
</para>
</callout>
</calloutlist>
<warning><simpara>When using time zones that follow DST (daylight savings time) changes,
buckets close to the moment when those changes happen can have slightly different
sizes than would be expected from the used <literal>interval</literal>.
For example, consider a DST start in the <literal>CET</literal> time zone: on 27 March 2016 at 2am,
clocks were turned forward 1 hour to 3am local time. When using <literal>day</literal> as <literal>interval</literal>,
the bucket covering that day will only hold data for 23 hours instead of the usual
24 hours for other buckets. The same is true for shorter intervals like e.g. 12h.
Here, we will have only a 11h bucket on the morning of 27 March when the DST shift
happens.</simpara></warning>
</section>
<section id="_offset">
<title>Offset<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/datehistogram-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>offset</literal> parameter is used to change the start value of each bucket by the
specified positive (<literal>+</literal>) or negative offset (<literal>-</literal>) duration, such as <literal>1h</literal> for
an hour, or <literal>1M</literal> for a month. See <xref linkend="time-units"/> for more possible time
duration options.</simpara>
<simpara>For instance, when using an interval of <literal>day</literal>, each bucket runs from midnight
to midnight.  Setting the <literal>offset</literal> parameter to <literal>+6h</literal> would change each bucket
to run from 6am to 6am:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index/log/1
{
  "date": "2015-10-01T05:30:00Z"
}

PUT my_index/log/2
{
  "date": "2015-10-01T06:30:00Z"
}

GET my_index/_search?size=0
{
  "aggs": {
    "by_day": {
      "date_histogram": {
        "field":     "date",
        "interval":  "day",
        "offset":    "+6h"
      }
    }
  }
}</programlisting>
<simpara>Instead of a single bucket starting at midnight, the above request groups the
documents into buckets starting at 6am:</simpara>
<programlisting language="js" linenumbering="unnumbered">"aggregations": {
  "by_day": {
    "buckets": [
      {
        "key_as_string": "2015-09-30T06:00:00.000Z",
        "key": 1443592800000,
        "doc_count": 1
      },
      {
        "key_as_string": "2015-10-01T06:00:00.000Z",
        "key": 1443679200000,
        "doc_count": 1
      }
    ]
  }
}</programlisting>
<note><simpara>The start <literal>offset</literal> of each bucket is calculated after the <literal>time_zone</literal>
adjustments have been made.</simpara></note>
</section>
<section id="_scripts">
<title>Scripts<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/datehistogram-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Like with the normal <link linkend="search-aggregations-bucket-histogram-aggregation">histogram</link>, both document level scripts and
value level scripts are supported. It is also possible to control the order of the returned buckets using the <literal>order</literal>
settings and filter the returned buckets based on a <literal>min_doc_count</literal> setting (by default all buckets between the first
bucket that matches documents and the last one are returned). This histogram also supports the <literal>extended_bounds</literal>
setting, which enables extending the bounds of the histogram beyond the data itself (to read more on why you&#8217;d want to
do that please refer to the explanation <link linkend="search-aggregations-bucket-histogram-aggregation-extended-bounds">here</link>).</simpara>
</section>
<section id="_missing_value_10">
<title>Missing value<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/datehistogram-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>missing</literal> parameter defines how documents that are missing a value should be treated.
By default they will be ignored but it is also possible to treat them as if they
had a value.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "publish_date" : {
             "date_histogram" : {
                 "field" : "publish_date",
                 "interval": "year",
                 "missing": "2000-01-01" <co id="CO68-1"/>
             }
         }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO68-1">
<para>
Documents without a value in the <literal>publish_date</literal> field will fall into the same bucket as documents that have the value <literal>2000-01-01</literal>.
</para>
</callout>
</calloutlist>
</section>
</section>
<section id="search-aggregations-bucket-daterange-aggregation">
<title>Date Range Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/daterange-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A range aggregation that is dedicated for date values. The main difference between this aggregation and the normal <link linkend="search-aggregations-bucket-range-aggregation">range</link> aggregation is that the <literal>from</literal> and <literal>to</literal> values can be expressed in <link linkend="date-math">Date Math</link> expressions, and it is also possible to specify a date format by which the <literal>from</literal> and <literal>to</literal> response fields will be returned.
Note that this aggregation includes the <literal>from</literal> value and excludes the <literal>to</literal> value for each range.</simpara>
<simpara>Example:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs": {
        "range": {
            "date_range": {
                "field": "date",
                "format": "MM-yyy",
                "ranges": [
                    { "to": "now-10M/M" }, <co id="CO69-1"/>
                    { "from": "now-10M/M" } <co id="CO69-2"/>
                ]
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO69-1">
<para>
&lt; now minus 10 months, rounded down to the start of the month.
</para>
</callout>
<callout arearefs="CO69-2">
<para>
&gt;= now minus 10 months, rounded down to the start of the month.
</para>
</callout>
</calloutlist>
<simpara>In the example above, we created two range buckets, the first will "bucket" all documents dated prior to 10 months ago and
the second will "bucket" all documents dated since 10 months ago</simpara>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

    "aggregations": {
        "range": {
            "buckets": [
                {
                    "to": 1.3437792E+12,
                    "to_as_string": "08-2012",
                    "doc_count": 7
                },
                {
                    "from": 1.3437792E+12,
                    "from_as_string": "08-2012",
                    "doc_count": 2
                }
            ]
        }
    }
}</programlisting>
<section id="date-format-pattern">
<title>Date Format/Pattern<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/daterange-aggregation.asciidoc">Edit me</ulink></title>
<note><simpara>this information was copied from <ulink url="http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html">JodaDate</ulink></simpara></note>
<simpara>All ASCII letters are reserved as format pattern letters, which are defined as follows:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top">Symbol </entry>
<entry align="left" valign="top">Meaning                </entry>
<entry align="left" valign="top">Presentation       </entry>
<entry align="left" valign="top">Examples</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>G</simpara></entry>
<entry align="left" valign="top"><simpara>era</simpara></entry>
<entry align="left" valign="top"><simpara>text</simpara></entry>
<entry align="left" valign="top"><simpara>AD</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>C</simpara></entry>
<entry align="left" valign="top"><simpara>century of era (&gt;=0)</simpara></entry>
<entry align="left" valign="top"><simpara>number</simpara></entry>
<entry align="left" valign="top"><simpara>20</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Y</simpara></entry>
<entry align="left" valign="top"><simpara>year of era (&gt;=0)</simpara></entry>
<entry align="left" valign="top"><simpara>year</simpara></entry>
<entry align="left" valign="top"><simpara>1996</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>x</simpara></entry>
<entry align="left" valign="top"><simpara>weekyear</simpara></entry>
<entry align="left" valign="top"><simpara>year</simpara></entry>
<entry align="left" valign="top"><simpara>1996</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>w</simpara></entry>
<entry align="left" valign="top"><simpara>week of weekyear</simpara></entry>
<entry align="left" valign="top"><simpara>number</simpara></entry>
<entry align="left" valign="top"><simpara>27</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>e</simpara></entry>
<entry align="left" valign="top"><simpara>day of week</simpara></entry>
<entry align="left" valign="top"><simpara>number</simpara></entry>
<entry align="left" valign="top"><simpara>2</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>E</simpara></entry>
<entry align="left" valign="top"><simpara>day of week</simpara></entry>
<entry align="left" valign="top"><simpara>text</simpara></entry>
<entry align="left" valign="top"><simpara>Tuesday; Tue</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>y</simpara></entry>
<entry align="left" valign="top"><simpara>year</simpara></entry>
<entry align="left" valign="top"><simpara>year</simpara></entry>
<entry align="left" valign="top"><simpara>1996</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>D</simpara></entry>
<entry align="left" valign="top"><simpara>day of year</simpara></entry>
<entry align="left" valign="top"><simpara>number</simpara></entry>
<entry align="left" valign="top"><simpara>189</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>M</simpara></entry>
<entry align="left" valign="top"><simpara>month of year</simpara></entry>
<entry align="left" valign="top"><simpara>month</simpara></entry>
<entry align="left" valign="top"><simpara>July; Jul; 07</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>d</simpara></entry>
<entry align="left" valign="top"><simpara>day of month</simpara></entry>
<entry align="left" valign="top"><simpara>number</simpara></entry>
<entry align="left" valign="top"><simpara>10</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>a</simpara></entry>
<entry align="left" valign="top"><simpara>halfday of day</simpara></entry>
<entry align="left" valign="top"><simpara>text</simpara></entry>
<entry align="left" valign="top"><simpara>PM</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>K</simpara></entry>
<entry align="left" valign="top"><simpara>hour of halfday (0~11)</simpara></entry>
<entry align="left" valign="top"><simpara>number</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>h</simpara></entry>
<entry align="left" valign="top"><simpara>clockhour of halfday (1~12)</simpara></entry>
<entry align="left" valign="top"><simpara>number</simpara></entry>
<entry align="left" valign="top"><simpara>12</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>H</simpara></entry>
<entry align="left" valign="top"><simpara>hour of day (0~23)</simpara></entry>
<entry align="left" valign="top"><simpara>number</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>k</simpara></entry>
<entry align="left" valign="top"><simpara>clockhour of day (1~24)</simpara></entry>
<entry align="left" valign="top"><simpara>number</simpara></entry>
<entry align="left" valign="top"><simpara>24</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>m</simpara></entry>
<entry align="left" valign="top"><simpara>minute of hour</simpara></entry>
<entry align="left" valign="top"><simpara>number</simpara></entry>
<entry align="left" valign="top"><simpara>30</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>s</simpara></entry>
<entry align="left" valign="top"><simpara>second of minute</simpara></entry>
<entry align="left" valign="top"><simpara>number</simpara></entry>
<entry align="left" valign="top"><simpara>55</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>S</simpara></entry>
<entry align="left" valign="top"><simpara>fraction of second</simpara></entry>
<entry align="left" valign="top"><simpara>number</simpara></entry>
<entry align="left" valign="top"><simpara>978</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>z</simpara></entry>
<entry align="left" valign="top"><simpara>time zone</simpara></entry>
<entry align="left" valign="top"><simpara>text</simpara></entry>
<entry align="left" valign="top"><simpara>Pacific Standard Time; PST</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Z</simpara></entry>
<entry align="left" valign="top"><simpara>time zone offset/id</simpara></entry>
<entry align="left" valign="top"><simpara>zone</simpara></entry>
<entry align="left" valign="top"><simpara>-0800; -08:00; America/Los_Angeles</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>'</simpara></entry>
<entry align="left" valign="top"><simpara>escape for text</simpara></entry>
<entry align="left" valign="top"><simpara>delimiter</simpara></entry>
<entry align="left" valign="top"><simpara>''</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>The count of pattern letters determine the format.</simpara>
<variablelist>
<varlistentry>
<term>
Text
</term>
<listitem>
<simpara>
If the number of pattern letters is 4 or more, the full form is used; otherwise a short or abbreviated form is used if available.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Number
</term>
<listitem>
<simpara>
The minimum number of digits. Shorter numbers are zero-padded to this amount.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Year
</term>
<listitem>
<simpara>
Numeric presentation for year and weekyear fields are handled specially. For example, if the count of <emphasis>y</emphasis> is 2, the year will be displayed as the zero-based year of the century, which is two digits.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Month
</term>
<listitem>
<simpara>
3 or over, use text, otherwise use number.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Zone
</term>
<listitem>
<simpara>
<emphasis>Z</emphasis> outputs offset without a colon, <emphasis>ZZ</emphasis> outputs the offset with a colon, <emphasis>ZZZ</emphasis> or more outputs the zone id.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Zone names
</term>
<listitem>
<simpara>
Time zone names (<emphasis>z</emphasis>) cannot be parsed.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>Any characters in the pattern that are not in the ranges of [<emphasis>a</emphasis>..<emphasis>z</emphasis>] and [<emphasis>A</emphasis>..<emphasis>Z</emphasis>] will be treated as quoted text. For instance, characters like <emphasis>:</emphasis>, <emphasis>.</emphasis>, ' <emphasis>, '#</emphasis> and <emphasis>?</emphasis> will appear in the resulting time text even they are not embraced within single quotes.</simpara>
</section>
<section id="time-zones">
<title>Time zone in date range aggregations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/daterange-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Dates can be converted from another time zone to UTC by specifying the <literal>time_zone</literal> parameter.</simpara>
<simpara>Time zones may either be specified as an ISO 8601 UTC offset (e.g. +01:00 or -08:00) or as one of
the <ulink url="http://www.joda.org/joda-time/timezones.html">time zone ids</ulink> from the TZ database.</simpara>
<simpara>The <literal>time_zone</literal> parameter is also applied to rounding in date math expressions. As an example,
to round to the beginning of the day in the CET time zone, you can do the following:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "aggs": {
           "range": {
               "date_range": {
                   "field": "date",
                   "time_zone": "CET",
                   "ranges": [
                      { "to": "2016-02-15/d" }, <co id="CO70-1"/>
                      { "from": "2016-02-15/d", "to" : "now/d" <co id="CO70-2"/>},
                      { "from": "now/d" },
                  ]
              }
          }
      }
  }</programlisting>
<calloutlist>
<callout arearefs="CO70-1">
<para>
This date will be converted to <literal>2016-02-15T00:00:00.000+01:00</literal>.
</para>
</callout>
<callout arearefs="CO70-2">
<para>
<literal>now/d</literal> will be rounded to the beginning of the day in the CET time zone.
</para>
</callout>
</calloutlist>
</section>
</section>
<section id="search-aggregations-bucket-diversified-sampler-aggregation">
<title>Diversified Sampler Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/diversified-sampler-aggregation.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This functionality is experimental and may be changed or removed completely in a future release.</simpara></warning>
<simpara>A filtering aggregation used to limit any sub aggregations' processing to a sample of the top-scoring documents. Diversity settings are
used to limit the number of matches that share a common value such as an "author".</simpara>
<itemizedlist><title>Example use cases:</title>
<listitem>
<simpara>
Tightening the focus of analytics to high-relevance matches rather than the potentially very long tail of low-quality matches
</simpara>
</listitem>
<listitem>
<simpara>
Removing bias from analytics by ensuring fair representation of content from different sources
</simpara>
</listitem>
<listitem>
<simpara>
Reducing the running cost of aggregations that can produce useful results using only samples e.g. <literal>significant_terms</literal>
</simpara>
</listitem>
</itemizedlist>
<simpara>Example:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "query": {
        "match": {
            "text": "iphone"
        }
    },
    "aggs": {
        "sample": {
            "diversified_sampler": {
                "shard_size": 200,
                "field" : "user.id"
            },
            "aggs": {
                "keywords": {
                    "significant_terms": {
                        "field": "text"
                    }
                }
            }
        }
    }
}</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...
        "aggregations": {
        "sample": {
            "doc_count": 1000,<co id="CO71-1"/>
            "keywords": {<co id="CO71-2"/>
                "doc_count": 1000,
                "buckets": [
                    ...
                    {
                        "key": "bend",
                        "doc_count": 58,
                        "score": 37.982536582524276,
                        "bg_count": 103
                    },
                    ....
}</programlisting>
<calloutlist>
<callout arearefs="CO71-1">
<para>
1000 documents were sampled in total because we asked for a maximum of 200 from an index with 5 shards. The cost of performing the nested significant_terms aggregation was therefore limited rather than unbounded.
</para>
</callout>
<callout arearefs="CO71-2">
<para>
The results of the significant_terms aggregation are not skewed by any single over-active Twitter user because we asked for a maximum of one tweet from any one user in our sample.
</para>
</callout>
</calloutlist>
<section id="_shard_size">
<title>shard_size<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/diversified-sampler-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>shard_size</literal> parameter limits how many top-scoring documents are collected in the sample processed on each shard.
The default value is 100.</simpara>
</section>
<section id="_controlling_diversity">
<title>Controlling diversity<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/diversified-sampler-aggregation.asciidoc">Edit me</ulink></title>
<simpara>=<literal>field</literal> or <literal>script</literal> and <literal>max_docs_per_value</literal> settings are used to control the maximum number of documents collected on any one shard which share a common value.
The choice of value (e.g. <literal>author</literal>) is loaded from a regular <literal>field</literal> or derived dynamically by a <literal>script</literal>.</simpara>
<simpara>The aggregation will throw an error if the choice of field or script produces multiple values for a document.
It is currently not possible to offer this form of de-duplication using many values, primarily due to concerns over efficiency.</simpara>
<note><simpara>Any good market researcher will tell you that when working with samples of data it is important
that the sample represents a healthy variety of opinions rather than being skewed by any single voice.
The same is true with aggregations and sampling with these diversify settings can offer a way to remove the bias in your content (an over-populated geography, a large spike in a timeline or an over-active forum spammer).</simpara></note>
</section>
<section id="_field">
<title>Field<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/diversified-sampler-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Controlling diversity using a field:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "sample" : {
            "diversified_sampler" : {
                "field" : "author",
                "max_docs_per_value" : 3
            }
        }
    }
}</programlisting>
<simpara>Note that the <literal>max_docs_per_value</literal> setting applies on a per-shard basis only for the purposes of shard-local sampling.
It is not intended as a way of providing a global de-duplication feature on search results.</simpara>
</section>
<section id="_script_11">
<title>Script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/diversified-sampler-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Controlling diversity using a script:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "sample" : {
            "diversified_sampler" : {
                "script" : {
                    "lang" : "painless",
                    "inline" : "doc['author'].value + '/' + doc['genre'].value"
                }
            }
        }
    }
}</programlisting>
<simpara>Note in the above example we chose to use the default <literal>max_docs_per_value</literal> setting of 1 and combine author and genre fields to ensure
each shard sample has, at most, one match for an author/genre pair.</simpara>
</section>
<section id="_execution_hint">
<title>execution_hint<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/diversified-sampler-aggregation.asciidoc">Edit me</ulink></title>
<simpara>When using the settings to control diversity, the optional <literal>execution_hint</literal> setting can influence the management of the values used for de-duplication.
Each option will hold up to <literal>shard_size</literal> values in memory while performing de-duplication but the type of value held can be controlled as follows:</simpara>
<itemizedlist>
<listitem>
<simpara>
hold field values directly (<literal>map</literal>)
</simpara>
</listitem>
<listitem>
<simpara>
hold ordinals of the field as determined by the Lucene index (<literal>global_ordinals</literal>)
</simpara>
</listitem>
<listitem>
<simpara>
hold hashes of the field values - with potential for hash collisions (<literal>bytes_hash</literal>)
</simpara>
</listitem>
</itemizedlist>
<simpara>The default setting is to use <literal>global_ordinals</literal> if this information is available from the Lucene index and reverting to <literal>map</literal> if not.
The <literal>bytes_hash</literal> setting may prove faster in some cases but introduces the possibility of false positives in de-duplication logic due to the possibility of hash collisions.
Please note that Elasticsearch will ignore the choice of execution hint if it is not applicable and that there is no backward compatibility guarantee on these hints.</simpara>
</section>
<section id="_limitations_2">
<title>Limitations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/diversified-sampler-aggregation.asciidoc">Edit me</ulink></title>
<section id="_cannot_be_nested_under_literal_breadth_first_literal_aggregations">
<title>Cannot be nested under <literal>breadth_first</literal> aggregations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/diversified-sampler-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Being a quality-based filter the sampler aggregation needs access to the relevance score produced for each document.
It therefore cannot be nested under a <literal>terms</literal> aggregation which has the <literal>collect_mode</literal> switched from the default <literal>depth_first</literal> mode to <literal>breadth_first</literal> as this discards scores.
In this situation an error will be thrown.</simpara>
</section>
<section id="_limited_de_dup_logic">
<title>Limited de-dup logic.<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/diversified-sampler-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The de-duplication logic in the diversify settings applies only at a shard level so will not apply across shards.</simpara>
</section>
<section id="_no_specialized_syntax_for_geo_date_fields">
<title>No specialized syntax for geo/date fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/diversified-sampler-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Currently the syntax for defining the diversifying values is defined by a choice of <literal>field</literal> or
<literal>script</literal> - there is no added syntactical sugar for expressing geo or date units such as "7d" (7
days). This support may be added in a later release and users will currently have to create these
sorts of values using a script.</simpara>
</section>
</section>
</section>
<section id="search-aggregations-bucket-filter-aggregation">
<title>Filter Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/filter-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Defines a single bucket of all the documents in the current document set context that match a specified filter. Often this will be used to narrow down the current aggregation context to a specific set of documents.</simpara>
<simpara>Example:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "red_products" : {
            "filter" : { "term": { "color": "red" } },
            "aggs" : {
                "avg_price" : { "avg" : { "field" : "price" } }
            }
        }
    }
}</programlisting>
<simpara>In the above example, we calculate the average price of all the products that are red.</simpara>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

    "aggs" : {
        "red_products" : {
            "doc_count" : 100,
            "avg_price" : { "value" : 56.3 }
        }
    }
}</programlisting>
</section>
<section id="search-aggregations-bucket-filters-aggregation">
<title>Filters Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/filters-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Defines a multi bucket aggregation where each bucket is associated with a
filter. Each bucket will collect all documents that match its associated
filter.</simpara>
<simpara>Example:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "aggs" : {
    "messages" : {
      "filters" : {
        "filters" : {
          "errors" :   { "term" : { "body" : "error"   }},
          "warnings" : { "term" : { "body" : "warning" }}
        }
      },
      "aggs" : {
        "monthly" : {
          "histogram" : {
            "field" : "timestamp",
            "interval" : "1M"
          }
        }
      }
    }
  }
}</programlisting>
<simpara>In the above example, we analyze log messages. The aggregation will build two
collection (buckets) of log messages - one for all those containing an error,
and another for all those containing a warning. And for each of these buckets
it will break them down by month.</simpara>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">...
  "aggs" : {
    "messages" : {
      "buckets" : {
        "errors" : {
          "doc_count" : 34,
          "monthly" : {
            "buckets" : [
              ... // the histogram monthly breakdown
            ]
          }
        },
        "warnings" : {
          "doc_count" : 439,
          "monthly" : {
            "buckets" : [
               ... // the histogram monthly breakdown
            ]
          }
        }
      }
    }
  }
...</programlisting>
<section id="_anonymous_filters">
<title>Anonymous filters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/filters-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The filters field can also be provided as an array of filters, as in the
following request:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "aggs" : {
    "messages" : {
      "filters" : {
        "filters" : [
          { "term" : { "body" : "error"   }},
          { "term" : { "body" : "warning" }}
        ]
      },
      "aggs" : {
        "monthly" : {
          "histogram" : {
            "field" : "timestamp",
            "interval" : "1M"
          }
        }
      }
    }
  }
}</programlisting>
<simpara>The filtered buckets are returned in the same order as provided in the
request.  The response for this example would be:</simpara>
<programlisting language="js" linenumbering="unnumbered">...
  "aggs" : {
    "messages" : {
      "buckets" : [
        {
          "doc_count" : 34,
          "monthly" : {
            "buckets" : [
              ... // the histogram monthly breakdown
            ]
          }
        },
        {
          "doc_count" : 439,
          "monthly" : {
            "buckets" : [
              ... // the histogram monthly breakdown
            ]
          }
        }
      ]
    }
  }
...</programlisting>
</section>
<section id="_literal_other_literal_bucket">
<title><literal>Other</literal> Bucket<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/filters-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>other_bucket</literal> parameter can be set to add a bucket to the response which will contain all documents that do
not match any of the given filters. The value of this parameter can be as follows:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>false</literal>
</term>
<listitem>
<simpara>
Does not compute the <literal>other</literal> bucket
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>true</literal>
</term>
<listitem>
<simpara>
Returns the <literal>other</literal> bucket bucket either in a bucket (named <literal>_other_</literal> by default) if named filters are being used,
                  or as the last bucket if anonymous filters are being used
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>The <literal>other_bucket_key</literal> parameter can be used to set the key for the <literal>other</literal> bucket to a value other than the default <literal>_other_</literal>. Setting
this parameter will implicitly set the <literal>other_bucket</literal> parameter to <literal>true</literal>.</simpara>
<simpara>The following snippet shows a response where the <literal>other</literal> bucket is requested to be named <literal>other_messages</literal>.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "aggs" : {
    "messages" : {
      "filters" : {
        "other_bucket_key": "other_messages",
        "filters" : {
          "errors" :   { "term" : { "body" : "error"   }},
          "warnings" : { "term" : { "body" : "warning" }}
        }
      },
      "aggs" : {
        "monthly" : {
          "histogram" : {
            "field" : "timestamp",
            "interval" : "1M"
          }
        }
      }
    }
  }
}</programlisting>
<simpara>The response would be something like the following:</simpara>
<programlisting language="js" linenumbering="unnumbered">...
  "aggs" : {
    "messages" : {
      "buckets" : {
        "errors" : {
          "doc_count" : 34,
            "monthly" : {
              "buckets" : [
                ... // the histogram monthly breakdown
              ]
            }
          },
          "warnings" : {
            "doc_count" : 439,
            "monthly" : {
              "buckets" : [
                 ... // the histogram monthly breakdown
              ]
            }
          },
          "other_messages" : {
            "doc_count" : 237,
            "monthly" : {
              "buckets" : [
                 ... // the histogram monthly breakdown
              ]
            }
          }
        }
      }
    }
  }
...</programlisting>
</section>
</section>
<section id="search-aggregations-bucket-geodistance-aggregation">
<title>Geo Distance Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/geodistance-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A multi-bucket aggregation that works on <literal>geo_point</literal> fields and conceptually works very similar to the <link linkend="search-aggregations-bucket-range-aggregation">range</link> aggregation. The user can define a point of origin and a set of distance range buckets. The aggregation evaluate the distance of each document value from the origin point and determines the buckets it belongs to based on the ranges (a document belongs to a bucket if the distance between the document and the origin falls within the distance range of the bucket).</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "rings_around_amsterdam" : {
            "geo_distance" : {
                "field" : "location",
                "origin" : "52.3760, 4.894",
                "ranges" : [
                    { "to" : 100 },
                    { "from" : 100, "to" : 300 },
                    { "from" : 300 }
                ]
            }
        }
    }
}</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggregations": {
        "rings" : {
            "buckets": [
                {
                    "key": "*-100.0",
                    "from": 0,
                    "to": 100.0,
                    "doc_count": 3
                },
                {
                    "key": "100.0-300.0",
                    "from": 100.0,
                    "to": 300.0,
                    "doc_count": 1
                },
                {
                    "key": "300.0-*",
                    "from": 300.0,
                    "doc_count": 7
                }
            ]
        }
    }
}</programlisting>
<simpara>The specified field must be of type <literal>geo_point</literal> (which can only be set explicitly in the mappings). And it can also hold an array of <literal>geo_point</literal> fields, in which case all will be taken into account during aggregation. The origin point can accept all formats supported by the <link linkend="geo-point"><literal>geo_point</literal> type</link>:</simpara>
<itemizedlist>
<listitem>
<simpara>
Object format: <literal>{ "lat" : 52.3760, "lon" : 4.894 }</literal> - this is the safest format as it is the most explicit about the <literal>lat</literal> &amp; <literal>lon</literal> values
</simpara>
</listitem>
<listitem>
<simpara>
String format: <literal>"52.3760, 4.894"</literal> - where the first number is the <literal>lat</literal> and the second is the <literal>lon</literal>
</simpara>
</listitem>
<listitem>
<simpara>
Array format: <literal>[4.894, 52.3760]</literal> - which is based on the <literal>GeoJson</literal> standard and where the first number is the <literal>lon</literal> and the second one is the <literal>lat</literal>
</simpara>
</listitem>
</itemizedlist>
<simpara>By default, the distance unit is <literal>m</literal> (metres) but it can also accept: <literal>mi</literal> (miles), <literal>in</literal> (inches), <literal>yd</literal> (yards), <literal>km</literal> (kilometers), <literal>cm</literal> (centimeters), <literal>mm</literal> (millimeters).</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "rings" : {
            "geo_distance" : {
                "field" : "location",
                "origin" : "52.3760, 4.894",
                "unit" : "mi", <co id="CO72-1"/>
                "ranges" : [
                    { "to" : 100 },
                    { "from" : 100, "to" : 300 },
                    { "from" : 300 }
                ]
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO72-1">
<para>
The distances will be computed as miles
</para>
</callout>
</calloutlist>
<simpara>There are three distance calculation modes: <literal>sloppy_arc</literal> (the default), <literal>arc</literal> (most accurate) and <literal>plane</literal> (fastest). The <literal>arc</literal> calculation is the most accurate one but also the more expensive one in terms of performance. The <literal>sloppy_arc</literal> is faster but less accurate. The <literal>plane</literal> is the fastest but least accurate distance function. Consider using <literal>plane</literal> when your search context is "narrow" and spans smaller geographical areas (like cities or even countries). <literal>plane</literal> may return higher error mergins for searches across very large areas (e.g. cross continent search). The distance calculation type can be set using the <literal>distance_type</literal> parameter:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "rings" : {
            "geo_distance" : {
                "field" : "location",
                "origin" : "52.3760, 4.894",
                "distance_type" : "plane",
                "ranges" : [
                    { "to" : 100 },
                    { "from" : 100, "to" : 300 },
                    { "from" : 300 }
                ]
            }
        }
    }
}</programlisting>
</section>
<section id="search-aggregations-bucket-geohashgrid-aggregation">
<title>GeoHash grid Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/geohashgrid-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A multi-bucket aggregation that works on <literal>geo_point</literal> fields and groups points into buckets that represent cells in a grid.
The resulting grid can be sparse and only contains cells that have matching data. Each cell is labeled using a <ulink url="http://en.wikipedia.org/wiki/Geohash">geohash</ulink> which is of user-definable precision.</simpara>
<itemizedlist>
<listitem>
<simpara>
High precision geohashes have a long string length and represent cells that cover only a small area.
</simpara>
</listitem>
<listitem>
<simpara>
Low precision geohashes have a short string length and represent cells that each cover a large area.
</simpara>
</listitem>
</itemizedlist>
<simpara>Geohashes used in this aggregation can have a choice of precision between 1 and 12.</simpara>
<warning><simpara>The highest-precision geohash of length 12 produces cells that cover less than a square metre of land and so high-precision requests can be very costly in terms of RAM and result sizes.
Please see the example below on how to first filter the aggregation to a smaller geographic area before requesting high-levels of detail.</simpara></warning>
<simpara>The specified field must be of type <literal>geo_point</literal> (which can only be set explicitly in the mappings) and it can also hold an array of <literal>geo_point</literal> fields, in which case all points will be taken into account during aggregation.</simpara>
<section id="_simple_low_precision_request">
<title>Simple low-precision request<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/geohashgrid-aggregation.asciidoc">Edit me</ulink></title>
<programlisting language="js" linenumbering="unnumbered">{
    "aggregations" : {
        "myLarge-GrainGeoHashGrid" : {
            "geohash_grid" : {
                "field" : "location",
                "precision" : 3
            }
        }
    }
}</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggregations": {
        "myLarge-GrainGeoHashGrid": {
            "buckets": [
                {
                    "key": "svz",
                    "doc_count": 10964
                },
                {
                    "key": "sv8",
                    "doc_count": 3198
                }
            ]
        }
    }
}</programlisting>
</section>
<section id="_high_precision_requests">
<title>High-precision requests<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/geohashgrid-aggregation.asciidoc">Edit me</ulink></title>
<simpara>When requesting detailed buckets (typically for displaying a "zoomed in" map) a filter like <link linkend="query-dsl-geo-bounding-box-query">geo_bounding_box</link> should be applied to narrow the subject area otherwise potentially millions of buckets will be created and returned.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggregations" : {
        "zoomedInView" : {
            "filter" : {
                "geo_bounding_box" : {
                    "location" : {
                        "top_left" : "51.73, 0.9",
                        "bottom_right" : "51.55, 1.1"
                    }
                }
            },
            "aggregations":{
                "zoom1":{
                    "geohash_grid" : {
                        "field":"location",
                        "precision":8
                    }
                }
            }
        }
    }
 }</programlisting>
</section>
<section id="_cell_dimensions_at_the_equator">
<title>Cell dimensions at the equator<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/geohashgrid-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The table below shows the metric dimensions for cells covered by various string lengths of geohash.
Cell dimensions vary with latitude and so the table is for the worst-case scenario at the equator.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<emphasis role="strong">GeoHash length</emphasis>
</simpara>
</entry>
<entry>
<simpara>
<emphasis role="strong">Area width x height</emphasis>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
1
</simpara>
</entry>
<entry>
<simpara>
5,009.4km x 4,992.6km
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
2
</simpara>
</entry>
<entry>
<simpara>
1,252.3km x 624.1km
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
3
</simpara>
</entry>
<entry>
<simpara>
156.5km x 156km
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
4
</simpara>
</entry>
<entry>
<simpara>
39.1km x 19.5km
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
5
</simpara>
</entry>
<entry>
<simpara>
4.9km x 4.9km
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
6
</simpara>
</entry>
<entry>
<simpara>
1.2km x 609.4m
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
7
</simpara>
</entry>
<entry>
<simpara>
152.9m x 152.4m
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
8
</simpara>
</entry>
<entry>
<simpara>
38.2m x 19m
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
9
</simpara>
</entry>
<entry>
<simpara>
4.8m x 4.8m
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
10
</simpara>
</entry>
<entry>
<simpara>
1.2m x 59.5cm
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
11
</simpara>
</entry>
<entry>
<simpara>
14.9cm x 14.9cm
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
12
</simpara>
</entry>
<entry>
<simpara>
3.7cm x 1.9cm
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
<section id="_options_3">
<title>Options<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/geohashgrid-aggregation.asciidoc">Edit me</ulink></title>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
field
</simpara>
</entry>
<entry>
<simpara>
Mandatory. The name of the field indexed with GeoPoints.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
precision
</simpara>
</entry>
<entry>
<simpara>
Optional. The string length of the geohashes used to define
                cells/buckets in the results. Defaults to 5.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
size
</simpara>
</entry>
<entry>
<simpara>
Optional. The maximum number of geohash buckets to return
                (defaults to 10,000). When results are trimmed, buckets are
                prioritised based on the volumes of documents they contain.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
shard_size
</simpara>
</entry>
<entry>
<simpara>
Optional. To allow for more accurate counting of the top cells
                returned in the final result the aggregation defaults to
                returning <literal>max(10,(size x number-of-shards))</literal> buckets from each
                shard. If this heuristic is undesirable, the number considered
                from each shard can be over-ridden using this parameter.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
</section>
<section id="search-aggregations-bucket-global-aggregation">
<title>Global Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/global-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Defines a single bucket of all the documents within the search execution context. This context is defined by the indices and the document types you&#8217;re searching on, but is <emphasis role="strong">not</emphasis> influenced by the search query itself.</simpara>
<note><simpara>Global aggregators can only be placed as top level aggregators (it makes no sense to embed a global aggregator
        within another bucket aggregator)</simpara></note>
<simpara>Example:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "query" : {
        "match" : { "title" : "shirt" }
    },
    "aggs" : {
        "all_products" : {
            "global" : {}, <co id="CO73-1"/>
            "aggs" : { <co id="CO73-2"/>
                "avg_price" : { "avg" : { "field" : "price" } }
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO73-1">
<para>
The <literal>global</literal> aggregation has an empty body
</para>
</callout>
<callout arearefs="CO73-2">
<para>
The sub-aggregations that are registered for this <literal>global</literal> aggregation
</para>
</callout>
</calloutlist>
<simpara>The above aggregation demonstrates how one would compute aggregations (<literal>avg_price</literal> in this example) on all the documents in the search context, regardless of the query (in our example, it will compute the average price over all products in our catalog, not just on the "shirts").</simpara>
<simpara>The response for the above aggregation:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

    "aggregations" : {
        "all_products" : {
            "doc_count" : 100, <co id="CO74-1"/>
            "avg_price" : {
                "value" : 56.3
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO74-1">
<para>
The number of documents that were aggregated (in our case, all documents within the search context)
</para>
</callout>
</calloutlist>
</section>
<section id="search-aggregations-bucket-histogram-aggregation">
<title>Histogram Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/histogram-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A multi-bucket values source based aggregation that can be applied on numeric values extracted from the documents.
It dynamically builds fixed size (a.k.a. interval) buckets over the values. For example, if the documents have a field
that holds a price (numeric), we can configure this aggregation to dynamically build buckets with interval <literal>5</literal>
(in case of price it may represent $5). When the aggregation executes, the price field of every document will be
evaluated and will be rounded down to its closest bucket - for example, if the price is <literal>32</literal> and the bucket size is <literal>5</literal>
then the rounding will yield <literal>30</literal> and thus the document will "fall" into the bucket that is associated with the key <literal>30</literal>.
To make this more formal, here is the rounding function that is used:</simpara>
<programlisting language="java" linenumbering="unnumbered">bucket_key = Math.floor((value - offset) / interval) * interval + offset</programlisting>
<simpara>The <literal>interval</literal> must be a positive decimal, while the <literal>offset</literal> must be a decimal in <literal>[0, interval[</literal>.</simpara>
<simpara>The following snippet "buckets" the products based on their <literal>price</literal> by interval of <literal>50</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "prices" : {
            "histogram" : {
                "field" : "price",
                "interval" : 50
            }
        }
    }
}</programlisting>
<simpara>And the following may be the response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggregations": {
        "prices" : {
            "buckets": [
                {
                    "key": 0,
                    "doc_count": 2
                },
                {
                    "key": 50,
                    "doc_count": 4
                },
                {
                    "key": 100,
                    "doc_count": 0
                },
                {
                    "key": 150,
                    "doc_count": 3
                }
            ]
        }
    }
}</programlisting>
<section id="_minimum_document_count">
<title>Minimum document count<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/histogram-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The response above show that no documents has a price that falls within the range of <literal>[100 - 150)</literal>. By default the
response will fill gaps in the histogram with empty buckets. It is possible change that and request buckets with
a higher minimum count thanks to the <literal>min_doc_count</literal> setting:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "prices" : {
            "histogram" : {
                "field" : "price",
                "interval" : 50,
                "min_doc_count" : 1
            }
        }
    }
}</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggregations": {
        "prices" : {
            "buckets": [
                {
                    "key": 0,
                    "doc_count": 2
                },
                {
                    "key": 50,
                    "doc_count": 4
                },
                {
                    "key": 150,
                    "doc_count": 3
                }
            ]
        }
    }
}</programlisting>
<simpara id="search-aggregations-bucket-histogram-aggregation-extended-bounds">By default the <literal>histogram</literal> returns all the buckets within the range of the data itself, that is, the documents with
the smallest values (on which with histogram) will determine the min bucket (the bucket with the smallest key) and the
documents with the highest values will determine the max bucket (the bucket with the highest key). Often, when
requesting empty buckets, this causes a confusion, specifically, when the data is also filtered.</simpara>
<simpara>To understand why, let&#8217;s look at an example:</simpara>
<simpara>Lets say the you&#8217;re filtering your request to get all docs with values between <literal>0</literal> and <literal>500</literal>, in addition you&#8217;d like
to slice the data per price using a histogram with an interval of <literal>50</literal>. You also specify <literal>"min_doc_count" : 0</literal> as you&#8217;d
like to get all buckets even the empty ones. If it happens that all products (documents) have prices higher than <literal>100</literal>,
the first bucket you&#8217;ll get will be the one with <literal>100</literal> as its key. This is confusing, as many times, you&#8217;d also like
to get those buckets between <literal>0 - 100</literal>.</simpara>
<simpara>With <literal>extended_bounds</literal> setting, you now can "force" the histogram aggregation to start building buckets on a specific
<literal>min</literal> values and also keep on building buckets up to a <literal>max</literal> value (even if there are no documents anymore). Using
<literal>extended_bounds</literal> only makes sense when <literal>min_doc_count</literal> is 0 (the empty buckets will never be returned if <literal>min_doc_count</literal>
is greater than 0).</simpara>
<simpara>Note that (as the name suggest) <literal>extended_bounds</literal> is <emphasis role="strong">not</emphasis> filtering buckets. Meaning, if the <literal>extended_bounds.min</literal> is higher
than the values extracted from the documents, the documents will still dictate what the first bucket will be (and the
same goes for the <literal>extended_bounds.max</literal> and the last bucket). For filtering buckets, one should nest the histogram aggregation
under a range <literal>filter</literal> aggregation with the appropriate <literal>from</literal>/<literal>to</literal> settings.</simpara>
<simpara>Example:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "query" : {
        "constant_score" : { "filter": { "range" : { "price" : { "to" : "500" } } } }
    },
    "aggs" : {
        "prices" : {
            "histogram" : {
                "field" : "price",
                "interval" : 50,
                "extended_bounds" : {
                    "min" : 0,
                    "max" : 500
                }
            }
        }
    }
}</programlisting>
</section>
<section id="_order">
<title>Order<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/histogram-aggregation.asciidoc">Edit me</ulink></title>
<simpara>By default the returned buckets are sorted by their <literal>key</literal> ascending, though the order behaviour can be controlled
using the <literal>order</literal> setting.</simpara>
<simpara>Ordering the buckets by their key - descending:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "prices" : {
            "histogram" : {
                "field" : "price",
                "interval" : 50,
                "order" : { "_key" : "desc" }
            }
        }
    }
}</programlisting>
<simpara>Ordering the buckets by their <literal>doc_count</literal> - ascending:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "prices" : {
            "histogram" : {
                "field" : "price",
                "interval" : 50,
                "order" : { "_count" : "asc" }
            }
        }
    }
}</programlisting>
<simpara>If the histogram aggregation has a direct metrics sub-aggregation, the latter can determine the order of the buckets:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "prices" : {
            "histogram" : {
                "field" : "price",
                "interval" : 50,
                "order" : { "price_stats.min" : "asc" } <co id="CO75-1"/>
            },
            "aggs" : {
                "price_stats" : { "stats" : {} } <co id="CO75-2"/>
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO75-1">
<para>
The <literal>{ "price_stats.min" : asc" }</literal> will sort the buckets based on <literal>min</literal> value of their <literal>price_stats</literal> sub-aggregation.
</para>
</callout>
<callout arearefs="CO75-2">
<para>
There is no need to configure the <literal>price</literal> field for the <literal>price_stats</literal> aggregation as it will inherit it by default from its parent histogram aggregation.
</para>
</callout>
</calloutlist>
<simpara>It is also possible to order the buckets based on a "deeper" aggregation in the hierarchy. This is supported as long
as the aggregations path are of a single-bucket type, where the last aggregation in the path may either by a single-bucket
one or a metrics one. If it&#8217;s a single-bucket type, the order will be defined by the number of docs in the bucket (i.e. <literal>doc_count</literal>),
in case it&#8217;s a metrics one, the same rules as above apply (where the path must indicate the metric name to sort by in case of
a multi-value metrics aggregation, and in case of a single-value metrics aggregation the sort will be applied on that value).</simpara>
<simpara>The path must be defined in the following form:</simpara>
<remark> https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_Form</remark>
<programlisting language="ebnf" linenumbering="unnumbered">AGG_SEPARATOR       =  '&gt;' ;
METRIC_SEPARATOR    =  '.' ;
AGG_NAME            =  &lt;the name of the aggregation&gt; ;
METRIC              =  &lt;the name of the metric (in case of multi-value metrics aggregation)&gt; ;
PATH                =  &lt;AGG_NAME&gt; [ &lt;AGG_SEPARATOR&gt;, &lt;AGG_NAME&gt; ]* [ &lt;METRIC_SEPARATOR&gt;, &lt;METRIC&gt; ] ;</programlisting>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "prices" : {
            "histogram" : {
                "field" : "price",
                "interval" : 50,
                "order" : { "promoted_products&gt;rating_stats.avg" : "desc" } <co id="CO76-1"/>
            },
            "aggs" : {
                "promoted_products" : {
                    "filter" : { "term" : { "promoted" : true }},
                    "aggs" : {
                        "rating_stats" : { "stats" : { "field" : "rating" }}
                    }
                }
            }
        }
    }
}</programlisting>
<simpara>The above will sort the buckets based on the avg rating among the promoted products</simpara>
</section>
<section id="_offset_2">
<title>Offset<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/histogram-aggregation.asciidoc">Edit me</ulink></title>
<simpara>By default the bucket keys start with 0 and then continue in even spaced steps of <literal>interval</literal>, e.g. if the interval is 10 the first buckets
(assuming there is data inside them) will be [0 - 9], [10-19], [20-29]. The bucket boundaries can be shifted by using the <literal>offset</literal> option.</simpara>
<simpara>This can be best illustrated with an example. If there are 10 documents with values ranging from 5 to 14, using interval <literal>10</literal> will result in
two buckets with 5 documents each. If an additional offset <literal>5</literal> is used, there will be only one single bucket [5-14] containing all the 10
documents.</simpara>
</section>
<section id="_response_format">
<title>Response Format<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/histogram-aggregation.asciidoc">Edit me</ulink></title>
<simpara>By default, the buckets are returned as an ordered array. It is also possible to request the response as a hash
instead keyed by the buckets keys:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "prices" : {
            "histogram" : {
                "field" : "price",
                "interval" : 50,
                "keyed" : true
            }
        }
    }
}</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggregations": {
        "prices": {
            "buckets": {
                "0": {
                    "key": 0,
                    "doc_count": 2
                },
                "50": {
                    "key": 50,
                    "doc_count": 4
                },
                "150": {
                    "key": 150,
                    "doc_count": 3
                }
            }
        }
    }
}</programlisting>
</section>
<section id="_missing_value_11">
<title>Missing value<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/histogram-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>missing</literal> parameter defines how documents that are missing a value should be treated.
By default they will be ignored but it is also possible to treat them as if they
had a value.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "quantity" : {
             "histogram" : {
                 "field" : "quantity",
                 "interval": 10,
                 "missing": 0 <co id="CO76-2"/>
             }
         }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO76-1 CO76-2">
<para>
Documents without a value in the <literal>quantity</literal> field will fall into the same bucket as documents that have the value <literal>0</literal>.
</para>
</callout>
</calloutlist>
</section>
</section>
<section id="search-aggregations-bucket-iprange-aggregation">
<title>IP Range Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/iprange-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Just like the dedicated <link linkend="search-aggregations-bucket-daterange-aggregation">date</link> range aggregation, there is also a dedicated range aggregation for IP typed fields:</simpara>
<simpara>Example:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "ip_ranges" : {
            "ip_range" : {
                "field" : "ip",
                "ranges" : [
                    { "to" : "10.0.0.5" },
                    { "from" : "10.0.0.5" }
                ]
            }
        }
    }
}</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

    "aggregations": {
        "ip_ranges": {
            "buckets" : [
                {
                    "to": "10.0.0.5",
                    "doc_count": 4
                },
                {
                    "from": "10.0.0.5",
                    "doc_count": 6
                }
            ]
        }
    }
}</programlisting>
<simpara>IP ranges can also be defined as CIDR masks:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "ip_ranges" : {
            "ip_range" : {
                "field" : "ip",
                "ranges" : [
                    { "mask" : "10.0.0.0/25" },
                    { "mask" : "10.0.0.127/25" }
                ]
            }
        }
    }
}</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggregations": {
        "ip_ranges": {
            "buckets": [
                {
                    "key": "10.0.0.0/25",
                    "from": "10.0.0.0",
                    "to": "10.0.0.127",
                    "doc_count": 127
                },
                {
                    "key": "10.0.0.127/25",
                    "from": "10.0.0.0",
                    "to": "10.0.0.127",
                    "doc_count": 127
                }
            ]
        }
    }
}</programlisting>
</section>
<section id="search-aggregations-bucket-missing-aggregation">
<title>Missing Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/missing-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A field data based single bucket aggregation, that creates a bucket of all documents in the current document set context that are missing a field value (effectively, missing a field or having the configured NULL value set). This aggregator will often be used in conjunction with other field data bucket aggregators (such as ranges) to return information for all the documents that could not be placed in any of the other buckets due to missing field data values.</simpara>
<simpara>Example:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "products_without_a_price" : {
            "missing" : { "field" : "price" }
        }
    }
}</programlisting>
<simpara>In the above example, we get the total number of products that do not have a price.</simpara>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

    "aggs" : {
        "products_without_a_price" : {
            "doc_count" : 10
        }
    }
}</programlisting>
</section>
<section id="search-aggregations-bucket-nested-aggregation">
<title>Nested Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/nested-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A special single bucket aggregation that enables aggregating nested documents.</simpara>
<simpara>For example, lets say we have a index of products, and each product holds the list of resellers - each having its own
price for the product. The mapping could look like:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

    "product" : {
        "properties" : {
            "resellers" : { <co id="CO77-1"/>
                "type" : "nested",
                "properties" : {
                    "name" : { "type" : "text" },
                    "price" : { "type" : "double" }
                }
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO77-1">
<para>
The <literal>resellers</literal> is an array that holds nested documents under the <literal>product</literal> object.
</para>
</callout>
</calloutlist>
<simpara>The following aggregations will return the minimum price products can be purchased in:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "query" : {
        "match" : { "name" : "led tv" }
    },
    "aggs" : {
        "resellers" : {
            "nested" : {
                "path" : "resellers"
            },
            "aggs" : {
                "min_price" : { "min" : { "field" : "resellers.price" } }
            }
        }
    }
}</programlisting>
<simpara>As you can see above, the nested aggregation requires the <literal>path</literal> of the nested documents within the top level documents.
Then one can define any type of aggregation over these nested documents.</simpara>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggregations": {
        "resellers": {
            "min_price": {
                "value" : 350
            }
        }
    }
}</programlisting>
</section>
<section id="search-aggregations-bucket-range-aggregation">
<title>Range Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/range-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A multi-bucket value source based aggregation that enables the user to define a set of ranges - each representing a bucket. During the aggregation process, the values extracted from each document will be checked against each bucket range and "bucket" the relevant/matching document.
Note that this aggregation includes the <literal>from</literal> value and excludes the <literal>to</literal> value for each range.</simpara>
<simpara>Example:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "price_ranges" : {
            "range" : {
                "field" : "price",
                "ranges" : [
                    { "to" : 50 },
                    { "from" : 50, "to" : 100 },
                    { "from" : 100 }
                ]
            }
        }
    }
}</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

    "aggregations": {
        "price_ranges" : {
            "buckets": [
                {
                    "to": 50,
                    "doc_count": 2
                },
                {
                    "from": 50,
                    "to": 100,
                    "doc_count": 4
                },
                {
                    "from": 100,
                    "doc_count": 4
                }
            ]
        }
    }
}</programlisting>
<section id="_keyed_response">
<title>Keyed Response<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/range-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Setting the <literal>keyed</literal> flag to <literal>true</literal> will associate a unique string key with each bucket and return the ranges as a hash rather than an array:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "price_ranges" : {
            "range" : {
                "field" : "price",
                "keyed" : true,
                "ranges" : [
                    { "to" : 50 },
                    { "from" : 50, "to" : 100 },
                    { "from" : 100 }
                ]
            }
        }
    }
}</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

    "aggregations": {
        "price_ranges" : {
            "buckets": {
                "*-50.0": {
                    "to": 50,
                    "doc_count": 2
                },
                "50.0-100.0": {
                    "from": 50,
                    "to": 100,
                    "doc_count": 4
                },
                "100.0-*": {
                    "from": 100,
                    "doc_count": 4
                }
            }
        }
    }
}</programlisting>
<simpara>It is also possible to customize the key for each range:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "price_ranges" : {
            "range" : {
                "field" : "price",
                "keyed" : true,
                "ranges" : [
                    { "key" : "cheap", "to" : 50 },
                    { "key" : "average", "from" : 50, "to" : 100 },
                    { "key" : "expensive", "from" : 100 }
                ]
            }
        }
    }
}</programlisting>
</section>
<section id="_script_12">
<title>Script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/range-aggregation.asciidoc">Edit me</ulink></title>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "price_ranges" : {
            "range" : {
                "script" : {
                    "lang": "painless",
                    "inline": "doc['price'].value"
                },
                "ranges" : [
                    { "to" : 50 },
                    { "from" : 50, "to" : 100 },
                    { "from" : 100 }
                ]
            }
        }
    }
}</programlisting>
<simpara>This will interpret the <literal>script</literal> parameter as an <literal>inline</literal> script with the <literal>painless</literal> script language and no script parameters. To use a file script use the following syntax:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "price_ranges" : {
            "range" : {
                "script" : {
                    "file": "my_script",
                    "params": {
                        "field": "price"
                    }
                },
                "ranges" : [
                    { "to" : 50 },
                    { "from" : 50, "to" : 100 },
                    { "from" : 100 }
                ]
            }
        }
    }
}</programlisting>
<tip><simpara>for indexed scripts replace the <literal>file</literal> parameter with an <literal>id</literal> parameter.</simpara></tip>
</section>
<section id="_value_script_7">
<title>Value Script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/range-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Lets say the product prices are in USD but we would like to get the price ranges in EURO. We can use value script to convert the prices prior the aggregation (assuming conversion rate of 0.8)</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "price_ranges" : {
            "range" : {
                "field" : "price",
                "script" : {
                    "lang": "painless",
                    "inline": "_value * params.conversion_rate",
                    "params" : {
                        "conversion_rate" : 0.8
                    }
                },
                "ranges" : [
                    { "to" : 35 },
                    { "from" : 35, "to" : 70 },
                    { "from" : 70 }
                ]
            }
        }
    }
}</programlisting>
</section>
<section id="_sub_aggregations">
<title>Sub Aggregations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/range-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The following example, not only "bucket" the documents to the different buckets but also computes statistics over the prices in each price range</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "price_ranges" : {
            "range" : {
                "field" : "price",
                "ranges" : [
                    { "to" : 50 },
                    { "from" : 50, "to" : 100 },
                    { "from" : 100 }
                ]
            },
            "aggs" : {
                "price_stats" : {
                    "stats" : { "field" : "price" }
                }
            }
        }
    }
}</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggregations": {
        "price_ranges" : {
            "buckets": [
                {
                    "to": 50,
                    "doc_count": 2,
                    "price_stats": {
                        "count": 2,
                        "min": 20,
                        "max": 47,
                        "avg": 33.5,
                        "sum": 67
                    }
                },
                {
                    "from": 50,
                    "to": 100,
                    "doc_count": 4,
                    "price_stats": {
                        "count": 4,
                        "min": 60,
                        "max": 98,
                        "avg": 82.5,
                        "sum": 330
                    }
                },
                {
                    "from": 100,
                    "doc_count": 4,
                    "price_stats": {
                        "count": 4,
                        "min": 134,
                        "max": 367,
                        "avg": 216,
                        "sum": 864
                    }
                }
            ]
        }
    }
}</programlisting>
<simpara>If a sub aggregation is also based on the same value source as the range aggregation (like the <literal>stats</literal> aggregation in the example above) it is possible to leave out the value source definition for it. The following will return the same response as above:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "price_ranges" : {
            "range" : {
                "field" : "price",
                "ranges" : [
                    { "to" : 50 },
                    { "from" : 50, "to" : 100 },
                    { "from" : 100 }
                ]
            },
            "aggs" : {
                "price_stats" : {
                    "stats" : {} <co id="CO78-1"/>
                }
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO78-1">
<para>
We don&#8217;t need to specify the <literal>price</literal> as we "inherit" it by default from the parent <literal>range</literal> aggregation
</para>
</callout>
</calloutlist>
</section>
</section>
<section id="search-aggregations-bucket-reverse-nested-aggregation">
<title>Reverse nested Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/reverse-nested-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A special single bucket aggregation that enables aggregating on parent docs from nested documents. Effectively this
aggregation can break out of the nested block structure and link to other nested structures or the root document,
which allows nesting other aggregations that aren&#8217;t part of the nested object in a nested aggregation.</simpara>
<simpara>The <literal>reverse_nested</literal> aggregation must be defined inside a <literal>nested</literal> aggregation.</simpara>
<itemizedlist><title>Options:</title>
<listitem>
<simpara>
<literal>path</literal> - Which defines to what nested object field should be joined back. The default is empty,
which means that it joins back to the root / main document level. The path cannot contain a reference to
a nested object field that falls outside the <literal>nested</literal> aggregation&#8217;s nested structure a <literal>reverse_nested</literal> is in.
</simpara>
</listitem>
</itemizedlist>
<simpara>For example, lets say we have an index for a ticket system with issues and comments. The comments are inlined into
the issue documents as nested documents. The mapping could look like:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

    "issue" : {
        "properties" : {
            "tags" : { "type" : "text" }
            "comments" : { <co id="CO79-1"/>
                "type" : "nested"
                "properties" : {
                    "username" : { "type" : "keyword" },
                    "comment" : { "type" : "text" }
                }
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO79-1">
<para>
The <literal>comments</literal> is an array that holds nested documents under the <literal>issue</literal> object.
</para>
</callout>
</calloutlist>
<simpara>The following aggregations will return the top commenters' username that have commented and per top commenter the top
tags of the issues the user has commented on:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "query": {
    "match": {
      "name": "led tv"
    }
  },
  "aggs": {
    "comments": {
      "nested": {
        "path": "comments"
      },
      "aggs": {
        "top_usernames": {
          "terms": {
            "field": "comments.username"
          },
          "aggs": {
            "comment_to_issue": {
              "reverse_nested": {}, <co id="CO80-1"/>
              "aggs": {
                "top_tags_per_comment": {
                  "terms": {
                    "field": "tags"
                  }
                }
              }
            }
          }
        }
      }
    }
  }
}</programlisting>
<simpara>As you can see above, the <literal>reverse_nested</literal> aggregation is put in to a <literal>nested</literal> aggregation as this is the only place
in the dsl where the <literal>reversed_nested</literal> aggregation can be used. Its sole purpose is to join back to a parent doc higher
up in the nested structure.</simpara>
<calloutlist>
<callout arearefs="CO80-1">
<para>
A <literal>reverse_nested</literal> aggregation that joins back to the root / main document level, because no <literal>path</literal> has been defined.
Via the <literal>path</literal> option the <literal>reverse_nested</literal> aggregation can join back to a different level, if multiple layered nested
object types have been defined in the mapping
</para>
</callout>
</calloutlist>
<simpara>Possible response snippet:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "aggregations": {
    "comments": {
      "top_usernames": {
        "buckets": [
          {
            "key": "username_1",
            "doc_count": 12,
            "comment_to_issue": {
              "top_tags_per_comment": {
                "buckets": [
                  {
                    "key": "tag1",
                    "doc_count": 9
                  },
                  ...
                ]
              }
            }
          },
          ...
        ]
      }
    }
  }
}</programlisting>
</section>
<section id="search-aggregations-bucket-sampler-aggregation">
<title>Sampler Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/sampler-aggregation.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This functionality is experimental and may be changed or removed completely in a future release.</simpara></warning>
<simpara>A filtering aggregation used to limit any sub aggregations' processing to a sample of the top-scoring documents.</simpara>
<itemizedlist><title>Example use cases:</title>
<listitem>
<simpara>
Tightening the focus of analytics to high-relevance matches rather than the potentially very long tail of low-quality matches
</simpara>
</listitem>
<listitem>
<simpara>
Reducing the running cost of aggregations that can produce useful results using only samples e.g. <literal>significant_terms</literal>
</simpara>
</listitem>
</itemizedlist>
<simpara>Example:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "query": {
        "match": {
            "text": "iphone"
        }
    },
    "aggs": {
        "sample": {
            "sampler": {
                "shard_size": 200
            },
            "aggs": {
                "keywords": {
                    "significant_terms": {
                        "field": "text"
                    }
                }
            }
        }
    }
}</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...
        "aggregations": {
        "sample": {
            "doc_count": 1000,<co id="CO81-1"/>
            "keywords": {
                "doc_count": 1000,
                "buckets": [
                    ...
                    {
                        "key": "bend",
                        "doc_count": 58,
                        "score": 37.982536582524276,
                        "bg_count": 103
                    },
                    ....
}</programlisting>
<calloutlist>
<callout arearefs="CO81-1">
<para>
1000 documents were sampled in total because we asked for a maximum of 200 from an index with 5 shards. The cost of performing the nested significant_terms aggregation was therefore limited rather than unbounded.
</para>
</callout>
</calloutlist>
<section id="_shard_size_2">
<title>shard_size<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/sampler-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>shard_size</literal> parameter limits how many top-scoring documents are collected in the sample processed on each shard.
The default value is 100.</simpara>
</section>
<section id="_limitations_3">
<title>Limitations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/sampler-aggregation.asciidoc">Edit me</ulink></title>
<section id="_cannot_be_nested_under_literal_breadth_first_literal_aggregations_2">
<title>Cannot be nested under <literal>breadth_first</literal> aggregations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/sampler-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Being a quality-based filter the sampler aggregation needs access to the relevance score produced for each document.
It therefore cannot be nested under a <literal>terms</literal> aggregation which has the <literal>collect_mode</literal> switched from the default <literal>depth_first</literal> mode to <literal>breadth_first</literal> as this discards scores.
In this situation an error will be thrown.</simpara>
</section>
</section>
</section>
<section id="search-aggregations-bucket-significantterms-aggregation">
<title>Significant Terms Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/significantterms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>An aggregation that returns interesting or unusual occurrences of terms in a set.</simpara>
<warning role="experimental"><simpara>The <literal>significant_terms</literal> aggregation can be very heavy when run on large indices.  Work is in progress to provide more lightweight sampling techniques.  As a result, the API for this feature may change in non-backwards compatible ways.</simpara></warning>
<itemizedlist><title>Example use cases:</title>
<listitem>
<simpara>
Suggesting "H5N1" when users search for "bird flu" in text
</simpara>
</listitem>
<listitem>
<simpara>
Identifying the merchant that is the "common point of compromise" from the transaction history of credit card owners reporting loss
</simpara>
</listitem>
<listitem>
<simpara>
Suggesting keywords relating to stock symbol $ATI for an automated news classifier
</simpara>
</listitem>
<listitem>
<simpara>
Spotting the fraudulent doctor who is diagnosing more than his fair share of whiplash injuries
</simpara>
</listitem>
<listitem>
<simpara>
Spotting the tire manufacturer who has a disproportionate number of blow-outs
</simpara>
</listitem>
</itemizedlist>
<simpara>In all these cases the terms being selected are not simply the most popular terms in a set.
They are the terms that have undergone a significant change in popularity measured between a <emphasis>foreground</emphasis> and <emphasis>background</emphasis> set.
If the term "H5N1" only exists in 5 documents in a 10 million document index and yet is found in 4 of the 100 documents that make up a user&#8217;s search results
that is significant and probably very relevant to their search. 5/10,000,000 vs 4/100 is a big swing in frequency.</simpara>
<section id="_single_set_analysis">
<title>Single-set analysis<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/significantterms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>In the simplest case, the <emphasis>foreground</emphasis> set of interest is the search results matched by a query and the <emphasis>background</emphasis>
set used for statistical comparisons is the index or indices from which the results were gathered.</simpara>
<simpara>Example:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "query" : {
        "terms" : {"force" : [ "British Transport Police" ]}
    },
    "aggregations" : {
        "significantCrimeTypes" : {
            "significant_terms" : { "field" : "crime_type" }
        }
    }
}</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

    "aggregations" : {
        "significantCrimeTypes" : {
            "doc_count": 47347,
            "buckets" : [
                {
                    "key": "Bicycle theft",
                    "doc_count": 3640,
                    "score": 0.371235374214817,
                    "bg_count": 66799
                }
                ...
            ]
        }
    }
}</programlisting>
<simpara>When querying an index of all crimes from all police forces, what these results show is that the British Transport Police force
stand out as a force dealing with a disproportionately large number of bicycle thefts. Ordinarily, bicycle thefts represent only 1% of crimes (66799/5064554)
but for the British Transport Police, who handle crime on railways and stations, 7% of crimes (3640/47347) is
a bike theft. This is a significant seven-fold increase in frequency and so this anomaly was highlighted as the top crime type.</simpara>
<simpara>The problem with using a query to spot anomalies is it only gives us one subset to use for comparisons.
To discover all the other police forces' anomalies we would have to repeat the query for each of the different forces.</simpara>
<simpara>This can be a tedious way to look for unusual patterns in an index</simpara>
</section>
<section id="_multi_set_analysis">
<title>Multi-set analysis<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/significantterms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A simpler way to perform analysis across multiple categories is to use a parent-level aggregation to segment the data ready for analysis.</simpara>
<simpara>Example using a parent aggregation for segmentation:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggregations": {
        "forces": {
            "terms": {"field": "force"},
            "aggregations": {
                "significantCrimeTypes": {
                    "significant_terms": {"field": "crime_type"}
                }
            }
        }
    }
}</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
 ...

 "aggregations": {
    "forces": {
        "buckets": [
            {
                "key": "Metropolitan Police Service",
                "doc_count": 894038,
                "significantCrimeTypes": {
                    "doc_count": 894038,
                    "buckets": [
                        {
                            "key": "Robbery",
                            "doc_count": 27617,
                            "score": 0.0599,
                            "bg_count": 53182
                        },
                        ...
                    ]
                }
            },
            {
                "key": "British Transport Police",
                "doc_count": 47347,
                "significantCrimeTypes": {
                    "doc_count": 47347,
                    "buckets": [
                        {
                            "key": "Bicycle theft",
                            "doc_count": 3640,
                            "score": 0.371,
                            "bg_count": 66799
                        },
                        ...
                    ]
                }
            }
        ]
    }
}</programlisting>
<simpara>Now we have anomaly detection for each of the police forces using a single request.</simpara>
<simpara>We can use other forms of top-level aggregations to segment our data, for example segmenting by geographic
area to identify unusual hot-spots of a particular crime type:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs": {
        "hotspots": {
            "geohash_grid" : {
                "field":"location",
                "precision":5,
            },
            "aggs": {
                "significantCrimeTypes": {
                    "significant_terms": {"field": "crime_type"}
                }
            }
        }
    }
}</programlisting>
<simpara>This example uses the <literal>geohash_grid</literal> aggregation to create result buckets that represent geographic areas, and inside each
bucket we can identify anomalous levels of a crime type in these tightly-focused areas e.g.</simpara>
<itemizedlist>
<listitem>
<simpara>
Airports exhibit unusual numbers of weapon confiscations
</simpara>
</listitem>
<listitem>
<simpara>
Universities show uplifts of bicycle thefts
</simpara>
</listitem>
</itemizedlist>
<simpara>At a higher geohash_grid zoom-level with larger coverage areas we would start to see where an entire police-force may be
tackling an unusual volume of a particular crime type.</simpara>
<simpara>Obviously a time-based top-level segmentation would help identify current trends for each point in time
where a simple <literal>terms</literal> aggregation would typically show the very popular "constants" that persist across all time slots.</simpara>
<sidebar>
<title>How are the scores calculated?</title>
<simpara>The numbers returned for scores are primarily intended for ranking different suggestions sensibly rather than something easily understood by end users. The scores are derived from the doc frequencies in <emphasis>foreground</emphasis> and <emphasis>background</emphasis> sets. In brief, a term is considered significant if there is a noticeable difference in the frequency in which a term appears in the subset and in the background. The way the terms are ranked can be configured, see "Parameters" section.</simpara>
</sidebar>
</section>
<section id="_use_on_free_text_fields">
<title>Use on free-text fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/significantterms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The significant_terms aggregation can be used effectively on tokenized free-text fields to suggest:</simpara>
<itemizedlist>
<listitem>
<simpara>
keywords for refining end-user searches
</simpara>
</listitem>
<listitem>
<simpara>
keywords for use in percolator queries
</simpara>
</listitem>
</itemizedlist>
<warning><simpara>Picking a free-text field as the subject of a significant terms analysis can be expensive! It will attempt
to load every unique word into RAM. It is recommended to only use this on smaller indices.</simpara></warning>
<sidebar>
<title>Use the <emphasis>"like this but not this"</emphasis> pattern</title>
<simpara>You can spot mis-categorized content by first searching a structured field e.g. <literal>category:adultMovie</literal> and use significant_terms on the
free-text "movie_description" field. Take the suggested words (I&#8217;ll leave them to your imagination) and then search for all movies NOT marked as category:adultMovie but containing these keywords.
You now have a ranked list of badly-categorized movies that you should reclassify or at least remove from the "familyFriendly" category.</simpara>
<simpara>The significance score from each term can also provide a useful <literal>boost</literal> setting to sort matches.
Using the <literal>minimum_should_match</literal> setting of the <literal>terms</literal> query with the keywords will help control the balance of precision/recall in the result set i.e
a high setting would have a small number of relevant results packed full of keywords and a setting of "1" would produce a more exhaustive results set with all documents containing <emphasis>any</emphasis> keyword.</simpara>
</sidebar>
<tip>
<formalpara><title>Show significant_terms in context</title><para>Free-text significant_terms are much more easily understood when viewed in context. Take the results of <literal>significant_terms</literal> suggestions from a
free-text field and use them in a <literal>terms</literal> query on the same field with a <literal>highlight</literal> clause to present users with example snippets of documents. When the terms
are presented unstemmed, highlighted, with the right case, in the right order and with some context, their significance/meaning is more readily apparent.</para></formalpara>
</tip>
</section>
<section id="_custom_background_sets">
<title>Custom background sets<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/significantterms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Ordinarily, the foreground set of documents is "diffed" against a background set of all the documents in your index.
However, sometimes it may prove useful to use a narrower background set as the basis for comparisons.
For example, a query on documents relating to "Madrid" in an index with content from all over the world might reveal that "Spanish"
was a significant term. This may be true but if you want some more focused terms you could use a <literal>background_filter</literal>
on the term <emphasis>spain</emphasis> to establish a narrower set of documents as context. With this as a background "Spanish" would now
be seen as commonplace and therefore not as significant as words like "capital" that relate more strongly with Madrid.
Note that using a background filter will slow things down - each term&#8217;s background frequency must now be derived on-the-fly from filtering posting lists rather than reading the index&#8217;s pre-computed count for a term.</simpara>
</section>
<section id="_limitations_4">
<title>Limitations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/significantterms-aggregation.asciidoc">Edit me</ulink></title>
<section id="_significant_terms_must_be_indexed_values">
<title>Significant terms must be indexed values<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/significantterms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Unlike the terms aggregation it is currently not possible to use script-generated terms for counting purposes.
Because of the way the significant_terms aggregation must consider both <emphasis>foreground</emphasis> and <emphasis>background</emphasis> frequencies
it would be prohibitively expensive to use a script on the entire index to obtain background frequencies for comparisons.
Also DocValues are not supported as sources of term data for similar reasons.</simpara>
</section>
<section id="_no_analysis_of_floating_point_fields">
<title>No analysis of floating point fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/significantterms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Floating point fields are currently not supported as the subject of significant_terms analysis.
While integer or long fields can be used to represent concepts like bank account numbers or category numbers which
can be interesting to track, floating point fields are usually used to represent quantities of something.
As such, individual floating point terms are not useful for this form of frequency analysis.</simpara>
</section>
<section id="_use_as_a_parent_aggregation">
<title>Use as a parent aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/significantterms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>If there is the equivalent of a <literal>match_all</literal> query or no query criteria providing a subset of the index the significant_terms aggregation should not be used as the
top-most aggregation - in this scenario the <emphasis>foreground</emphasis> set is exactly the same as the <emphasis>background</emphasis> set and
so there is no difference in document frequencies to observe and from which to make sensible suggestions.</simpara>
<simpara>Another consideration is that  the significant_terms aggregation produces many candidate results at shard level
that are only later pruned on the reducing node once all statistics from all shards are merged. As a result,
it can be inefficient and costly in terms of RAM to embed large child aggregations under a significant_terms
aggregation that later discards many candidate terms. It is advisable in these cases to perform two searches - the first to provide a rationalized list of
significant_terms and then add this shortlist of terms to a second query to go back and fetch the required child aggregations.</simpara>
</section>
<section id="_approximate_counts">
<title>Approximate counts<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/significantterms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The counts of how many documents contain a term provided in results are based on summing the samples returned from each shard and
as such may be:</simpara>
<itemizedlist>
<listitem>
<simpara>
low if certain shards did not provide figures for a given term in their top sample
</simpara>
</listitem>
<listitem>
<simpara>
high when considering the background frequency as it may count occurrences found in deleted documents
</simpara>
</listitem>
</itemizedlist>
<simpara>Like most design decisions, this is the basis of a trade-off in which we have chosen to provide fast performance at the cost of some (typically small) inaccuracies.
However, the <literal>size</literal> and <literal>shard size</literal> settings covered in the next section provide tools to help control the accuracy levels.</simpara>
</section>
</section>
<section id="_parameters_5">
<title>Parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/significantterms-aggregation.asciidoc">Edit me</ulink></title>
<section id="_jlh_score">
<title>JLH score<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/significantterms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The scores are derived from the doc frequencies in <emphasis>foreground</emphasis> and <emphasis>background</emphasis> sets. The <emphasis>absolute</emphasis> change in popularity (foregroundPercent - backgroundPercent) would favor common terms whereas the <emphasis>relative</emphasis> change in popularity (foregroundPercent/ backgroundPercent) would favor rare terms. Rare vs common is essentially a precision vs recall balance and so the absolute and relative changes are multiplied to provide a sweet spot between precision and recall.</simpara>
</section>
<section id="_mutual_information">
<title>mutual information<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/significantterms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Mutual information as described in "Information Retrieval", Manning et al., Chapter 13.5.1 can be used as significance score by adding the parameter</simpara>
<programlisting language="js" linenumbering="unnumbered">         "mutual_information": {
              "include_negatives": true
         }</programlisting>
<simpara>Mutual information does not differentiate between terms that are descriptive for the subset or for documents outside the subset. The significant terms therefore can contain terms that appear more or less frequent in the subset than outside the subset. To filter out the terms that appear less often in the subset than in documents outside the subset, <literal>include_negatives</literal> can be set to <literal>false</literal>.</simpara>
<simpara>Per default, the assumption is that the documents in the bucket are also contained in the background. If instead you defined a custom background filter that represents a different set of documents that you want to compare to, set</simpara>
<programlisting language="js" linenumbering="unnumbered">"background_is_superset": false</programlisting>
</section>
<section id="_chi_square">
<title>Chi square<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/significantterms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Chi square as described in "Information Retrieval", Manning et al., Chapter 13.5.2 can be used as significance score by adding the parameter</simpara>
<programlisting language="js" linenumbering="unnumbered">         "chi_square": {
         }</programlisting>
<simpara>Chi square behaves like mutual information and can be configured with the same parameters <literal>include_negatives</literal> and <literal>background_is_superset</literal>.</simpara>
</section>
<section id="_google_normalized_distance">
<title>google normalized distance<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/significantterms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Google normalized distance  as described in "The Google Similarity Distance", Cilibrasi and Vitanyi, 2007 (<ulink url="http://arxiv.org/pdf/cs/0412098v3.pdf">http://arxiv.org/pdf/cs/0412098v3.pdf</ulink>) can be used as significance score by adding the parameter</simpara>
<programlisting language="js" linenumbering="unnumbered">         "gnd": {
         }</programlisting>
<simpara><literal>gnd</literal> also accepts the <literal>background_is_superset</literal> parameter.</simpara>
</section>
<section id="_percentage">
<title>Percentage<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/significantterms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A simple calculation of the number of documents in the foreground sample with a term divided by the number of documents in the background with the term.
By default this produces a score greater than zero and less than one.</simpara>
<simpara>The benefit of this heuristic is that the scoring logic is simple to explain to anyone familiar with a "per capita" statistic. However, for fields with high cardinality there is a tendency for this heuristic to select the rarest terms such as typos that occur only once because they score 1/1 = 100%.</simpara>
<simpara>It would be hard for a seasoned boxer to win a championship if the prize was awarded purely on the basis of percentage of fights won - by these rules a newcomer with only one fight under his belt would be impossible to beat.
Multiple observations are typically required to reinforce a view so it is recommended in these cases to set both <literal>min_doc_count</literal> and <literal>shard_min_doc_count</literal> to a higher value such as 10 in order to filter out the low-frequency terms that otherwise take precedence.</simpara>
<programlisting language="js" linenumbering="unnumbered">         "percentage": {
         }</programlisting>
</section>
<section id="_which_one_is_best">
<title>Which one is best?<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/significantterms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Roughly, <literal>mutual_information</literal> prefers high frequent terms even if they occur also frequently in the background. For example, in an analysis of natural language text this might lead to selection of stop words. <literal>mutual_information</literal> is unlikely to select very rare terms like misspellings. <literal>gnd</literal> prefers terms with a high co-occurrence and avoids selection of stopwords. It might be better suited for synonym detection. However, <literal>gnd</literal> has a tendency to select very rare terms that are, for example, a result of misspelling. <literal>chi_square</literal> and <literal>jlh</literal> are somewhat in-between.</simpara>
<simpara>It is hard to say which one of the different heuristics will be the best choice as it depends on what the significant terms are used for (see for example [Yang and Pedersen, "A Comparative Study on Feature Selection in Text Categorization", 1997](<ulink url="http://courses.ischool.berkeley.edu/i256/f06/papers/yang97comparative.pdf">http://courses.ischool.berkeley.edu/i256/f06/papers/yang97comparative.pdf</ulink>) for a study on using significant terms for feature selection for text classification).</simpara>
<simpara>If none of the above measures suits your usecase than another option is to implement a custom significance measure:</simpara>
</section>
<section id="_scripted">
<title>scripted<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/significantterms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Customized scores can be implemented via a script:</simpara>
<programlisting language="js" linenumbering="unnumbered">            "script_heuristic": {
              "script": {
                "lang": "painless",
                "inline": "params._subset_freq/(params._superset_freq - params._subset_freq + 1)"
              }
            }</programlisting>
<simpara>Scripts can be inline (as in above example), indexed or stored on disk. For details on the options, see <link linkend="modules-scripting">script documentation</link>.</simpara>
<simpara>Available parameters in the script are</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>_subset_freq</literal>
</simpara>
</entry>
<entry>
<simpara>
Number of documents the term appears in in the subset.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>_superset_freq</literal>
</simpara>
</entry>
<entry>
<simpara>
Number of documents the term appears in in the superset.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>_subset_size</literal>
</simpara>
</entry>
<entry>
<simpara>
Number of documents in the subset.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>_superset_size</literal>
</simpara>
</entry>
<entry>
<simpara>
Number of documents in the superset.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
<section id="_size_amp_shard_size">
<title>Size &amp; Shard Size<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/significantterms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>size</literal> parameter can be set to define how many term buckets should be returned out of the overall terms list. By
default, the node coordinating the search process will request each shard to provide its own top term buckets
and once all shards respond, it will reduce the results to the final list that will then be returned to the client.
If the number of unique terms is greater than <literal>size</literal>, the returned list can be slightly off and not accurate
(it could be that the term counts are slightly off and it could even be that a term that should have been in the top
size buckets was not returned).</simpara>
<simpara>To ensure better accuracy a multiple of the final <literal>size</literal> is used as the number of terms to request from each shard
using a heuristic based on the number of shards. To take manual control of this setting the <literal>shard_size</literal> parameter
can be  used to control the volumes of candidate terms produced by each shard.</simpara>
<simpara>Low-frequency terms can turn out to be the most interesting ones once all results are combined so the
significant_terms aggregation can produce higher-quality results when the <literal>shard_size</literal> parameter is set to
values significantly higher than the <literal>size</literal> setting. This ensures that a bigger volume of promising candidate terms are given
a consolidated review by the reducing node before the final selection. Obviously large candidate term lists
will cause extra network traffic and RAM usage so this is  quality/cost trade off that needs to be balanced.  If <literal>shard_size</literal> is set to -1 (the default) then <literal>shard_size</literal> will be automatically estimated based on the number of shards and the <literal>size</literal> parameter.</simpara>
<note><simpara><literal>shard_size</literal> cannot be smaller than <literal>size</literal> (as it doesn&#8217;t make much sense). When it is, elasticsearch will
        override it and reset it to be equal to <literal>size</literal>.</simpara></note>
</section>
<section id="_minimum_document_count_2">
<title>Minimum document count<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/significantterms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>It is possible to only return terms that match more than a configured number of hits using the <literal>min_doc_count</literal> option:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "tags" : {
            "significant_terms" : {
                "field" : "tag",
                "min_doc_count": 10
            }
        }
    }
}</programlisting>
<simpara>The above aggregation would only return tags which have been found in 10 hits or more. Default value is <literal>3</literal>.</simpara>
<simpara>Terms that score highly will be collected on a shard level and merged with the terms collected from other shards in a second step. However, the shard does not have the information about the global term frequencies available. The decision if a term is added to a candidate list depends only on the score computed on the shard using local shard frequencies, not the global frequencies of the word. The <literal>min_doc_count</literal> criterion is only applied after merging local terms statistics of all shards. In a way the decision to add the term as a candidate is made without being very <emphasis>certain</emphasis> about if the term will actually reach the required <literal>min_doc_count</literal>. This might cause many (globally) high frequent terms to be missing in the final result if low frequent but high scoring terms populated the candidate lists. To avoid this, the <literal>shard_size</literal> parameter can be increased to allow more candidate terms on the shards. However, this increases memory consumption and network traffic.</simpara>
<simpara><literal>shard_min_doc_count</literal> parameter</simpara>
<simpara>The parameter <literal>shard_min_doc_count</literal> regulates the <emphasis>certainty</emphasis> a shard has if the term should actually be added to the candidate list or not with respect to the <literal>min_doc_count</literal>. Terms will only be considered if their local shard frequency within the set is higher than the <literal>shard_min_doc_count</literal>. If your dictionary contains many low frequent words and you are not interested in these (for example misspellings), then you can set the <literal>shard_min_doc_count</literal> parameter to filter out candidate terms on a shard level that will with a reasonable certainty not reach the required <literal>min_doc_count</literal> even after merging the local frequencies. <literal>shard_min_doc_count</literal> is set to <literal>1</literal> per default and has no effect unless you explicitly set it.</simpara>
<warning><simpara>Setting <literal>min_doc_count</literal> to <literal>1</literal> is generally not advised as it tends to return terms that
         are typos or other bizarre curiosities. Finding more than one instance of a term helps
         reinforce that, while still rare, the term was not the result of a one-off accident. The
         default value of 3 is used to provide a minimum weight-of-evidence.
         Setting <literal>shard_min_doc_count</literal> too high will cause significant candidate terms to be filtered out on a shard level. This value should be set much lower than <literal>min_doc_count/#shards</literal>.</simpara></warning>
</section>
<section id="_custom_background_context">
<title>Custom background context<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/significantterms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The default source of statistical information for background term frequencies is the entire index and this
scope can be narrowed through the use of a <literal>background_filter</literal> to focus in on significant terms within a narrower
context:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "query" : {
        "match" : "madrid"
    },
    "aggs" : {
        "tags" : {
            "significant_terms" : {
                "field" : "tag",
                "background_filter": {
                        "term" : { "text" : "spain"}
                }
            }
        }
    }
}</programlisting>
<simpara>The above filter would help focus in on terms that were peculiar to the city of Madrid rather than revealing
terms like "Spanish" that are unusual in the full index&#8217;s worldwide context but commonplace in the subset of documents containing the
word "Spain".</simpara>
<warning><simpara>Use of background filters will slow the query as each term&#8217;s postings must be filtered to determine a frequency</simpara></warning>
</section>
<section id="_filtering_values">
<title>Filtering Values<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/significantterms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>It is possible (although rarely required) to filter the values for which buckets will be created. This can be done using the <literal>include</literal> and
<literal>exclude</literal> parameters which are based on a regular expression string or arrays of exact terms. This functionality mirrors the features
described in the <link linkend="search-aggregations-bucket-terms-aggregation">terms aggregation</link> documentation.</simpara>
</section>
<section id="_execution_hint_2">
<title>Execution hint<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/significantterms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>There are different mechanisms by which terms aggregations can be executed:</simpara>
<itemizedlist>
<listitem>
<simpara>
by using field values directly in order to aggregate data per-bucket (<literal>map</literal>)
</simpara>
</listitem>
<listitem>
<simpara>
by using ordinals of the field and preemptively allocating one bucket per ordinal value (<literal>global_ordinals</literal>)
</simpara>
</listitem>
<listitem>
<simpara>
by using ordinals of the field and dynamically allocating one bucket per ordinal value (<literal>global_ordinals_hash</literal>)
</simpara>
</listitem>
</itemizedlist>
<simpara>Elasticsearch tries to have sensible defaults so this is something that generally doesn&#8217;t need to be configured.</simpara>
<simpara><literal>map</literal> should only be considered when very few documents match a query. Otherwise the ordinals-based execution modes
are significantly faster. By default, <literal>map</literal> is only used when running an aggregation on scripts, since they don&#8217;t have
ordinals.</simpara>
<simpara><literal>global_ordinals</literal> is the second fastest option, but the fact that it preemptively allocates buckets can be memory-intensive,
especially if you have one or more sub aggregations. It is used by default on top-level terms aggregations.</simpara>
<simpara><literal>global_ordinals_hash</literal> on the contrary to <literal>global_ordinals</literal> and <literal>global_ordinals_low_cardinality</literal> allocates buckets dynamically
so memory usage is linear to the number of values of the documents that are part of the aggregation scope. It is used by default
in inner aggregations.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "tags" : {
             "significant_terms" : {
                 "field" : "tags",
                 "execution_hint": "map" <co id="CO82-1"/>
             }
         }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO82-1">
<para>
the possible values are <literal>map</literal>, <literal>global_ordinals</literal> and <literal>global_ordinals_hash</literal>
</para>
</callout>
</calloutlist>
<simpara>Please note that Elasticsearch will ignore this execution hint if it is not applicable.</simpara>
</section>
</section>
</section>
<section id="search-aggregations-bucket-terms-aggregation">
<title>Terms Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/terms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A multi-bucket value source based aggregation where buckets are dynamically built - one per unique value.</simpara>
<simpara>Example:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "genres" : {
            "terms" : { "field" : "genre" }
        }
    }
}</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

    "aggregations" : {
        "genres" : {
            "doc_count_error_upper_bound": 0, <co id="CO83-1"/>
            "sum_other_doc_count": 0, <co id="CO83-2"/>
            "buckets" : [ <co id="CO83-3"/>
                {
                    "key" : "jazz",
                    "doc_count" : 10
                },
                {
                    "key" : "rock",
                    "doc_count" : 10
                },
                {
                    "key" : "electronic",
                    "doc_count" : 10
                },
            ]
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO83-1">
<para>
an upper bound of the error on the document counts for each term, see <link linkend="search-aggregations-bucket-terms-aggregation-approximate-counts">below</link>
</para>
</callout>
<callout arearefs="CO83-2">
<para>
when there are lots of unique terms, elasticsearch only returns the top terms; this number is the sum of the document counts for all buckets that are not part of the response
</para>
</callout>
<callout arearefs="CO83-3">
<para>
the list of the top buckets, the meaning of <literal>top</literal> being defined by the <link linkend="search-aggregations-bucket-terms-aggregation-order">order</link>
</para>
</callout>
</calloutlist>
<simpara>By default, the <literal>terms</literal> aggregation will return the buckets for the top ten terms ordered by the <literal>doc_count</literal>. One can
change this default behaviour by setting the <literal>size</literal> parameter.</simpara>
<section id="_size">
<title>Size<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/terms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>size</literal> parameter can be set to define how many term buckets should be returned out of the overall terms list. By
default, the node coordinating the search process will request each shard to provide its own top <literal>size</literal> term buckets
and once all shards respond, it will reduce the results to the final list that will then be returned to the client.
This means that if the number of unique terms is greater than <literal>size</literal>, the returned list is slightly off and not accurate
(it could be that the term counts are slightly off and it could even be that a term that should have been in the top
size buckets was not returned).</simpara>
</section>
<section id="search-aggregations-bucket-terms-aggregation-approximate-counts">
<title>Document counts are approximate<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/terms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>As described above, the document counts (and the results of any sub aggregations) in the terms aggregation are not always
accurate.  This is because each shard provides its own view of what the ordered list of terms should be and these are
combined to give a final view. Consider the following scenario:</simpara>
<simpara>A request is made to obtain the top 5 terms in the field product, ordered by descending document count from an index with
3 shards. In this case each shard is asked to give its top 5 terms.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "products" : {
            "terms" : {
                "field" : "product",
                "size" : 5
            }
        }
    }
}</programlisting>
<simpara>The terms for each of the three shards are shown below with their
respective document counts in brackets:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<?dbhtml table-width="100%"?>
<?dbfo table-width="100%"?>
<?dblatex table-width="100%"?>
<tgroup cols="4">
<colspec colname="col_1" colwidth="106*"/>
<colspec colname="col_2" colwidth="106*"/>
<colspec colname="col_3" colwidth="106*"/>
<colspec colname="col_4" colwidth="106*"/>
<thead>
<row>
<entry align="center" valign="top">    </entry>
<entry align="center" valign="top"> Shard A        </entry>
<entry align="center" valign="top"> Shard B        </entry>
<entry align="center" valign="top"> Shard C</entry>
</row>
</thead>
<tbody>
<row>
<entry align="center" valign="top"><simpara>1</simpara></entry>
<entry align="center" valign="top"><simpara>Product A (25)</simpara></entry>
<entry align="center" valign="top"><simpara>Product A (30)</simpara></entry>
<entry align="center" valign="top"><simpara>Product A (45)</simpara></entry>
</row>
<row>
<entry align="center" valign="top"><simpara>2</simpara></entry>
<entry align="center" valign="top"><simpara>Product B (18)</simpara></entry>
<entry align="center" valign="top"><simpara>Product B (25)</simpara></entry>
<entry align="center" valign="top"><simpara>Product C (44)</simpara></entry>
</row>
<row>
<entry align="center" valign="top"><simpara>3</simpara></entry>
<entry align="center" valign="top"><simpara>Product C (6)</simpara></entry>
<entry align="center" valign="top"><simpara>Product F (17)</simpara></entry>
<entry align="center" valign="top"><simpara>Product Z (36)</simpara></entry>
</row>
<row>
<entry align="center" valign="top"><simpara>4</simpara></entry>
<entry align="center" valign="top"><simpara>Product D (3)</simpara></entry>
<entry align="center" valign="top"><simpara>Product Z (16)</simpara></entry>
<entry align="center" valign="top"><simpara>Product G (30)</simpara></entry>
</row>
<row>
<entry align="center" valign="top"><simpara>5</simpara></entry>
<entry align="center" valign="top"><simpara>Product E (2)</simpara></entry>
<entry align="center" valign="top"><simpara>Product G (15)</simpara></entry>
<entry align="center" valign="top"><simpara>Product E (29)</simpara></entry>
</row>
<row>
<entry align="center" valign="top"><simpara>6</simpara></entry>
<entry align="center" valign="top"><simpara>Product F (2)</simpara></entry>
<entry align="center" valign="top"><simpara>Product H (14)</simpara></entry>
<entry align="center" valign="top"><simpara>Product H (28)</simpara></entry>
</row>
<row>
<entry align="center" valign="top"><simpara>7</simpara></entry>
<entry align="center" valign="top"><simpara>Product G (2)</simpara></entry>
<entry align="center" valign="top"><simpara>Product I (10)</simpara></entry>
<entry align="center" valign="top"><simpara>Product Q (2)</simpara></entry>
</row>
<row>
<entry align="center" valign="top"><simpara>8</simpara></entry>
<entry align="center" valign="top"><simpara>Product H (2)</simpara></entry>
<entry align="center" valign="top"><simpara>Product Q (6)</simpara></entry>
<entry align="center" valign="top"><simpara>Product D (1)</simpara></entry>
</row>
<row>
<entry align="center" valign="top"><simpara>9</simpara></entry>
<entry align="center" valign="top"><simpara>Product I (1)</simpara></entry>
<entry align="center" valign="top"><simpara>Product J (8)</simpara></entry>
<entry align="center" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="center" valign="top"><simpara>10</simpara></entry>
<entry align="center" valign="top"><simpara>Product J (1)</simpara></entry>
<entry align="center" valign="top"><simpara>Product C (4)</simpara></entry>
<entry align="center" valign="top"><simpara></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>The shards will return their top 5 terms so the results from the shards will be:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<?dbhtml table-width="100%"?>
<?dbfo table-width="100%"?>
<?dblatex table-width="100%"?>
<tgroup cols="4">
<colspec colname="col_1" colwidth="106*"/>
<colspec colname="col_2" colwidth="106*"/>
<colspec colname="col_3" colwidth="106*"/>
<colspec colname="col_4" colwidth="106*"/>
<thead>
<row>
<entry align="center" valign="top">    </entry>
<entry align="center" valign="top"> Shard A        </entry>
<entry align="center" valign="top"> Shard B        </entry>
<entry align="center" valign="top"> Shard C</entry>
</row>
</thead>
<tbody>
<row>
<entry align="center" valign="top"><simpara>1</simpara></entry>
<entry align="center" valign="top"><simpara>Product A (25)</simpara></entry>
<entry align="center" valign="top"><simpara>Product A (30)</simpara></entry>
<entry align="center" valign="top"><simpara>Product A (45)</simpara></entry>
</row>
<row>
<entry align="center" valign="top"><simpara>2</simpara></entry>
<entry align="center" valign="top"><simpara>Product B (18)</simpara></entry>
<entry align="center" valign="top"><simpara>Product B (25)</simpara></entry>
<entry align="center" valign="top"><simpara>Product C (44)</simpara></entry>
</row>
<row>
<entry align="center" valign="top"><simpara>3</simpara></entry>
<entry align="center" valign="top"><simpara>Product C (6)</simpara></entry>
<entry align="center" valign="top"><simpara>Product F (17)</simpara></entry>
<entry align="center" valign="top"><simpara>Product Z (36)</simpara></entry>
</row>
<row>
<entry align="center" valign="top"><simpara>4</simpara></entry>
<entry align="center" valign="top"><simpara>Product D (3)</simpara></entry>
<entry align="center" valign="top"><simpara>Product Z (16)</simpara></entry>
<entry align="center" valign="top"><simpara>Product G (30)</simpara></entry>
</row>
<row>
<entry align="center" valign="top"><simpara>5</simpara></entry>
<entry align="center" valign="top"><simpara>Product E (2)</simpara></entry>
<entry align="center" valign="top"><simpara>Product G (15)</simpara></entry>
<entry align="center" valign="top"><simpara>Product E (29)</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>Taking the top 5 results from each of the shards (as requested) and combining them to make a final top 5 list produces
the following:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<?dbhtml table-width="40%"?>
<?dbfo table-width="40%"?>
<?dblatex table-width="40%"?>
<tgroup cols="2">
<colspec colname="col_1" colwidth="85*"/>
<colspec colname="col_2" colwidth="85*"/>
<tbody>
<row>
<entry align="center" valign="top"><simpara>1</simpara></entry>
<entry align="center" valign="top"><simpara>Product A (100)</simpara></entry>
</row>
<row>
<entry align="center" valign="top"><simpara>2</simpara></entry>
<entry align="center" valign="top"><simpara>Product Z (52)</simpara></entry>
</row>
<row>
<entry align="center" valign="top"><simpara>3</simpara></entry>
<entry align="center" valign="top"><simpara>Product C (50)</simpara></entry>
</row>
<row>
<entry align="center" valign="top"><simpara>4</simpara></entry>
<entry align="center" valign="top"><simpara>Product G (45)</simpara></entry>
</row>
<row>
<entry align="center" valign="top"><simpara>5</simpara></entry>
<entry align="center" valign="top"><simpara>Product B (43)</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>Because Product A was returned from all shards we know that its document count value is accurate. Product C was only
returned by shards A and C so its document count is shown as 50 but this is not an accurate count. Product C exists on
shard B, but its count of 4 was not high enough to put Product C into the top 5 list for that shard. Product Z was also
returned only by 2 shards but the third shard does not contain the term. There is no way of knowing, at the point of
combining the results to produce the final list of terms, that there is an error in the document count for Product C and
not for Product Z. Product H has a document count of 44 across all 3 shards but was not included in the final list of
terms because it did not make it into the top five terms on any of the shards.</simpara>
</section>
<section id="_shard_size_3">
<title>Shard Size<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/terms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The higher the requested <literal>size</literal> is, the more accurate the results will be, but also, the more expensive it will be to
compute the final results (both due to bigger priority queues that are managed on a shard level and due to bigger data
transfers between the nodes and the client).</simpara>
<simpara>The <literal>shard_size</literal> parameter can be  used to minimize the extra work that comes with bigger requested <literal>size</literal>. When defined,
it will determine how many terms the coordinating node will request from each shard. Once all the shards responded, the
coordinating node will then reduce them to a final result which will be based on the <literal>size</literal> parameter - this way,
one can increase the accuracy of the returned terms and avoid the overhead of streaming a big list of buckets back to
the client.</simpara>
<note><simpara><literal>shard_size</literal> cannot be smaller than <literal>size</literal> (as it doesn&#8217;t make much sense). When it is, elasticsearch will
        override it and reset it to be equal to <literal>size</literal>.</simpara></note>
<simpara>The default <literal>shard_size</literal> will be <literal>size</literal> if the search request needs to go to a single shard, and <literal>(size * 1.5 + 10)</literal>
otherwise.</simpara>
</section>
<section id="_calculating_document_count_error">
<title>Calculating Document Count Error<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/terms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>There are two error values which can be shown on the terms aggregation.  The first gives a value for the aggregation as
a whole which represents the maximum potential document count for a term which did not make it into the final list of
terms. This is calculated as the sum of the document count from the last term returned from each shard .For the example
given above the value would be 46 (2 + 15 + 29). This means that in the worst case scenario a term which was not returned
could have the 4th highest document count.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

    "aggregations" : {
        "products" : {
            "doc_count_error_upper_bound" : 46,
            "buckets" : [
                {
                    "key" : "Product A",
                    "doc_count" : 100
                },
                {
                    "key" : "Product Z",
                    "doc_count" : 52
                },
                ...
            ]
        }
    }
}</programlisting>
</section>
<section id="_per_bucket_document_count_error">
<title>Per bucket document count error<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/terms-aggregation.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This functionality is experimental and may be changed or removed completely in a future release.</simpara></warning>
<simpara>The second error value can be enabled by setting the <literal>show_term_doc_count_error</literal> parameter to true. This shows an error value
for each term returned by the aggregation which represents the <emphasis>worst case</emphasis> error in the document count and can be useful when
deciding on a value for the <literal>shard_size</literal> parameter. This is calculated by summing the document counts for the last term returned
by all shards which did not return the term. In the example above the error in the document count for Product C would be 15 as
Shard B was the only shard not to return the term and the document count of the last term it did return was 15. The actual document
count of Product C was 54 so the document count was only actually off by 4 even though the worst case was that it would be off by
15.  Product A, however has an error of 0 for its document count, since every shard returned it we can be confident that the count
returned is accurate.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...

    "aggregations" : {
        "products" : {
            "doc_count_error_upper_bound" : 46,
            "buckets" : [
                {
                    "key" : "Product A",
                    "doc_count" : 100,
                    "doc_count_error_upper_bound" : 0
                },
                {
                    "key" : "Product Z",
                    "doc_count" : 52,
                    "doc_count_error_upper_bound" : 2
                },
                ...
            ]
        }
    }
}</programlisting>
<simpara>These errors can only be calculated in this way when the terms are ordered by descending document count. When the aggregation is
ordered by the terms values themselves (either ascending or descending) there is no error in the document count since if a shard
does not return a particular term which appears in the results from another shard, it must not have that term in its index. When the
aggregation is either sorted by a sub aggregation or in order of ascending document count, the error in the document counts cannot be
determined and is given a value of -1 to indicate this.</simpara>
</section>
<section id="search-aggregations-bucket-terms-aggregation-order">
<title>Order<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/terms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The order of the buckets can be customized by setting the <literal>order</literal> parameter. By default, the buckets are ordered by
their <literal>doc_count</literal> descending.  It is possible to change this behaviour as documented below:</simpara>
<warning><simpara>Sorting by ascending <literal>_count</literal> or by sub aggregation is discouraged as it increases the
<link linkend="search-aggregations-bucket-terms-aggregation-approximate-counts">error</link> on document counts.
It is fine when a single shard is queried, or when the field that is being aggregated was used
as a routing key at index time: in these cases results will be accurate since shards have disjoint
values. However otherwise, errors are unbounded. One particular case that could still be useful
is sorting by <link linkend="search-aggregations-metrics-min-aggregation"><literal>min</literal></link> or
<link linkend="search-aggregations-metrics-max-aggregation"><literal>max</literal></link> aggregation: counts will not be accurate
but at least the top buckets will be correctly picked.</simpara></warning>
<simpara>Ordering the buckets by their doc <literal>_count</literal> in an ascending manner:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "genres" : {
            "terms" : {
                "field" : "genre",
                "order" : { "_count" : "asc" }
            }
        }
    }
}</programlisting>
<simpara>Ordering the buckets alphabetically by their terms in an ascending manner:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "genres" : {
            "terms" : {
                "field" : "genre",
                "order" : { "_term" : "asc" }
            }
        }
    }
}</programlisting>
<simpara>Ordering the buckets by single value metrics sub-aggregation (identified by the aggregation name):</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "genres" : {
            "terms" : {
                "field" : "genre",
                "order" : { "avg_play_count" : "desc" }
            },
            "aggs" : {
                "avg_play_count" : { "avg" : { "field" : "play_count" } }
            }
        }
    }
}</programlisting>
<simpara>Ordering the buckets by multi value metrics sub-aggregation (identified by the aggregation name):</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "genres" : {
            "terms" : {
                "field" : "genre",
                "order" : { "playback_stats.avg" : "desc" }
            },
            "aggs" : {
                "playback_stats" : { "stats" : { "field" : "play_count" } }
            }
        }
    }
}</programlisting>
<note>
<title>Pipeline aggs cannot be used for sorting</title>
<simpara><link linkend="search-aggregations-pipeline">Pipeline aggregations</link> are run during the
reduce phase after all other aggregations have already completed.  For this
reason, they cannot be used for ordering.</simpara>
</note>
<simpara>It is also possible to order the buckets based on a "deeper" aggregation in the hierarchy. This is supported as long
as the aggregations path are of a single-bucket type, where the last aggregation in the path may either be a single-bucket
one or a metrics one. If it&#8217;s a single-bucket type, the order will be defined by the number of docs in the bucket (i.e. <literal>doc_count</literal>),
in case it&#8217;s a metrics one, the same rules as above apply (where the path must indicate the metric name to sort by in case of
a multi-value metrics aggregation, and in case of a single-value metrics aggregation the sort will be applied on that value).</simpara>
<simpara>The path must be defined in the following form:</simpara>
<remark> https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_Form</remark>
<programlisting language="ebnf" linenumbering="unnumbered">AGG_SEPARATOR       =  '&gt;' ;
METRIC_SEPARATOR    =  '.' ;
AGG_NAME            =  &lt;the name of the aggregation&gt; ;
METRIC              =  &lt;the name of the metric (in case of multi-value metrics aggregation)&gt; ;
PATH                =  &lt;AGG_NAME&gt; [ &lt;AGG_SEPARATOR&gt;, &lt;AGG_NAME&gt; ]* [ &lt;METRIC_SEPARATOR&gt;, &lt;METRIC&gt; ] ;</programlisting>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "countries" : {
            "terms" : {
                "field" : "artist.country",
                "order" : { "rock&gt;playback_stats.avg" : "desc" }
            },
            "aggs" : {
                "rock" : {
                    "filter" : { "term" : { "genre" :  "rock" }},
                    "aggs" : {
                        "playback_stats" : { "stats" : { "field" : "play_count" }}
                    }
                }
            }
        }
    }
}</programlisting>
<simpara>The above will sort the artist&#8217;s countries buckets based on the average play count among the rock songs.</simpara>
<simpara>Multiple criteria can be used to order the buckets by providing an array of order criteria such as the following:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "countries" : {
            "terms" : {
                "field" : "artist.country",
                "order" : [ { "rock&gt;playback_stats.avg" : "desc" }, { "_count" : "desc" } ]
            },
            "aggs" : {
                "rock" : {
                    "filter" : { "term" : { "genre" : { "rock" }}},
                    "aggs" : {
                        "playback_stats" : { "stats" : { "field" : "play_count" }}
                    }
                }
            }
        }
    }
}</programlisting>
<simpara>The above will sort the artist&#8217;s countries buckets based on the average play count among the rock songs and then by
their <literal>doc_count</literal> in descending order.</simpara>
<note><simpara>In the event that two buckets share the same values for all order criteria the bucket&#8217;s term value is used as a
tie-breaker in ascending alphabetical order to prevent non-deterministic ordering of buckets.</simpara></note>
</section>
<section id="_minimum_document_count_3">
<title>Minimum document count<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/terms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>It is possible to only return terms that match more than a configured number of hits using the <literal>min_doc_count</literal> option:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "tags" : {
            "terms" : {
                "field" : "tags",
                "min_doc_count": 10
            }
        }
    }
}</programlisting>
<simpara>The above aggregation would only return tags which have been found in 10 hits or more. Default value is <literal>1</literal>.</simpara>
<simpara>Terms are collected and ordered on a shard level and merged with the terms collected from other shards in a second step. However, the shard does not have the information about the global document count available. The decision if a term is added to a candidate list depends only on the order computed on the shard using local shard frequencies. The <literal>min_doc_count</literal> criterion is only applied after merging local terms statistics of all shards. In a way the decision to add the term as a candidate is made without being very <emphasis>certain</emphasis> about if the term will actually reach the required <literal>min_doc_count</literal>. This might cause many (globally) high frequent terms to be missing in the final result if low frequent terms populated the candidate lists. To avoid this, the <literal>shard_size</literal> parameter can be increased to allow more candidate terms on the shards. However, this increases memory consumption and network traffic.</simpara>
<simpara><literal>shard_min_doc_count</literal> parameter</simpara>
<simpara>The parameter <literal>shard_min_doc_count</literal> regulates the <emphasis>certainty</emphasis> a shard has if the term should actually be added to the candidate list or not with respect to the <literal>min_doc_count</literal>. Terms will only be considered if their local shard frequency within the set is higher than the <literal>shard_min_doc_count</literal>. If your dictionary contains many low frequent terms and you are not interested in those (for example misspellings), then you can set the <literal>shard_min_doc_count</literal> parameter to filter out candidate terms on a shard level that will with a reasonable certainty not reach the required <literal>min_doc_count</literal> even after merging the local counts. <literal>shard_min_doc_count</literal> is set to <literal>0</literal> per default and has no effect unless you explicitly set it.</simpara>
<note><simpara>Setting <literal>min_doc_count</literal>=<literal>0</literal> will also return buckets for terms that didn&#8217;t match any hit. However, some of
         the returned terms which have a document count of zero might only belong to deleted documents or documents
         from other types, so there is no warranty that a <literal>match_all</literal> query would find a positive document count for
         those terms.</simpara></note>
<warning><simpara>When NOT sorting on <literal>doc_count</literal> descending, high values of <literal>min_doc_count</literal> may return a number of buckets
         which is less than <literal>size</literal> because not enough data was gathered from the shards. Missing buckets can be
         back by increasing <literal>shard_size</literal>.
         Setting <literal>shard_min_doc_count</literal> too high will cause terms to be filtered out on a shard level. This value should be set much lower than <literal>min_doc_count/#shards</literal>.</simpara></warning>
</section>
<section id="search-aggregations-bucket-terms-aggregation-script">
<title>Script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/terms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Generating the terms using a script:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "genres" : {
            "terms" : {
                "script" : {
                    "inline": "doc['genre'].value",
                    "lang": "painless"
                }
            }
        }
    }
}</programlisting>
<simpara>This will interpret the <literal>script</literal> parameter as an <literal>inline</literal> script with the default script language and no script parameters. To use a file script use the following syntax:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "genres" : {
            "terms" : {
                "script" : {
                    "file": "my_script",
                    "params": {
                        "field": "genre"
                    }
                }
            }
        }
    }
}</programlisting>
<tip><simpara>for indexed scripts replace the <literal>file</literal> parameter with an <literal>id</literal> parameter.</simpara></tip>
</section>
<section id="_value_script_8">
<title>Value Script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/terms-aggregation.asciidoc">Edit me</ulink></title>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "genres" : {
            "terms" : {
                "field" : "gender",
                "script" : {
                    "inline" : "'Genre: ' +_value"
                    "lang" : "painless"
                }
            }
        }
    }
}</programlisting>
</section>
<section id="_filtering_values_2">
<title>Filtering Values<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/terms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>It is possible to filter the values for which buckets will be created. This can be done using the <literal>include</literal> and
<literal>exclude</literal> parameters which are based on regular expression strings or arrays of exact values.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "tags" : {
            "terms" : {
                "field" : "tags",
                "include" : ".*sport.*",
                "exclude" : "water_.*"
            }
        }
    }
}</programlisting>
<simpara>In the above example, buckets will be created for all the tags that has the word <literal>sport</literal> in them, except those starting
with <literal>water_</literal> (so the tag <literal>water_sports</literal> will no be aggregated). The <literal>include</literal> regular expression will determine what
values are "allowed" to be aggregated, while the <literal>exclude</literal> determines the values that should not be aggregated. When
both are defined, the <literal>exclude</literal> has precedence, meaning, the <literal>include</literal> is evaluated first and only then the <literal>exclude</literal>.</simpara>
<simpara>The syntax is the same as <link linkend="regexp-syntax">regexp queries</link>.</simpara>
<simpara>For matching based on exact values the <literal>include</literal> and <literal>exclude</literal> parameters can simply take an array of
strings that represent the terms as they are found in the index:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "JapaneseCars" : {
             "terms" : {
                 "field" : "make",
                 "include" : ["mazda", "honda"]
             }
         },
        "ActiveCarManufacturers" : {
             "terms" : {
                 "field" : "make",
                 "exclude" : ["rover", "jensen"]
             }
         }
    }
}</programlisting>
</section>
<section id="_multi_field_terms_aggregation">
<title>Multi-field terms aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/terms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>terms</literal> aggregation does not support collecting terms from multiple fields
in the same document.  The reason is that the <literal>terms</literal> agg doesn&#8217;t collect the
string term values themselves, but rather uses
<link linkend="search-aggregations-bucket-terms-aggregation-execution-hint">global ordinals</link>
to produce a list of all of the unique values in the field.  Global ordinals
results in an important performance boost which would not be possible across
multiple fields.</simpara>
<simpara>There are two approaches that you can use to perform a <literal>terms</literal> agg across
multiple fields:</simpara>
<variablelist>
<varlistentry>
<term>
<link linkend="search-aggregations-bucket-terms-aggregation-script">Script</link>
</term>
<listitem>
<simpara>
Use a script to retrieve terms from multiple fields.  This disables the global
ordinals optimization and will be slower than collecting terms from a single
field, but it gives you the flexibility to implement this option at search
time.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="copy-to"><literal>copy_to</literal> field</link>
</term>
<listitem>
<simpara>
If you know ahead of time that you want to collect the terms from two or more
fields, then use <literal>copy_to</literal> in your mapping to create a new dedicated field at
index time which contains the values from both fields.  You can aggregate on
this single field, which will benefit from the global ordinals optimization.
</simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
<section id="_collect_mode">
<title>Collect mode<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/terms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Deferring calculation of child aggregations</simpara>
<simpara>For fields with many unique terms and a small number of required results it can be more efficient to delay the calculation
of child aggregations until the top parent-level aggs have been pruned. Ordinarily, all branches of the aggregation tree
are expanded in one depth-first pass and only then any pruning occurs.
In some scenarios this can be very wasteful and can hit memory constraints.
An example problem scenario is querying a movie database for the 10 most popular actors and their 5 most common co-stars:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "actors" : {
             "terms" : {
                 "field" : "actors",
                 "size" : 10
             },
            "aggs" : {
                "costars" : {
                     "terms" : {
                         "field" : "actors",
                         "size" : 5
                     }
                 }
            }
         }
    }
}</programlisting>
<simpara>Even though the number of actors may be comparatively small and we want only 50 result buckets there is a combinatorial explosion of buckets
during calculation - a single actor can produce n² buckets where n is the number of actors. The sane option would be to first determine
the 10 most popular actors and only then examine the top co-stars for these 10 actors. This alternative strategy is what we call the <literal>breadth_first</literal> collection
mode as opposed to the <literal>depth_first</literal> mode.</simpara>
<note><simpara>The <literal>breadth_first</literal> is the default mode for fields with a cardinality bigger than the requested size or when the cardinality is unknown (numeric fields or scripts for instance).
It is possible to override the default heuristic and to provide a collect mode directly in the request:</simpara></note>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "actors" : {
             "terms" : {
                 "field" : "actors",
                 "size" : 10,
                 "collect_mode" : "breadth_first" <co id="CO84-1"/>
             },
            "aggs" : {
                "costars" : {
                     "terms" : {
                         "field" : "actors",
                         "size" : 5
                     }
                 }
            }
         }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO84-1">
<para>
the possible values are <literal>breadth_first</literal> and <literal>depth_first</literal>
</para>
</callout>
</calloutlist>
<simpara>When using <literal>breadth_first</literal> mode the set of documents that fall into the uppermost buckets are
cached for subsequent replay so there is a memory overhead in doing this which is linear with the number of matching documents.
Note that the <literal>order</literal> parameter can still be used to refer to data from a child aggregation when using the <literal>breadth_first</literal> setting - the parent
aggregation understands that this child aggregation will need to be called first before any of the other child aggregations.</simpara>
<warning><simpara>Nested aggregations such as <literal>top_hits</literal> which require access to score information under an aggregation that uses the <literal>breadth_first</literal>
collection mode need to replay the query on the second pass but only for the documents belonging to the top buckets.</simpara></warning>
</section>
<section id="search-aggregations-bucket-terms-aggregation-execution-hint">
<title>Execution hint<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/terms-aggregation.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>The automated execution optimization is experimental, so this parameter is provided temporarily as a way to override the default behaviour.</simpara></warning>
<simpara>There are different mechanisms by which terms aggregations can be executed:</simpara>
<itemizedlist>
<listitem>
<simpara>
by using field values directly in order to aggregate data per-bucket (<literal>map</literal>)
</simpara>
</listitem>
<listitem>
<simpara>
by using ordinals of the field and preemptively allocating one bucket per ordinal value (<literal>global_ordinals</literal>)
</simpara>
</listitem>
<listitem>
<simpara>
by using ordinals of the field and dynamically allocating one bucket per ordinal value (<literal>global_ordinals_hash</literal>)
</simpara>
</listitem>
<listitem>
<simpara>
by using per-segment ordinals to compute counts and remap these counts to global counts using global ordinals (<literal>global_ordinals_low_cardinality</literal>)
</simpara>
</listitem>
</itemizedlist>
<simpara>Elasticsearch tries to have sensible defaults so this is something that generally doesn&#8217;t need to be configured.</simpara>
<simpara><literal>map</literal> should only be considered when very few documents match a query. Otherwise the ordinals-based execution modes
are significantly faster. By default, <literal>map</literal> is only used when running an aggregation on scripts, since they don&#8217;t have
ordinals.</simpara>
<simpara><literal>global_ordinals_low_cardinality</literal> only works for leaf terms aggregations but is usually the fastest execution mode. Memory
usage is linear with the number of unique values in the field, so it is only enabled by default on low-cardinality fields.</simpara>
<simpara><literal>global_ordinals</literal> is the second fastest option, but the fact that it preemptively allocates buckets can be memory-intensive,
especially if you have one or more sub aggregations. It is used by default on top-level terms aggregations.</simpara>
<simpara><literal>global_ordinals_hash</literal> on the contrary to <literal>global_ordinals</literal> and <literal>global_ordinals_low_cardinality</literal> allocates buckets dynamically
so memory usage is linear to the number of values of the documents that are part of the aggregation scope. It is used by default
in inner aggregations.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "tags" : {
             "terms" : {
                 "field" : "tags",
                 "execution_hint": "map" <co id="CO85-1"/>
             }
         }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO85-1">
<para>
<phrase role="experimental">This functionality is experimental and may be changed or removed completely in a future release.</phrase> the possible values are <literal>map</literal>, <literal>global_ordinals</literal>, <literal>global_ordinals_hash</literal> and <literal>global_ordinals_low_cardinality</literal>
</para>
</callout>
</calloutlist>
<simpara>Please note that Elasticsearch will ignore this execution hint if it is not applicable and that there is no backward compatibility guarantee on these hints.</simpara>
</section>
<section id="_missing_value_12">
<title>Missing value<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/bucket/terms-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>missing</literal> parameter defines how documents that are missing a value should be treated.
By default they will be ignored but it is also possible to treat them as if they
had a value.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs" : {
        "tags" : {
             "terms" : {
                 "field" : "tags",
                 "missing": "N/A" <co id="CO86-1"/>
             }
         }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO86-1">
<para>
Documents without a value in the <literal>tags</literal> field will fall into the same bucket as documents that have the value <literal>N/A</literal>.
</para>
</callout>
</calloutlist>
</section>
</section>
</chapter>
<chapter id="search-aggregations-pipeline">
<title>Pipeline Aggregations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This functionality is experimental and may be changed or removed completely in a future release.</simpara></warning>
<simpara>Pipeline aggregations work on the outputs produced from other aggregations rather than from document sets, adding
information to the output tree. There are many different types of pipeline aggregation, each computing different information from
other aggregations, but these types can be broken down into two families:</simpara>
<variablelist>
<varlistentry>
<term>
<emphasis>Parent</emphasis>
</term>
<listitem>
<simpara>
                A family of pipeline aggregations that is provided with the output of its parent aggregation and is able
                to compute new buckets or new aggregations to add to existing buckets.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<emphasis>Sibling</emphasis>
</term>
<listitem>
<simpara>
                Pipeline aggregations that are provided with the output of a sibling aggregation and are able to compute a
                new aggregation which will be at the same level as the sibling aggregation.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>Pipeline aggregations can reference the aggregations they need to perform their computation by using the <literal>buckets_path</literal>
parameter to indicate the paths to the required metrics. The syntax for defining these paths can be found in the
<link linkend="buckets-path-syntax"><literal>buckets_path</literal> Syntax</link> section below.</simpara>
<simpara>Pipeline aggregations cannot have sub-aggregations but depending on the type it can reference another pipeline in the <literal>buckets_path</literal>
allowing pipeline aggregations to be chained.  For example, you can chain together two derivatives to calculate the second derivative
(i.e. a derivative of a derivative).</simpara>
<note><simpara>Because pipeline aggregations only add to the output, when chaining pipeline aggregations the output of each pipeline aggregation
will be included in the final output.</simpara></note>
<bridgehead id="buckets-path-syntax" renderas="sect2"><literal>buckets_path</literal> Syntax<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline.asciidoc">Edit me</ulink></bridgehead>
<simpara>Most pipeline aggregations require another aggregation as their input.  The input aggregation is defined via the <literal>buckets_path</literal>
parameter, which follows a specific format:</simpara>
<remark> https://en.wikipedia.org/wiki/Extended_Backus%E2%80%93Naur_Form</remark>
<programlisting language="ebnf" linenumbering="unnumbered">AGG_SEPARATOR       =  '&gt;' ;
METRIC_SEPARATOR    =  '.' ;
AGG_NAME            =  &lt;the name of the aggregation&gt; ;
METRIC              =  &lt;the name of the metric (in case of multi-value metrics aggregation)&gt; ;
PATH                =  &lt;AGG_NAME&gt; [ &lt;AGG_SEPARATOR&gt;, &lt;AGG_NAME&gt; ]* [ &lt;METRIC_SEPARATOR&gt;, &lt;METRIC&gt; ] ;</programlisting>
<simpara>For example, the path <literal>"my_bucket&gt;my_stats.avg"</literal> will path to the <literal>avg</literal> value in the <literal>"my_stats"</literal> metric, which is
contained in the <literal>"my_bucket"</literal> bucket aggregation.</simpara>
<simpara>Paths are relative from the position of the pipeline aggregation; they are not absolute paths, and the path cannot go back "up" the
aggregation tree. For example, this moving average is embedded inside a date_histogram and refers to a "sibling"
metric <literal>"the_sum"</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /_search
{
    "aggs": {
        "my_date_histo":{
            "date_histogram":{
                "field":"timestamp",
                "interval":"day"
            },
            "aggs":{
                "the_sum":{
                    "sum":{ "field": "lemmings" } <co id="CO87-1"/>
                },
                "the_movavg":{
                    "moving_avg":{ "buckets_path": "the_sum" } <co id="CO87-2"/>
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO87-1">
<para>
The metric is called <literal>"the_sum"</literal>
</para>
</callout>
<callout arearefs="CO87-2">
<para>
The <literal>buckets_path</literal> refers to the metric via a relative path <literal>"the_sum"</literal>
</para>
</callout>
</calloutlist>
<simpara><literal>buckets_path</literal> is also used for Sibling pipeline aggregations, where the aggregation is "next" to a series of buckets
instead of embedded "inside" them.  For example, the <literal>max_bucket</literal> aggregation uses the <literal>buckets_path</literal> to specify
a metric embedded inside a sibling aggregation:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /_search
{
    "aggs" : {
        "sales_per_month" : {
            "date_histogram" : {
                "field" : "date",
                "interval" : "month"
            },
            "aggs": {
                "sales": {
                    "sum": {
                        "field": "price"
                    }
                }
            }
        },
        "max_monthly_sales": {
            "max_bucket": {
                "buckets_path": "sales_per_month&gt;sales" <co id="CO88-1"/>
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:sales]</remark>
<calloutlist>
<callout arearefs="CO88-1">
<para>
<literal>buckets_path</literal> instructs this max_bucket aggregation that we want the maximum value of the <literal>sales</literal> aggregation in the
<literal>sales_per_month</literal> date histogram.
</para>
</callout>
</calloutlist>
<bridgehead id="_special_paths" renderas="sect2">Special Paths<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline.asciidoc">Edit me</ulink></bridgehead>
<simpara>Instead of pathing to a metric, <literal>buckets_path</literal> can use a special <literal>"_count"</literal> path.  This instructs
the pipeline aggregation to use the document count as it&#8217;s input.  For example, a moving average can be calculated on the document count of each bucket, instead of a specific metric:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /_search
{
    "aggs": {
        "my_date_histo": {
            "date_histogram": {
                "field":"timestamp",
                "interval":"day"
            },
            "aggs": {
                "the_movavg": {
                    "moving_avg": { "buckets_path": "_count" } <co id="CO89-1"/>
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO89-1">
<para>
By using <literal>_count</literal> instead of a metric name, we can calculate the moving average of document counts in the histogram
</para>
</callout>
</calloutlist>
<simpara>The <literal>buckets_path</literal> can also use <literal>"_bucket_count"</literal> and path to a multi-bucket aggregation to use the number of buckets
returned by that aggregation in the pipeline aggregation instead of a metric. for example a <literal>bucket_selector</literal> can be
used here to filter out buckets which contain no buckets for an inner terms aggregation:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /sales/_search
{
  "size": 0,
  "aggs": {
    "histo": {
      "date_histogram": {
        "field": "date",
        "interval": "day"
      },
      "aggs": {
        "categories": {
          "terms": {
            "field": "category"
          }
        },
        "min_bucket_selector": {
          "bucket_selector": {
            "buckets_path": {
              "count": "categories._bucket_count" <co id="CO90-1"/>
            },
            "script": {
              "inline": "params.count != 0"
            }
          }
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:sales]</remark>
<calloutlist>
<callout arearefs="CO90-1">
<para>
By using <literal>_bucket_count</literal> instead of a metric name, we can filter out <literal>histo</literal> buckets where they contain no buckets
for the <literal>categories</literal> aggregation
</para>
</callout>
</calloutlist>
<bridgehead id="dots-in-agg-names" renderas="sect2">Dealing with dots in agg names<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline.asciidoc">Edit me</ulink></bridgehead>
<simpara>An alternate syntax is supported to cope with aggregations or metrics which
have dots in the name, such as the <literal>99.9</literal>th
<link linkend="search-aggregations-metrics-percentile-aggregation">percentile</link>. This metric
may be referred to as:</simpara>
<programlisting language="js" linenumbering="unnumbered">"buckets_path": "my_percentile[99.9]"</programlisting>
<bridgehead id="gap-policy" renderas="sect2">Dealing with gaps in the data<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline.asciidoc">Edit me</ulink></bridgehead>
<simpara>Data in the real world is often noisy and sometimes contains <emphasis role="strong">gaps</emphasis>&#8201;&#8212;&#8201;places where data simply doesn&#8217;t exist.  This can
occur for a variety of reasons, the most common being:</simpara>
<itemizedlist>
<listitem>
<simpara>
Documents falling into a bucket do not contain a required field
</simpara>
</listitem>
<listitem>
<simpara>
There are no documents matching the query for one or more buckets
</simpara>
</listitem>
<listitem>
<simpara>
The metric being calculated is unable to generate a value, likely because another dependent bucket is missing a value.
Some pipeline aggregations have specific requirements that must be met (e.g. a derivative cannot calculate a metric for the
first value because there is no previous value, HoltWinters moving average need "warmup" data to begin calculating, etc)
</simpara>
</listitem>
</itemizedlist>
<simpara>Gap policies are a mechanism to inform the pipeline aggregation about the desired behavior when "gappy" or missing
data is encountered.  All pipeline aggregations accept the <literal>gap_policy</literal> parameter.  There are currently two gap policies
to choose from:</simpara>
<variablelist>
<varlistentry>
<term>
<emphasis>skip</emphasis>
</term>
<listitem>
<simpara>
                This option treats missing data as if the bucket does not exist.  It will skip the bucket and continue
                calculating using the next available value.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<emphasis>insert_zeros</emphasis>
</term>
<listitem>
<simpara>
                This option will replace missing values with a zero (<literal>0</literal>) and pipeline aggregation computation will
                proceed as normal.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<section id="search-aggregations-pipeline-avg-bucket-aggregation">
<title>Avg Bucket Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/avg-bucket-aggregation.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This functionality is experimental and may be changed or removed completely in a future release.</simpara></warning>
<simpara>A sibling pipeline aggregation which calculates the (mean) average value of a specified metric in a sibling aggregation.
The specified metric must be numeric and the sibling aggregation must be a multi-bucket aggregation.</simpara>
<section id="_syntax">
<title>Syntax<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/avg-bucket-aggregation.asciidoc">Edit me</ulink></title>
<simpara>An <literal>avg_bucket</literal> aggregation looks like this in isolation:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "avg_bucket": {
        "buckets_path": "the_sum"
    }
}</programlisting>
<table
frame="all"
rowsep="1" colsep="1"
>
<title><literal>avg_bucket</literal> Parameters</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Parameter Name</simpara></entry>
<entry align="left" valign="top"><simpara>Description</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara>Default Value</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>buckets_path</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The path to the buckets we wish to find the average for (see <xref linkend="buckets-path-syntax"/> for more
 details)</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>gap_policy</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The policy to apply when gaps are found in the data (see <xref linkend="gap-policy"/> for more
 details)</simpara></entry>
<entry align="left" valign="top"><simpara>Optional, defaults to <literal>skip</literal></simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara><literal>format</literal></simpara></entry>
<entry align="left" valign="top"><simpara>format to apply to the output value of this aggregation</simpara></entry>
<entry align="left" valign="top"><simpara>Optional, defaults to <literal>null</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara>The following snippet calculates the average of the total monthly <literal>sales</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /_search
{
  "size": 0,
  "aggs": {
    "sales_per_month": {
      "date_histogram": {
        "field": "date",
        "interval": "month"
      },
      "aggs": {
        "sales": {
          "sum": {
            "field": "price"
          }
        }
      }
    },
    "avg_monthly_sales": {
      "avg_bucket": {
        "buckets_path": "sales_per_month&gt;sales" <co id="CO91-1"/>
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:sales]</remark>
<calloutlist>
<callout arearefs="CO91-1">
<para>
<literal>buckets_path</literal> instructs this avg_bucket aggregation that we want the (mean) average value of the <literal>sales</literal> aggregation in the
<literal>sales_per_month</literal> date histogram.
</para>
</callout>
</calloutlist>
<simpara>And the following may be the response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "took": 11,
   "timed_out": false,
   "_shards": ...,
   "hits": ...,
   "aggregations": {
      "sales_per_month": {
         "buckets": [
            {
               "key_as_string": "2015/01/01 00:00:00",
               "key": 1420070400000,
               "doc_count": 3,
               "sales": {
                  "value": 550.0
               }
            },
            {
               "key_as_string": "2015/02/01 00:00:00",
               "key": 1422748800000,
               "doc_count": 2,
               "sales": {
                  "value": 60.0
               }
            },
            {
               "key_as_string": "2015/03/01 00:00:00",
               "key": 1425168000000,
               "doc_count": 2,
               "sales": {
                  "value": 375.0
               }
            }
         ]
      },
      "avg_monthly_sales": {
          "value": 328.33333333333333
      }
   }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 11/"took": $body.took/]</remark>
<remark> TESTRESPONSE[s/"_shards": \.\.\./"_shards": $body._shards/]</remark>
<remark> TESTRESPONSE[s/"hits": \.\.\./"hits": $body.hits/]</remark>
</section>
</section>
<section id="search-aggregations-pipeline-derivative-aggregation">
<title>Derivative Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/derivative-aggregation.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This functionality is experimental and may be changed or removed completely in a future release.</simpara></warning>
<simpara>A parent pipeline aggregation which calculates the derivative of a specified metric in a parent histogram (or date_histogram)
aggregation. The specified metric must be numeric and the enclosing histogram must have <literal>min_doc_count</literal> set to <literal>0</literal> (default
for <literal>histogram</literal> aggregations).</simpara>
<section id="_syntax_2">
<title>Syntax<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/derivative-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A <literal>derivative</literal> aggregation looks like this in isolation:</simpara>
<programlisting language="js" linenumbering="unnumbered">"derivative": {
  "buckets_path": "the_sum"
}</programlisting>
<table
frame="all"
rowsep="1" colsep="1"
>
<title><literal>derivative</literal> Parameters</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Parameter Name</simpara></entry>
<entry align="left" valign="top"><simpara>Description</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara>Default Value</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>buckets_path</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The path to the buckets we wish to find the derivative for (see <xref linkend="buckets-path-syntax"/> for more
 details)</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>gap_policy</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The policy to apply when gaps are found in the data (see <xref linkend="gap-policy"/> for more
 details)</simpara></entry>
<entry align="left" valign="top"><simpara>Optional, defaults to <literal>skip</literal></simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>format</literal></simpara></entry>
<entry align="left" valign="top"><simpara>format to apply to the output value of this aggregation</simpara></entry>
<entry align="left" valign="top"><simpara>Optional, defaults to <literal>null</literal></simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</section>
<section id="_first_order_derivative">
<title>First Order Derivative<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/derivative-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The following snippet calculates the derivative of the total monthly <literal>sales</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /sales/_search
{
    "size": 0,
    "aggs" : {
        "sales_per_month" : {
            "date_histogram" : {
                "field" : "date",
                "interval" : "month"
            },
            "aggs": {
                "sales": {
                    "sum": {
                        "field": "price"
                    }
                },
                "sales_deriv": {
                    "derivative": {
                        "buckets_path": "sales" <co id="CO92-1"/>
                    }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:sales]</remark>
<calloutlist>
<callout arearefs="CO92-1">
<para>
<literal>buckets_path</literal> instructs this derivative aggregation to use the output of the <literal>sales</literal> aggregation for the derivative
</para>
</callout>
</calloutlist>
<simpara>And the following may be the response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "took": 11,
   "timed_out": false,
   "_shards": ...,
   "hits": ...,
   "aggregations": {
      "sales_per_month": {
         "buckets": [
            {
               "key_as_string": "2015/01/01 00:00:00",
               "key": 1420070400000,
               "doc_count": 3,
               "sales": {
                  "value": 550.0
               } <co id="CO93-1"/>
            },
            {
               "key_as_string": "2015/02/01 00:00:00",
               "key": 1422748800000,
               "doc_count": 2,
               "sales": {
                  "value": 60.0
               },
               "sales_deriv": {
                  "value": -490.0 <co id="CO93-2"/>
               }
            },
            {
               "key_as_string": "2015/03/01 00:00:00",
               "key": 1425168000000,
               "doc_count": 2, <co id="CO93-3"/>
               "sales": {
                  "value": 375.0
               },
               "sales_deriv": {
                  "value": 315.0
               }
            }
         ]
      }
   }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 11/"took": $body.took/]</remark>
<remark> TESTRESPONSE[s/"_shards": \.\.\./"_shards": $body._shards/]</remark>
<remark> TESTRESPONSE[s/"hits": \.\.\./"hits": $body.hits/]</remark>
<calloutlist>
<callout arearefs="CO93-1">
<para>
No derivative for the first bucket since we need at least 2 data points to calculate the derivative
</para>
</callout>
<callout arearefs="CO93-2">
<para>
Derivative value units are implicitly defined by the <literal>sales</literal> aggregation and the parent histogram so in this case the units
would be $/month assuming the <literal>price</literal> field has units of $.
</para>
</callout>
<callout arearefs="CO93-3">
<para>
The number of documents in the bucket are represented by the <literal>doc_count</literal> f
</para>
</callout>
</calloutlist>
</section>
<section id="_second_order_derivative">
<title>Second Order Derivative<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/derivative-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A second order derivative can be calculated by chaining the derivative pipeline aggregation onto the result of another derivative
pipeline aggregation as in the following example which will calculate both the first and the second order derivative of the total
monthly sales:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /sales/_search
{
    "size": 0,
    "aggs" : {
        "sales_per_month" : {
            "date_histogram" : {
                "field" : "date",
                "interval" : "month"
            },
            "aggs": {
                "sales": {
                    "sum": {
                        "field": "price"
                    }
                },
                "sales_deriv": {
                    "derivative": {
                        "buckets_path": "sales"
                    }
                },
                "sales_2nd_deriv": {
                    "derivative": {
                        "buckets_path": "sales_deriv" <co id="CO94-1"/>
                    }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:sales]</remark>
<calloutlist>
<callout arearefs="CO94-1">
<para>
<literal>buckets_path</literal> for the second derivative points to the name of the first derivative
</para>
</callout>
</calloutlist>
<simpara>And the following may be the response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "took": 50,
   "timed_out": false,
   "_shards": ...,
   "hits": ...,
   "aggregations": {
      "sales_per_month": {
         "buckets": [
            {
               "key_as_string": "2015/01/01 00:00:00",
               "key": 1420070400000,
               "doc_count": 3,
               "sales": {
                  "value": 550.0
               } <co id="CO95-1"/>
            },
            {
               "key_as_string": "2015/02/01 00:00:00",
               "key": 1422748800000,
               "doc_count": 2,
               "sales": {
                  "value": 60.0
               },
               "sales_deriv": {
                  "value": -490.0
               } <co id="CO95-2"/>
            },
            {
               "key_as_string": "2015/03/01 00:00:00",
               "key": 1425168000000,
               "doc_count": 2,
               "sales": {
                  "value": 375.0
               },
               "sales_deriv": {
                  "value": 315.0
               },
               "sales_2nd_deriv": {
                  "value": 805.0
               }
            }
         ]
      }
   }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 50/"took": $body.took/]</remark>
<remark> TESTRESPONSE[s/"_shards": \.\.\./"_shards": $body._shards/]</remark>
<remark> TESTRESPONSE[s/"hits": \.\.\./"hits": $body.hits/]</remark>
<calloutlist>
<callout arearefs="CO95-1 CO95-2">
<para>
No second derivative for the first two buckets since we need at least 2 data points from the first derivative to calculate the
second derivative
</para>
</callout>
</calloutlist>
</section>
<section id="_units">
<title>Units<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/derivative-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The derivative aggregation allows the units of the derivative values to be specified. This returns an extra field in the response
<literal>normalized_value</literal> which reports the derivative value in the desired x-axis units.  In the below example we calculate the derivative
of the total sales per month but ask for the derivative of the sales as in the units of sales per day:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /sales/_search
{
    "size": 0,
    "aggs" : {
        "sales_per_month" : {
            "date_histogram" : {
                "field" : "date",
                "interval" : "month"
            },
            "aggs": {
                "sales": {
                    "sum": {
                        "field": "price"
                    }
                },
                "sales_deriv": {
                    "derivative": {
                        "buckets_path": "sales",
                        "unit": "day" <co id="CO96-1"/>
                    }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:sales]</remark>
<calloutlist>
<callout arearefs="CO96-1">
<para>
<literal>unit</literal> specifies what unit to use for the x-axis of the derivative calculation
</para>
</callout>
</calloutlist>
<simpara>And the following may be the response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "took": 50,
   "timed_out": false,
   "_shards": ...,
   "hits": ...,
   "aggregations": {
      "sales_per_month": {
         "buckets": [
            {
               "key_as_string": "2015/01/01 00:00:00",
               "key": 1420070400000,
               "doc_count": 3,
               "sales": {
                  "value": 550.0
               } <co id="CO97-1"/>
            },
            {
               "key_as_string": "2015/02/01 00:00:00",
               "key": 1422748800000,
               "doc_count": 2,
               "sales": {
                  "value": 60.0
               },
               "sales_deriv": {
                  "value": -490.0, <co id="CO97-2"/>
                  "normalized_value": -15.806451612903226 <co id="CO97-3"/>
               }
            },
            {
               "key_as_string": "2015/03/01 00:00:00",
               "key": 1425168000000,
               "doc_count": 2,
               "sales": {
                  "value": 375.0
               },
               "sales_deriv": {
                  "value": 315.0,
                  "normalized_value": 11.25
               }
            }
         ]
      }
   }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 50/"took": $body.took/]</remark>
<remark> TESTRESPONSE[s/"_shards": \.\.\./"_shards": $body._shards/]</remark>
<remark> TESTRESPONSE[s/"hits": \.\.\./"hits": $body.hits/]</remark>
<calloutlist>
<callout arearefs="CO97-1 CO97-2">
<para>
<literal>value</literal> is reported in the original units of <emphasis>per month</emphasis>
</para>
</callout>
<callout arearefs="CO97-3">
<para>
<literal>normalized_value</literal> is reported in the desired units of <emphasis>per day</emphasis>
</para>
</callout>
</calloutlist>
</section>
</section>
<section id="search-aggregations-pipeline-max-bucket-aggregation">
<title>Max Bucket Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/max-bucket-aggregation.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This functionality is experimental and may be changed or removed completely in a future release.</simpara></warning>
<simpara>A sibling pipeline aggregation which identifies the bucket(s) with the maximum value of a specified metric in a sibling aggregation
and outputs both the value and the key(s) of the bucket(s). The specified metric must be numeric and the sibling aggregation must
be a multi-bucket aggregation.</simpara>
<section id="_syntax_3">
<title>Syntax<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/max-bucket-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A <literal>max_bucket</literal> aggregation looks like this in isolation:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "max_bucket": {
        "buckets_path": "the_sum"
    }
}</programlisting>
<table
frame="all"
rowsep="1" colsep="1"
>
<title><literal>max_bucket</literal> Parameters</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Parameter Name</simpara></entry>
<entry align="left" valign="top"><simpara>Description</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara>Default Value</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>buckets_path</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The path to the buckets we wish to find the maximum for (see <xref linkend="buckets-path-syntax"/> for more
 details)</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>gap_policy</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The policy to apply when gaps are found in the data (see <xref linkend="gap-policy"/> for more
 details)</simpara></entry>
<entry align="left" valign="top"><simpara>Optional, defaults to <literal>skip</literal></simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>format</literal></simpara></entry>
<entry align="left" valign="top"><simpara>format to apply to the output value of this aggregation</simpara></entry>
<entry align="left" valign="top"><simpara>Optional, defaults to <literal>null</literal></simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara>The following snippet calculates the maximum of the total monthly <literal>sales</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /sales/_search
{
    "size": 0,
    "aggs" : {
        "sales_per_month" : {
            "date_histogram" : {
                "field" : "date",
                "interval" : "month"
            },
            "aggs": {
                "sales": {
                    "sum": {
                        "field": "price"
                    }
                }
            }
        },
        "max_monthly_sales": {
            "max_bucket": {
                "buckets_path": "sales_per_month&gt;sales" <co id="CO98-1"/>
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:sales]</remark>
<calloutlist>
<callout arearefs="CO98-1">
<para>
<literal>buckets_path</literal> instructs this max_bucket aggregation that we want the maximum value of the <literal>sales</literal> aggregation in the
<literal>sales_per_month</literal> date histogram.
</para>
</callout>
</calloutlist>
<simpara>And the following may be the response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "took": 11,
   "timed_out": false,
   "_shards": ...,
   "hits": ...,
   "aggregations": {
      "sales_per_month": {
         "buckets": [
            {
               "key_as_string": "2015/01/01 00:00:00",
               "key": 1420070400000,
               "doc_count": 3,
               "sales": {
                  "value": 550.0
               }
            },
            {
               "key_as_string": "2015/02/01 00:00:00",
               "key": 1422748800000,
               "doc_count": 2,
               "sales": {
                  "value": 60.0
               }
            },
            {
               "key_as_string": "2015/03/01 00:00:00",
               "key": 1425168000000,
               "doc_count": 2,
               "sales": {
                  "value": 375.0
               }
            }
         ]
      },
      "max_monthly_sales": {
          "keys": ["2015/01/01 00:00:00"], <co id="CO99-1"/>
          "value": 550.0
      }
   }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 11/"took": $body.took/]</remark>
<remark> TESTRESPONSE[s/"_shards": \.\.\./"_shards": $body._shards/]</remark>
<remark> TESTRESPONSE[s/"hits": \.\.\./"hits": $body.hits/]</remark>
<calloutlist>
<callout arearefs="CO99-1">
<para>
<literal>keys</literal> is an array of strings since the maximum value may be present in multiple buckets
</para>
</callout>
</calloutlist>
</section>
</section>
<section id="search-aggregations-pipeline-min-bucket-aggregation">
<title>Min Bucket Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/min-bucket-aggregation.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This functionality is experimental and may be changed or removed completely in a future release.</simpara></warning>
<simpara>A sibling pipeline aggregation which identifies the bucket(s) with the minimum value of a specified metric in a sibling aggregation
and outputs both the value and the key(s) of the bucket(s). The specified metric must be numeric and the sibling aggregation must
be a multi-bucket aggregation.</simpara>
<section id="_syntax_4">
<title>Syntax<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/min-bucket-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A <literal>max_bucket</literal> aggregation looks like this in isolation:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "min_bucket": {
        "buckets_path": "the_sum"
    }
}</programlisting>
<table
frame="all"
rowsep="1" colsep="1"
>
<title><literal>min_bucket</literal> Parameters</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Parameter Name</simpara></entry>
<entry align="left" valign="top"><simpara>Description</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara>Default Value</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>buckets_path</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The path to the buckets we wish to find the minimum for (see <xref linkend="buckets-path-syntax"/> for more
 details)</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>gap_policy</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The policy to apply when gaps are found in the data (see <xref linkend="gap-policy"/> for more
 details)</simpara></entry>
<entry align="left" valign="top"><simpara>Optional, defaults to <literal>skip</literal></simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>format</literal></simpara></entry>
<entry align="left" valign="top"><simpara>format to apply to the output value of this aggregation</simpara></entry>
<entry align="left" valign="top"><simpara>Optional, defaults to <literal>null</literal></simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara>The following snippet calculates the minimum of the total monthly <literal>sales</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /sales/_search
{
    "size": 0,
    "aggs" : {
        "sales_per_month" : {
            "date_histogram" : {
                "field" : "date",
                "interval" : "month"
            },
            "aggs": {
                "sales": {
                    "sum": {
                        "field": "price"
                    }
                }
            }
        },
        "min_monthly_sales": {
            "min_bucket": {
                "buckets_path": "sales_per_month&gt;sales" <co id="CO100-1"/>
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:sales]</remark>
<calloutlist>
<callout arearefs="CO100-1">
<para>
<literal>buckets_path</literal> instructs this max_bucket aggregation that we want the minimum value of the <literal>sales</literal> aggregation in the
<literal>sales_per_month</literal> date histogram.
</para>
</callout>
</calloutlist>
<simpara>And the following may be the response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "took": 11,
   "timed_out": false,
   "_shards": ...,
   "hits": ...,
   "aggregations": {
      "sales_per_month": {
         "buckets": [
            {
               "key_as_string": "2015/01/01 00:00:00",
               "key": 1420070400000,
               "doc_count": 3,
               "sales": {
                  "value": 550.0
               }
            },
            {
               "key_as_string": "2015/02/01 00:00:00",
               "key": 1422748800000,
               "doc_count": 2,
               "sales": {
                  "value": 60.0
               }
            },
            {
               "key_as_string": "2015/03/01 00:00:00",
               "key": 1425168000000,
               "doc_count": 2,
               "sales": {
                  "value": 375.0
               }
            }
         ]
      },
      "min_monthly_sales": {
          "keys": ["2015/02/01 00:00:00"], <co id="CO101-1"/>
          "value": 60.0
      }
   }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 11/"took": $body.took/]</remark>
<remark> TESTRESPONSE[s/"_shards": \.\.\./"_shards": $body._shards/]</remark>
<remark> TESTRESPONSE[s/"hits": \.\.\./"hits": $body.hits/]</remark>
<calloutlist>
<callout arearefs="CO101-1">
<para>
<literal>keys</literal> is an array of strings since the minimum value may be present in multiple buckets
</para>
</callout>
</calloutlist>
</section>
</section>
<section id="search-aggregations-pipeline-sum-bucket-aggregation">
<title>Sum Bucket Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/sum-bucket-aggregation.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This functionality is experimental and may be changed or removed completely in a future release.</simpara></warning>
<simpara>A sibling pipeline aggregation which calculates the sum across all bucket of a specified metric in a sibling aggregation.
The specified metric must be numeric and the sibling aggregation must be a multi-bucket aggregation.</simpara>
<section id="_syntax_5">
<title>Syntax<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/sum-bucket-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A <literal>sum_bucket</literal> aggregation looks like this in isolation:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "sum_bucket": {
        "buckets_path": "the_sum"
    }
}</programlisting>
<table
frame="all"
rowsep="1" colsep="1"
>
<title><literal>sum_bucket</literal> Parameters</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Parameter Name</simpara></entry>
<entry align="left" valign="top"><simpara>Description</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara>Default Value</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>buckets_path</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The path to the buckets we wish to find the sum for (see <xref linkend="buckets-path-syntax"/> for more
 details)</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>gap_policy</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The policy to apply when gaps are found in the data (see <xref linkend="gap-policy"/> for more
 details)</simpara></entry>
<entry align="left" valign="top"><simpara>Optional, defaults to <literal>skip</literal></simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara><literal>format</literal></simpara></entry>
<entry align="left" valign="top"><simpara>format to apply to the output value of this aggregation</simpara></entry>
<entry align="left" valign="top"><simpara>Optional, defaults to <literal>null</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara>The following snippet calculates the sum of all the total monthly <literal>sales</literal> buckets:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /sales/_search
{
    "size": 0,
    "aggs" : {
        "sales_per_month" : {
            "date_histogram" : {
                "field" : "date",
                "interval" : "month"
            },
            "aggs": {
                "sales": {
                    "sum": {
                        "field": "price"
                    }
                }
            }
        },
        "sum_monthly_sales": {
            "sum_bucket": {
                "buckets_path": "sales_per_month&gt;sales" <co id="CO102-1"/>
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:sales]</remark>
<calloutlist>
<callout arearefs="CO102-1">
<para>
<literal>buckets_path</literal> instructs this sum_bucket aggregation that we want the sum of the <literal>sales</literal> aggregation in the
<literal>sales_per_month</literal> date histogram.
</para>
</callout>
</calloutlist>
<simpara>And the following may be the response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "took": 11,
   "timed_out": false,
   "_shards": ...,
   "hits": ...,
   "aggregations": {
      "sales_per_month": {
         "buckets": [
            {
               "key_as_string": "2015/01/01 00:00:00",
               "key": 1420070400000,
               "doc_count": 3,
               "sales": {
                  "value": 550.0
               }
            },
            {
               "key_as_string": "2015/02/01 00:00:00",
               "key": 1422748800000,
               "doc_count": 2,
               "sales": {
                  "value": 60.0
               }
            },
            {
               "key_as_string": "2015/03/01 00:00:00",
               "key": 1425168000000,
               "doc_count": 2,
               "sales": {
                  "value": 375.0
               }
            }
         ]
      },
      "sum_monthly_sales": {
          "value": 985.0
      }
   }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 11/"took": $body.took/]</remark>
<remark> TESTRESPONSE[s/"_shards": \.\.\./"_shards": $body._shards/]</remark>
<remark> TESTRESPONSE[s/"hits": \.\.\./"hits": $body.hits/]</remark>
</section>
</section>
<section id="search-aggregations-pipeline-stats-bucket-aggregation">
<title>Stats Bucket Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/stats-bucket-aggregation.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This functionality is experimental and may be changed or removed completely in a future release.</simpara></warning>
<simpara>A sibling pipeline aggregation which calculates a variety of stats across all bucket of a specified metric in a sibling aggregation.
The specified metric must be numeric and the sibling aggregation must be a multi-bucket aggregation.</simpara>
<section id="_syntax_6">
<title>Syntax<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/stats-bucket-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A <literal>stats_bucket</literal> aggregation looks like this in isolation:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "stats_bucket": {
        "buckets_path": "the_sum"
    }
}</programlisting>
<table
frame="all"
rowsep="1" colsep="1"
>
<title><literal>stats_bucket</literal> Parameters</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Parameter Name</simpara></entry>
<entry align="left" valign="top"><simpara>Description</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara>Default Value</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>buckets_path</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The path to the buckets we wish to calculate stats for (see <xref linkend="buckets-path-syntax"/> for more
 details)</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>gap_policy</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The policy to apply when gaps are found in the data (see <xref linkend="gap-policy"/> for more
 details)</simpara></entry>
<entry align="left" valign="top"><simpara>Optional</simpara></entry>
<entry align="left" valign="top"><simpara><literal>skip</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>format</literal></simpara></entry>
<entry align="left" valign="top"><simpara>format to apply to the output value of this aggregation</simpara></entry>
<entry align="left" valign="top"><simpara>Optional</simpara></entry>
<entry align="left" valign="top"><simpara><literal>null</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara>The following snippet calculates the sum of all the total monthly <literal>sales</literal> buckets:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /sales/_search
{
    "size": 0,
    "aggs" : {
        "sales_per_month" : {
            "date_histogram" : {
                "field" : "date",
                "interval" : "month"
            },
            "aggs": {
                "sales": {
                    "sum": {
                        "field": "price"
                    }
                }
            }
        },
        "stats_monthly_sales": {
            "stats_bucket": {
                "buckets_path": "sales_per_month&gt;sales" <co id="CO103-1"/>
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:sales]</remark>
<calloutlist>
<callout arearefs="CO103-1">
<para>
<literal>bucket_paths</literal> instructs this <literal>stats_bucket</literal> aggregation that we want the calculate stats for the <literal>sales</literal> aggregation in the
<literal>sales_per_month</literal> date histogram.
</para>
</callout>
</calloutlist>
<simpara>And the following may be the response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "took": 11,
   "timed_out": false,
   "_shards": ...,
   "hits": ...,
   "aggregations": {
      "sales_per_month": {
         "buckets": [
            {
               "key_as_string": "2015/01/01 00:00:00",
               "key": 1420070400000,
               "doc_count": 3,
               "sales": {
                  "value": 550.0
               }
            },
            {
               "key_as_string": "2015/02/01 00:00:00",
               "key": 1422748800000,
               "doc_count": 2,
               "sales": {
                  "value": 60.0
               }
            },
            {
               "key_as_string": "2015/03/01 00:00:00",
               "key": 1425168000000,
               "doc_count": 2,
               "sales": {
                  "value": 375.0
               }
            }
         ]
      },
      "stats_monthly_sales": {
         "count": 3,
         "min": 60.0,
         "max": 550.0,
         "avg": 328.3333333333333,
         "sum": 985.0
      }
   }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 11/"took": $body.took/]</remark>
<remark> TESTRESPONSE[s/"_shards": \.\.\./"_shards": $body._shards/]</remark>
<remark> TESTRESPONSE[s/"hits": \.\.\./"hits": $body.hits/]</remark>
</section>
</section>
<section id="search-aggregations-pipeline-extended-stats-bucket-aggregation">
<title>Extended Stats Bucket Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/extended-stats-bucket-aggregation.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This functionality is experimental and may be changed or removed completely in a future release.</simpara></warning>
<simpara>A sibling pipeline aggregation which calculates a variety of stats across all bucket of a specified metric in a sibling aggregation.
The specified metric must be numeric and the sibling aggregation must be a multi-bucket aggregation.</simpara>
<simpara>This aggregation provides a few more statistics (sum of squares, standard deviation, etc) compared to the <literal>stats_bucket</literal> aggregation.</simpara>
<section id="_syntax_7">
<title>Syntax<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/extended-stats-bucket-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A <literal>extended_stats_bucket</literal> aggregation looks like this in isolation:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "extended_stats_bucket": {
        "buckets_path": "the_sum"
    }
}</programlisting>
<table
frame="all"
rowsep="1" colsep="1"
>
<title><literal>extended_stats_bucket</literal> Parameters</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Parameter Name</simpara></entry>
<entry align="left" valign="top"><simpara>Description</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara>Default Value</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>buckets_path</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The path to the buckets we wish to calculate stats for (see <xref linkend="buckets-path-syntax"/> for more
 details)</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>gap_policy</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The policy to apply when gaps are found in the data (see <xref linkend="gap-policy"/> for more
 details)</simpara></entry>
<entry align="left" valign="top"><simpara>Optional</simpara></entry>
<entry align="left" valign="top"><simpara><literal>skip</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>format</literal></simpara></entry>
<entry align="left" valign="top"><simpara>format to apply to the output value of this aggregation</simpara></entry>
<entry align="left" valign="top"><simpara>Optional</simpara></entry>
<entry align="left" valign="top"><simpara><literal>null</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>sigma</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The number of standard deviations above/below the mean to display</simpara></entry>
<entry align="left" valign="top"><simpara>Optional</simpara></entry>
<entry align="left" valign="top"><simpara>2</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara>The following snippet calculates the sum of all the total monthly <literal>sales</literal> buckets:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /sales/_search
{
    "size": 0,
    "aggs" : {
        "sales_per_month" : {
            "date_histogram" : {
                "field" : "date",
                "interval" : "month"
            },
            "aggs": {
                "sales": {
                    "sum": {
                        "field": "price"
                    }
                }
            }
        },
        "stats_monthly_sales": {
            "extended_stats_bucket": {
                "buckets_path": "sales_per_month&gt;sales" <co id="CO104-1"/>
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:sales]</remark>
<calloutlist>
<callout arearefs="CO104-1">
<para>
<literal>bucket_paths</literal> instructs this <literal>extended_stats_bucket</literal> aggregation that we want the calculate stats for the <literal>sales</literal> aggregation in the
<literal>sales_per_month</literal> date histogram.
</para>
</callout>
</calloutlist>
<simpara>And the following may be the response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "took": 11,
   "timed_out": false,
   "_shards": ...,
   "hits": ...,
   "aggregations": {
      "sales_per_month": {
         "buckets": [
            {
               "key_as_string": "2015/01/01 00:00:00",
               "key": 1420070400000,
               "doc_count": 3,
               "sales": {
                  "value": 550.0
               }
            },
            {
               "key_as_string": "2015/02/01 00:00:00",
               "key": 1422748800000,
               "doc_count": 2,
               "sales": {
                  "value": 60.0
               }
            },
            {
               "key_as_string": "2015/03/01 00:00:00",
               "key": 1425168000000,
               "doc_count": 2,
               "sales": {
                  "value": 375.0
               }
            }
         ]
      },
      "stats_monthly_sales": {
         "count": 3,
         "min": 60.0,
         "max": 550.0,
         "avg": 328.3333333333333,
         "sum": 985.0,
         "sum_of_squares": 446725.0,
         "variance": 41105.55555555556,
         "std_deviation": 202.74505063146563,
         "std_deviation_bounds": {
           "upper": 733.8234345962646,
           "lower": -77.15676792959795
         }
      }
   }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 11/"took": $body.took/]</remark>
<remark> TESTRESPONSE[s/"_shards": \.\.\./"_shards": $body._shards/]</remark>
<remark> TESTRESPONSE[s/"hits": \.\.\./"hits": $body.hits/]</remark>
</section>
</section>
<section id="search-aggregations-pipeline-percentiles-bucket-aggregation">
<title>Percentiles Bucket Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/percentiles-bucket-aggregation.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This functionality is experimental and may be changed or removed completely in a future release.</simpara></warning>
<simpara>A sibling pipeline aggregation which calculates percentiles across all bucket of a specified metric in a sibling aggregation.
The specified metric must be numeric and the sibling aggregation must be a multi-bucket aggregation.</simpara>
<section id="_syntax_8">
<title>Syntax<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/percentiles-bucket-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A <literal>percentiles_bucket</literal> aggregation looks like this in isolation:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "percentiles_bucket": {
        "buckets_path": "the_sum"
    }
}</programlisting>
<table
frame="all"
rowsep="1" colsep="1"
>
<title><literal>sum_bucket</literal> Parameters</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Parameter Name</simpara></entry>
<entry align="left" valign="top"><simpara>Description</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara>Default Value</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>buckets_path</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The path to the buckets we wish to find the sum for (see <xref linkend="buckets-path-syntax"/> for more
 details)</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>gap_policy</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The policy to apply when gaps are found in the data (see <xref linkend="gap-policy"/> for more
 details)</simpara></entry>
<entry align="left" valign="top"><simpara>Optional</simpara></entry>
<entry align="left" valign="top"><simpara><literal>skip</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>format</literal></simpara></entry>
<entry align="left" valign="top"><simpara>format to apply to the output value of this aggregation</simpara></entry>
<entry align="left" valign="top"><simpara>Optional</simpara></entry>
<entry align="left" valign="top"><simpara><literal>null</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>percents</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The list of percentiles to calculate</simpara></entry>
<entry align="left" valign="top"><simpara>Optional</simpara></entry>
<entry align="left" valign="top"><simpara><literal>[ 1, 5, 25, 50, 75, 95, 99 ]</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara>The following snippet calculates the sum of all the total monthly <literal>sales</literal> buckets:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /sales/_search
{
    "size": 0,
    "aggs" : {
        "sales_per_month" : {
            "date_histogram" : {
                "field" : "date",
                "interval" : "month"
            },
            "aggs": {
                "sales": {
                    "sum": {
                        "field": "price"
                    }
                }
            }
        },
        "percentiles_monthly_sales": {
            "percentiles_bucket": {
                "buckets_path": "sales_per_month&gt;sales", <co id="CO105-1"/>
                "percents": [ 25.0, 50.0, 75.0 ] <co id="CO105-2"/>
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:sales]</remark>
<calloutlist>
<callout arearefs="CO105-1">
<para>
<literal>buckets_path</literal> instructs this percentiles_bucket aggregation that we want to calculate percentiles for
the <literal>sales</literal> aggregation in the <literal>sales_per_month</literal> date histogram.
</para>
</callout>
<callout arearefs="CO105-2">
<para>
<literal>percents</literal> specifies which percentiles we wish to calculate, in this case, the 25th, 50th and 75th percentiles.
</para>
</callout>
</calloutlist>
<simpara>And the following may be the response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "took": 11,
   "timed_out": false,
   "_shards": ...,
   "hits": ...,
   "aggregations": {
      "sales_per_month": {
         "buckets": [
            {
               "key_as_string": "2015/01/01 00:00:00",
               "key": 1420070400000,
               "doc_count": 3,
               "sales": {
                  "value": 550.0
               }
            },
            {
               "key_as_string": "2015/02/01 00:00:00",
               "key": 1422748800000,
               "doc_count": 2,
               "sales": {
                  "value": 60.0
               }
            },
            {
               "key_as_string": "2015/03/01 00:00:00",
               "key": 1425168000000,
               "doc_count": 2,
               "sales": {
                  "value": 375.0
               }
            }
         ]
      },
      "percentiles_monthly_sales": {
        "values" : {
            "25.0": 375.0,
            "50.0": 375.0,
            "75.0": 550.0
         }
      }
   }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 11/"took": $body.took/]</remark>
<remark> TESTRESPONSE[s/"_shards": \.\.\./"_shards": $body._shards/]</remark>
<remark> TESTRESPONSE[s/"hits": \.\.\./"hits": $body.hits/]</remark>
</section>
<section id="_percentiles_bucket_implementation">
<title>Percentiles_bucket implementation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/percentiles-bucket-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The Percentile Bucket returns the nearest input data point that is not greater than the requested percentile; it does not
interpolate between data points.</simpara>
<simpara>The percentiles are calculated exactly and is not an approximation (unlike the Percentiles Metric). This means
the implementation maintains an in-memory, sorted list of your data to compute the percentiles, before discarding the
data.  You may run into memory pressure issues if you attempt to calculate percentiles over many millions of
data-points in a single <literal>percentiles_bucket</literal>.</simpara>
</section>
</section>
<section id="search-aggregations-pipeline-movavg-aggregation">
<title>Moving Average Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/movavg-aggregation.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This functionality is experimental and may be changed or removed completely in a future release.</simpara></warning>
<simpara>Given an ordered series of data, the Moving Average aggregation will slide a window across the data and emit the average
value of that window.  For example, given the data <literal>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</literal>, we can calculate a simple moving
average with windows size of <literal>5</literal> as follows:</simpara>
<itemizedlist>
<listitem>
<simpara>
(1 + 2 + 3 + 4 + 5) / 5  = 3
</simpara>
</listitem>
<listitem>
<simpara>
(2 + 3 + 4 + 5 + 6) / 5  = 4
</simpara>
</listitem>
<listitem>
<simpara>
(3 + 4 + 5 + 6 + 7) / 5 = 5
</simpara>
</listitem>
<listitem>
<simpara>
etc
</simpara>
</listitem>
</itemizedlist>
<simpara>Moving averages are a simple method to smooth sequential data.  Moving averages are typically applied to time-based data,
such as stock prices or server metrics.  The smoothing can be used to eliminate high frequency fluctuations or random noise,
which allows the lower frequency trends to be more easily visualized, such as seasonality.</simpara>
<section id="_syntax_9">
<title>Syntax<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/movavg-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A <literal>moving_avg</literal> aggregation looks like this in isolation:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "moving_avg": {
        "buckets_path": "the_sum",
        "model": "holt",
        "window": 5,
        "gap_policy": "insert_zero",
        "settings": {
            "alpha": 0.8
        }
    }
}</programlisting>
<table
frame="all"
rowsep="1" colsep="1"
>
<title><literal>moving_avg</literal> Parameters</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Parameter Name</simpara></entry>
<entry align="left" valign="top"><simpara>Description</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara>Default Value</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>buckets_path</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Path to the metric of interest (see <link linkend="buckets-path-syntax"><literal>buckets_path</literal> Syntax</link> for more details</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>model</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The moving average weighting model that we wish to use</simpara></entry>
<entry align="left" valign="top"><simpara>Optional</simpara></entry>
<entry align="left" valign="top"><simpara><literal>simple</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>gap_policy</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Determines what should happen when a gap in the data is encountered.</simpara></entry>
<entry align="left" valign="top"><simpara>Optional</simpara></entry>
<entry align="left" valign="top"><simpara><literal>insert_zero</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>window</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The size of window to "slide" across the histogram.</simpara></entry>
<entry align="left" valign="top"><simpara>Optional</simpara></entry>
<entry align="left" valign="top"><simpara><literal>5</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>minimize</literal></simpara></entry>
<entry align="left" valign="top"><simpara>If the model should be algorithmically minimized.  See <link linkend="movavg-minimizer">Minimization</link> for more
 details</simpara></entry>
<entry align="left" valign="top"><simpara>Optional</simpara></entry>
<entry align="left" valign="top"><simpara><literal>false</literal> for most models</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>settings</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Model-specific settings, contents which differ depending on the model specified.</simpara></entry>
<entry align="left" valign="top"><simpara>Optional</simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara><literal>moving_avg</literal> aggregations must be embedded inside of a <literal>histogram</literal> or <literal>date_histogram</literal> aggregation.  They can be
embedded like any other metric aggregation:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /_search
{
    "size": 0,
    "aggs": {
        "my_date_histo":{                <co id="CO106-1"/>
            "date_histogram":{
                "field":"timestamp",
                "interval":"day"
            },
            "aggs":{
                "the_sum":{
                    "sum":{ "field": "lemmings" } <co id="CO106-2"/>
                },
                "the_movavg":{
                    "moving_avg":{ "buckets_path": "the_sum" } <co id="CO106-3"/>
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO106-1">
<para>
A <literal>date_histogram</literal> named "my_date_histo" is constructed on the "timestamp" field, with one-day intervals
</para>
</callout>
<callout arearefs="CO106-2">
<para>
A <literal>sum</literal> metric is used to calculate the sum of a field.  This could be any metric (sum, min, max, etc)
</para>
</callout>
<callout arearefs="CO106-3">
<para>
Finally, we specify a <literal>moving_avg</literal> aggregation which uses "the_sum" metric as its input.
</para>
</callout>
</calloutlist>
<simpara>Moving averages are built by first specifying a <literal>histogram</literal> or <literal>date_histogram</literal> over a field.  You can then optionally
add normal metrics, such as a <literal>sum</literal>, inside of that histogram.  Finally, the <literal>moving_avg</literal> is embedded inside the histogram.
The <literal>buckets_path</literal> parameter is then used to "point" at one of the sibling metrics inside of the histogram (see
<xref linkend="buckets-path-syntax"/> for a description of the syntax for <literal>buckets_path</literal>.</simpara>
</section>
<section id="_models">
<title>Models<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/movavg-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>moving_avg</literal> aggregation includes four different moving average "models".  The main difference is how the values in the
window are weighted.  As data-points become "older" in the window, they may be weighted differently.  This will
affect the final average for that window.</simpara>
<simpara>Models are specified using the <literal>model</literal> parameter.  Some models may have optional configurations which are specified inside
the <literal>settings</literal> parameter.</simpara>
<section id="_simple">
<title>Simple<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/movavg-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>simple</literal> model calculates the sum of all values in the window, then divides by the size of the window.  It is effectively
a simple arithmetic mean of the window.  The simple model does not perform any time-dependent weighting, which means
the values from a <literal>simple</literal> moving average tend to "lag" behind the real data.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "the_movavg":{
        "moving_avg":{
            "buckets_path": "the_sum",
            "window" : 30,
            "model" : "simple"
        }
    }
}</programlisting>
<simpara>A <literal>simple</literal> model has no special settings to configure</simpara>
<simpara>The window size can change the behavior of the moving average.  For example, a small window (<literal>"window": 10</literal>) will closely
track the data and only smooth out small scale fluctuations:</simpara>
<figure id="movavg_10window"><title>Moving average with window of size 10</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="images/pipeline_movavg/movavg_10window.png"/>
  </imageobject>
  <textobject><phrase>images/pipeline_movavg/movavg_10window.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>In contrast, a <literal>simple</literal> moving average with larger window (<literal>"window": 100</literal>) will smooth out all higher-frequency fluctuations,
leaving only low-frequency, long term trends.  It also tends to "lag" behind the actual data by a substantial amount:</simpara>
<figure id="movavg_100window"><title>Moving average with window of size 100</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="images/pipeline_movavg/movavg_100window.png"/>
  </imageobject>
  <textobject><phrase>images/pipeline_movavg/movavg_100window.png</phrase></textobject>
</mediaobject>
</figure>
</section>
</section>
<section id="_linear">
<title>Linear<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/movavg-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>linear</literal> model assigns a linear weighting to points in the series, such that "older" datapoints (e.g. those at
the beginning of the window) contribute a linearly less amount to the total average.  The linear weighting helps reduce
the "lag" behind the data&#8217;s mean, since older points have less influence.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "the_movavg":{
        "moving_avg":{
            "buckets_path": "the_sum",
            "window" : 30,
            "model" : "linear"
        }
}</programlisting>
<simpara>A <literal>linear</literal> model has no special settings to configure</simpara>
<simpara>Like the <literal>simple</literal> model, window size can change the behavior of the moving average.  For example, a small window (<literal>"window": 10</literal>)
will closely track the data and only smooth out small scale fluctuations:</simpara>
<figure id="linear_10window"><title>Linear moving average with window of size 10</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="images/pipeline_movavg/linear_10window.png"/>
  </imageobject>
  <textobject><phrase>images/pipeline_movavg/linear_10window.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>In contrast, a <literal>linear</literal> moving average with larger window (<literal>"window": 100</literal>) will smooth out all higher-frequency fluctuations,
leaving only low-frequency, long term trends.  It also tends to "lag" behind the actual data by a substantial amount,
although typically less than the <literal>simple</literal> model:</simpara>
<figure id="linear_100window"><title>Linear moving average with window of size 100</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="images/pipeline_movavg/linear_100window.png"/>
  </imageobject>
  <textobject><phrase>images/pipeline_movavg/linear_100window.png</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_ewma_exponentially_weighted">
<title>EWMA (Exponentially Weighted)<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/movavg-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>ewma</literal> model (aka "single-exponential") is similar to the <literal>linear</literal> model, except older data-points become exponentially less important,
rather than linearly less important.  The speed at which the importance decays can be controlled with an <literal>alpha</literal>
setting.  Small values make the weight decay slowly, which provides greater smoothing and takes into account a larger
portion of the window.  Larger valuers make the weight decay quickly, which reduces the impact of older values on the
moving average.  This tends to make the moving average track the data more closely but with less smoothing.</simpara>
<simpara>The default value of <literal>alpha</literal> is <literal>0.3</literal>, and the setting accepts any float from 0-1 inclusive.</simpara>
<simpara>The EWMA model can be <link linkend="movavg-minimizer">Minimized</link></simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "the_movavg":{
        "moving_avg":{
            "buckets_path": "the_sum",
            "window" : 30,
            "model" : "ewma",
            "settings" : {
                "alpha" : 0.5
            }
        }
}</programlisting>
<figure id="single_0.2alpha"><title>EWMA with window of size 10, alpha = 0.2</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="images/pipeline_movavg/single_0.2alpha.png"/>
  </imageobject>
  <textobject><phrase>images/pipeline_movavg/single_0.2alpha.png</phrase></textobject>
</mediaobject>
</figure>
<figure id="single_0.7alpha"><title>EWMA with window of size 10, alpha = 0.7</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="images/pipeline_movavg/single_0.7alpha.png"/>
  </imageobject>
  <textobject><phrase>images/pipeline_movavg/single_0.7alpha.png</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_holt_linear">
<title>Holt-Linear<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/movavg-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>holt</literal> model (aka "double exponential") incorporates a second exponential term which
tracks the data&#8217;s trend.  Single exponential does not perform well when the data has an underlying linear trend.  The
double exponential model calculates two values internally: a "level" and a "trend".</simpara>
<simpara>The level calculation is similar to <literal>ewma</literal>, and is an exponentially weighted view of the data.  The difference is
that the previously smoothed value is used instead of the raw value, which allows it to stay close to the original series.
The trend calculation looks at the difference between the current and last value (e.g. the slope, or trend, of the
smoothed data).  The trend value is also exponentially weighted.</simpara>
<simpara>Values are produced by multiplying the level and trend components.</simpara>
<simpara>The default value of <literal>alpha</literal> is <literal>0.3</literal> and <literal>beta</literal> is <literal>0.1</literal>. The settings accept any float from 0-1 inclusive.</simpara>
<simpara>The Holt-Linear model can be <link linkend="movavg-minimizer">Minimized</link></simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "the_movavg":{
        "moving_avg":{
            "buckets_path": "the_sum",
            "window" : 30,
            "model" : "holt",
            "settings" : {
                "alpha" : 0.5,
                "beta" : 0.5
            }
        }
}</programlisting>
<simpara>In practice, the <literal>alpha</literal> value behaves very similarly in <literal>holt</literal> as <literal>ewma</literal>: small values produce more smoothing
and more lag, while larger values produce closer tracking and less lag.  The value of <literal>beta</literal> is often difficult
to see.  Small values emphasize long-term trends (such as a constant linear trend in the whole series), while larger
values emphasize short-term trends.  This will become more apparently when you are predicting values.</simpara>
<figure id="double_0.2beta"><title>Holt-Linear moving average with window of size 100, alpha = 0.5, beta = 0.2</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="images/pipeline_movavg/double_0.2beta.png"/>
  </imageobject>
  <textobject><phrase>images/pipeline_movavg/double_0.2beta.png</phrase></textobject>
</mediaobject>
</figure>
<figure id="double_0.7beta"><title>Holt-Linear moving average with window of size 100, alpha = 0.5, beta = 0.7</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="images/pipeline_movavg/double_0.7beta.png"/>
  </imageobject>
  <textobject><phrase>images/pipeline_movavg/double_0.7beta.png</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_holt_winters">
<title>Holt-Winters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/movavg-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>holt_winters</literal> model (aka "triple exponential") incorporates a third exponential term which
tracks the seasonal aspect of your data.  This aggregation therefore smooths based on three components: "level", "trend"
and "seasonality".</simpara>
<simpara>The level and trend calculation is identical to <literal>holt</literal> The seasonal calculation looks at the difference between
the current point, and the point one period earlier.</simpara>
<simpara>Holt-Winters requires a little more handholding than the other moving averages.  You need to specify the "periodicity"
of your data: e.g. if your data has cyclic trends every 7 days, you would set <literal>period: 7</literal>.  Similarly if there was
a monthly trend, you would set it to <literal>30</literal>.  There is currently no periodicity detection, although that is planned
for future enhancements.</simpara>
<simpara>There are two varieties of Holt-Winters: additive and multiplicative.</simpara>
<section id="_cold_start">
<title>"Cold Start"<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/movavg-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Unfortunately, due to the nature of Holt-Winters, it requires two periods of data to "bootstrap" the algorithm.  This
means that your <literal>window</literal> must always be <emphasis role="strong">at least</emphasis> twice the size of your period.  An exception will be thrown if it
isn&#8217;t.  It also means that Holt-Winters will not emit a value for the first <literal>2 * period</literal> buckets; the current algorithm
does not backcast.</simpara>
<figure id="holt_winters_cold_start"><title>Holt-Winters showing a "cold" start where no values are emitted</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="images/pipeline_movavg/triple_untruncated.png"/>
  </imageobject>
  <textobject><phrase>images/pipeline_movavg/triple_untruncated.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>Because the "cold start" obscures what the moving average looks like, the rest of the Holt-Winters images are truncated
to not show the "cold start".  Just be aware this will always be present at the beginning of your moving averages!</simpara>
</section>
<section id="_additive_holt_winters">
<title>Additive Holt-Winters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/movavg-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Additive seasonality is the default; it can also be specified by setting <literal>"type": "add"</literal>.  This variety is preferred
when the seasonal affect is additive to your data. E.g. you could simply subtract the seasonal effect to "de-seasonalize"
your data into a flat trend.</simpara>
<simpara>The default values of <literal>alpha</literal> and <literal>gamma</literal> are <literal>0.3</literal> while <literal>beta</literal> is <literal>0.1</literal>.  The settings accept any float from 0-1 inclusive.
The default value of <literal>period</literal> is <literal>1</literal>.</simpara>
<simpara>The additive Holt-Winters model can be <link linkend="movavg-minimizer">Minimized</link></simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "the_movavg":{
        "moving_avg":{
            "buckets_path": "the_sum",
            "window" : 30,
            "model" : "holt_winters",
            "settings" : {
                "type" : "add",
                "alpha" : 0.5,
                "beta" : 0.5,
                "gamma" : 0.5,
                "period" : 7
            }
        }
}</programlisting>
<figure id="holt_winters_add"><title>Holt-Winters moving average with window of size 120, alpha = 0.5, beta = 0.7, gamma = 0.3, period = 30</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="images/pipeline_movavg/triple.png"/>
  </imageobject>
  <textobject><phrase>images/pipeline_movavg/triple.png</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="_multiplicative_holt_winters">
<title>Multiplicative Holt-Winters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/movavg-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Multiplicative is specified by setting <literal>"type": "mult"</literal>.  This variety is preferred when the seasonal affect is
multiplied against your data. E.g. if the seasonal affect is x5 the data, rather than simply adding to it.</simpara>
<simpara>The default values of <literal>alpha</literal> and <literal>gamma</literal> are <literal>0.3</literal> while <literal>beta</literal> is <literal>0.1</literal>.  The settings accept any float from 0-1 inclusive.
The default value of <literal>period</literal> is <literal>1</literal>.</simpara>
<simpara>The multiplicative Holt-Winters model can be <link linkend="movavg-minimizer">Minimized</link></simpara>
<warning>
<simpara>Multiplicative Holt-Winters works by dividing each data point by the seasonal value.  This is problematic if any of
your data is zero, or if there are gaps in the data (since this results in a divid-by-zero).  To combat this, the
<literal>mult</literal> Holt-Winters pads all values by a very small amount (1*10<superscript>-10</superscript>) so that all values are non-zero.  This affects
the result, but only minimally.  If your data is non-zero, or you prefer to see <literal>NaN</literal> when zero&#8217;s are encountered,
you can disable this behavior with <literal>pad: false</literal></simpara>
</warning>
<programlisting language="js" linenumbering="unnumbered">{
    "the_movavg":{
        "moving_avg":{
            "buckets_path": "the_sum",
            "window" : 30,
            "model" : "holt_winters",
            "settings" : {
                "type" : "mult",
                "alpha" : 0.5,
                "beta" : 0.5,
                "gamma" : 0.5,
                "period" : 7,
                "pad" : true
            }
        }
}</programlisting>
</section>
</section>
<section id="_prediction">
<title>Prediction<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/movavg-aggregation.asciidoc">Edit me</ulink></title>
<simpara>All the moving average model support a "prediction" mode, which will attempt to extrapolate into the future given the
current smoothed, moving average.  Depending on the model and parameter, these predictions may or may not be accurate.</simpara>
<simpara>Predictions are enabled by adding a <literal>predict</literal> parameter to any moving average aggregation, specifying the number of
predictions you would like appended to the end of the series.  These predictions will be spaced out at the same interval
as your buckets:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "the_movavg":{
        "moving_avg":{
            "buckets_path": "the_sum",
            "window" : 30,
            "model" : "simple",
            "predict" : 10
        }
}</programlisting>
<simpara>The <literal>simple</literal>, <literal>linear</literal> and <literal>ewma</literal> models all produce "flat" predictions: they essentially converge on the mean
of the last value in the series, producing a flat:</simpara>
<figure id="simple_prediction"><title>Simple moving average with window of size 10, predict = 50</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="images/pipeline_movavg/simple_prediction.png"/>
  </imageobject>
  <textobject><phrase>images/pipeline_movavg/simple_prediction.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>In contrast, the <literal>holt</literal> model can extrapolate based on local or global constant trends.  If we set a high <literal>beta</literal>
value, we can extrapolate based on local constant trends (in this case the predictions head down, because the data at the end
of the series was heading in a downward direction):</simpara>
<figure id="double_prediction_local"><title>Holt-Linear moving average with window of size 100, predict = 20, alpha = 0.5, beta = 0.8</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="images/pipeline_movavg/double_prediction_local.png"/>
  </imageobject>
  <textobject><phrase>images/pipeline_movavg/double_prediction_local.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>In contrast, if we choose a small <literal>beta</literal>, the predictions are based on the global constant trend.  In this series, the
global trend is slightly positive, so the prediction makes a sharp u-turn and begins a positive slope:</simpara>
<figure id="double_prediction_global"><title>Double Exponential moving average with window of size 100, predict = 20, alpha = 0.5, beta = 0.1</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="images/pipeline_movavg/double_prediction_global.png"/>
  </imageobject>
  <textobject><phrase>images/pipeline_movavg/double_prediction_global.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>The <literal>holt_winters</literal> model has the potential to deliver the best predictions, since it also incorporates seasonal
fluctuations into the model:</simpara>
<figure id="holt_winters_prediction_global"><title>Holt-Winters moving average with window of size 120, predict = 25, alpha = 0.8, beta = 0.2, gamma = 0.7, period = 30</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="images/pipeline_movavg/triple_prediction.png"/>
  </imageobject>
  <textobject><phrase>images/pipeline_movavg/triple_prediction.png</phrase></textobject>
</mediaobject>
</figure>
</section>
<section id="movavg-minimizer">
<title>Minimization<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/movavg-aggregation.asciidoc">Edit me</ulink></title>
<simpara>Some of the models (EWMA, Holt-Linear, Holt-Winters) require one or more parameters to be configured.  Parameter choice
can be tricky and sometimes non-intuitive.  Furthermore, small deviations in these parameters can sometimes have a drastic
effect on the output moving average.</simpara>
<simpara>For that reason, the three "tunable" models can be algorithmically <emphasis role="strong">minimized</emphasis>.  Minimization is a process where parameters
are tweaked until the predictions generated by the model closely match the output data.  Minimization is not fullproof
and can be susceptible to overfitting, but it often gives better results than hand-tuning.</simpara>
<simpara>Minimization is disabled by default for <literal>ewma</literal> and <literal>holt_linear</literal>, while it is enabled by default for <literal>holt_winters</literal>.
Minimization is most useful with Holt-Winters, since it helps improve the accuracy of the predictions.  EWMA and
Holt-Linear are not great predictors, and mostly used for smoothing data, so minimization is less useful on those
models.</simpara>
<simpara>Minimization is enabled/disabled via the <literal>minimize</literal> parameter:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "the_movavg":{
        "moving_avg":{
            "buckets_path": "the_sum",
            "model" : "holt_winters",
            "window" : 30,
            "minimize" : true,  <co id="CO107-1"/>
            "settings" : {
                "period" : 7
            }
        }
}</programlisting>
<calloutlist>
<callout arearefs="CO107-1">
<para>
Minimization is enabled with the <literal>minimize</literal> parameter
</para>
</callout>
</calloutlist>
<simpara>When enabled, minimization will find the optimal values for <literal>alpha</literal>, <literal>beta</literal> and <literal>gamma</literal>.  The user should still provide
appropriate values for <literal>window</literal>, <literal>period</literal> and <literal>type</literal>.</simpara>
<warning>
<simpara>Minimization works by running a stochastic process called <emphasis role="strong">simulated annealing</emphasis>.  This process will usually generate
a good solution, but is not guaranteed to find the global optimum.  It also requires some amount of additional
computational power, since the model needs to be re-run multiple times as the values are tweaked.  The run-time of
minimization is linear to the size of the window being processed: excessively large windows may cause latency.</simpara>
<simpara>Finally, minimization fits the model to the last <literal>n</literal> values, where <literal>n = window</literal>.  This generally produces
better forecasts into the future, since the parameters are tuned around the end of the series.  It can, however, generate
poorer fitting moving averages at the beginning of the series.</simpara>
</warning>
</section>
</section>
<section id="search-aggregations-pipeline-cumulative-sum-aggregation">
<title>Cumulative Sum Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/cumulative-sum-aggregation.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This functionality is experimental and may be changed or removed completely in a future release.</simpara></warning>
<simpara>A parent pipeline aggregation which calculates the cumulative sum of a specified metric in a parent histogram (or date_histogram)
aggregation. The specified metric must be numeric and the enclosing histogram must have <literal>min_doc_count</literal> set to <literal>0</literal> (default
for <literal>histogram</literal> aggregations).</simpara>
<section id="_syntax_10">
<title>Syntax<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/cumulative-sum-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A <literal>cumulative_sum</literal> aggregation looks like this in isolation:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "cumulative_sum": {
        "buckets_path": "the_sum"
    }
}</programlisting>
<table
frame="all"
rowsep="1" colsep="1"
>
<title><literal>cumulative_sum</literal> Parameters</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Parameter Name</simpara></entry>
<entry align="left" valign="top"><simpara>Description</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara>Default Value</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>buckets_path</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The path to the buckets we wish to find the cumulative sum for (see <xref linkend="buckets-path-syntax"/> for more
 details)</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>format</literal></simpara></entry>
<entry align="left" valign="top"><simpara>format to apply to the output value of this aggregation</simpara></entry>
<entry align="left" valign="top"><simpara>Optional, defaults to <literal>null</literal></simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara>The following snippet calculates the cumulative sum of the total monthly <literal>sales</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /sales/_search
{
    "size": 0,
    "aggs" : {
        "sales_per_month" : {
            "date_histogram" : {
                "field" : "date",
                "interval" : "month"
            },
            "aggs": {
                "sales": {
                    "sum": {
                        "field": "price"
                    }
                },
                "cumulative_sales": {
                    "cumulative_sum": {
                        "buckets_path": "sales" <co id="CO108-1"/>
                    }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:sales]</remark>
<calloutlist>
<callout arearefs="CO108-1">
<para>
<literal>buckets_path</literal> instructs this cumulative sum aggregation to use the output of the <literal>sales</literal> aggregation for the cumulative sum
</para>
</callout>
</calloutlist>
<simpara>And the following may be the response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "took": 11,
   "timed_out": false,
   "_shards": ...,
   "hits": ...,
   "aggregations": {
      "sales_per_month": {
         "buckets": [
            {
               "key_as_string": "2015/01/01 00:00:00",
               "key": 1420070400000,
               "doc_count": 3,
               "sales": {
                  "value": 550.0
               },
               "cumulative_sales": {
                  "value": 550.0
               }
            },
            {
               "key_as_string": "2015/02/01 00:00:00",
               "key": 1422748800000,
               "doc_count": 2,
               "sales": {
                  "value": 60.0
               },
               "cumulative_sales": {
                  "value": 610.0
               }
            },
            {
               "key_as_string": "2015/03/01 00:00:00",
               "key": 1425168000000,
               "doc_count": 2,
               "sales": {
                  "value": 375.0
               },
               "cumulative_sales": {
                  "value": 985.0
               }
            }
         ]
      }
   }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 11/"took": $body.took/]</remark>
<remark> TESTRESPONSE[s/"_shards": \.\.\./"_shards": $body._shards/]</remark>
<remark> TESTRESPONSE[s/"hits": \.\.\./"hits": $body.hits/]</remark>
</section>
</section>
<section id="search-aggregations-pipeline-bucket-script-aggregation">
<title>Bucket Script Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/bucket-script-aggregation.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This functionality is experimental and may be changed or removed completely in a future release.</simpara></warning>
<simpara>A parent pipeline aggregation which executes a script which can perform per bucket computations on specified metrics
in the parent multi-bucket aggregation. The specified metric must be numeric and the script must return a numeric value.</simpara>
<section id="_syntax_11">
<title>Syntax<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/bucket-script-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A <literal>bucket_script</literal> aggregation looks like this in isolation:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "bucket_script": {
        "buckets_path": {
            "my_var1": "the_sum", <co id="CO109-1"/>
            "my_var2": "the_value_count"
        },
        "script": "my_var1 / my_var2"
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO109-1">
<para>
Here, <literal>my_var1</literal> is the name of the variable for this buckets path to use in the script, <literal>the_sum</literal> is the path to
the metrics to use for that variable.
</para>
</callout>
</calloutlist>
<table
frame="all"
rowsep="1" colsep="1"
>
<title><literal>bucket_script</literal> Parameters</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Parameter Name</simpara></entry>
<entry align="left" valign="top"><simpara>Description</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara>Default Value</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>script</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The script to run for this aggregation. The script can be inline, file or indexed. (see <xref linkend="modules-scripting"/>
for more details)</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>buckets_path</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A map of script variables and their associated path to the buckets we wish to use for the variable
(see <xref linkend="buckets-path-syntax"/> for more details)</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>gap_policy</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The policy to apply when gaps are found in the data (see <xref linkend="gap-policy"/> for more
 details)</simpara></entry>
<entry align="left" valign="top"><simpara>Optional, defaults to <literal>skip</literal></simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>format</literal></simpara></entry>
<entry align="left" valign="top"><simpara>format to apply to the output value of this aggregation</simpara></entry>
<entry align="left" valign="top"><simpara>Optional, defaults to <literal>null</literal></simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara>The following snippet calculates the ratio percentage of t-shirt sales compared to total sales each month:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /sales/_search
{
    "size": 0,
    "aggs" : {
        "sales_per_month" : {
            "date_histogram" : {
                "field" : "date",
                "interval" : "month"
            },
            "aggs": {
                "total_sales": {
                    "sum": {
                        "field": "price"
                    }
                },
                "t-shirts": {
                  "filter": {
                    "term": {
                      "type": "t-shirt"
                    }
                  },
                  "aggs": {
                    "sales": {
                      "sum": {
                        "field": "price"
                      }
                    }
                  }
                },
                "t-shirt-percentage": {
                    "bucket_script": {
                        "buckets_path": {
                          "tShirtSales": "t-shirts&gt;sales",
                          "totalSales": "total_sales"
                        },
                        "script": "params.tShirtSales / params.totalSales * 100"
                    }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:sales]</remark>
<simpara>And the following may be the response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "took": 11,
   "timed_out": false,
   "_shards": ...,
   "hits": ...,
   "aggregations": {
      "sales_per_month": {
         "buckets": [
            {
               "key_as_string": "2015/01/01 00:00:00",
               "key": 1420070400000,
               "doc_count": 3,
               "total_sales": {
                   "value": 550.0
               },
               "t-shirts": {
                   "doc_count": 1,
                   "sales": {
                       "value": 200.0
                   }
               },
               "t-shirt-percentage": {
                   "value": 36.36363636363637
               }
            },
            {
               "key_as_string": "2015/02/01 00:00:00",
               "key": 1422748800000,
               "doc_count": 2,
               "total_sales": {
                   "value": 60.0
               },
               "t-shirts": {
                   "doc_count": 1,
                   "sales": {
                       "value": 10.0
                   }
               },
               "t-shirt-percentage": {
                   "value": 16.666666666666664
               }
            },
            {
               "key_as_string": "2015/03/01 00:00:00",
               "key": 1425168000000,
               "doc_count": 2,
               "total_sales": {
                   "value": 375.0
               },
               "t-shirts": {
                   "doc_count": 1,
                   "sales": {
                       "value": 175.0
                   }
               },
               "t-shirt-percentage": {
                   "value": 46.666666666666664
               }
            }
         ]
      }
   }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 11/"took": $body.took/]</remark>
<remark> TESTRESPONSE[s/"_shards": \.\.\./"_shards": $body._shards/]</remark>
<remark> TESTRESPONSE[s/"hits": \.\.\./"hits": $body.hits/]</remark>
</section>
</section>
<section id="search-aggregations-pipeline-bucket-selector-aggregation">
<title>Bucket Selector Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/bucket-selector-aggregation.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This functionality is experimental and may be changed or removed completely in a future release.</simpara></warning>
<simpara>A parent pipeline aggregation which executes a script which determines whether the current bucket will be retained
in the parent multi-bucket aggregation. The specified metric must be numeric and the script must return a boolean value.
If the script language is <literal>expression</literal> then a numeric return value is permitted. In this case 0.0 will be evaluated as <literal>false</literal>
and all other values will evaluate to true.</simpara>
<simpara>Note: The bucket_selector aggregation, like all pipeline aggregations, executions after all other sibling aggregations. This means that
using the bucket_selector aggregation to filter the returned buckets in the response does not save on execution time running the aggregations.</simpara>
<section id="_syntax_12">
<title>Syntax<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/bucket-selector-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A <literal>bucket_selector</literal> aggregation looks like this in isolation:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "bucket_selector": {
        "buckets_path": {
            "my_var1": "the_sum", <co id="CO110-1"/>
            "my_var2": "the_value_count"
        },
        "script": "params.my_var1 &gt; params.my_var2"
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO110-1">
<para>
Here, <literal>my_var1</literal> is the name of the variable for this buckets path to use in the script, <literal>the_sum</literal> is the path to
the metrics to use for that variable.
</para>
</callout>
</calloutlist>
<table
frame="all"
rowsep="1" colsep="1"
>
<title><literal>bucket_selector</literal> Parameters</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Parameter Name</simpara></entry>
<entry align="left" valign="top"><simpara>Description</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara>Default Value</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>script</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The script to run for this aggregation. The script can be inline, file or indexed. (see <xref linkend="modules-scripting"/>
for more details)</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>buckets_path</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A map of script variables and their associated path to the buckets we wish to use for the variable
(see <xref linkend="buckets-path-syntax"/> for more details)</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>gap_policy</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The policy to apply when gaps are found in the data (see <xref linkend="gap-policy"/> for more
 details)</simpara></entry>
<entry align="left" valign="top"><simpara>Optional, defaults to <literal>skip</literal></simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara>The following snippet only retains buckets where the total sales for the month is more than 400:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /sales/_search
{
    "size": 0,
    "aggs" : {
        "sales_per_month" : {
            "date_histogram" : {
                "field" : "date",
                "interval" : "month"
            },
            "aggs": {
                "total_sales": {
                    "sum": {
                        "field": "price"
                    }
                },
                "sales_bucket_filter": {
                    "bucket_selector": {
                        "buckets_path": {
                          "totalSales": "total_sales"
                        },
                        "script": "params.totalSales &gt; 200"
                    }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:sales]</remark>
<simpara>And the following may be the response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "took": 11,
   "timed_out": false,
   "_shards": ...,
   "hits": ...,
   "aggregations": {
      "sales_per_month": {
         "buckets": [
            {
               "key_as_string": "2015/01/01 00:00:00",
               "key": 1420070400000,
               "doc_count": 3,
               "total_sales": {
                   "value": 550.0
               }
            },<co id="CO111-1"/>
            {
               "key_as_string": "2015/03/01 00:00:00",
               "key": 1425168000000,
               "doc_count": 2,
               "total_sales": {
                   "value": 375.0
               },
            }
         ]
      }
   }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 11/"took": $body.took/]</remark>
<remark> TESTRESPONSE[s/"_shards": \.\.\./"_shards": $body._shards/]</remark>
<remark> TESTRESPONSE[s/"hits": \.\.\./"hits": $body.hits/]</remark>
<calloutlist>
<callout arearefs="CO111-1">
<para>
Bucket for <literal>2015/02/01 00:00:00</literal> has been removed as its total sales was less than 200
</para>
</callout>
</calloutlist>
</section>
</section>
<section id="search-aggregations-pipeline-serialdiff-aggregation">
<title>Serial Differencing Aggregation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/serial-diff-aggregation.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This functionality is experimental and may be changed or removed completely in a future release.</simpara></warning>
<simpara>Serial differencing is a technique where values in a time series are subtracted from itself at
different time lags or periods. For example, the datapoint f(x) = f(x<subscript>t</subscript>) - f(x<subscript>t-n</subscript>), where n is the period being used.</simpara>
<simpara>A period of 1 is equivalent to a derivative with no time normalization: it is simply the change from one point to the
next. Single periods are useful for removing constant, linear trends.</simpara>
<simpara>Single periods are also useful for transforming data into a stationary series. In this example, the Dow Jones is
plotted over ~250 days. The raw data is not stationary, which would make it difficult to use with some techniques.</simpara>
<simpara>By calculating the first-difference, we de-trend the data (e.g. remove a constant, linear trend).  We can see that the
data becomes a stationary series (e.g. the first difference is randomly distributed around zero, and doesn&#8217;t seem to
exhibit any pattern/behavior). The transformation reveals that the dataset is following a random-walk; the value is the
previous value +/- a random amount.  This insight allows selection of further tools for analysis.</simpara>
<figure id="serialdiff_dow"><title>Dow Jones plotted and made stationary with first-differencing</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="images/pipeline_serialdiff/dow.png"/>
  </imageobject>
  <textobject><phrase>images/pipeline_serialdiff/dow.png</phrase></textobject>
</mediaobject>
</figure>
<simpara>Larger periods can be used to remove seasonal / cyclic behavior. In this example, a population of lemmings was
synthetically generated with a sine wave + constant linear trend + random noise. The sine wave has a period of 30 days.</simpara>
<simpara>The first-difference removes the constant trend, leaving just a sine wave. The 30th-difference is then applied to the
first-difference to remove the cyclic behavior, leaving a stationary series which is amenable to other analysis.</simpara>
<figure id="serialdiff_lemmings"><title>Lemmings data plotted made stationary with 1st and 30th difference</title>
<mediaobject>
  <imageobject>
  <imagedata fileref="images/pipeline_serialdiff/lemmings.png"/>
  </imageobject>
  <textobject><phrase>images/pipeline_serialdiff/lemmings.png</phrase></textobject>
</mediaobject>
</figure>
<section id="_syntax_13">
<title>Syntax<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/pipeline/serial-diff-aggregation.asciidoc">Edit me</ulink></title>
<simpara>A <literal>serial_diff</literal> aggregation looks like this in isolation:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "serial_diff": {
        "buckets_path": "the_sum",
        "lag": "7"
    }
}</programlisting>
<table
frame="all"
rowsep="1" colsep="1"
>
<title><literal>serial_diff</literal> Parameters</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Parameter Name</simpara></entry>
<entry align="left" valign="top"><simpara>Description</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara>Default Value</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>buckets_path</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Path to the metric of interest (see <link linkend="buckets-path-syntax"><literal>buckets_path</literal> Syntax</link> for more details</simpara></entry>
<entry align="left" valign="top"><simpara>Required</simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>lag</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The historical bucket to subtract from the current value. E.g. a lag of 7 will subtract the current value from
 the value 7 buckets ago. Must be a positive, non-zero integer</simpara></entry>
<entry align="left" valign="top"><simpara>Optional</simpara></entry>
<entry align="left" valign="top"><simpara><literal>1</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>gap_policy</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Determines what should happen when a gap in the data is encountered.</simpara></entry>
<entry align="left" valign="top"><simpara>Optional</simpara></entry>
<entry align="left" valign="top"><simpara><literal>insert_zero</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>format</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Format to apply to the output value of this aggregation</simpara></entry>
<entry align="left" valign="top"><simpara>Optional</simpara></entry>
<entry align="left" valign="top"><simpara><literal>null</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara><literal>serial_diff</literal> aggregations must be embedded inside of a <literal>histogram</literal> or <literal>date_histogram</literal> aggregation:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /_search
{
   "size": 0,
   "aggs": {
      "my_date_histo": {                  <co id="CO112-1"/>
         "date_histogram": {
            "field": "timestamp",
            "interval": "day"
         },
         "aggs": {
            "the_sum": {
               "sum": {
                  "field": "lemmings"     <co id="CO112-2"/>
               }
            },
            "thirtieth_difference": {
               "serial_diff": {                <co id="CO112-3"/>
                  "buckets_path": "the_sum",
                  "lag" : 30
               }
            }
         }
      }
   }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO112-1">
<para>
A <literal>date_histogram</literal> named "my_date_histo" is constructed on the "timestamp" field, with one-day intervals
</para>
</callout>
<callout arearefs="CO112-2">
<para>
A <literal>sum</literal> metric is used to calculate the sum of a field.  This could be any metric (sum, min, max, etc)
</para>
</callout>
<callout arearefs="CO112-3">
<para>
Finally, we specify a <literal>serial_diff</literal> aggregation which uses "the_sum" metric as its input.
</para>
</callout>
</calloutlist>
<simpara>Serial differences are built by first specifying a <literal>histogram</literal> or <literal>date_histogram</literal> over a field.  You can then optionally
add normal metrics, such as a <literal>sum</literal>, inside of that histogram.  Finally, the <literal>serial_diff</literal> is embedded inside the histogram.
The <literal>buckets_path</literal> parameter is then used to "point" at one of the sibling metrics inside of the histogram (see
<xref linkend="buckets-path-syntax"/> for a description of the syntax for <literal>buckets_path</literal>.</simpara>
</section>
</section>
</chapter>
<chapter id="search-aggregations-matrix">
<title>Matrix Aggregations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/matrix.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This functionality is experimental and may be changed or removed completely in a future release.</simpara></warning>
<simpara>The aggregations in this family operate on multiple fields and produce a matrix result based on the values extracted from
the requested document fields. Unlike metric and bucket aggregations, this aggregation family does not yet support scripting.</simpara>
<section id="search-aggregations-matrix-stats-aggregation">
<title>Matrix Stats<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/matrix/stats-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>matrix_stats</literal> aggregation is a numeric aggregation that computes the following statistics over a set of document fields:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>count</literal>
</simpara>
</entry>
<entry>
<simpara>
Number of per field samples included in the calculation.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>mean</literal>
</simpara>
</entry>
<entry>
<simpara>
The average value for each field.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>variance</literal>
</simpara>
</entry>
<entry>
<simpara>
Per field Measurement for how spread out the samples are from the mean.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>skewness</literal>
</simpara>
</entry>
<entry>
<simpara>
Per field measurement quantifying the asymmetric distribution around the mean.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>kurtosis</literal>
</simpara>
</entry>
<entry>
<simpara>
Per field measurement quantifying the shape of the distribution.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>covariance</literal>
</simpara>
</entry>
<entry>
<simpara>
A matrix that quantitatively describes how changes in one field are associated with another.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>correlation</literal>
</simpara>
</entry>
<entry>
<simpara>
The covariance matrix scaled to a range of -1 to 1, inclusive. Describes the relationship between field
            distributions.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>The following example demonstrates the use of matrix stats to describe the relationship between income and poverty.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs": {
        "matrixstats": {
            "matrix_stats": {
                "fields": ["poverty", "income"]
            }
        }
    }
}</programlisting>
<simpara>The aggregation type is <literal>matrix_stats</literal> and the <literal>fields</literal> setting defines the set of fields (as an array) for computing
the statistics. The above request returns the following response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...
    "aggregations": {
        "matrixstats": {
            "fields": [{
                "name": "income",
                "count": 50,
                "mean": 51985.1,
                "variance": 7.383377037755103E7,
                "skewness": 0.5595114003506483,
                "kurtosis": 2.5692365287787124,
                "covariance": {
                    "income": 7.383377037755103E7,
                    "poverty": -21093.65836734694
                },
                "correlation": {
                    "income": 1.0,
                    "poverty": -0.8352655256272504
                }
            }, {
                "name": "poverty",
                "count": 50,
                "mean": 12.732000000000001,
                "variance": 8.637730612244896,
                "skewness": 0.4516049811903419,
                "kurtosis": 2.8615929677997767,
                "covariance": {
                    "income": -21093.65836734694,
                    "poverty": 8.637730612244896
                },
                "correlation": {
                    "income": -0.8352655256272504,
                    "poverty": 1.0
                }
            }]
        }
    }
}</programlisting>
<section id="_multi_value_fields">
<title>Multi Value Fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/matrix/stats-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>matrix_stats</literal> aggregation treats each document field as an independent sample. The <literal>mode</literal> parameter controls what
array value the aggregation will use for array or multi-valued fields. This parameter can take one of the following:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>avg</literal>
</simpara>
</entry>
<entry>
<simpara>
(default) Use the average of all values.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>min</literal>
</simpara>
</entry>
<entry>
<simpara>
Pick the lowest value.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max</literal>
</simpara>
</entry>
<entry>
<simpara>
Pick the highest value.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>sum</literal>
</simpara>
</entry>
<entry>
<simpara>
Use the sum of all values.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>median</literal>
</simpara>
</entry>
<entry>
<simpara>
Use the median of all values.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
<section id="_missing_values_2">
<title>Missing Values<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/matrix/stats-aggregation.asciidoc">Edit me</ulink></title>
<simpara>The <literal>missing</literal> parameter defines how documents that are missing a value should be treated.
By default they will be ignored but it is also possible to treat them as if they had a value.
This is done by adding a set of fieldname : value mappings to specify default values per field.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggs": {
        "matrixstats": {
            "matrix_stats": {
                "fields": ["poverty", "income"],
                "missing": {"income" : 50000} <co id="CO113-1"/>
            }
        }
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO113-1">
<para>
Documents without a value in the <literal>income</literal> field will have the default value <literal>50000</literal>.
</para>
</callout>
</calloutlist>
</section>
<section id="_script_13">
<title>Script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/matrix/stats-aggregation.asciidoc">Edit me</ulink></title>
<simpara>This aggregation family does not yet support scripting.</simpara>
</section>
</section>
</chapter>
<chapter id="caching-heavy-aggregations">
<title>Caching heavy aggregations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/misc.asciidoc">Edit me</ulink></title>
<simpara>Frequently used aggregations (e.g. for display on the home page of a website)
can be cached for faster responses. These cached results are the same results
that would be returned by an uncached aggregation&#8201;&#8212;&#8201;you will never get stale
results.</simpara>
<simpara>See <xref linkend="shard-request-cache"/> for more details.</simpara>
</chapter>
<chapter id="returning-only-agg-results">
<title>Returning only aggregation results<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/misc.asciidoc">Edit me</ulink></title>
<simpara>There are many occasions when aggregations are required but search hits are not.  For these cases the hits can be ignored by
setting <literal>size=0</literal>. For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /twitter/tweet/_search
{
  "size": 0,
  "aggregations": {
    "my_agg": {
      "terms": {
        "field": "text"
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>Setting <literal>size</literal> to <literal>0</literal> avoids executing the fetch phase of the search making the request more efficient.</simpara>
</chapter>
<chapter id="agg-metadata">
<title>Aggregation Metadata<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/aggregations/misc.asciidoc">Edit me</ulink></title>
<simpara>You can associate a piece of metadata with individual aggregations at request time that will be returned in place
at response time.</simpara>
<simpara>Consider this example where we want to associate the color blue with our <literal>terms</literal> aggregation.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /twitter/tweet/_search
{
  "size": 0,
  "aggs": {
    "titles": {
      "terms": {
        "field": "title"
      },
      "meta": {
        "color": "blue"
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>Then that piece of metadata will be returned in place for our <literal>titles</literal> terms aggregation</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "aggregations": {
        "titles": {
            "meta": {
                "color" : "blue"
            },
            "doc_count_error_upper_bound" : 0,
            "sum_other_doc_count" : 0,
            "buckets": [
            ]
        }
    },
    ...
}</programlisting>
<remark> TESTRESPONSE[s/\.\.\./"took": "$body.took", "timed_out": false, "_shards": "$body._shards", "hits": "$body.hits"/]</remark>
</chapter>
</part>
<part id="indices">
<title>Indices APIs <ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices.asciidoc">Edit me</ulink></title>
<partintro>
<simpara>The indices APIs are used to manage individual indices,
index settings, aliases, mappings, and index templates.</simpara>
<bridgehead id="index-management" renderas="sect1">Index management:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices.asciidoc">Edit me</ulink></bridgehead>
<itemizedlist>
<listitem>
<simpara>
<xref linkend="indices-create-index"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="indices-delete-index"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="indices-get-index"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="indices-exists"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="indices-open-close"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="indices-shrink-index"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="indices-rollover-index"/>
</simpara>
</listitem>
</itemizedlist>
<bridgehead id="mapping-management" renderas="sect1">Mapping management:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices.asciidoc">Edit me</ulink></bridgehead>
<itemizedlist>
<listitem>
<simpara>
<xref linkend="indices-put-mapping"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="indices-get-mapping"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="indices-get-field-mapping"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="indices-types-exists"/>
</simpara>
</listitem>
</itemizedlist>
<bridgehead id="alias-management" renderas="sect1">Alias management:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices.asciidoc">Edit me</ulink></bridgehead>
<itemizedlist>
<listitem>
<simpara>
<xref linkend="indices-aliases"/>
</simpara>
</listitem>
</itemizedlist>
<bridgehead id="index-settings" renderas="sect1">Index settings:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices.asciidoc">Edit me</ulink></bridgehead>
<itemizedlist>
<listitem>
<simpara>
<xref linkend="indices-update-settings"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="indices-get-settings"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="indices-analyze"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="indices-templates"/>
</simpara>
</listitem>
</itemizedlist>
<bridgehead id="shadow-replicas" renderas="sect1">Replica configurations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices.asciidoc">Edit me</ulink></bridgehead>
<itemizedlist>
<listitem>
<simpara>
<xref linkend="indices-shadow-replicas"/>
</simpara>
</listitem>
</itemizedlist>
<bridgehead id="monitoring" renderas="sect1">Monitoring:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices.asciidoc">Edit me</ulink></bridgehead>
<itemizedlist>
<listitem>
<simpara>
<xref linkend="indices-stats"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="indices-segments"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="indices-recovery"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="indices-shards-stores"/>
</simpara>
</listitem>
</itemizedlist>
<bridgehead id="status-management" renderas="sect1">Status management:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices.asciidoc">Edit me</ulink></bridgehead>
<itemizedlist>
<listitem>
<simpara>
<xref linkend="indices-clearcache"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="indices-refresh"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="indices-flush"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="indices-forcemerge"/>
</simpara>
</listitem>
</itemizedlist>
</partintro>
<chapter id="indices-create-index">
<title>Create Index<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/create-index.asciidoc">Edit me</ulink></title>
<simpara>The create index API allows to instantiate an index. Elasticsearch
provides support for multiple indices, including executing operations
across several indices.</simpara>
<bridgehead id="create-index-settings" renderas="sect2">Index Settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/create-index.asciidoc">Edit me</ulink></bridgehead>
<simpara>Each index created can have specific settings
associated with it.</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT twitter
{
    "settings" : {
        "index" : {
            "number_of_shards" : 3, <co id="CO114-1"/>
            "number_of_replicas" : 2 <co id="CO114-2"/>
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO114-1">
<para>
Default for <literal>number_of_shards</literal> is 5
</para>
</callout>
<callout arearefs="CO114-2">
<para>
Default for <literal>number_of_replicas</literal> is 1 (ie one replica for each primary shard)
</para>
</callout>
</calloutlist>
<simpara>The above second curl example shows how an index called <literal>twitter</literal> can be
created with specific settings for it using <ulink url="http://www.yaml.org">YAML</ulink>.
In this case, creating an index with 3 shards, each with 2 replicas. The
index settings can also be defined with <ulink url="http://www.json.org">JSON</ulink>:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT twitter
{
    "settings" : {
        "index" : {
            "number_of_shards" : 3,
            "number_of_replicas" : 2
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>or more simplified</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT twitter
{
    "settings" : {
        "number_of_shards" : 3,
        "number_of_replicas" : 2
    }
}</programlisting>
<remark> CONSOLE</remark>
<note><simpara>You do not have to explicitly specify <literal>index</literal> section inside the
<literal>settings</literal> section.</simpara></note>
<simpara>For more information regarding all the different index level settings
that can be set when creating an index, please check the
<link linkend="index-modules">index modules</link> section.</simpara>
<bridgehead id="mappings" renderas="sect2">Mappings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/create-index.asciidoc">Edit me</ulink></bridgehead>
<simpara>The create index API allows to provide a set of one or more mappings:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT test
{
    "settings" : {
        "number_of_shards" : 1
    },
    "mappings" : {
        "type1" : {
            "properties" : {
                "field1" : { "type" : "text" }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="create-index-aliases" renderas="sect2">Aliases<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/create-index.asciidoc">Edit me</ulink></bridgehead>
<simpara>The create index API allows also to provide a set of <link linkend="indices-aliases">aliases</link>:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT test
{
    "aliases" : {
        "alias_1" : {},
        "alias_2" : {
            "filter" : {
                "term" : {"user" : "kimchy" }
            },
            "routing" : "kimchy"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="create-index-wait-for-active-shards" renderas="sect2">Wait For Active Shards<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/create-index.asciidoc">Edit me</ulink></bridgehead>
<simpara>By default, index creation will only return a response to the client when the primary copies of
each shard have been started, or the request times out. The index creation response will indicate
what happened:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "acknowledged": true,
    "shards_acknowledged": true
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara><literal>acknowledged</literal> indicates whether the index was successfully created in the cluster, while
<literal>shards_acknowledged</literal> indices whether the requisite number of shard copies were started for
each shard in the index before timing out. Note that it is still possible for either
<literal>acknowledged</literal> or <literal>shards_acknowledged</literal> to be <literal>false</literal>, but the index creation was successful.
These values simply indicate whether the operation completed before the timeout. If
<literal>acknowledged</literal> is <literal>false</literal>, then we timed out before the cluster state was updated with the
newly created index, but it probably will be created sometime soon. If <literal>shards_acknowledged</literal>
is <literal>false</literal>, then we timed out before the requisite number of shards were started (by default
just the primaries), even if the cluster state was successfully updated to reflect the newly
created index (i.e. <literal>acknowledged=true</literal>).</simpara>
<simpara>We can change the default of only waiting for the primary shards to start through the index
setting <literal>index.write.wait_for_active_shards</literal> (note that changing this setting will also affect
the <literal>wait_for_active_shards</literal> value on all subsequent write operations):</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT test
{
    "settings": {
        "index.write.wait_for_active_shards": "2"
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[skip:requires two nodes]</remark>
<simpara>or through the request parameter <literal>wait_for_active_shards</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT test?wait_for_active_shards=2</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[skip:requires two nodes]</remark>
<simpara>A detailed explanation of <literal>wait_for_active_shards</literal> and its possible values can be found
<link linkend="index-wait-for-active-shards">here</link>.</simpara>
</chapter>
<chapter id="indices-delete-index">
<title>Delete Index<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/delete-index.asciidoc">Edit me</ulink></title>
<simpara>The delete index API allows to delete an existing index.</simpara>
<programlisting language="js" linenumbering="unnumbered">DELETE /twitter</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>The above example deletes an index called <literal>twitter</literal>. Specifying an index,
alias or wildcard expression is required.</simpara>
<simpara>The delete index API can also be applied to more than one index, by either using a comma separated list, or on all indices (be careful!) by using <literal>_all</literal> or <literal>*</literal> as index.</simpara>
<simpara>In order to disable allowing to delete indices via wildcards or <literal>_all</literal>,
set <literal>action.destructive_requires_name</literal> setting in the config to <literal>true</literal>.
This setting can also be changed via the cluster update settings api.</simpara>
</chapter>
<chapter id="indices-get-index">
<title>Get Index<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/get-index.asciidoc">Edit me</ulink></title>
<simpara>The get index API allows to retrieve information about one or more indexes.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /twitter</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>The above example gets the information for an index called <literal>twitter</literal>. Specifying an index,
alias or wildcard expression is required.</simpara>
<simpara>The get index API can also be applied to more than one index, or on
all indices by using <literal>_all</literal> or <literal>*</literal> as index.</simpara>
<bridgehead id="_filtering_index_information" renderas="sect2">Filtering index information<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/get-index.asciidoc">Edit me</ulink></bridgehead>
<simpara>The information returned by the get API can be filtered to include only specific features
by specifying a comma delimited list of features in the URL:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET twitter/_settings,_mappings</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>The above command will only return the settings and mappings for the index called <literal>twitter</literal>.</simpara>
<simpara>The available features are <literal>_settings</literal>, <literal>_mappings</literal> and <literal>_aliases</literal>.</simpara>
</chapter>
<chapter id="indices-exists">
<title>Indices Exists<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/indices-exists.asciidoc">Edit me</ulink></title>
<simpara>Used to check if the index (indices) exists or not. For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">HEAD twitter</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>The HTTP status code indicates if the index exists or not. A <literal>404</literal> means
it does not exist, and <literal>200</literal> means it does.</simpara>
</chapter>
<chapter id="indices-open-close">
<title>Open / Close Index API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/open-close.asciidoc">Edit me</ulink></title>
<simpara>The open and close index APIs allow to close an index, and later on
opening it. A closed index has almost no overhead on the cluster (except
for maintaining its metadata), and is blocked for read/write operations.
A closed index can be opened which will then go through the normal
recovery process.</simpara>
<simpara>The REST endpoint is <literal>/{index}/_close</literal> and <literal>/{index}/_open</literal>. For
example:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /my_index/_close

POST /my_index/_open</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT my_index\n/]</remark>
<simpara>It is possible to open and close multiple indices. An error will be thrown
if the request explicitly refers to a missing index. This behaviour can be
disabled using the <literal>ignore_unavailable=true</literal> parameter.</simpara>
<simpara>All indices can be opened or closed at once using <literal>_all</literal> as the index name
or specifying patterns that identify them all (e.g. <literal>*</literal>).</simpara>
<simpara>Identifying indices via wildcards or <literal>_all</literal> can be disabled by setting the
<literal>action.destructive_requires_name</literal> flag in the config file to <literal>true</literal>.
This setting can also be changed via the cluster update settings api.</simpara>
<simpara>Closed indices consume a significant amount of disk-space which can cause problems in managed environments. Closing indices can be disabled via the cluster settings
API by setting <literal>cluster.indices.close.enable</literal> to <literal>false</literal>. The default is <literal>true</literal>.</simpara>
</chapter>
<chapter id="indices-shrink-index">
<title>Shrink Index<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/shrink-index.asciidoc">Edit me</ulink></title>
<simpara>The shrink index API allows you to shrink an existing index into a new index
with fewer primary shards. The requested number of primary shards in the target index
must be a factor of the number of shards in the source index. For example an index with
<literal>8</literal> primary shards can be shrunk into <literal>4</literal>, <literal>2</literal> or <literal>1</literal> primary shards or an index
with <literal>15</literal> primary shards can be shrunk into <literal>5</literal>, <literal>3</literal> or <literal>1</literal>. If the number
of shards in the index is a prime number it can only be shrunk into a single
primary shard. Before shrinking, a (primary or replica) copy of every shard
in the index must be present on the same node.</simpara>
<simpara>Shrinking works as follows:</simpara>
<itemizedlist>
<listitem>
<simpara>
First, it creates a new target index with the same definition as the source
  index, but with a smaller number of primary shards.
</simpara>
</listitem>
<listitem>
<simpara>
Then it hard-links segments from the source index into the target index. (If
  the file system doesn&#8217;t support hard-linking, then all segments are copied
  into the new index, which is a much more time consuming process.)
</simpara>
</listitem>
<listitem>
<simpara>
Finally, it recovers the target index as though it were a closed index which
  had just been re-opened.
</simpara>
</listitem>
</itemizedlist>
<bridgehead id="_preparing_an_index_for_shrinking" renderas="sect2">Preparing an index for shrinking<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/shrink-index.asciidoc">Edit me</ulink></bridgehead>
<simpara>In order to shrink an index, the index must be marked as read-only, and a
(primary or replica) copy of every shard in the index must be relocated to the
same node and have <link linkend="cluster-health">health</link> <literal>green</literal>.</simpara>
<simpara>These two conditions can be achieved with the following request:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /my_source_index/_settings
{
  "settings": {
    "index.routing.allocation.require._name": "shrink_node_name", <co id="CO115-1"/>
    "index.blocks.write": true <co id="CO115-2"/>
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT my_source_index\n/]</remark>
<calloutlist>
<callout arearefs="CO115-1">
<para>
Forces the relocation of a copy of each shard to the node with name
    <literal>shrink_node_name</literal>.  See <xref linkend="shard-allocation-filtering"/> for more options.
</para>
</callout>
<callout arearefs="CO115-2">
<para>
Prevents write operations to this index while still allowing metadata
    changes like deleting the index.
</para>
</callout>
</calloutlist>
<simpara>It can take a while to relocate the source index.  Progress can be tracked
with the <link linkend="cat-recovery"><literal>_cat recovery</literal> API</link>, or the <link linkend="cluster-health"><literal>cluster health</literal> API</link> can be used to wait until all shards have relocated
with the <literal>wait_for_no_relocating_shards</literal> parameter.</simpara>
<bridgehead id="_shrinking_an_index" renderas="sect2">Shrinking an index<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/shrink-index.asciidoc">Edit me</ulink></bridgehead>
<simpara>To shrink <literal>my_source_index</literal> into a new index called <literal>my_target_index</literal>, issue
the following request:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST my_source_index/_shrink/my_target_index</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>The above request returns immediately once the target index has been added to
the cluster state&#8201;&#8212;&#8201;it doesn&#8217;t wait for the shrink operation to start.</simpara>
<important>
<simpara>Indices can only be shrunk if they satisfy the following requirements:</simpara>
<itemizedlist>
<listitem>
<simpara>
the target index must not exist
</simpara>
</listitem>
<listitem>
<simpara>
The index must have more primary shards than the target index.
</simpara>
</listitem>
<listitem>
<simpara>
The number of primary shards in the target index must be a factor of the
  number of primary shards in the source index. The source index must have
  more primary shards than the target index.
</simpara>
</listitem>
<listitem>
<simpara>
The index must not contain more than <literal>2,147,483,519</literal> documents in total
  across all shards that will be shrunk into a single shard on the target index
  as this is the maximum number of docs that can fit into a single shard.
</simpara>
</listitem>
<listitem>
<simpara>
The node handling the shrink process must have sufficient free disk space to
  accommodate a second copy of the existing index.
</simpara>
</listitem>
</itemizedlist>
</important>
<simpara>The <literal>_shrink</literal> API is similar to the <link linkend="indices-create-index"><literal>create index</literal> API</link>
and accepts <literal>settings</literal> and <literal>aliases</literal> parameters for the target index:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST my_source_index/_shrink/my_target_index
{
  "settings": {
    "index.number_of_replicas": 1,
    "index.number_of_shards": 1, <co id="CO116-1"/>
    "index.codec": "best_compression" <co id="CO116-2"/>
  },
  "aliases": {
    "my_search_indices": {}
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT my_source_index\n{"settings": {"index.blocks.write": true}}\n/]</remark>
<calloutlist>
<callout arearefs="CO116-1">
<para>
The number of shards in the target index. This must be a factor of the
    number of shards in the source index.
</para>
</callout>
<callout arearefs="CO116-2">
<para>
Best compression will only take affect when new writes are made to the
    index, such as when <link linkend="indices-forcemerge">force-merging</link> the shard to a single
    segment.
</para>
</callout>
</calloutlist>
<note><simpara>Mappings may not be specified in the <literal>_shrink</literal> request, and all
<literal>index.analysis.*</literal> and <literal>index.similarity.*</literal> settings will be overwritten with
the settings from the source index.</simpara></note>
<bridgehead id="_monitoring_the_shrink_process" renderas="sect2">Monitoring the shrink process<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/shrink-index.asciidoc">Edit me</ulink></bridgehead>
<simpara>The shrink process can be monitored with the <link linkend="cat-recovery"><literal>_cat recovery</literal> API</link>, or the <link linkend="cluster-health"><literal>cluster health</literal> API</link> can be used to wait
until all primary shards have been allocated by setting the  <literal>wait_for_status</literal>
parameter to <literal>yellow</literal>.</simpara>
<simpara>The <literal>_shrink</literal> API returns as soon as the target index has been added to the
cluster state, before any shards have been allocated. At this point, all
shards are in the state <literal>unassigned</literal>. If, for any reason, the target index
can&#8217;t be allocated on the shrink node, its primary shard will remain
<literal>unassigned</literal> until it can be allocated on that node.</simpara>
<simpara>Once the primary shard is allocated, it moves to state <literal>initializing</literal>, and the
shrink process begins. When the shrink operation completes, the shard will
become <literal>active</literal>. At that  point, Elasticsearch will try to allocate any
replicas and may decide to relocate the primary shard to another node.</simpara>
<bridgehead id="_wait_for_active_shards" renderas="sect2">Wait For Active Shards<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/shrink-index.asciidoc">Edit me</ulink></bridgehead>
<simpara>Because the shrink operation creates a new index to shrink the shards to,
the <link linkend="create-index-wait-for-active-shards">wait for active shards</link> setting
on index creation applies to the shrink index action as well.</simpara>
</chapter>
<chapter id="indices-rollover-index">
<title>Rollover Index<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/rollover-index.asciidoc">Edit me</ulink></title>
<simpara>The rollover index API rolls an alias over to a new index when the existing
index is considered to be too large or too old.</simpara>
<simpara>The API accepts a single alias name and a list of <literal>conditions</literal>.  The alias
must point to a single index only.  If the index satisfies the specified
conditions then a new index is created and the alias is switched to point to
the new index.</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /logs-000001 <co id="CO117-1"/>
{
  "aliases": {
    "logs_write": {}
  }
}

# Add &gt; 1000 documents to logs-000001

POST /logs_write/_rollover <co id="CO117-2"/>
{
  "conditions": {
    "max_age":   "7d",
    "max_docs":  1000
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:huge_twitter]</remark>
<remark> TEST[s/# Add &gt; 1000 documents to logs-000001/POST _reindex?refresh\n{"source":{"index":"twitter"},"dest":{"index":"logs-000001"}}/]</remark>
<calloutlist>
<callout arearefs="CO117-1">
<para>
Creates an index called <literal>logs-0000001</literal> with the alias <literal>logs_write</literal>.
</para>
</callout>
<callout arearefs="CO117-2">
<para>
If the index pointed to by <literal>logs_write</literal> was created 7 or more days ago, or
    contains 1,000 or more documents, then the <literal>logs-000002</literal> index is created
    and the <literal>logs_write</literal> alias is updated to point to <literal>logs-000002</literal>.
</para>
</callout>
</calloutlist>
<simpara>The above request might return the following response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "acknowledged": true,
  "shards_acknowledged": true,
  "old_index": "logs-000001",
  "new_index": "logs-000002",
  "rolled_over": true, <co id="CO118-1"/>
  "dry_run": false, <co id="CO118-2"/>
  "conditions": { <co id="CO118-3"/>
    "[max_age: 7d]": false,
    "[max_docs: 1000]": true
  }
}</programlisting>
<remark> TESTRESPONSE</remark>
<calloutlist>
<callout arearefs="CO118-1">
<para>
Whether the index was rolled over.
</para>
</callout>
<callout arearefs="CO118-2">
<para>
Whether the rollover was dry run.
</para>
</callout>
<callout arearefs="CO118-3">
<para>
The result of each condition.
</para>
</callout>
</calloutlist>
<bridgehead id="_naming_the_new_index" renderas="sect2">Naming the new index<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/rollover-index.asciidoc">Edit me</ulink></bridgehead>
<simpara>If the name of the existing index ends with <literal>-</literal> and a number&#8201;&#8212;&#8201;e.g.
<literal>logs-000001</literal>&#8201;&#8212;&#8201;then the name of the new index will follow the same pattern,
incrementing the number (<literal>logs-000002</literal>). The number is zero-padded with a length
of 6, regardless of the old index name.</simpara>
<simpara>If the old name doesn&#8217;t match this pattern then you must specify the name for
the new index as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /my_alias/_rollover/my_new_index_name
{
  "conditions": {
    "max_age":   "7d",
    "max_docs":  1000
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT my_old_index_name\nPUT my_old_index_name\/_alias\/my_alias\n/]</remark>
<bridgehead id="_using_date_math_with_the_rolllover_api" renderas="sect2">Using date math with the rolllover API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/rollover-index.asciidoc">Edit me</ulink></bridgehead>
<simpara>It can be useful to use <link linkend="date-math-index-names">date math</link> to name the
rollover index according to the date that the index rolled over, e.g.
<literal>logstash-2016.02.03</literal>.  The rollover API supports date math, but requires the
index name to end with a dash followed by a number, e.g.
<literal>logstash-2016.02.03-1</literal> which is incremented every time the index is rolled
over. For instance:</simpara>
<programlisting language="js" linenumbering="unnumbered"># PUT /&lt;logs-{now/d}-1&gt; with URI encoding:
PUT /%3Clogs-%7Bnow%2Fd%7D-1%3E <co id="CO119-1"/>
{
  "aliases": {
    "logs_write": {}
  }
}

PUT logs_write/log/1
{
  "message": "a dummy log"
}

# Wait for a day to pass

POST /logs_write/_rollover <co id="CO119-2"/>
{
  "conditions": {
    "max_docs":   "1"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/now/2016.10.31||/]</remark>
<calloutlist>
<callout arearefs="CO119-1">
<para>
Creates an index named with today&#8217;s date (e.g.) <literal>logs-2016.10.31-1</literal>
</para>
</callout>
<callout arearefs="CO119-2">
<para>
Rolls over to a new index with today&#8217;s date, e.g. <literal>logs-2016.10.31-000002</literal> if run immediately, or <literal>logs-2016.11.01-000002</literal> if run after 24 hours
</para>
</callout>
</calloutlist>
<simpara>These indices can then be referenced as described in the
<link linkend="date-math-index-names">date math documentation</link>.  For example, to search
over indices created in the last three days, you could do the following:</simpara>
<programlisting language="js" linenumbering="unnumbered"># GET /&lt;logs-{now/d}-*&gt;,&lt;logs-{now/d-1d}-*&gt;,&lt;logs-{now/d-2d}-*&gt;/_search
GET /%3Clogs-%7Bnow%2Fd%7D-*%3E%2C%3Clogs-%7Bnow%2Fd-1d%7D-*%3E%2C%3Clogs-%7Bnow%2Fd-2d%7D-*%3E/_search</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<remark> TEST[s/now/2016.10.31||/]</remark>
<bridgehead id="_defining_the_new_index" renderas="sect2">Defining the new index<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/rollover-index.asciidoc">Edit me</ulink></bridgehead>
<simpara>The settings, mappings, and aliases for the new index are taken from any
matching <link linkend="indices-templates">index templates</link>. Additionally, you can specify
<literal>settings</literal>, <literal>mappings</literal>, and <literal>aliases</literal> in the body of the request, just like the
<link linkend="indices-create-index">create index</link> API. Values specified in the request
override any values set in matching index templates. For example, the following
<literal>rollover</literal> request overrides the <literal>index.number_of_shards</literal> setting:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /logs-000001
{
  "aliases": {
    "logs_write": {}
  }
}

POST /logs_write/_rollover
{
  "conditions" : {
    "max_age": "7d",
    "max_docs": 1000
  },
  "settings": {
    "index.number_of_shards": 2
  }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_dry_run" renderas="sect2">Dry run<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/rollover-index.asciidoc">Edit me</ulink></bridgehead>
<simpara>The rollover API supports <literal>dry_run</literal> mode, where request conditions can be
checked without performing the actual rollover:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /logs-000001
{
  "aliases": {
    "logs_write": {}
  }
}

POST /logs_write/_rollover?dry_run
{
  "conditions" : {
    "max_age": "7d",
    "max_docs": 1000
  }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_wait_for_active_shards_2" renderas="sect2">Wait For Active Shards<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/rollover-index.asciidoc">Edit me</ulink></bridgehead>
<simpara>Because the rollover operation creates a new index to rollover to, the
<link linkend="create-index-wait-for-active-shards"><literal>wait_for_active_shards</literal></link> setting on
index creation applies to the rollover action as well.</simpara>
</chapter>
<chapter id="indices-put-mapping">
<title>Put Mapping<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/put-mapping.asciidoc">Edit me</ulink></title>
<simpara>The PUT mapping API allows you to add a new type to an existing index, or add new
fields to an existing type:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT twitter <co id="CO120-1"/>
{
  "mappings": {
    "tweet": {
      "properties": {
        "message": {
          "type": "text"
        }
      }
    }
  }
}

PUT twitter/_mapping/user <co id="CO120-2"/>
{
  "properties": {
    "name": {
      "type": "text"
    }
  }
}

PUT twitter/_mapping/tweet <co id="CO120-3"/>
{
  "properties": {
    "user_name": {
      "type": "text"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO120-1">
<para>
<link linkend="indices-create-index">Creates an index</link> called <literal>twitter</literal> with the <literal>message</literal> field in the <literal>tweet</literal> <link linkend="mapping-type">mapping type</link>.
</para>
</callout>
<callout arearefs="CO120-2">
<para>
Uses the PUT mapping API to add a new mapping type called <literal>user</literal>.
</para>
</callout>
<callout arearefs="CO120-3">
<para>
Uses the PUT mapping API to add a new field called <literal>user_name</literal> to the <literal>tweet</literal> mapping type.
</para>
</callout>
</calloutlist>
<simpara>More information on how to define type mappings can be found in the
<link linkend="mapping">mapping</link> section.</simpara>
<bridgehead id="_multi_index" renderas="sect2">Multi-index<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/put-mapping.asciidoc">Edit me</ulink></bridgehead>
<simpara>The PUT mapping API can be applied to multiple indices with a single request.
It has the following format:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /{index}/_mapping/{type}
{ body }</programlisting>
<itemizedlist>
<listitem>
<simpara>
<literal>{index}</literal> accepts <link linkend="multi-index">multiple index names</link> and wildcards.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>{type}</literal> is the name of the type to update.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>{body}</literal> contains the mapping changes that should be applied.
</simpara>
</listitem>
</itemizedlist>
<note><simpara>When updating the <literal>_default_</literal> mapping with the
<link linkend="indices-put-mapping">PUT mapping</link> API, the new mapping is not merged with
the existing mapping.  Instead, the new <literal>_default_</literal> mapping replaces the
existing one.</simpara></note>
<bridgehead id="updating-field-mappings" renderas="sect2">Updating field mappings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/put-mapping.asciidoc">Edit me</ulink></bridgehead>
<simpara>In general, the mapping for existing fields cannot be updated.  There are some
exceptions to this rule. For instance:</simpara>
<itemizedlist>
<listitem>
<simpara>
new <xref linkend="properties"/> can be added to <xref linkend="object"/> fields.
</simpara>
</listitem>
<listitem>
<simpara>
new <link linkend="multi-fields">multi-fields</link> can be added to existing fields.
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="doc-values"/> can be disabled, but not enabled.
</simpara>
</listitem>
<listitem>
<simpara>
the <xref linkend="ignore-above"/> parameter can be updated.
</simpara>
</listitem>
</itemizedlist>
<simpara>For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index <co id="CO121-1"/>
{
  "mappings": {
    "user": {
      "properties": {
        "name": {
          "properties": {
            "first": {
              "type": "text"
            }
          }
        },
        "user_id": {
          "type": "keyword"
        }
      }
    }
  }
}

PUT my_index/_mapping/user
{
  "properties": {
    "name": {
      "properties": {
        "last": { <co id="CO121-2"/>
          "type": "text"
        }
      }
    },
    "user_id": {
      "type": "keyword",
      "ignore_above": 100 <co id="CO121-3"/>
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO121-1">
<para>
Create an index with a <literal>first</literal> field under the <literal>name</literal> <xref linkend="object"/> field, and a <literal>user_id</literal> field.
</para>
</callout>
<callout arearefs="CO121-2">
<para>
Add a <literal>last</literal> field under the <literal>name</literal> object field.
</para>
</callout>
<callout arearefs="CO121-3">
<para>
Update the <literal>ignore_above</literal> setting from its default of 0.
</para>
</callout>
</calloutlist>
<simpara>Each <link linkend="mapping-params">mapping parameter</link> specifies whether or not its setting
can be updated on an existing field.</simpara>
<bridgehead id="merging-conflicts" renderas="sect2">Conflicts between fields in different types<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/put-mapping.asciidoc">Edit me</ulink></bridgehead>
<simpara>Fields in the same index with the same name in two different types must have
the same mapping, as they are backed by the same field internally.  Trying to
<link linkend="updating-field-mappings">update a mapping parameter</link> for a field which
exists in more than one type will throw an exception, unless you specify the
<literal>update_all_types</literal> parameter, in which case it will update that parameter
across all fields with the same name in the same index.</simpara>
<tip><simpara>The only parameters which are exempt from this rule&#8201;&#8212;&#8201;they can be set to
different values on each field&#8201;&#8212;&#8201;can be found in <xref linkend="field-conflicts"/>.</simpara></tip>
<simpara>For example, this fails:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "type_one": {
      "properties": {
        "text": { <co id="CO122-1"/>
          "type": "text",
          "analyzer": "standard"
        }
      }
    },
    "type_two": {
      "properties": {
        "text": { <co id="CO122-2"/>
          "type": "text",
          "analyzer": "standard"
        }
      }
    }
  }
}

PUT my_index/_mapping/type_one <co id="CO122-3"/>
{
  "properties": {
    "text": {
      "type": "text",
      "analyzer": "standard",
      "search_analyzer": "whitespace"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[catch:request]</remark>
<calloutlist>
<callout arearefs="CO122-1 CO122-2">
<para>
Create an index with two types, both of which contain a <literal>text</literal> field which have the same mapping.
</para>
</callout>
<callout arearefs="CO122-3">
<para>
Trying to update the <literal>search_analyzer</literal> just for <literal>type_one</literal> throws an exception like <literal>"Merge failed with failures..."</literal>.
</para>
</callout>
</calloutlist>
<simpara>But this then running this succeeds:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index/_mapping/type_one?update_all_types <co id="CO123-1"/>
{
  "properties": {
    "text": {
      "type": "text",
      "analyzer": "standard",
      "search_analyzer": "whitespace"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<calloutlist>
<callout arearefs="CO123-1">
<para>
Adding the <literal>update_all_types</literal> parameter updates the <literal>text</literal> field in <literal>type_one</literal> and <literal>type_two</literal>.
</para>
</callout>
</calloutlist>
</chapter>
<chapter id="indices-get-mapping">
<title>Get Mapping<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/get-mapping.asciidoc">Edit me</ulink></title>
<simpara>The get mapping API allows to retrieve mapping definitions for an index or
index/type.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /twitter/_mapping/tweet</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<bridgehead id="_multiple_indices_and_types" renderas="sect2">Multiple Indices and Types<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/get-mapping.asciidoc">Edit me</ulink></bridgehead>
<simpara>The get mapping API can be used to get more than one index or type
mapping with a single call. General usage of the API follows the
following syntax: <literal>host:port/{index}/_mapping/{type}</literal> where both
<literal>{index}</literal> and <literal>{type}</literal> can accept a comma-separated list of names. To
get mappings for all indices you can use <literal>_all</literal> for <literal>{index}</literal>. The
following are some examples:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_mapping/tweet,kimchy

GET /_all/_mapping/tweet,book</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>If you want to get mappings of all indices and types then the following
two examples are equivalent:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_all/_mapping

GET /_mapping</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
</chapter>
<chapter id="indices-get-field-mapping">
<title>Get Field Mapping<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/get-field-mapping.asciidoc">Edit me</ulink></title>
<simpara>The get field mapping API allows you to retrieve mapping definitions for one or more fields.
This is useful when you do not need the complete type mapping returned by
the <xref linkend="indices-get-mapping"/> API.</simpara>
<simpara>The following returns the mapping of the field <literal>text</literal> only:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /twitter/_mapping/tweet/field/message</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>For which the response is (assuming <literal>text</literal> is a default string field):</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "twitter": {
      "mappings": {
         "tweet": {
            "message": {
               "full_name": "message",
               "mapping": {
                  "message": {
                     "type": "text",
                     "fields": {
                        "keyword": {
                           "type": "keyword",
                           "ignore_above": 256
                        }
                     }
                  }
               }
            }
         }
      }
   }
}</programlisting>
<remark> TESTRESPONSE</remark>
<bridgehead id="_multiple_indices_types_and_fields" renderas="sect2">Multiple Indices, Types and Fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/get-field-mapping.asciidoc">Edit me</ulink></bridgehead>
<simpara>The get field mapping API can be used to get the mapping of multiple fields from more than one index or type
with a single call. General usage of the API follows the
following syntax: <literal>host:port/{index}/{type}/_mapping/field/{field}</literal> where
<literal>{index}</literal>, <literal>{type}</literal> and <literal>{field}</literal> can stand for comma-separated list of names or wild cards. To
get mappings for all indices you can use <literal>_all</literal> for <literal>{index}</literal>. The
following are some examples:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /twitter,kimchy/_mapping/field/message

GET /_all/_mapping/tweet,book/field/message,user.id

GET /_all/_mapping/tw*/field/*.id</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<remark> TEST[s/^/PUT kimchy\nPUT book\n/]</remark>
<bridgehead id="_specifying_fields" renderas="sect2">Specifying fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/get-field-mapping.asciidoc">Edit me</ulink></bridgehead>
<simpara>The get mapping api allows you to specify one or more fields separated with by a comma.
You can also use wildcards. The field names can be any of the following:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
Full names
</simpara>
</entry>
<entry>
<simpara>
the full path, including any parent object name the field is
   part of (ex. <literal>user.id</literal>).
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Field names
</simpara>
</entry>
<entry>
<simpara>
the name of the field without the path to it (ex. <literal>id</literal> for <literal>{ "user" : { "id" : 1 } }</literal>).
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>The above options are specified in the order the <literal>field</literal> parameter is resolved.
The first field found which matches is returned. This is especially important
if index names or field names are used as those can be ambiguous.</simpara>
<simpara>For example, consider the following mapping:</simpara>
<programlisting language="js" linenumbering="unnumbered"> {
     "article": {
         "properties": {
             "id": { "type": "text" },
             "title":  { "type": "text"},
             "abstract": { "type": "text"},
             "author": {
                 "properties": {
                     "id": { "type": "text" },
                     "name": { "type": "text" }
                 }
             }
         }
     }
 }</programlisting>
<simpara>To select the <literal>id</literal> of the <literal>author</literal> field, you can use its full name <literal>author.id</literal>. <literal>name</literal> will return
the field <literal>author.name</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET "http://localhost:9200/publications/_mapping/article/field/author.id,abstract,name"</programlisting>
<simpara>returns:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "publications": {
      "article": {
         "abstract": {
            "full_name": "abstract",
            "mapping": {
               "abstract": { "type": "text" }
            }
         },
         "author.id": {
            "full_name": "author.id",
            "mapping": {
               "id": { "type": "text" }
            }
         },
         "name": {
            "full_name": "author.name",
            "mapping": {
               "name": { "type": "text" }
            }
         }
      }
   }
}</programlisting>
<simpara>Note how the response always use the same fields specified in the request as keys.
The <literal>full_name</literal> in every entry contains the full name of the field whose mapping were returned.
This is useful when the request can refer to to multiple fields.</simpara>
<bridgehead id="_other_options" renderas="sect2">Other options<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/get-field-mapping.asciidoc">Edit me</ulink></bridgehead>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>include_defaults</literal>
</simpara>
</entry>
<entry>
<simpara>
    adding <literal>include_defaults=true</literal> to the query string will cause the response
    to include default values, which are normally suppressed.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</chapter>
<chapter id="indices-types-exists">
<title>Types Exists<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/types-exists.asciidoc">Edit me</ulink></title>
<simpara>Used to check if a type/types exists in an index/indices.</simpara>
<programlisting language="js" linenumbering="unnumbered">HEAD twitter/_mapping/tweet</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>The HTTP status code indicates if the type exists or not. A <literal>404</literal> means
it does not exist, and <literal>200</literal> means it does.</simpara>
</chapter>
<chapter id="indices-aliases">
<title>Index Aliases<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/aliases.asciidoc">Edit me</ulink></title>
<simpara>APIs in elasticsearch accept an index name when working against a
specific index, and several indices when applicable. The index aliases
API allow to alias an index with a name, with all APIs automatically
converting the alias name to the actual index name. An alias can also be
mapped to more than one index, and when specifying it, the alias will
automatically expand to the aliases indices. An alias can also be
associated with a filter that will automatically be applied when
searching, and routing values. An alias cannot have the same name as an index.</simpara>
<simpara>Here is a sample of associating the alias <literal>alias1</literal> with index <literal>test1</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /_aliases
{
    "actions" : [
        { "add" : { "index" : "test1", "alias" : "alias1" } }
    ]
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT test1\nPUT test2\n/]</remark>
<simpara>And here is removing that same alias:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /_aliases
{
    "actions" : [
        { "remove" : { "index" : "test1", "alias" : "alias1" } }
    ]
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Renaming an alias is a simple <literal>remove</literal> then <literal>add</literal> operation within the
same API. This operation is atomic, no need to worry about a short
period of time where the alias does not point to an index:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /_aliases
{
    "actions" : [
        { "remove" : { "index" : "test1", "alias" : "alias1" } },
        { "add" : { "index" : "test2", "alias" : "alias1" } }
    ]
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Associating an alias with more than one index are simply several <literal>add</literal>
actions:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /_aliases
{
    "actions" : [
        { "add" : { "index" : "test1", "alias" : "alias1" } },
        { "add" : { "index" : "test2", "alias" : "alias1" } }
    ]
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT test1\nPUT test2\n/]</remark>
<simpara>Multiple indices can be specified for an action with the <literal>indices</literal> array syntax:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /_aliases
{
    "actions" : [
        { "add" : { "indices" : ["test1", "test2"], "alias" : "alias1" } }
    ]
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT test1\nPUT test2\n/]</remark>
<simpara>To specify multiple aliases in one action, the corresponding <literal>aliases</literal> array
syntax exists as well.</simpara>
<simpara>For the example above, a glob pattern can also be used to associate an alias to
more than one index that share a common name:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /_aliases
{
    "actions" : [
        { "add" : { "index" : "test*", "alias" : "all_test_indices" } }
    ]
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT test1\nPUT test2\n/]</remark>
<simpara>In this case, the alias is a point-in-time alias that will group all
current indices that match, it will not automatically update as new
indices that match this pattern are added/removed.</simpara>
<simpara>It is an error to index to an alias which points to more than one index.</simpara>
<simpara>It is also possible to swap an index with an alias in one operation:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT test     <co id="CO124-1"/>
PUT test_2   <co id="CO124-2"/>
POST /_aliases
{
    "actions" : [
        { "add":  { "index": "test_2", "alias": "test" } },
        { "remove_index": { "index": "test" } }  <co id="CO124-3"/>
    ]
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO124-1">
<para>
An index we&#8217;ve added by mistake
</para>
</callout>
<callout arearefs="CO124-2">
<para>
The index we should have added
</para>
</callout>
<callout arearefs="CO124-3">
<para>
<literal>remove_index</literal> is just like <xref linkend="indices-delete-index"/>
</para>
</callout>
</calloutlist>
<bridgehead id="filtered" renderas="sect2">Filtered Aliases<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/aliases.asciidoc">Edit me</ulink></bridgehead>
<simpara>Aliases with filters provide an easy way to create different "views" of
the same index. The filter can be defined using Query DSL and is applied
to all Search, Count, Delete By Query and More Like This operations with
this alias.</simpara>
<simpara>To create a filtered alias, first we need to ensure that the fields already
exist in the mapping:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /test1
{
  "mappings": {
    "type1": {
      "properties": {
        "user" : {
          "type": "keyword"
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Now we can create an alias that uses a filter on field <literal>user</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /_aliases
{
    "actions" : [
        {
            "add" : {
                 "index" : "test1",
                 "alias" : "alias2",
                 "filter" : { "term" : { "user" : "kimchy" } }
            }
        }
    ]
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<bridgehead id="aliases-routing" renderas="sect3">Routing<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/aliases.asciidoc">Edit me</ulink></bridgehead>
<simpara>It is possible to associate routing values with aliases. This feature
can be used together with filtering aliases in order to avoid
unnecessary shard operations.</simpara>
<simpara>The following command creates a new alias <literal>alias1</literal> that points to index
<literal>test</literal>. After <literal>alias1</literal> is created, all operations with this alias are
automatically modified to use value <literal>1</literal> for routing:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /_aliases
{
    "actions" : [
        {
            "add" : {
                 "index" : "test",
                 "alias" : "alias1",
                 "routing" : "1"
            }
        }
    ]
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT test\n/]</remark>
<simpara>It&#8217;s also possible to specify different routing values for searching
and indexing operations:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /_aliases
{
    "actions" : [
        {
            "add" : {
                 "index" : "test",
                 "alias" : "alias2",
                 "search_routing" : "1,2",
                 "index_routing" : "2"
            }
        }
    ]
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT test\n/]</remark>
<simpara>As shown in the example above, search routing may contain several values
separated by comma. Index routing can contain only a single value.</simpara>
<simpara>If a search operation that uses routing alias also has a routing parameter, an
intersection of both search alias routing and routing specified in the
parameter is used. For example the following command will use "2" as a
routing value:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /alias2/_search?q=user:kimchy&amp;routing=2,3</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>If an index operation that uses index routing alias also has a parent routing, the
parent routing is ignored.</simpara>
<bridgehead id="alias-adding" renderas="sect2">Add a single alias<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/aliases.asciidoc">Edit me</ulink></bridgehead>
<simpara>An alias can also be added with the endpoint</simpara>
<simpara><literal>PUT /{index}/_alias/{name}</literal></simpara>
<simpara>where</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>index</literal>
</simpara>
</entry>
<entry>
<simpara>
The index the alias refers to. Can be any of <literal>* | _all | glob pattern | name1, name2, …</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>name</literal>
</simpara>
</entry>
<entry>
<simpara>
The name of the alias. This is a required option.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>routing</literal>
</simpara>
</entry>
<entry>
<simpara>
An optional routing that can be associated with an alias.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>filter</literal>
</simpara>
</entry>
<entry>
<simpara>
An optional filter that can be associated with an alias.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>You can also use the plural <literal>_aliases</literal>.</simpara>
<bridgehead id="_examples_2" renderas="sect3">Examples:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/aliases.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
Adding time based alias
</term>
<listitem>
<programlisting language="js" linenumbering="unnumbered">PUT /logs_201305/_alias/2013</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT logs_201305\n/]</remark>
</listitem>
</varlistentry>
<varlistentry>
<term>
Adding a user alias
</term>
<listitem>
<simpara>First create the index and add a mapping for the <literal>user_id</literal> field:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /users
{
    "mappings" : {
        "user" : {
            "properties" : {
                "user_id" : {"type" : "integer"}
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Then add the alias for a specific user:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /users/_alias/user_12
{
    "routing" : "12",
    "filter" : {
        "term" : {
            "user_id" : 12
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="alias-index-creation" renderas="sect2">Aliases during index creation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/aliases.asciidoc">Edit me</ulink></bridgehead>
<simpara>Aliases can also be specified during <link linkend="create-index-aliases">index creation</link>:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /logs_20162801
{
    "mappings" : {
        "type" : {
            "properties" : {
                "year" : {"type" : "integer"}
            }
        }
    },
    "aliases" : {
        "current_day" : {},
        "2016" : {
            "filter" : {
                "term" : {"year" : 2016 }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="deleting" renderas="sect2">Delete aliases<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/aliases.asciidoc">Edit me</ulink></bridgehead>
<simpara>The rest endpoint is: <literal>/{index}/_alias/{name}</literal></simpara>
<simpara>where</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>index</literal>
</simpara>
</entry>
<entry>
<simpara>
<literal>* | _all | glob pattern | name1, name2, …</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>name</literal>
</simpara>
</entry>
<entry>
<simpara>
<literal>* | _all | glob pattern | name1, name2, …</literal>
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>Alternatively you can use the plural <literal>_aliases</literal>. Example:</simpara>
<programlisting language="js" linenumbering="unnumbered">DELETE /logs_20162801/_alias/current_day</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<bridgehead id="alias-retrieving" renderas="sect2">Retrieving existing aliases<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/aliases.asciidoc">Edit me</ulink></bridgehead>
<simpara>The get index alias api allows to filter by
alias name and index name. This api redirects to the master and fetches
the requested index aliases, if available. This api only serialises the
found index aliases.</simpara>
<simpara>Possible options:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>index</literal>
</simpara>
</entry>
<entry>
<simpara>
    The index name to get aliases for. Partially names are
    supported via wildcards, also multiple index names can be specified
    separated with a comma. Also the alias name for an index can be used.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>alias</literal>
</simpara>
</entry>
<entry>
<simpara>
    The name of alias to return in the response. Like the index
    option, this option supports wildcards and the option the specify
    multiple alias names separated by a comma.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>ignore_unavailable</literal>
</simpara>
</entry>
<entry>
<simpara>
    What to do if an specified index name doesn&#8217;t
    exist. If set to <literal>true</literal> then those indices are ignored.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>The rest endpoint is: <literal>/{index}/_alias/{alias}</literal>.</simpara>
<bridgehead id="_examples_3" renderas="sect3">Examples:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/aliases.asciidoc">Edit me</ulink></bridgehead>
<simpara>All aliases for the index users:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /logs_20162801/_alias/*</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
 "logs_20162801" : {
   "aliases" : {
     "2016" : {
       "filter" : {
         "term" : {
           "year" : 2016
         }
       }
     }
   }
 }
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>All aliases with the name 2016 in any index:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_alias/2016</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "logs_20162801" : {
    "aliases" : {
      "2016" : {
        "filter" : {
          "term" : {
            "year" : 2016
          }
        }
      }
    }
  }
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>All aliases that start with 20 in any index:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_alias/20*</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "logs_20162801" : {
    "aliases" : {
      "2016" : {
        "filter" : {
          "term" : {
            "year" : 2016
          }
        }
      }
    }
  }
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>There is also a HEAD variant of the get indices aliases api to check if
index aliases exist. The indices aliases exists api supports the same
option as the get indices aliases api. Examples:</simpara>
<programlisting language="js" linenumbering="unnumbered">HEAD /_alias/2016
HEAD /_alias/20*
HEAD /logs_20162801/_alias/*</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
</chapter>
<chapter id="indices-update-settings">
<title>Update Indices Settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/update-settings.asciidoc">Edit me</ulink></title>
<simpara>Change specific index level settings in real time.</simpara>
<simpara>The REST endpoint is <literal>/_settings</literal> (to update all indices) or
<literal>{index}/_settings</literal> to update one (or more) indices settings. The body
of the request includes the updated settings, for example:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "index" : {
        "number_of_replicas" : 4
    }
}</programlisting>
<simpara>The above will change the number of replicas to 4 from the current
number of replicas. Here is a curl example:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XPUT 'localhost:9200/my_index/_settings' -d '
{
    "index" : {
        "number_of_replicas" : 4
    }
}'</programlisting>
<simpara>The list of per-index settings which can be updated dynamically on live
indices can be found in <xref linkend="index-modules"/>.</simpara>
<bridgehead id="bulk" renderas="sect2">Bulk Indexing Usage<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/update-settings.asciidoc">Edit me</ulink></bridgehead>
<simpara>For example, the update settings API can be used to dynamically change
the index from being more performant for bulk indexing, and then move it
to more real time indexing state. Before the bulk indexing is started,
use:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XPUT localhost:9200/test/_settings -d '{
    "index" : {
        "refresh_interval" : "-1"
    } }'</programlisting>
<simpara>(Another optimization option is to start the index without any replicas,
and only later adding them, but that really depends on the use case).</simpara>
<simpara>Then, once bulk indexing is done, the settings can be updated (back to
the defaults for example):</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XPUT localhost:9200/test/_settings -d '{
    "index" : {
        "refresh_interval" : "1s"
    } }'</programlisting>
<simpara>And, a force merge should be called:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XPOST 'http://localhost:9200/test/_forcemerge?max_num_segments=5'</programlisting>
<bridgehead id="update-settings-analysis" renderas="sect2">Updating Index Analysis<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/update-settings.asciidoc">Edit me</ulink></bridgehead>
<simpara>It is also possible to define new <link linkend="analysis">analyzers</link> for the index.
But it is required to <link linkend="indices-open-close">close</link> the index
first and <link linkend="indices-open-close">open</link> it after the changes are made.</simpara>
<simpara>For example if <literal>content</literal> analyzer hasn&#8217;t been defined on <literal>myindex</literal> yet
you can use the following commands to add it:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XPOST 'localhost:9200/myindex/_close'

curl -XPUT 'localhost:9200/myindex/_settings' -d '{
  "analysis" : {
    "analyzer":{
      "content":{
        "type":"custom",
        "tokenizer":"whitespace"
      }
    }
  }
}'

curl -XPOST 'localhost:9200/myindex/_open'</programlisting>
</chapter>
<chapter id="indices-get-settings">
<title>Get Settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/get-settings.asciidoc">Edit me</ulink></title>
<simpara>The get settings API allows to retrieve settings of index/indices:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /twitter/_settings</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<bridgehead id="_multiple_indices_and_types_2" renderas="sect2">Multiple Indices and Types<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/get-settings.asciidoc">Edit me</ulink></bridgehead>
<simpara>The get settings API can be used to get settings for more than one index
with a single call. General usage of the API follows the
following syntax: <literal>host:port/{index}/_settings</literal> where
<literal>{index}</literal> can stand for comma-separated list of index names and aliases. To
get settings for all indices you can use <literal>_all</literal> for <literal>{index}</literal>.
Wildcard expressions are also supported. The following are some examples:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /twitter,kimchy/_settings

GET /_all/_settings

GET /log_2013_*/_settings</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<remark> TEST[s/^/PUT kimchy\nPUT log_2013_01_01\n/]</remark>
<bridgehead id="_filtering_settings_by_name" renderas="sect2">Filtering settings by name<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/get-settings.asciidoc">Edit me</ulink></bridgehead>
<simpara>The settings that are returned can be filtered with wildcard matching
as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET 'http://localhost:9200/2013-*/_settings/index.number_*'</programlisting>
</chapter>
<chapter id="indices-analyze">
<title>Analyze<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/analyze.asciidoc">Edit me</ulink></title>
<simpara>Performs the analysis process on a text and return the tokens breakdown
of the text.</simpara>
<simpara>Can be used without specifying an index against one of the many built in
analyzers:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET 'localhost:9200/_analyze' -d '
{
  "analyzer" : "standard",
  "text" : "this is a test"
}'</programlisting>
<simpara>If text parameter is provided as array of strings, it is analyzed as a multi-valued field.</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET 'localhost:9200/_analyze' -d '
{
  "analyzer" : "standard",
  "text" : ["this is a test", "the second text"]
}'</programlisting>
<simpara>Or by building a custom transient analyzer out of tokenizers,
token filters and char filters. Token filters can use the shorter <emphasis>filter</emphasis>
parameter name:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET 'localhost:9200/_analyze' -d '
{
  "tokenizer" : "keyword",
  "filter" : ["lowercase"],
  "text" : "this is a test"
}'

curl -XGET 'localhost:9200/_analyze' -d '
{
  "tokenizer" : "keyword",
  "filter" : ["lowercase"],
  "char_filter" : ["html_strip"],
  "text" : "this is a &lt;b&gt;test&lt;/b&gt;"
}'</programlisting>
<warning revisionflag="deleted" revision="5.0.0"><title>Deprecated in 5.0.0.</title><simpara> Use <literal>filter</literal>/<literal>char_filter</literal> instead of <literal>filters</literal>/<literal>char_filters</literal> and <literal>token_filters</literal> has been removed.</simpara></warning>
<simpara>Custom tokenizers, token filters, and character filters can be specified in the request body as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET 'localhost:9200/_analyze' -d '
{
  "tokenizer" : "whitespace",
  "filter" : ["lowercase", {"type": "stop", "stopwords": ["a", "is", "this"]}],
  "text" : "this is a test"
}'</programlisting>
<simpara>It can also run against a specific index:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET 'localhost:9200/test/_analyze' -d '
{
  "text" : "this is a test"
}'</programlisting>
<simpara>The above will run an analysis on the "this is a test" text, using the
default index analyzer associated with the <literal>test</literal> index. An <literal>analyzer</literal>
can also be provided to use a different analyzer:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET 'localhost:9200/test/_analyze' -d '
{
  "analyzer" : "whitespace",
  "text" : "this is a test"
}'</programlisting>
<simpara>Also, the analyzer can be derived based on a field mapping, for example:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET 'localhost:9200/test/_analyze' -d '
{
  "field" : "obj1.field1",
  "text" : "this is a test"
}'</programlisting>
<simpara>Will cause the analysis to happen based on the analyzer configured in the
mapping for <literal>obj1.field1</literal> (and if not, the default index analyzer).</simpara>
<warning revisionflag="deleted" revision="5.1.0 request parameters are deprecated and will be removed in the next major release. please use JSON params instead of request params"><simpara>Deprecated in 5.1.0 request parameters are deprecated and will be removed in the next major release. please use JSON params instead of request params.</simpara></warning>
<simpara>All parameters can also supplied as request parameters. For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET 'localhost:9200/_analyze?tokenizer=keyword&amp;filter=lowercase&amp;text=this+is+a+test'</programlisting>
<simpara>For backwards compatibility, we also accept the text parameter as the body of the request,
provided it doesn&#8217;t start with <literal>{</literal> :</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET 'localhost:9200/_analyze?tokenizer=keyword&amp;filter=lowercase&amp;char_filter=html_strip' -d 'this is a &lt;b&gt;test&lt;/b&gt;'</programlisting>
<warning revisionflag="deleted" revision="5.1.0 the text parameter as the body of the request are deprecated and this feature will be removed in the next major release. please use JSON text param"><simpara>Deprecated in 5.1.0 the text parameter as the body of the request are deprecated and this feature will be removed in the next major release. please use JSON text param.</simpara></warning>
<section id="_explain_analyze">
<title>Explain Analyze<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/analyze.asciidoc">Edit me</ulink></title>
<simpara>If you want to get more advanced details, set <literal>explain</literal> to <literal>true</literal> (defaults to <literal>false</literal>). It will output all token attributes for each token.
You can filter token attributes you want to output by setting <literal>attributes</literal> option.</simpara>
<warning role="experimental"><simpara>The format of the additional detail information is experimental and can change at any time.</simpara></warning>
<programlisting language="js" linenumbering="unnumbered">GET _analyze
{
  "tokenizer" : "standard",
  "filter" : ["snowball"],
  "text" : "detailed output",
  "explain" : true,
  "attributes" : ["keyword"] <co id="CO125-1"/>
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO125-1">
<para>
Set "keyword" to output "keyword" attribute only
</para>
</callout>
</calloutlist>
<simpara>The request returns the following result:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "detail" : {
    "custom_analyzer" : true,
    "charfilters" : [ ],
    "tokenizer" : {
      "name" : "standard",
      "tokens" : [ {
        "token" : "detailed",
        "start_offset" : 0,
        "end_offset" : 8,
        "type" : "&lt;ALPHANUM&gt;",
        "position" : 0
      }, {
        "token" : "output",
        "start_offset" : 9,
        "end_offset" : 15,
        "type" : "&lt;ALPHANUM&gt;",
        "position" : 1
      } ]
    },
    "tokenfilters" : [ {
      "name" : "snowball",
      "tokens" : [ {
        "token" : "detail",
        "start_offset" : 0,
        "end_offset" : 8,
        "type" : "&lt;ALPHANUM&gt;",
        "position" : 0,
        "keyword" : false <co id="CO126-1"/>
      }, {
        "token" : "output",
        "start_offset" : 9,
        "end_offset" : 15,
        "type" : "&lt;ALPHANUM&gt;",
        "position" : 1,
        "keyword" : false <co id="CO126-2"/>
      } ]
    } ]
  }
}</programlisting>
<remark> TESTRESPONSE</remark>
<calloutlist>
<callout arearefs="CO126-1 CO126-2">
<para>
Output only "keyword" attribute, since specify "attributes" in the request.
</para>
</callout>
</calloutlist>
</section>
</chapter>
<chapter id="indices-templates">
<title>Index Templates<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/templates.asciidoc">Edit me</ulink></title>
<simpara>Index templates allow you to define templates that will automatically be
applied when new indices are created. The templates include both settings and
mappings, and a simple pattern template that controls whether the template
should be applied to the new index.</simpara>
<note><simpara>Templates are only applied at index creation time.  Changing a template
will have no impact on existing indices.</simpara></note>
<simpara>For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT _template/template_1
{
  "template": "te*",
  "settings": {
    "number_of_shards": 1
  },
  "mappings": {
    "type1": {
      "_source": {
        "enabled": false
      },
      "properties": {
        "host_name": {
          "type": "keyword"
        },
        "created_at": {
          "type": "date",
          "format": "EEE MMM dd HH:mm:ss Z YYYY"
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TESTSETUP</remark>
<note><simpara>Index templates provide C-style /* */ block comments. Comments are allowed
everywhere in the JSON document except before the initial opening curly bracket.</simpara></note>
<simpara>Defines a template named <literal>template_1</literal>, with a template pattern of <literal>te*</literal>.
The settings and mappings will be applied to any index name that matches
the <literal>te*</literal> pattern.</simpara>
<simpara>It is also possible to include aliases in an index template as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT _template/template_1
{
    "template" : "te*",
    "settings" : {
        "number_of_shards" : 1
    },
    "aliases" : {
        "alias1" : {},
        "alias2" : {
            "filter" : {
                "term" : {"user" : "kimchy" }
            },
            "routing" : "kimchy"
        },
        "{index}-alias" : {} <co id="CO127-1"/>
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/DELETE _template\/template_1\n/]</remark>
<calloutlist>
<callout arearefs="CO127-1">
<para>
the <literal>{index}</literal> placeholder in the alias name will be replaced with the
actual index name that the template gets applied to, during index creation.
</para>
</callout>
</calloutlist>
<bridgehead id="delete" renderas="sect2">Deleting a Template<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/templates.asciidoc">Edit me</ulink></bridgehead>
<simpara>Index templates are identified by a name (in the above case
<literal>template_1</literal>) and can be deleted as well:</simpara>
<programlisting language="js" linenumbering="unnumbered">DELETE /_template/template_1</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="getting" renderas="sect2">Getting templates<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/templates.asciidoc">Edit me</ulink></bridgehead>
<simpara>Index templates are identified by a name (in the above case
<literal>template_1</literal>) and can be retrieved using the following:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_template/template_1</programlisting>
<remark> CONSOLE</remark>
<simpara>You can also match several templates by using wildcards like:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_template/temp*
GET /_template/template_1,template_2</programlisting>
<remark> CONSOLE</remark>
<simpara>To get list of all index templates you can run:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_template</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="indices-templates-exists" renderas="sect2">Template exists<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/templates.asciidoc">Edit me</ulink></bridgehead>
<simpara>Used to check if the template exists or not. For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">HEAD _template/template_1</programlisting>
<remark> CONSOLE</remark>
<simpara>The HTTP status code indicates if the template with the given name
exists or not. Status code <literal>200</literal> means it exists and <literal>404</literal> means
it does not.</simpara>
<bridgehead id="multiple-templates" renderas="sect2">Multiple Templates Matching<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/templates.asciidoc">Edit me</ulink></bridgehead>
<simpara>Multiple index templates can potentially match an index, in this case,
both the settings and mappings are merged into the final configuration
of the index. The order of the merging can be controlled using the
<literal>order</literal> parameter, with lower order being applied first, and higher
orders overriding them. For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /_template/template_1
{
    "template" : "*",
    "order" : 0,
    "settings" : {
        "number_of_shards" : 1
    },
    "mappings" : {
        "type1" : {
            "_source" : { "enabled" : false }
        }
    }
}

PUT /_template/template_2
{
    "template" : "te*",
    "order" : 1,
    "settings" : {
        "number_of_shards" : 1
    },
    "mappings" : {
        "type1" : {
            "_source" : { "enabled" : true }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/DELETE _template\/template_1\n/]</remark>
<simpara>The above will disable storing the <literal>_source</literal> on all <literal>type1</literal> types, but
for indices that start with <literal>te*</literal>, <literal>_source</literal> will still be enabled.
Note, for mappings, the merging is "deep", meaning that specific
object/property based mappings can easily be added/overridden on higher
order templates, with lower order templates providing the basis.</simpara>
<bridgehead id="versioning-templates" renderas="sect2">Template Versioning<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/templates.asciidoc">Edit me</ulink></bridgehead>
<simpara>Templates can optionally add a <literal>version</literal> number, which can be any integer value,
in order to simplify template management by external systems. The <literal>version</literal>
field is completely optional and it is meant solely for external management of
templates. To unset a <literal>version</literal>, simply replace the template without specifying
one.</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /_template/template_1
{
    "template" : "*",
    "order" : 0,
    "settings" : {
        "number_of_shards" : 1
    },
    "version": 123
}</programlisting>
<remark> CONSOLE</remark>
<simpara>To check the <literal>version</literal>, you can
<link linkend="common-options-response-filtering">filter responses</link>
using <literal>filter_path</literal> to limit the response to just the <literal>version</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_template/template_1?filter_path=*.version</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>This should give a small response that makes it both easy and inexpensive to parse:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "template_1" : {
    "version" : 123
  }
}</programlisting>
<remark> TESTRESPONSE</remark>
</chapter>
<chapter id="indices-shadow-replicas">
<title>Shadow replica indices<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/shadow-replicas.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This functionality is experimental and may be changed or removed completely in a future release.</simpara></warning>
<simpara>If you would like to use a shared filesystem, you can use the shadow replicas
settings to choose where on disk the data for an index should be kept, as well
as how Elasticsearch should replay operations on all the replica shards of an
index.</simpara>
<simpara>In order to fully utilize the <literal>index.data_path</literal> and <literal>index.shadow_replicas</literal>
settings, you need to allow Elasticsearch to use the same data directory for
multiple instances by setting <literal>node.add_lock_id_to_custom_path</literal> to false in
elasticsearch.yml:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">node.add_lock_id_to_custom_path: false</programlisting>
<simpara>You will also need to indicate to the security manager where the custom indices
will be, so that the correct permissions can be applied. You can do this by
setting the <literal>path.shared_data</literal> setting in elasticsearch.yml:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">path.shared_data: /opt/data</programlisting>
<simpara>This means that Elasticsearch can read and write to files in any subdirectory of
the <literal>path.shared_data</literal> setting.</simpara>
<simpara>You can then create an index with a custom data path, where each node will use
this path for the data:</simpara>
<warning>
<simpara>Because shadow replicas do not index the document on replica shards, it&#8217;s
possible for the replica&#8217;s known mapping to be behind the index&#8217;s known mapping
if the latest cluster state has not yet been processed on the node containing
the replica. Because of this, it is highly recommended to use pre-defined
mappings when using shadow replicas.</simpara>
</warning>
<programlisting language="js" linenumbering="unnumbered">curl -XPUT 'localhost:9200/my_index' -d '
{
    "index" : {
        "number_of_shards" : 1,
        "number_of_replicas" : 4,
        "data_path": "/opt/data/my_index",
        "shadow_replicas": true
    }
}'</programlisting>
<warning>
<simpara>In the above example, the "/opt/data/my_index" path is a shared filesystem that
must be available on every node in the Elasticsearch cluster. You must also
ensure that the Elasticsearch process has the correct permissions to read from
and write to the directory used in the <literal>index.data_path</literal> setting.</simpara>
</warning>
<simpara>The <literal>data_path</literal> does not have to contain the index name, in this case,
"my_index" was used but it could easily also have been "/opt/data/"</simpara>
<simpara>An index that has been created with the <literal>index.shadow_replicas</literal> setting set to
"true" will not replicate document operations to any of the replica shards,
instead, it will only continually refresh. Once segments are available on the
filesystem where the shadow replica resides (after an Elasticsearch "flush"), a
regular refresh (governed by the <literal>index.refresh_interval</literal>) can be used to make
the new data searchable.</simpara>
<note><simpara>Since documents are only indexed on the primary shard, realtime GET
requests could fail to return a document if executed on the replica shard,
therefore, GET API requests automatically have the <literal>?preference=_primary</literal> flag
set if there is no preference flag already set.</simpara></note>
<simpara>In order to ensure the data is being synchronized in a fast enough manner, you
may need to tune the flush threshold for the index to a desired number. A flush
is needed to fsync segment files to disk, so they will be visible to all other
replica nodes. Users should test what flush threshold levels they are
comfortable with, as increased flushing can impact indexing performance.</simpara>
<simpara>The Elasticsearch cluster will still detect the loss of a primary shard, and
transform the replica into a primary in this situation. This transformation will
take slightly longer, since no <literal>IndexWriter</literal> is maintained for each shadow
replica.</simpara>
<simpara>Below is the list of settings that can be changed using the update
settings API:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>index.data_path</literal> (string)
</term>
<listitem>
<simpara>
    Path to use for the index&#8217;s data. Note that by default Elasticsearch will
    append the node ordinal by default to the path to ensure multiple instances
    of Elasticsearch on the same machine do not share a data directory.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>index.shadow_replicas</literal>
</term>
<listitem>
<simpara>
    Boolean value indicating this index should use shadow replicas. Defaults to
    <literal>false</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>index.shared_filesystem</literal>
</term>
<listitem>
<simpara>
    Boolean value indicating this index uses a shared filesystem. Defaults to
    the <literal>true</literal> if <literal>index.shadow_replicas</literal> is set to true, <literal>false</literal> otherwise.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>index.shared_filesystem.recover_on_any_node</literal>
</term>
<listitem>
<simpara>
    Boolean value indicating whether the primary shards for the index should be
    allowed to recover on any node in the cluster. If a node holding a copy of
    the shard is found, recovery prefers that node. Defaults to <literal>false</literal>.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<section id="_node_level_settings_related_to_shadow_replicas">
<title>Node level settings related to shadow replicas<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/shadow-replicas.asciidoc">Edit me</ulink></title>
<simpara>These are non-dynamic settings that need to be configured in <literal>elasticsearch.yml</literal></simpara>
<variablelist>
<varlistentry>
<term>
<literal>node.add_lock_id_to_custom_path</literal>
</term>
<listitem>
<simpara>
    Boolean setting indicating whether Elasticsearch should append the node&#8217;s
    ordinal to the custom data path. For example, if this is enabled and a path
    of "/tmp/foo" is used, the first locally-running node will use "/tmp/foo/0",
    the second will use "/tmp/foo/1", the third "/tmp/foo/2", etc. Defaults to
    <literal>true</literal>.
</simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
</chapter>
<chapter id="indices-stats">
<title>Indices Stats<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/stats.asciidoc">Edit me</ulink></title>
<simpara>Indices level stats provide statistics on different operations happening
on an index. The API provides statistics on the index level scope
(though most stats can also be retrieved using node level scope).</simpara>
<simpara>The following returns high level aggregation and index level stats for
all indices:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_stats</programlisting>
<remark> CONSOLE</remark>
<simpara>Specific index stats can be retrieved using:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /index1,index2/_stats</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT index1\nPUT index2\n/]</remark>
<simpara>By default, all stats are returned, returning only specific stats can be
specified as well in the URI. Those stats can be any of:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>docs</literal>
</simpara>
</entry>
<entry>
<simpara>
The number of docs / deleted docs (docs not yet merged out).
                                Note, affected by refreshing the index.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>store</literal>
</simpara>
</entry>
<entry>
<simpara>
The size of the index.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>indexing</literal>
</simpara>
</entry>
<entry>
<simpara>
Indexing statistics, can be combined with a comma
                                separated list of <literal>types</literal> to provide document type level stats.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>get</literal>
</simpara>
</entry>
<entry>
<simpara>
Get statistics, including missing stats.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>search</literal>
</simpara>
</entry>
<entry>
<simpara>
Search statistics including suggest statistics.
                You can include statistics for custom groups by adding
                an extra <literal>groups</literal> parameter (search operations can be associated with one or more
                groups). The <literal>groups</literal> parameter accepts a comma separated list of group names.
                Use <literal>_all</literal> to return statistics for all groups.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>segments</literal>
</simpara>
</entry>
<entry>
<simpara>
Retrieve the memory use of the open segments. Optionally, setting the <literal>include_segment_file_sizes</literal> flag, report the aggregated disk usage of each one of the Lucene index files.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>completion</literal>
</simpara>
</entry>
<entry>
<simpara>
Completion suggest statistics.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>fielddata</literal>
</simpara>
</entry>
<entry>
<simpara>
Fielddata statistics.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>flush</literal>
</simpara>
</entry>
<entry>
<simpara>
Flush statistics.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>merge</literal>
</simpara>
</entry>
<entry>
<simpara>
Merge statistics.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>request_cache</literal>
</simpara>
</entry>
<entry>
<simpara>
<link linkend="shard-request-cache">Shard request cache</link> statistics.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>refresh</literal>
</simpara>
</entry>
<entry>
<simpara>
Refresh statistics.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>warmer</literal>
</simpara>
</entry>
<entry>
<simpara>
Warmer statistics.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>translog</literal>
</simpara>
</entry>
<entry>
<simpara>
Translog statistics.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>Some statistics allow per field granularity which accepts a list
comma-separated list of included fields. By default all fields are included:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>fields</literal>
</simpara>
</entry>
<entry>
<simpara>
    List of fields to be included in the statistics. This is used as the
    default list unless a more specific field list is provided (see below).
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>completion_fields</literal>
</simpara>
</entry>
<entry>
<simpara>
    List of fields to be included in the Completion Suggest statistics.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>fielddata_fields</literal>
</simpara>
</entry>
<entry>
<simpara>
    List of fields to be included in the Fielddata statistics.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>Here are some samples:</simpara>
<programlisting language="js" linenumbering="unnumbered"># Get back stats for merge and refresh only for all indices
GET /_stats/merge,refresh
# Get back stats for type1 and type2 documents for the my_index index
GET /my_index/_stats/indexing?types=type1,type2
# Get back just search stats for group1 and group2
GET /_stats/search?groups=group1,group2</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT my_index\n/]</remark>
<simpara>The stats returned are aggregated on the index level, with
<literal>primaries</literal> and <literal>total</literal> aggregations, where <literal>primaries</literal> are the values for only the
primary shards, and <literal>total</literal> are the cumulated values for both primary and replica shards.</simpara>
<simpara>In order to get back shard level stats, set the <literal>level</literal> parameter to <literal>shards</literal>.</simpara>
<simpara>Note, as shards move around the cluster, their stats will be cleared as
they are created on other nodes. On the other hand, even though a shard
"left" a node, that node will still retain the stats that shard
contributed to.</simpara>
</chapter>
<chapter id="indices-segments">
<title>Indices Segments<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/segments.asciidoc">Edit me</ulink></title>
<simpara>Provide low level segments information that a Lucene index (shard level)
is built with. Allows to be used to provide more information on the
state of a shard and an index, possibly optimization information, data
"wasted" on deletes, and so on.</simpara>
<simpara>Endpoints include segments for a specific index, several indices, or
all:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET 'http://localhost:9200/test/_segments'
curl -XGET 'http://localhost:9200/test1,test2/_segments'
curl -XGET 'http://localhost:9200/_segments'</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...
        "_3": {
            "generation": 3,
            "num_docs": 1121,
            "deleted_docs": 53,
            "size_in_bytes": 228288,
            "memory_in_bytes": 3211,
            "committed": true,
            "search": true,
            "version": "4.6",
            "compound": true
        }
    ...
}</programlisting>
<variablelist>
<varlistentry>
<term>
_0
</term>
<listitem>
<simpara>
The key of the JSON document is the name of the segment. This name
             is used to generate file names: all files starting with this
             segment name in the directory of the shard belong to this segment.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
generation
</term>
<listitem>
<simpara>
A generation number that is basically incremented when needing to
             write a new segment. The segment name is derived from this
             generation number.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
num_docs
</term>
<listitem>
<simpara>
The number of non-deleted documents that are stored in this segment.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
deleted_docs
</term>
<listitem>
<simpara>
The number of deleted documents that are stored in this segment.
             It is perfectly fine if this number is greater than 0, space is
             going to be reclaimed when this segment gets merged.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
size_in_bytes
</term>
<listitem>
<simpara>
The amount of disk space that this segment uses, in bytes.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
memory_in_bytes
</term>
<listitem>
<simpara>
Segments need to store some data into memory in order to be
             searchable efficiently. This number returns the number of bytes
             that are used for that purpose. A value of -1 indicates that
             Elasticsearch was not able to compute this number.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
committed
</term>
<listitem>
<simpara>
Whether the segment has been sync&#8217;ed on disk. Segments that are
             committed would survive a hard reboot. No need to worry in case
             of false, the data from uncommitted segments is also stored in
             the transaction log so that Elasticsearch is able to replay
             changes on the next start.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
search
</term>
<listitem>
<simpara>
Whether the segment is searchable. A value of false would most
             likely mean that the segment has been written to disk but no
             refresh occurred since then to make it searchable.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
version
</term>
<listitem>
<simpara>
The version of Lucene that has been used to write this segment.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
compound
</term>
<listitem>
<simpara>
Whether the segment is stored in a compound file. When true, this
             means that Lucene merged all files from the segment in a single
             one in order to save file descriptors.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_verbose_mode" renderas="sect2">Verbose mode<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/segments.asciidoc">Edit me</ulink></bridgehead>
<simpara>To add additional information that can be used for debugging, use the <literal>verbose</literal> flag.</simpara>
<warning role="experimental"><simpara>The format of the additional verbose information is experimental and can change at any time.</simpara></warning>
<programlisting language="js" linenumbering="unnumbered">curl -XGET 'http://localhost:9200/test/_segments?verbose=true'</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...
        "_3": {
            ...
            "ram_tree": [
                {
                    "description": "postings [PerFieldPostings(format=1)]",
                    "size_in_bytes": 2696,
                    "children": [
                        {
                            "description": "format 'Lucene50_0' ...",
                            "size_in_bytes": 2608,
                            "children" :[ ... ]
                        },
                        ...
                    ]
                },
                ...
                ]

        }
    ...
}</programlisting>
</chapter>
<chapter id="indices-recovery">
<title>Indices Recovery<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/recovery.asciidoc">Edit me</ulink></title>
<simpara>The indices recovery API provides insight into on-going index shard recoveries.
Recovery status may be reported for specific indices, or cluster-wide.</simpara>
<simpara>For example, the following command would show recovery information for the indices "index1" and "index2".</simpara>
<programlisting language="js" linenumbering="unnumbered">GET index1,index2/_recovery?human</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT index1\nPUT index2\n/]</remark>
<simpara>To see cluster-wide recovery status simply leave out the index names.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_recovery?human</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT index1\n{"settings": {"index.number_of_shards": 1}}\n/]</remark>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "index1" : {
    "shards" : [ {
      "id" : 0,
      "type" : "SNAPSHOT",
      "stage" : "INDEX",
      "primary" : true,
      "start_time" : "2014-02-24T12:15:59.716",
      "start_time_in_millis": 1393244159716,
      "total_time" : "2.9m",
      "total_time_in_millis" : 175576,
      "source" : {
        "repository" : "my_repository",
        "snapshot" : "my_snapshot",
        "index" : "index1"
      },
      "target" : {
        "id" : "ryqJ5lO5S4-lSFbGntkEkg",
        "hostname" : "my.fqdn",
        "ip" : "10.0.1.7",
        "name" : "my_es_node"
      },
      "index" : {
        "size" : {
          "total" : "75.4mb",
          "total_in_bytes" : 79063092,
          "reused" : "0b",
          "reused_in_bytes" : 0,
          "recovered" : "65.7mb",
          "recovered_in_bytes" : 68891939,
          "percent" : "87.1%"
        },
        "files" : {
          "total" : 73,
          "reused" : 0,
          "recovered" : 69,
          "percent" : "94.5%"
        },
        "total_time" : "0s",
        "total_time_in_millis" : 0
      },
      "translog" : {
        "recovered" : 0,
        "total" : 0,
        "percent" : "100.0%",
        "total_on_start" : 0,
        "total_time" : "0s",
        "total_time_in_millis" : 0,
      },
      "start" : {
        "check_index_time" : "0s",
        "check_index_time_in_millis" : 0,
        "total_time" : "0s",
        "total_time_in_millis" : 0
      }
    } ]
  }
}</programlisting>
<remark> We should really assert that this is up to date but that is hard!</remark>
<simpara>The above response shows a single index recovering a single shard. In this case, the source of the recovery is a snapshot repository
and the target of the recovery is the node with name "my_es_node".</simpara>
<simpara>Additionally, the output shows the number and percent of files recovered, as well as the number and percent of bytes recovered.</simpara>
<simpara>In some cases a higher level of detail may be preferable. Setting "detailed=true" will present a list of physical files in recovery.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _recovery?human&amp;detailed=true</programlisting>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "index1" : {
    "shards" : [ {
      "id" : 0,
      "type" : "STORE",
      "stage" : "DONE",
      "primary" : true,
      "start_time" : "2014-02-24T12:38:06.349",
      "start_time_in_millis" : "1393245486349",
      "stop_time" : "2014-02-24T12:38:08.464",
      "stop_time_in_millis" : "1393245488464",
      "total_time" : "2.1s",
      "total_time_in_millis" : 2115,
      "source" : {
        "id" : "RGMdRc-yQWWKIBM4DGvwqQ",
        "hostname" : "my.fqdn",
        "ip" : "10.0.1.7",
        "name" : "my_es_node"
      },
      "target" : {
        "id" : "RGMdRc-yQWWKIBM4DGvwqQ",
        "hostname" : "my.fqdn",
        "ip" : "10.0.1.7",
        "name" : "my_es_node"
      },
      "index" : {
        "size" : {
          "total" : "24.7mb",
          "total_in_bytes" : 26001617,
          "reused" : "24.7mb",
          "reused_in_bytes" : 26001617,
          "recovered" : "0b",
          "recovered_in_bytes" : 0,
          "percent" : "100.0%"
        },
        "files" : {
          "total" : 26,
          "reused" : 26,
          "recovered" : 0,
          "percent" : "100.0%",
          "details" : [ {
            "name" : "segments.gen",
            "length" : 20,
            "recovered" : 20
          }, {
            "name" : "_0.cfs",
            "length" : 135306,
            "recovered" : 135306
          }, {
            "name" : "segments_2",
            "length" : 251,
            "recovered" : 251
          },
           ...
          ]
        },
        "total_time" : "2ms",
        "total_time_in_millis" : 2
      },
      "translog" : {
        "recovered" : 71,
        "total_time" : "2.0s",
        "total_time_in_millis" : 2025
      },
      "start" : {
        "check_index_time" : 0,
        "total_time" : "88ms",
        "total_time_in_millis" : 88
      }
    } ]
  }
}</programlisting>
<remark> We should really assert that this is up to date but that is hard!</remark>
<simpara>This response shows a detailed listing (truncated for brevity) of the actual files recovered and their sizes.</simpara>
<simpara>Also shown are the timings in milliseconds of the various stages of recovery: index retrieval, translog replay, and index start time.</simpara>
<simpara>Note that the above listing indicates that the recovery is in stage "done". All recoveries, whether on-going or complete, are kept in
cluster state and may be reported on at any time. Setting "active_only=true" will cause only on-going recoveries to be reported.</simpara>
<simpara>Here is a complete list of options:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>detailed</literal>
</simpara>
</entry>
<entry>
<simpara>
Display a detailed view. This is primarily useful for viewing the recovery of physical index files. Default: false.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>active_only</literal>
</simpara>
</entry>
<entry>
<simpara>
Display only those recoveries that are currently on-going. Default: false.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>Description of output fields:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>id</literal>
</simpara>
</entry>
<entry>
<simpara>
Shard ID
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>type</literal>
</simpara>
</entry>
<entry>
<simpara>
Recovery type:
</simpara>
<itemizedlist>
<listitem>
<simpara>
store
</simpara>
</listitem>
<listitem>
<simpara>
snapshot
</simpara>
</listitem>
<listitem>
<simpara>
replica
</simpara>
</listitem>
<listitem>
<simpara>
relocating
</simpara>
</listitem>
</itemizedlist>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>stage</literal>
</simpara>
</entry>
<entry>
<simpara>
Recovery stage:
</simpara>
<itemizedlist>
<listitem>
<simpara>
init:     Recovery has not started
</simpara>
</listitem>
<listitem>
<simpara>
index:    Reading index meta-data and copying bytes from source to destination
</simpara>
</listitem>
<listitem>
<simpara>
start:    Starting the engine; opening the index for use
</simpara>
</listitem>
<listitem>
<simpara>
translog: Replaying transaction log
</simpara>
</listitem>
<listitem>
<simpara>
finalize: Cleanup
</simpara>
</listitem>
<listitem>
<simpara>
done:     Complete
</simpara>
</listitem>
</itemizedlist>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>primary</literal>
</simpara>
</entry>
<entry>
<simpara>
True if shard is primary, false otherwise
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>start_time</literal>
</simpara>
</entry>
<entry>
<simpara>
Timestamp of recovery start
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>stop_time</literal>
</simpara>
</entry>
<entry>
<simpara>
Timestamp of recovery finish
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>total_time_in_millis</literal>
</simpara>
</entry>
<entry>
<simpara>
Total time to recover shard in milliseconds
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>source</literal>
</simpara>
</entry>
<entry>
<simpara>
Recovery source:
</simpara>
<itemizedlist>
<listitem>
<simpara>
repository description if recovery is from a snapshot
</simpara>
</listitem>
<listitem>
<simpara>
description of source node otherwise
</simpara>
</listitem>
</itemizedlist>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>target</literal>
</simpara>
</entry>
<entry>
<simpara>
Destination node
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>index</literal>
</simpara>
</entry>
<entry>
<simpara>
Statistics about physical index recovery
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>translog</literal>
</simpara>
</entry>
<entry>
<simpara>
Statistics about translog recovery
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>start</literal>
</simpara>
</entry>
<entry>
<simpara>
Statistics about time to open and start the index
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</chapter>
<chapter id="indices-shards-stores">
<title>Indices Shard Stores<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/shard-stores.asciidoc">Edit me</ulink></title>
<simpara>Provides store information for shard copies of indices.
Store information reports on which nodes shard copies exist, the shard
copy allocation ID, a unique identifier for each shard copy, and any exceptions
encountered while opening the shard index or from earlier engine failure.</simpara>
<simpara>By default, only lists store information for shards that have at least one
unallocated copy. When the cluster health status is yellow, this will list
store information for shards that have at least one unassigned replica.
When the cluster health status is red, this will list store information
for shards, which has unassigned primaries.</simpara>
<simpara>Endpoints include shard stores information for a specific index, several
indices, or all:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET 'http://localhost:9200/test/_shard_stores'
curl -XGET 'http://localhost:9200/test1,test2/_shard_stores'
curl -XGET 'http://localhost:9200/_shard_stores'</programlisting>
<simpara>The scope of shards to list store information can be changed through
<literal>status</literal> param. Defaults to <emphasis>yellow</emphasis> and <emphasis>red</emphasis>. <emphasis>yellow</emphasis> lists store information of
shards with at least one unassigned replica and <emphasis>red</emphasis> for shards with unassigned
primary shard.
Use <emphasis>green</emphasis> to list store information for shards with all assigned copies.</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET 'http://localhost:9200/_shard_stores?status=green'</programlisting>
<simpara>Response:</simpara>
<simpara>The shard stores information is grouped by indices and shard ids.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    ...
   "0": { <co id="CO128-1"/>
        "stores": [ <co id="CO128-2"/>
            {
                "sPa3OgxLSYGvQ4oPs-Tajw": { <co id="CO128-3"/>
                    "name": "node_t0",
                    "transport_address": "local[1]",
                    "attributes": {
                        "mode": "local"
                    }
                },
                "allocation_id": "2iNySv_OQVePRX-yaRH_lQ", <co id="CO128-4"/>
                "legacy_version": 42, <co id="CO128-5"/>
                "allocation" : "primary" | "replica" | "unused", <co id="CO128-6"/>
                "store_exception": ... <co id="CO128-7"/>
            },
            ...
        ]
   },
    ...
}</programlisting>
<calloutlist>
<callout arearefs="CO128-1">
<para>
The key is the corresponding shard id for the store information
</para>
</callout>
<callout arearefs="CO128-2">
<para>
A list of store information for all copies of the shard
</para>
</callout>
<callout arearefs="CO128-3">
<para>
The node information that hosts a copy of the store, the key
    is the unique node id.
</para>
</callout>
<callout arearefs="CO128-4">
<para>
The allocation id of the store copy
</para>
</callout>
<callout arearefs="CO128-5">
<para>
The version of the store copy (available only for legacy shard copies that have
    not yet been active in a current version of Elasticsearch)
</para>
</callout>
<callout arearefs="CO128-6">
<para>
The status of the store copy, whether it is used as a
    primary, replica or not used at all
</para>
</callout>
<callout arearefs="CO128-7">
<para>
Any exception encountered while opening the shard index or
    from earlier engine failure
</para>
</callout>
</calloutlist>
</chapter>
<chapter id="indices-clearcache">
<title>Clear Cache<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/clearcache.asciidoc">Edit me</ulink></title>
<simpara>The clear cache API allows to clear either all caches or specific cached
associated with one or more indices.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /twitter/_cache/clear</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>The API, by default, will clear all caches. Specific caches can be cleaned
explicitly by setting <literal>query</literal>, <literal>fielddata</literal> or <literal>request</literal>.</simpara>
<simpara>All caches relating to a specific field(s) can also be cleared by
specifying <literal>fields</literal> parameter with a comma delimited list of the
relevant fields.</simpara>
<bridgehead id="_multi_index_2" renderas="sect2">Multi Index<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/clearcache.asciidoc">Edit me</ulink></bridgehead>
<simpara>The clear cache API can be applied to more than one index with a single
call, or even on <literal>_all</literal> the indices.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /kimchy,elasticsearch/_cache/clear

POST /_cache/clear</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT kimchy\nPUT elasticsearch\n/]</remark>
</chapter>
<chapter id="indices-flush">
<title>Flush<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/flush.asciidoc">Edit me</ulink></title>
<simpara>The flush API allows to flush one or more indices through an API. The
flush process of an index basically frees memory from the index by
flushing data to the index storage and clearing the internal
<link linkend="index-modules-translog">transaction log</link>. By
default, Elasticsearch uses memory heuristics in order to automatically
trigger flush operations as required in order to clear memory.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST twitter/_flush</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<bridgehead id="flush-parameters" renderas="sect2">Request Parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/flush.asciidoc">Edit me</ulink></bridgehead>
<simpara>The flush API accepts the following request parameters:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>wait_if_ongoing</literal>
</simpara>
</entry>
<entry>
<simpara>
If set to <literal>true</literal> the flush operation will block until the
flush can be executed if another flush operation is already executing.
The default is <literal>false</literal> and will cause an exception to be thrown on
the shard level if another flush operation is already running.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>force</literal>
</simpara>
</entry>
<entry>
<simpara>
Whether a flush should be forced even if it is not necessarily needed ie.
if no changes will be committed to the index. This is useful if transaction log IDs
should be incremented even if no uncommitted changes are present.
(This setting can be considered as internal)
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="flush-multi-index" renderas="sect2">Multi Index<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/flush.asciidoc">Edit me</ulink></bridgehead>
<simpara>The flush API can be applied to more than one index with a single call,
or even on <literal>_all</literal> the indices.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST kimchy,elasticsearch/_flush

POST _flush</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT kimchy\nPUT elasticsearch\n/]</remark>
<section id="indices-synced-flush">
<title>Synced Flush<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/flush.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch tracks the indexing activity of each shard. Shards that have not
received any indexing operations for 5 minutes are automatically marked as inactive. This presents
an opportunity for Elasticsearch to reduce shard resources and also perform
a special kind of flush, called <literal>synced flush</literal>. A synced flush performs a normal flush, then adds
a generated unique marker (sync_id) to all shards.</simpara>
<simpara>Since the sync id marker was added when there were no ongoing indexing operations, it can
be used as a quick way to check if the two shards' lucene indices are identical. This quick sync id
comparison (if present) is used during recovery or restarts to skip the first and
most costly phase of the process. In that case, no segment files need to be copied and
the transaction log replay phase of the recovery can start immediately. Note that since the sync id
marker was applied together with a flush, it is very likely that the transaction log will be empty,
speeding up recoveries even more.</simpara>
<simpara>This is particularly useful for use cases having lots of indices which are
never or very rarely updated, such as time based data. This use case typically generates lots of indices whose
recovery without the synced flush marker would take a long time.</simpara>
<simpara>To check whether a shard has a marker or not, look for the <literal>commit</literal> section of shard stats returned by
the <link linkend="indices-stats">indices stats</link> API:</simpara>
<programlisting language="sh" linenumbering="unnumbered">GET twitter/_stats?level=shards</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT twitter\n/]</remark>
<simpara>which returns something similar to:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   ...
   "indices": {
      "twitter": {
         "primaries": {},
         "total": {},
         "shards": {
            "0": [
               {
                  "routing": {
                     ...
                  },
                  "commit": {
                     "id": "te7zF7C4UsirqvL6jp/vUg==",
                     "generation": 2,
                     "user_data": {
                        "sync_id": "AU2VU0meX-VX2aNbEUsD" <co id="CO129-1"/>,
                        ...
                     },
                     "num_docs": 0
                  }
               }
               ...
            ],
            ...
         }
      }
   }
}</programlisting>
<calloutlist>
<callout arearefs="CO129-1">
<para>
the <literal>sync id</literal> marker
</para>
</callout>
</calloutlist>
<bridgehead id="_synced_flush_api" renderas="sect2">Synced Flush API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/flush.asciidoc">Edit me</ulink></bridgehead>
<simpara>The Synced Flush API allows an administrator to initiate a synced flush manually. This can be particularly useful for
a planned (rolling) cluster restart where you can stop indexing and don&#8217;t want to wait the default 5 minutes for
idle indices to be sync-flushed automatically.</simpara>
<simpara>While handy, there are a couple of caveats for this API:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>
Synced flush is a best effort operation. Any ongoing indexing operations will cause
the synced flush to fail on that shard. This means that some shards may be synced flushed while others aren&#8217;t. See below for more.
</simpara>
</listitem>
<listitem>
<simpara>
The <literal>sync_id</literal> marker is removed as soon as the shard is flushed again. That is because a flush replaces the low level
lucene commit point where the marker is stored. Uncommitted operations in the transaction log do not remove the marker.
In practice, one should consider any indexing operation on an index as removing the marker as a flush can be triggered by Elasticsearch
at any time.
</simpara>
</listitem>
</orderedlist>
<note><simpara>It is harmless to request a synced flush while there is ongoing indexing. Shards that are idle will succeed and shards
 that are not will fail. Any shards that succeeded will have faster recovery times.</simpara></note>
<programlisting language="sh" linenumbering="unnumbered">POST twitter/_flush/synced</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<simpara>The response contains details about how many shards were successfully sync-flushed and information about any failure.</simpara>
<simpara>Here is what it looks like when all shards of a two shards and one replica index successfully
sync-flushed:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "_shards": {
      "total": 2,
      "successful": 2,
      "failed": 0
   },
   "twitter": {
      "total": 2,
      "successful": 2,
      "failed": 0
   }
}</programlisting>
<remark> TESTRESPONSE[s/"successful": 2/"successful": 1/]</remark>
<simpara>Here is what it looks like when one shard group failed due to pending operations:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "_shards": {
      "total": 4,
      "successful": 2,
      "failed": 2
   },
   "twitter": {
      "total": 4,
      "successful": 2,
      "failed": 2,
      "failures": [
         {
            "shard": 1,
            "reason": "[2] ongoing operations on primary"
         }
      ]
   }
}</programlisting>
<note><simpara>The above error is shown when the synced flush fails due to concurrent indexing operations. The HTTP
status code in that case will be <literal>409 CONFLICT</literal>.</simpara></note>
<simpara>Sometimes the failures are specific to a shard copy. The copies that failed will not be eligible for
fast recovery but those that succeeded still will be. This case is reported as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "_shards": {
      "total": 4,
      "successful": 1,
      "failed": 1
   },
   "twitter": {
      "total": 4,
      "successful": 3,
      "failed": 1,
      "failures": [
         {
            "shard": 1,
            "reason": "unexpected error",
            "routing": {
               "state": "STARTED",
               "primary": false,
               "node": "SZNr2J_ORxKTLUCydGX4zA",
               "relocating_node": null,
               "shard": 1,
               "index": "twitter"
            }
         }
      ]
   }
}</programlisting>
<note><simpara>When a shard copy fails to sync-flush, the HTTP status code returned will be <literal>409 CONFLICT</literal>.</simpara></note>
<simpara>The synced flush API can be applied to more than one index with a single call,
or even on <literal>_all</literal> the indices.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST kimchy,elasticsearch/_flush/synced

POST _flush/synced</programlisting>
<remark> CONSOLE</remark>
</section>
</chapter>
<chapter id="indices-refresh">
<title>Refresh<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/refresh.asciidoc">Edit me</ulink></title>
<simpara>The refresh API allows to explicitly refresh one or more index, making
all operations performed since the last refresh available for search.
The (near) real-time capabilities depend on the index engine used. For
example, the internal one requires refresh to be called, but by default a
refresh is scheduled periodically.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /twitter/_refresh</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<bridgehead id="_multi_index_3" renderas="sect2">Multi Index<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/refresh.asciidoc">Edit me</ulink></bridgehead>
<simpara>The refresh API can be applied to more than one index with a single
call, or even on <literal>_all</literal> the indices.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /kimchy,elasticsearch/_refresh

POST /_refresh</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT kimchy\nPUT elasticsearch\n/]</remark>
</chapter>
<chapter id="indices-forcemerge">
<title>Force Merge<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/forcemerge.asciidoc">Edit me</ulink></title>
<simpara>The force merge API allows to force merging of one or more indices through an
API. The merge relates to the number of segments a Lucene index holds within
each shard. The force merge operation allows to reduce the number of segments by
merging them.</simpara>
<simpara>This call will block until the merge is complete. If the http connection is
lost, the request will continue in the background, and any new requests will
block until the previous force merge is complete.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /twitter/_forcemerge</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
<bridgehead id="forcemerge-parameters" renderas="sect2">Request Parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/forcemerge.asciidoc">Edit me</ulink></bridgehead>
<simpara>The force merge API accepts the following request parameters:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>max_num_segments</literal>
</simpara>
</entry>
<entry>
<simpara>
The number of segments to merge to. To fully
merge the index, set it to <literal>1</literal>. Defaults to simply checking if a
merge needs to execute, and if so, executes it.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>only_expunge_deletes</literal>
</simpara>
</entry>
<entry>
<simpara>
Should the merge process only expunge segments with
deletes in it. In Lucene, a document is not deleted from a segment, just marked
as deleted. During a merge process of segments, a new segment is created that
does not have those deletes. This flag allows to only merge segments that have
deletes. Defaults to <literal>false</literal>.  Note that this won&#8217;t override the
<literal>index.merge.policy.expunge_deletes_allowed</literal> threshold.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>flush</literal>
</simpara>
</entry>
<entry>
<simpara>
Should a flush be performed after the forced merge. Defaults to
<literal>true</literal>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="forcemerge-multi-index" renderas="sect2">Multi Index<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/indices/forcemerge.asciidoc">Edit me</ulink></bridgehead>
<simpara>The force merge API can be applied to more than one index with a single call, or
even on <literal>_all</literal> the indices.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /kimchy,elasticsearch/_forcemerge

POST /_forcemerge</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT kimchy\nPUT elasticsearch\n/]</remark>
</chapter>
</part>
<part id="cat">
<title>cat APIs <ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat.asciidoc">Edit me</ulink></title>
<partintro>
<bridgehead id="intro" renderas="sect1">Introduction<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat.asciidoc">Edit me</ulink></bridgehead>
<simpara>JSON is great&#8230; for computers.  Even if it&#8217;s pretty-printed, trying
to find relationships in the data is tedious.  Human eyes, especially
when looking at an ssh terminal, need compact and aligned text.  The
cat API aims to meet this need.</simpara>
<simpara>All the cat commands accept a query string parameter <literal>help</literal> to see all
the headers and info they provide, and the <literal>/_cat</literal> command alone lists all
the available commands.</simpara>
<bridgehead id="common-parameters" renderas="sect1">Common parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat.asciidoc">Edit me</ulink></bridgehead>
<bridgehead id="verbose" renderas="sect2">Verbose<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat.asciidoc">Edit me</ulink></bridgehead>
<simpara>Each of the commands accepts a query string parameter <literal>v</literal> to turn on
verbose output. For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/master?v</programlisting>
<remark> CONSOLE</remark>
<simpara>Might respond with:</simpara>
<programlisting language="js" linenumbering="unnumbered">id                     host      ip        node
u_n93zwxThWHi1PDBJAGAg 127.0.0.1 127.0.0.1 u_n93zw</programlisting>
<remark> TESTRESPONSE[s/u_n93zw(xThWHi1PDBJAGAg)?/.+/ _cat]</remark>
<bridgehead id="help" renderas="sect2">Help<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat.asciidoc">Edit me</ulink></bridgehead>
<simpara>Each of the commands accepts a query string parameter <literal>help</literal> which will
output its available columns. For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/master?help</programlisting>
<remark> CONSOLE</remark>
<simpara>Might respond respond with:</simpara>
<programlisting language="js" linenumbering="unnumbered">id   |   | node id
host | h | host name
ip   |   | ip address
node | n | node name</programlisting>
<remark> TESTRESPONSE[s/[|]/[|]/ _cat]</remark>
<bridgehead id="headers" renderas="sect2">Headers<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat.asciidoc">Edit me</ulink></bridgehead>
<simpara>Each of the commands accepts a query string parameter <literal>h</literal> which forces
only those columns to appear. For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/nodes?h=ip,port,heapPercent,name</programlisting>
<remark> CONSOLE</remark>
<simpara>Responds with:</simpara>
<programlisting language="js" linenumbering="unnumbered">127.0.0.1 9300 27 sLBaIGK</programlisting>
<remark> TESTRESPONSE[s/9300 27 sLBaIGK/\\d+ \\d+ .+/ _cat]</remark>
<simpara>You can also request multiple columns using simple wildcards like
<literal>/_cat/thread_pool?h=ip,bulk.*</literal> to get all headers (or aliases) starting
with <literal>bulk.</literal>.</simpara>
<bridgehead id="numeric-formats" renderas="sect2">Numeric formats<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat.asciidoc">Edit me</ulink></bridgehead>
<simpara>Many commands provide a few types of numeric output, either a byte, size
or a time value.  By default, these types are human-formatted,
for example, <literal>3.5mb</literal> instead of <literal>3763212</literal>.  The human values are not
sortable numerically, so in order to operate on these values where
order is important, you can change it.</simpara>
<simpara>Say you want to find the largest index in your cluster (storage used
by all the shards, not number of documents).  The <literal>/_cat/indices</literal> API
is ideal.  We only need to tweak two things.  First, we want to turn
off human mode.  We&#8217;ll use a byte-level resolution.  Then we&#8217;ll pipe
our output into <literal>sort</literal> using the appropriate column, which in this
case is the eight one.</simpara>
<programlisting language="sh" linenumbering="unnumbered">% curl '192.168.56.10:9200/_cat/indices?bytes=b' | sort -rnk8
green wiki2 3 0 10000   0 105274918 105274918
green wiki1 3 0 10000 413 103776272 103776272
green foo   1 0   227   0   2065131   2065131</programlisting>
<remark> NOTCONSOLE</remark>
<simpara>If you want to change the <link linkend="time-units">time units</link>, use <literal>time</literal> parameter.</simpara>
<simpara>If you want to change the <link linkend="size-units">size units</link>, use <literal>size</literal> parameter.</simpara>
<simpara>If you want to change the <link linkend="byte-units">byte units</link>, use <literal>bytes</literal> parameter.</simpara>
<bridgehead id="_response_as_text_json_smile_yaml_or_cbor" renderas="sect2">Response as text, json, smile, yaml or cbor<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="sh" linenumbering="unnumbered">% curl 'localhost:9200/_cat/indices?format=json&amp;pretty'
[
  {
    "pri.store.size": "650b",
    "health": "yellow",
    "status": "open",
    "index": "twitter",
    "pri": "5",
    "rep": "1",
    "docs.count": "0",
    "docs.deleted": "0",
    "store.size": "650b"
  }
]</programlisting>
<remark> NOTCONSOLE</remark>
<simpara>Currently supported formats (for the <literal>?format=</literal> parameter):
- text (default)
- json
- smile
- yaml
- cbor</simpara>
<simpara>Alternatively you can set the "Accept" HTTP header to the appropriate media format.
All formats above are supported, the GET parameter takes precedence over the header.
For example:</simpara>
<programlisting language="sh" linenumbering="unnumbered">% curl '192.168.56.10:9200/_cat/indices?pretty' -H "Accept: application/json"
[
  {
    "pri.store.size": "650b",
    "health": "yellow",
    "status": "open",
    "index": "twitter",
    "pri": "5",
    "rep": "1",
    "docs.count": "0",
    "docs.deleted": "0",
    "store.size": "650b"
  }
]</programlisting>
<remark> NOTCONSOLE</remark>
<bridgehead id="sort" renderas="sect2">Sort<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat.asciidoc">Edit me</ulink></bridgehead>
<simpara>Each of the commands accepts a query string parameter <literal>s</literal> which sorts the table by
the columns specified as the parameter value. Columns are specified either by name or by
alias, and are provided as a comma separated string. By default, sorting is done in
ascending fashion. Appending <literal>:desc</literal> to a column will invert the ordering for
that column. <literal>:asc</literal> is also accepted but exhibits the same behavior as the default sort order.</simpara>
<simpara>For example, with a sort string <literal>s=column1,column2:desc,column3</literal>, the table will be
sorted in ascending order by column1, in descending order by column2, and in ascending
order by column3.</simpara>
<programlisting language="sh" linenumbering="unnumbered">GET _cat/templates?v&amp;s=order:desc,template</programlisting>
<remark>CONSOLE</remark>
<simpara>returns:</simpara>
<programlisting language="sh" linenumbering="unnumbered">name                  template     order version
pizza_pepperoni       *pepperoni*  2
sushi_california_roll *avocado*    1     1
pizza_hawaiian        *pineapples* 1</programlisting>
</partintro>
<chapter id="cat-alias">
<title>cat aliases<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/alias.asciidoc">Edit me</ulink></title>
<simpara><literal>aliases</literal> shows information about currently configured aliases to indices
including filter and routing infos.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/aliases?v</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Might respond with:</simpara>
<programlisting language="txt" linenumbering="unnumbered">alias  index filter routing.index routing.search
alias1 test1 -      -            -
alias2 test1 *      -            -
alias3 test1 -      1            1
alias4 test1 -      2            1,2</programlisting>
<remark> TESTRESPONSE[s/[*]/[*]/ _cat]</remark>
<simpara>The output shows that <literal>alias</literal> has configured a filter, and specific routing
configurations in <literal>alias3</literal> and <literal>alias4</literal>.</simpara>
<simpara>If you only want to get information about a single alias, you can specify
the alias in the URL, for example <literal>/_cat/aliases/alias1</literal>.</simpara>
</chapter>
<chapter id="cat-allocation">
<title>cat allocation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/allocation.asciidoc">Edit me</ulink></title>
<simpara><literal>allocation</literal> provides a snapshot of how many shards are allocated to each data node
and how much disk space they are using.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/allocation?v</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT test\n{"settings": {"number_of_replicas": 0}}\n/]</remark>
<simpara>Might respond with:</simpara>
<programlisting language="txt" linenumbering="unnumbered">shards disk.indices disk.used disk.avail disk.total disk.percent host      ip        node
     5         260b    47.3gb     43.4gb    100.7gb           46 127.0.0.1 127.0.0.1 CSUXak2</programlisting>
<remark> TESTRESPONSE[s/260b/\\d+b/ s/\d+(\.\d+)?[tgmk]?b/\\d+(\\.\\d+)?[tgmk]?b/ s/46/\\d+/]</remark>
<remark> TESTRESPONSE[s/CSUXak2/.+/ _cat]</remark>
<simpara>Here we can see that each node has been allocated a single shard and
that they&#8217;re all using about the same amount of space.</simpara>
</chapter>
<chapter id="cat-count">
<title>cat count<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/count.asciidoc">Edit me</ulink></title>
<simpara><literal>count</literal> provides quick access to the document count of the entire
cluster, or individual indices.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/count?v</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:big_twitter]</remark>
<remark> TEST[s/^/POST test\/test\?refresh\n{"test": "test"}\n/]</remark>
<simpara>Looks like:</simpara>
<programlisting language="txt" linenumbering="unnumbered">epoch      timestamp count
1475868259 15:24:19  121</programlisting>
<remark> TESTRESPONSE[s/1475868259 15:24:19/\\d+ \\d+:\\d+:\\d+/ _cat]</remark>
<simpara>Or for a single index:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/count/twitter?v</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<programlisting language="txt" linenumbering="unnumbered">epoch      timestamp count
1475868259 15:24:20  120</programlisting>
<remark> TESTRESPONSE[s/1475868259 15:24:20/\\d+ \\d+:\\d+:\\d+/ _cat]</remark>
<note><simpara>The document count indicates the number of live documents and does not include deleted documents which have not yet been cleaned up by the merge process.</simpara></note>
</chapter>
<chapter id="cat-fielddata">
<title>cat fielddata<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/fielddata.asciidoc">Edit me</ulink></title>
<simpara><literal>fielddata</literal> shows how much heap memory is currently being used by fielddata
on every data node in the cluster.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/fielddata?v</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Looks like:</simpara>
<programlisting language="txt" linenumbering="unnumbered">id                     host      ip        node    field   size
Nqk-6inXQq-OxUfOUI8jNQ 127.0.0.1 127.0.0.1 Nqk-6in body    544b
Nqk-6inXQq-OxUfOUI8jNQ 127.0.0.1 127.0.0.1 Nqk-6in soul    480b</programlisting>
<remark> TESTRESPONSE[s/544b|480b/\\d+(\\.\\d+)?[tgmk]?b/]</remark>
<remark> TESTRESPONSE[s/Nqk-6in[^ ]*/.+/ s/soul|body/\\w+/ _cat]</remark>
<simpara>Fields can be specified either as a query parameter, or in the URL path:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/fielddata?v&amp;fields=body</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Which looks like:</simpara>
<programlisting language="txt" linenumbering="unnumbered">id                     host      ip        node    field   size
Nqk-6inXQq-OxUfOUI8jNQ 127.0.0.1 127.0.0.1 Nqk-6in body    544b</programlisting>
<remark> TESTRESPONSE[s/544b|480b/\\d+(\\.\\d+)?[tgmk]?b/]</remark>
<remark> TESTRESPONSE[s/Nqk-6in[^ ]*/.+/ _cat]</remark>
<simpara>And it accepts a comma delimited list:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/fielddata/body,soul?v</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Which produces the same output as the first snippet:</simpara>
<programlisting language="txt" linenumbering="unnumbered">id                     host      ip        node    field   size
Nqk-6inXQq-OxUfOUI8jNQ 127.0.0.1 127.0.0.1 Nqk-6in body    544b
Nqk-6inXQq-OxUfOUI8jNQ 127.0.0.1 127.0.0.1 Nqk-6in soul    480b</programlisting>
<remark> TESTRESPONSE[s/544b|480b/\\d+(\\.\\d+)?[tgmk]?b/]</remark>
<remark> TESTRESPONSE[s/Nqk-6in[^ ]*/.+/ s/soul|body/\\w+/ _cat]</remark>
<simpara>The output shows the individual fielddata for the`body` and <literal>text</literal> fields, one row per field per node.</simpara>
</chapter>
<chapter id="cat-health">
<title>cat health<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/health.asciidoc">Edit me</ulink></title>
<simpara><literal>health</literal> is a terse, one-line representation of the same information
from <literal>/_cluster/health</literal>.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/health?v</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT twitter\n{"settings":{"number_of_replicas": 0}}\n/]</remark>
<programlisting language="txt" linenumbering="unnumbered">epoch      timestamp cluster       status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent
1475871424 16:17:04  elasticsearch green           1         1      5   5    0    0        0             0                  -                100.0%</programlisting>
<remark> TESTRESPONSE[s/1475871424 16:17:04/\\d+ \\d+:\\d+:\\d+/ s/elasticsearch/[^ ]+/ s/0                  -/\\d+ -/ _cat]</remark>
<simpara>It has one option <literal>ts</literal> to disable the timestamping:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/health?v&amp;ts=0</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT twitter\n{"settings":{"number_of_replicas": 0}}\n/]</remark>
<simpara>which looks like:</simpara>
<programlisting language="txt" linenumbering="unnumbered">cluster       status node.total node.data shards pri relo init unassign pending_tasks max_task_wait_time active_shards_percent
elasticsearch green           1         1      5   5    0    0        0             0                  -                100.0%</programlisting>
<remark> TESTRESPONSE[s/elasticsearch/[^ ]+/ s/0                  -/\\d+ -/ _cat]</remark>
<simpara>A common use of this command is to verify the health is consistent
across nodes:</simpara>
<programlisting language="sh" linenumbering="unnumbered">% pssh -i -h list.of.cluster.hosts curl -s localhost:9200/_cat/health
[1] 20:20:52 [SUCCESS] es3.vm
1384309218 18:20:18 foo green 3 3 3 3 0 0 0 0
[2] 20:20:52 [SUCCESS] es1.vm
1384309218 18:20:18 foo green 3 3 3 3 0 0 0 0
[3] 20:20:52 [SUCCESS] es2.vm
1384309218 18:20:18 foo green 3 3 3 3 0 0 0 0</programlisting>
<remark> NOTCONSOLE</remark>
<simpara>A less obvious use is to track recovery of a large cluster over
time. With enough shards, starting a cluster, or even recovering after
losing a node, can take time (depending on your network &amp; disk). A way
to track its progress is by using this command in a delayed loop:</simpara>
<programlisting language="sh" linenumbering="unnumbered">% while true; do curl localhost:9200/_cat/health; sleep 120; done
1384309446 18:24:06 foo red 3 3 20 20 0 0 1812 0
1384309566 18:26:06 foo yellow 3 3 950 916 0 12 870 0
1384309686 18:28:06 foo yellow 3 3 1328 916 0 12 492 0
1384309806 18:30:06 foo green 3 3 1832 916 4 0 0
^C</programlisting>
<remark> NOTCONSOLE</remark>
<simpara>In this scenario, we can tell that recovery took roughly four minutes.
If this were going on for hours, we would be able to watch the
<literal>UNASSIGNED</literal> shards drop precipitously.  If that number remained
static, we would have an idea that there is a problem.</simpara>
<bridgehead id="timestamp" renderas="sect2">Why the timestamp?<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/health.asciidoc">Edit me</ulink></bridgehead>
<simpara>You typically are using the <literal>health</literal> command when a cluster is
malfunctioning.  During this period, it&#8217;s extremely important to
correlate activities across log files, alerting systems, etc.</simpara>
<simpara>There are two outputs.  The <literal>HH:MM:SS</literal> output is simply for quick
human consumption.  The epoch time retains more information, including
date, and is machine sortable if your recovery spans days.</simpara>
</chapter>
<chapter id="cat-indices">
<title>cat indices<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/indices.asciidoc">Edit me</ulink></title>
<simpara>The <literal>indices</literal> command provides a cross-section of each index.  This
information <emphasis role="strong">spans nodes</emphasis>. For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/indices/twi*?v&amp;s=index</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:huge_twitter]</remark>
<remark> TEST[s/^/PUT twitter2\n{"settings": {"number_of_replicas": 0}}\n/]</remark>
<simpara>Might respond with:</simpara>
<programlisting language="txt" linenumbering="unnumbered">health status index    uuid                   pri rep docs.count docs.deleted store.size pri.store.size
yellow open   twitter  u8FNjxh8Rfy_awN11oDKYQ   1   1       1200            0     88.1kb         88.1kb
green  open   twitter2 nYFWZEO7TUiOjLQXBaYJpA   5   0          0            0       260b           260b</programlisting>
<remark> TESTRESPONSE[s/\d+(\.\d+)?[tgmk]?b/\\d+(\\.\\d+)?[tgmk]?b/]</remark>
<remark> TESTRESPONSE[s/u8FNjxh8Rfy_awN11oDKYQ|nYFWZEO7TUiOjLQXBaYJpA/.+/ _cat]</remark>
<simpara>We can tell quickly how many shards make up an index, the number of
docs at the Lucene level, including hidden docs (e.g., from nested types),
deleted docs, primary store size, and total store size (all shards including replicas).
All these exposed metrics come directly from Lucene APIs.</simpara>
<bridgehead id="pri-flag" renderas="sect2">Primaries<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/indices.asciidoc">Edit me</ulink></bridgehead>
<simpara>The index stats by default will show them for all of an index&#8217;s
shards, including replicas.  A <literal>pri</literal> flag can be supplied to enable
the view of relevant stats in the context of only the primaries.</simpara>
<bridgehead id="examples" renderas="sect2">Examples<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/indices.asciidoc">Edit me</ulink></bridgehead>
<simpara>Which indices are yellow?</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/indices?v&amp;health=yellow</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Which looks like:</simpara>
<programlisting language="txt" linenumbering="unnumbered">health status index    uuid                   pri rep docs.count docs.deleted store.size pri.store.size
yellow open   twitter  u8FNjxh8Rfy_awN11oDKYQ   1   1       1200            0     88.1kb         88.1kb</programlisting>
<remark> TESTRESPONSE[s/\d+(\.\d+)?[tgmk]?b/\\d+(\\.\\d+)?[tgmk]?b/]</remark>
<remark> TESTRESPONSE[s/u8FNjxh8Rfy_awN11oDKYQ/.+/ _cat]</remark>
<simpara>Which index has the largest number of documents?</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/indices?v&amp;s=docs.count:desc</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Which looks like:</simpara>
<programlisting language="txt" linenumbering="unnumbered">health status index    uuid                   pri rep docs.count docs.deleted store.size pri.store.size
yellow open   twitter  u8FNjxh8Rfy_awN11oDKYQ   1   1       1200            0     88.1kb         88.1kb
green  open   twitter2 nYFWZEO7TUiOjLQXBaYJpA   5   0          0            0       260b           260b</programlisting>
<remark> TESTRESPONSE[s/\d+(\.\d+)?[tgmk]?b/\\d+(\\.\\d+)?[tgmk]?b/]</remark>
<remark> TESTRESPONSE[s/u8FNjxh8Rfy_awN11oDKYQ|nYFWZEO7TUiOjLQXBaYJpA/.+/ _cat]</remark>
<simpara>How many merge operations have the shards for the <literal>twitter</literal> completed?</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/indices/twitter?pri&amp;v&amp;h=health,index,pri,rep,docs.count,mt</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Might look like:</simpara>
<programlisting language="js" linenumbering="unnumbered">health index   pri rep docs.count mt pri.mt
yellow twitter   1   1 1200       16     16</programlisting>
<remark> TESTRESPONSE[s/16/\\d+/ _cat]</remark>
<simpara>How much memory is used per index?</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/indices?v&amp;h=i,tm&amp;s=tm:desc</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Might look like:</simpara>
<programlisting language="js" linenumbering="unnumbered">i         tm
twitter   8.1gb
twitter2  30.5kb</programlisting>
<remark> TESTRESPONSE[s/\d+(\.\d+)?[tgmk]?b/\\d+(\\.\\d+)?[tgmk]?b/]</remark>
<remark> TESTRESPONSE[_cat]</remark>
</chapter>
<chapter id="cat-master">
<title>cat master<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/master.asciidoc">Edit me</ulink></title>
<simpara><literal>master</literal> doesn&#8217;t have any extra options. It simply displays the
master&#8217;s node ID, bound IP address, and node name. For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/master?v</programlisting>
<remark> CONSOLE</remark>
<simpara>might respond:</simpara>
<programlisting language="txt" linenumbering="unnumbered">id                     host      ip        node
YzWoH_2BT-6UjVGDyPdqYg 127.0.0.1 127.0.0.1 YzWoH_2</programlisting>
<remark> TESTRESPONSE[s/YzWoH_2.+/.+/ _cat]</remark>
<simpara>This information is also available via the <literal>nodes</literal> command, but this
is slightly shorter when all you want to do, for example, is verify
all nodes agree on the master:</simpara>
<programlisting language="sh" linenumbering="unnumbered">% pssh -i -h list.of.cluster.hosts curl -s localhost:9200/_cat/master
[1] 19:16:37 [SUCCESS] es3.vm
Ntgn2DcuTjGuXlhKDUD4vA 192.168.56.30 H5dfFeA
[2] 19:16:37 [SUCCESS] es2.vm
Ntgn2DcuTjGuXlhKDUD4vA 192.168.56.30 H5dfFeA
[3] 19:16:37 [SUCCESS] es1.vm
Ntgn2DcuTjGuXlhKDUD4vA 192.168.56.30 H5dfFeA</programlisting>
<remark> NOTCONSOLE</remark>
</chapter>
<chapter id="cat-nodeattrs">
<title>cat nodeattrs<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/nodeattrs.asciidoc">Edit me</ulink></title>
<simpara>The <literal>nodeattrs</literal> command shows custom node attributes.
For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/nodeattrs?v</programlisting>
<remark> CONSOLE</remark>
<simpara>Could look like:</simpara>
<programlisting language="txt" linenumbering="unnumbered">node    host      ip        attr     value
EK_AsJb 127.0.0.1 127.0.0.1 testattr test</programlisting>
<remark> TESTRESPONSE[s/EK_AsJb/.+/ _cat]</remark>
<simpara>The first few columns (<literal>node</literal>, <literal>host</literal>, <literal>ip</literal>) give you basic info per node
and the <literal>attr</literal> and <literal>value</literal> columns give you the custom node attributes,
one per line.</simpara>
<bridgehead id="_columns" renderas="sect2">Columns<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/nodeattrs.asciidoc">Edit me</ulink></bridgehead>
<simpara>Below is an exhaustive list of the existing headers that can be
passed to <literal>nodeattrs?h=</literal> to retrieve the relevant details in ordered
columns.  If no headers are specified, then those marked to Appear
by Default will appear. If any header is specified, then the defaults
are not used.</simpara>
<simpara>Aliases can be used in place of the full header name for brevity.
Columns appear in the order that they are listed below unless a
different order is specified (e.g., <literal>h=attr,value</literal> versus <literal>h=value,attr</literal>).</simpara>
<simpara>When specifying headers, the headers are not placed in the output
by default.  To have the headers appear in the output, use verbose
mode (<literal>v</literal>). The header name will match the supplied value (e.g.,
<literal>pid</literal> versus <literal>p</literal>).  For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/nodeattrs?v&amp;h=name,pid,attr,value</programlisting>
<remark> CONSOLE</remark>
<simpara>Might look like:</simpara>
<programlisting language="js" linenumbering="unnumbered">name    pid   attr     value
EK_AsJb 19566 testattr test</programlisting>
<remark> TESTRESPONSE[s/EK_AsJb/.+/ s/19566/\\d*/ _cat]</remark>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="5">
<colspec colname="col_1" colwidth="20*"/>
<colspec colname="col_2" colwidth="20*"/>
<colspec colname="col_3" colwidth="20*"/>
<colspec colname="col_4" colwidth="20*"/>
<colspec colname="col_5" colwidth="20*"/>
<thead>
<row>
<entry align="left" valign="top">Header </entry>
<entry align="left" valign="top">Alias </entry>
<entry align="left" valign="top">Appear by Default </entry>
<entry align="left" valign="top">Description </entry>
<entry align="left" valign="top">Example</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>node</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>name</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>Name of the node</simpara></entry>
<entry align="left" valign="top"><simpara>DKDM97B</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>id</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>nodeId</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Unique node ID</simpara></entry>
<entry align="left" valign="top"><simpara>k0zy</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>pid</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>p</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Process ID</simpara></entry>
<entry align="left" valign="top"><simpara>13061</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>host</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>h</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>Host name</simpara></entry>
<entry align="left" valign="top"><simpara>n1</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ip</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>i</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>IP address</simpara></entry>
<entry align="left" valign="top"><simpara>127.0.1.1</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>port</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>po</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Bound transport port</simpara></entry>
<entry align="left" valign="top"><simpara>9300</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>attr</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>attr.name</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>Attribute name</simpara></entry>
<entry align="left" valign="top"><simpara>rack</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>value</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>attr.value</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>Attribute value</simpara></entry>
<entry align="left" valign="top"><simpara>rack123</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</chapter>
<chapter id="cat-nodes">
<title>cat nodes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/nodes.asciidoc">Edit me</ulink></title>
<simpara>The <literal>nodes</literal> command shows the cluster topology. For example</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/nodes?v</programlisting>
<remark> CONSOLE</remark>
<simpara>Might look like:</simpara>
<programlisting language="txt" linenumbering="unnumbered">ip        heap.percent ram.percent cpu load_1m load_5m load_15m node.role master name
127.0.0.1           65          99  42    3.07                  mdi       *      mJw06l1</programlisting>
<remark> TESTRESPONSE[s/3.07/(\\d+\\.\\d+( \\d+\\.\\d+ (\\d+\\.\\d+)?)?)?/]</remark>
<remark> TESTRESPONSE[s/65          99  42/\\d+ \\d+ \\d+/]</remark>
<remark> TESTRESPONSE[s/[*]/[*]/ s/mJw06l1/.+/ _cat]</remark>
<simpara>The first few columns (<literal>ip, `heap.percent</literal>, <literal>ram.percent</literal>, <literal>cpu, `load_*</literal>) tell
you where your nodes live and give a quick picture of performance stats.</simpara>
<simpara>The last (<literal>node.role</literal>, <literal>master</literal>, and <literal>name</literal>) columns provide ancillary
information that can often be useful when looking at the cluster as a whole,
particularly large ones.  How many master-eligible nodes do I have?</simpara>
<bridgehead id="_columns_2" renderas="sect2">Columns<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/nodes.asciidoc">Edit me</ulink></bridgehead>
<simpara>Below is an exhaustive list of the existing headers that can be
passed to <literal>nodes?h=</literal> to retrieve the relevant details in ordered
columns.  If no headers are specified, then those marked to Appear
by Default will appear. If any header is specified, then the defaults
are not used.</simpara>
<simpara>Aliases can be used in place of the full header name for brevity.
Columns appear in the order that they are listed below unless a
different order is specified (e.g., <literal>h=pid,id</literal> versus <literal>h=id,pid</literal>).</simpara>
<simpara>When specifying headers, the headers are not placed in the output
by default.  To have the headers appear in the output, use verbose
mode (<literal>v</literal>). The header name will match the supplied value (e.g.,
<literal>pid</literal> versus <literal>p</literal>).  For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/nodes?v&amp;h=id,ip,port,v,m</programlisting>
<remark> CONSOLE</remark>
<simpara>Might look like:</simpara>
<programlisting language="js" linenumbering="unnumbered">id   ip        port  v         m
veJR 127.0.0.1 59938 5.1.1 *</programlisting>
<remark> TESTRESPONSE[s/veJR/.+/ s/59938/\\d+/ s/[*]/[*]/ _cat]</remark>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="5">
<colspec colname="col_1" colwidth="20*"/>
<colspec colname="col_2" colwidth="20*"/>
<colspec colname="col_3" colwidth="20*"/>
<colspec colname="col_4" colwidth="20*"/>
<colspec colname="col_5" colwidth="20*"/>
<thead>
<row>
<entry align="left" valign="top">Header </entry>
<entry align="left" valign="top">Alias </entry>
<entry align="left" valign="top">Appear by Default </entry>
<entry align="left" valign="top">Description </entry>
<entry align="left" valign="top">Example</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>id</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>nodeId</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Unique node ID</simpara></entry>
<entry align="left" valign="top"><simpara>k0zy</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>pid</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>p</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Process ID</simpara></entry>
<entry align="left" valign="top"><simpara>13061</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ip</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>i</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>IP address</simpara></entry>
<entry align="left" valign="top"><simpara>127.0.1.1</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>port</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>po</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Bound transport port</simpara></entry>
<entry align="left" valign="top"><simpara>9300</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>http_address</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>http</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>bound http address</simpara></entry>
<entry align="left" valign="top"><simpara>127.0.0.1:9200</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>version</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>v</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Elasticsearch version</simpara></entry>
<entry align="left" valign="top"><simpara>5.1.1</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>build</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>b</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Elasticsearch Build hash</simpara></entry>
<entry align="left" valign="top"><simpara>5c03844</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>jdk</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>j</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Running Java version</simpara></entry>
<entry align="left" valign="top"><simpara>1.8.0</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>disk.avail</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>d</literal>, <literal>disk</literal>, <literal>diskAvail</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Available disk space</simpara></entry>
<entry align="left" valign="top"><simpara>1.8gb</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>heap.current</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>hc</literal>, <literal>heapCurrent</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Used heap</simpara></entry>
<entry align="left" valign="top"><simpara>311.2mb</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>heap.percent</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>hp</literal>, <literal>heapPercent</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>Used heap percentage</simpara></entry>
<entry align="left" valign="top"><simpara>7</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>heap.max</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>hm</literal>, <literal>heapMax</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Maximum configured heap</simpara></entry>
<entry align="left" valign="top"><simpara>1015.6mb</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ram.current</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>rc</literal>, <literal>ramCurrent</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Used total memory</simpara></entry>
<entry align="left" valign="top"><simpara>513.4mb</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ram.percent</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>rp</literal>, <literal>ramPercent</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>Used total memory percentage</simpara></entry>
<entry align="left" valign="top"><simpara>47</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ram.max</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>rm</literal>, <literal>ramMax</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Total memory</simpara></entry>
<entry align="left" valign="top"><simpara>2.9gb</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>file_desc.current</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>fdc</literal>, <literal>fileDescriptorCurrent</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Used file
descriptors</simpara></entry>
<entry align="left" valign="top"><simpara>123</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>file_desc.percent</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>fdp</literal>, <literal>fileDescriptorPercent</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>Used file
descriptors percentage</simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>file_desc.max</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>fdm</literal>, <literal>fileDescriptorMax</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Maximum number of file
descriptors</simpara></entry>
<entry align="left" valign="top"><simpara>1024</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>cpu</literal></simpara></entry>
<entry align="left" valign="top"><simpara></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Recent system CPU usage as percent</simpara></entry>
<entry align="left" valign="top"><simpara>12</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>load_1m</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>l</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Most recent load average</simpara></entry>
<entry align="left" valign="top"><simpara>0.22</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>load_5m</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>l</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Load average for the last five minutes</simpara></entry>
<entry align="left" valign="top"><simpara>0.78</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>load_15m</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>l</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Load average for the last fifteen minutes</simpara></entry>
<entry align="left" valign="top"><simpara>1.24</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>uptime</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>u</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Node uptime</simpara></entry>
<entry align="left" valign="top"><simpara>17.3m</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>node.role</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>r</literal>, <literal>role</literal>, <literal>nodeRole</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>Master eligible node (m);
Data node (d); Ingest node (i); Coordinating node only (-)</simpara></entry>
<entry align="left" valign="top"><simpara>mdi</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>master</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>m</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>Elected master (*); Not elected master (-)</simpara></entry>
<entry align="left" valign="top"><simpara>*</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>name</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>n</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
<entry align="left" valign="top"><simpara>Node name</simpara></entry>
<entry align="left" valign="top"><simpara>I8hydUG</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>completion.size</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>cs</literal>, <literal>completionSize</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Size of completion</simpara></entry>
<entry align="left" valign="top"><simpara>0b</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>fielddata.memory_size</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>fm</literal>, <literal>fielddataMemory</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Used fielddata
cache memory</simpara></entry>
<entry align="left" valign="top"><simpara>0b</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>fielddata.evictions</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>fe</literal>, <literal>fielddataEvictions</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Fielddata cache
evictions</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>query_cache.memory_size</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>qcm</literal>, <literal>queryCacheMemory</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Used query
cache memory</simpara></entry>
<entry align="left" valign="top"><simpara>0b</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>query_cache.evictions</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>qce</literal>, <literal>queryCacheEvictions</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Query
cache evictions</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>request_cache.memory_size</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>rcm</literal>, <literal>requestCacheMemory</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Used request
cache memory</simpara></entry>
<entry align="left" valign="top"><simpara>0b</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>request_cache.evictions</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>rce</literal>, <literal>requestCacheEvictions</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Request
cache evictions</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>request_cache.hit_count</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>rchc</literal>, <literal>requestCacheHitCount</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Request
cache hit count</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>request_cache.miss_count</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>rcmc</literal>, <literal>requestCacheMissCount</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Request
cache miss count</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>flush.total</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>ft</literal>, <literal>flushTotal</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Number of flushes</simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>flush.total_time</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>ftt</literal>, <literal>flushTotalTime</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Time spent in flush</simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>get.current</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>gc</literal>, <literal>getCurrent</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Number of current get
operations</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>get.time</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>gti</literal>, <literal>getTime</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Time spent in get</simpara></entry>
<entry align="left" valign="top"><simpara>14ms</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>get.total</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>gto</literal>, <literal>getTotal</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Number of get operations</simpara></entry>
<entry align="left" valign="top"><simpara>2</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>get.exists_time</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>geti</literal>, <literal>getExistsTime</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Time spent in
successful gets</simpara></entry>
<entry align="left" valign="top"><simpara>14ms</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>get.exists_total</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>geto</literal>, <literal>getExistsTotal</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Number of successful
get operations</simpara></entry>
<entry align="left" valign="top"><simpara>2</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>get.missing_time</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>gmti</literal>, <literal>getMissingTime</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Time spent in failed
gets</simpara></entry>
<entry align="left" valign="top"><simpara>0s</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>get.missing_total</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>gmto</literal>, <literal>getMissingTotal</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Number of failed
get operations</simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>indexing.delete_current</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>idc</literal>, <literal>indexingDeleteCurrent</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Number
of current deletion operations</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>indexing.delete_time</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>idti</literal>, <literal>indexingDeleteTime</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Time spent in
deletions</simpara></entry>
<entry align="left" valign="top"><simpara>2ms</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>indexing.delete_total</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>idto</literal>, <literal>indexingDeleteTotal</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Number of
deletion operations</simpara></entry>
<entry align="left" valign="top"><simpara>2</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>indexing.index_current</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>iic</literal>, <literal>indexingIndexCurrent</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Number
of current indexing operations</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>indexing.index_time</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>iiti</literal>, <literal>indexingIndexTime</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Time spent in
indexing</simpara></entry>
<entry align="left" valign="top"><simpara>134ms</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>indexing.index_total</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>iito</literal>, <literal>indexingIndexTotal</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Number of
indexing operations</simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>indexing.index_failed</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>iif</literal>, <literal>indexingIndexFailed</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Number of
failed indexing operations</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>merges.current</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>mc</literal>, <literal>mergesCurrent</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Number of current
merge operations</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>merges.current_docs</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>mcd</literal>, <literal>mergesCurrentDocs</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Number of
current merging documents</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>merges.current_size</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>mcs</literal>, <literal>mergesCurrentSize</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Size of current
merges</simpara></entry>
<entry align="left" valign="top"><simpara>0b</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>merges.total</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>mt</literal>, <literal>mergesTotal</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Number of completed merge
operations</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>merges.total_docs</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>mtd</literal>, <literal>mergesTotalDocs</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Number of merged
documents</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>merges.total_size</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>mts</literal>, <literal>mergesTotalSize</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Size of current
merges</simpara></entry>
<entry align="left" valign="top"><simpara>0b</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>merges.total_time</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>mtt</literal>, <literal>mergesTotalTime</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Time spent merging
documents</simpara></entry>
<entry align="left" valign="top"><simpara>0s</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>refresh.total</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>rto</literal>, <literal>refreshTotal</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Number of refreshes</simpara></entry>
<entry align="left" valign="top"><simpara>16</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>refresh.time</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>rti</literal>, <literal>refreshTime</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Time spent in refreshes</simpara></entry>
<entry align="left" valign="top"><simpara>91ms</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>script.compilations</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>scrcc</literal>, <literal>scriptCompilations</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Total script compilations</simpara></entry>
<entry align="left" valign="top"><simpara>17</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>script.cache_evictions</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>scrce</literal>, <literal>scriptCacheEvictions</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Total compiled scripts evicted from cache</simpara></entry>
<entry align="left" valign="top"><simpara>6</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>search.fetch_current</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>sfc</literal>, <literal>searchFetchCurrent</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Current fetch
phase operations</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>search.fetch_time</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>sfti</literal>, <literal>searchFetchTime</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Time spent in fetch
phase</simpara></entry>
<entry align="left" valign="top"><simpara>37ms</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>search.fetch_total</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>sfto</literal>, <literal>searchFetchTotal</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Number of fetch
operations</simpara></entry>
<entry align="left" valign="top"><simpara>7</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>search.open_contexts</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>so</literal>, <literal>searchOpenContexts</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Open search
contexts</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>search.query_current</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>sqc</literal>, <literal>searchFetchCurrent</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Current query
phase operations</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>search.query_time</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>sqti</literal>, <literal>searchFetchTime</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Time spent in query
phase</simpara></entry>
<entry align="left" valign="top"><simpara>43ms</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>search.query_total</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>sqto</literal>, <literal>searchFetchTotal</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Number of query
operations</simpara></entry>
<entry align="left" valign="top"><simpara>9</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>search.scroll_current</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>scc</literal>, <literal>searchScrollCurrent</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Open scroll contexts</simpara></entry>
<entry align="left" valign="top"><simpara>2</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>search.scroll_time</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>scti</literal>, <literal>searchScrollTime</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Time scroll contexts held open</simpara></entry>
<entry align="left" valign="top"><simpara>2m</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>search.scroll_total</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>scto</literal>, <literal>searchScrollTotal</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Completed scroll contexts</simpara></entry>
<entry align="left" valign="top"><simpara>1</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>segments.count</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>sc</literal>, <literal>segmentsCount</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Number of segments</simpara></entry>
<entry align="left" valign="top"><simpara>4</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>segments.memory</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>sm</literal>, <literal>segmentsMemory</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Memory used by
segments</simpara></entry>
<entry align="left" valign="top"><simpara>1.4kb</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>segments.index_writer_memory</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>siwm</literal>, <literal>segmentsIndexWriterMemory</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Memory used by index writer</simpara></entry>
<entry align="left" valign="top"><simpara>18mb</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>segments.version_map_memory</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>svmm</literal>, <literal>segmentsVersionMapMemory</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Memory used by version map</simpara></entry>
<entry align="left" valign="top"><simpara>1.0kb</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>segments.fixed_bitset_memory</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>sfbm</literal>, <literal>fixedBitsetMemory</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Memory used by fixed bit sets for nested object field types and type filters for types referred in _parent fields</simpara></entry>
<entry align="left" valign="top"><simpara>1.0kb</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>suggest.current</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>suc</literal>, <literal>suggestCurrent</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Number of current suggest operations</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>suggest.time</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>suti</literal>, <literal>suggestTime</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Time spent in suggest</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>suggest.total</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>suto</literal>, <literal>suggestTotal</literal></simpara></entry>
<entry align="left" valign="top"><simpara>No</simpara></entry>
<entry align="left" valign="top"><simpara>Number of suggest operations</simpara></entry>
<entry align="left" valign="top"><simpara>0</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</chapter>
<chapter id="cat-pending-tasks">
<title>cat pending tasks<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/pending_tasks.asciidoc">Edit me</ulink></title>
<simpara><literal>pending_tasks</literal> provides the same information as the
<link linkend="cluster-pending"><literal>/_cluster/pending_tasks</literal></link> API in a
convenient tabular format. For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/pending_tasks?v</programlisting>
<remark> CONSOLE</remark>
<simpara>Might look like:</simpara>
<programlisting language="txt" linenumbering="unnumbered">insertOrder timeInQueue priority source
       1685       855ms HIGH     update-mapping [foo][t]
       1686       843ms HIGH     update-mapping [foo][t]
       1693       753ms HIGH     refresh-mapping [foo][[t]]
       1688       816ms HIGH     update-mapping [foo][t]
       1689       802ms HIGH     update-mapping [foo][t]
       1690       787ms HIGH     update-mapping [foo][t]
       1691       773ms HIGH     update-mapping [foo][t]</programlisting>
<remark> TESTRESPONSE[s/(\n.+)+/(\\n.+)*/ _cat]</remark>
<remark> We can't assert anything about the tasks in progress here because we don't</remark>
<remark> know what might be in progress....</remark>
</chapter>
<chapter id="cat-plugins">
<title>cat plugins<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/plugins.asciidoc">Edit me</ulink></title>
<simpara>The <literal>plugins</literal> command provides a view per node of running plugins. This information <emphasis role="strong">spans nodes</emphasis>.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/plugins?v&amp;s=component&amp;h=name,component,version,description</programlisting>
<remark> CONSOLE</remark>
<simpara>Might look like:</simpara>
<programlisting language="txt" linenumbering="unnumbered">name    component               version   description
U7321H6 analysis-icu            5.1.1 The ICU Analysis plugin integrates Lucene ICU module into elasticsearch, adding ICU relates analysis components.
U7321H6 analysis-kuromoji       5.1.1 The Japanese (kuromoji) Analysis plugin integrates Lucene kuromoji analysis module into elasticsearch.
U7321H6 analysis-phonetic       5.1.1 The Phonetic Analysis plugin integrates phonetic token filter analysis with elasticsearch.
U7321H6 analysis-smartcn        5.1.1 Smart Chinese Analysis plugin integrates Lucene Smart Chinese analysis module into elasticsearch.
U7321H6 analysis-stempel        5.1.1 The Stempel (Polish) Analysis plugin integrates Lucene stempel (polish) analysis module into elasticsearch.
U7321H6 analysis-ukrainian        5.1.1 The Ukrainian Analysis plugin integrates the Lucene UkrainianMorfologikAnalyzer into elasticsearch.
U7321H6 discovery-azure-classic 5.1.1 The Azure Classic Discovery plugin allows to use Azure Classic API for the unicast discovery mechanism
U7321H6 discovery-ec2           5.1.1 The EC2 discovery plugin allows to use AWS API for the unicast discovery mechanism.
U7321H6 discovery-file          5.1.1 Discovery file plugin enables unicast discovery from hosts stored in a file.
U7321H6 discovery-gce           5.1.1 The Google Compute Engine (GCE) Discovery plugin allows to use GCE API for the unicast discovery mechanism.
U7321H6 ingest-attachment       5.1.1 Ingest processor that uses Apache Tika to extract contents
U7321H6 ingest-geoip            5.1.1 Ingest processor that uses looksup geo data based on ip adresses using the Maxmind geo database
U7321H6 ingest-user-agent       5.1.1 Ingest processor that extracts information from a user agent
U7321H6 jvm-example             5.1.1 Demonstrates all the pluggable Java entry points in Elasticsearch
U7321H6 lang-javascript         5.1.1 The JavaScript language plugin allows to have javascript as the language of scripts to execute.
U7321H6 lang-python             5.1.1 The Python language plugin allows to have python as the language of scripts to execute.
U7321H6 mapper-attachments      5.1.1 The mapper attachments plugin adds the attachment type to Elasticsearch using Apache Tika.
U7321H6 mapper-murmur3          5.1.1 The Mapper Murmur3 plugin allows to compute hashes of a field's values at index-time and to store them in the index.
U7321H6 mapper-size             5.1.1 The Mapper Size plugin allows document to record their uncompressed size at index time.
U7321H6 store-smb               5.1.1 The Store SMB plugin adds support for SMB stores.</programlisting>
<remark> TESTRESPONSE[s/([.()])/\\$1/ s/U7321H6/.+/ _cat]</remark>
<simpara>We can tell quickly how many plugins per node we have and which versions.</simpara>
</chapter>
<chapter id="cat-recovery">
<title>cat recovery<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/recovery.asciidoc">Edit me</ulink></title>
<simpara>The <literal>recovery</literal> command is a view of index shard recoveries, both on-going and previously
completed. It is a more compact view of the JSON <link linkend="indices-recovery">recovery</link> API.</simpara>
<simpara>A recovery event occurs anytime an index shard moves to a different node in the cluster.
This can happen during a snapshot recovery, a change in replication level, node failure, or
on node startup. This last type is called a local store recovery and is the normal
way for shards to be loaded from disk when a node starts up.</simpara>
<simpara>As an example, here is what the recovery state of a cluster may look like when there
are no shards in transit from one node to another:</simpara>
<programlisting language="sh" linenumbering="unnumbered">&gt; curl -XGET 'localhost:9200/_cat/recovery?v'
index shard time type  stage source_host  source_node target_host target_node repository snapshot files files_percent bytes bytes_percent
 total_files total_bytes translog translog_percent total_translog
index 0     87ms store done  127.0.0.1        I8hydUG      127.0.0.1        I8hydUG      n/a        n/a      0     0.0%          0     0.0%          0           0           0        100.0%           0
index 1     97ms store done  127.0.0.1        I8hydUG      127.0.0.1        I8hydUG      n/a        n/a      0     0.0%          0     0.0%          0           0           0        100.0%           0
index 2     93ms store done  127.0.0.1        I8hydUG      127.0.0.1        I8hydUG      n/a        n/a      0     0.0%          0     0.0%          0           0           0        100.0%           0
index 3     90ms store done  127.0.0.1        I8hydUG      127.0.0.1        I8hydUG      n/a        n/a      0     0.0%          0     0.0%          0           0           0        100.0%           0
index 4     9ms  store done  127.0.0.1        I8hydUG      127.0.0.1        I8hydUG      n/a        n/a      0     0.0%          0     0.0%          0           0           0        100.0%           0</programlisting>
<simpara>In the above case, the source and target nodes are the same because the recovery
type was store, i.e. they were read from local storage on node start.</simpara>
<simpara>Now let&#8217;s see what a live recovery looks like. By increasing the replica count
of our index and bringing another node online to host the replicas, we can see
what a live shard recovery looks like.</simpara>
<programlisting language="sh" linenumbering="unnumbered">&gt; curl -XPUT 'localhost:9200/wiki/_settings' -d'{"number_of_replicas":1}'
{"acknowledged":true}

&gt; curl -XGET 'localhost:9200/_cat/recovery?v&amp;h=i,s,t,ty,st,shost,thost,f,fp,b,bp'
i     s t      ty      st    shost  thost  f     fp      b        bp
wiki  0 1252ms store   done  hostA  hostA  4     100.0%  23638870 100.0%
wiki  0 1672ms replica index hostA  hostB  4     75.0%   23638870 48.8%
wiki  1 1698ms replica index hostA  hostB  4     75.0%   23348540 49.4%
wiki  1 4812ms store   done  hostA  hostA  33    100.0%  24501912 100.0%
wiki  2 1689ms replica index hostA  hostB  4     75.0%   28681851 40.2%
wiki  2 5317ms store   done  hostA  hostA  36    100.0%  30267222 100.0%</programlisting>
<simpara>We can see in the above listing that our 3 initial shards are in various stages
of being replicated from one node to another. Notice that the recovery type is
shown as <literal>replica</literal>. The files and bytes copied are real-time measurements.</simpara>
<simpara>Finally, let&#8217;s see what a snapshot recovery looks like. Assuming I have previously
made a backup of my index, I can restore it using the <link linkend="modules-snapshots">snapshot and restore</link>
API.</simpara>
<programlisting language="sh" linenumbering="unnumbered">&gt; curl -XPOST 'localhost:9200/_snapshot/imdb/snapshot_2/_restore'
{"acknowledged":true}
&gt; curl -XGET 'localhost:9200/_cat/recovery?v&amp;h=i,s,t,ty,st,rep,snap,f,fp,b,bp'
i     s t      ty       st    rep        snap     f     fp      b     bp
imdb  0 1978ms snapshot done  imdb       snap_1   79    8.0%    12086 9.0%
imdb  1 2790ms snapshot index imdb       snap_1   88    7.7%    11025 8.1%
imdb  2 2790ms snapshot index imdb       snap_1   85    0.0%    12072 0.0%
imdb  3 2796ms snapshot index imdb       snap_1   85    2.4%    12048 7.2%
imdb  4  819ms snapshot init  imdb       snap_1   0     0.0%    0     0.0%</programlisting>
</chapter>
<chapter id="cat-repositories">
<title>cat repositories<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/repositories.asciidoc">Edit me</ulink></title>
<simpara>The <literal>repositories</literal> command shows the snapshot repositories registered in the
cluster. For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/repositories?v</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT \/_snapshot\/repo1\n{"type": "fs", "settings": {"location": "repo\/1"}}\n/]</remark>
<simpara>might looks like:</simpara>
<programlisting language="txt" linenumbering="unnumbered">id    type
repo1   fs
repo2   s3</programlisting>
<remark> TESTRESPONSE[s/\nrepo2   s3// _cat]</remark>
<simpara>We can quickly see which repositories are registered and their type.</simpara>
</chapter>
<chapter id="cat-thread-pool">
<title>cat thread pool<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/thread_pool.asciidoc">Edit me</ulink></title>
<simpara>The <literal>thread_pool</literal> command shows cluster wide thread pool statistics per node. By default the active, queue and rejected
statistics are returned for all thread pools.</simpara>
<programlisting language="sh" linenumbering="unnumbered">% curl 192.168.56.10:9200/_cat/thread_pool
0EWUhXe bulk                0 0 0
0EWUhXe fetch_shard_started 0 0 0
0EWUhXe fetch_shard_store   0 0 0
0EWUhXe flush               0 0 0
0EWUhXe force_merge         0 0 0
0EWUhXe generic             0 0 0
0EWUhXe get                 0 0 0
0EWUhXe index               0 0 0
0EWUhXe listener            0 0 0
0EWUhXe management          1 0 0
0EWUhXe refresh             0 0 0
0EWUhXe search              0 0 0
0EWUhXe snapshot            0 0 0
0EWUhXe warmer              0 0 0</programlisting>
<simpara>The first column is the node name</simpara>
<programlisting language="sh" linenumbering="unnumbered">node_name
0EWUhXe</programlisting>
<simpara>The second column is the thread pool name</simpara>
<programlisting language="sh" linenumbering="unnumbered">name
bulk
fetch_shard_started
fetch_shard_store
flush
force_merge
generic
get
index
listener
management
refresh
search
snapshot
warmer</programlisting>
<simpara>The next three columns show the active, queue, and rejected statistics for each thread pool</simpara>
<programlisting language="sh" linenumbering="unnumbered">active queue rejected
     0     0        0
     0     0        0
     0     0        0
     0     0        0
     0     0        0
     0     0        0
     0     0        0
     0     0        0
     0     0        0
     1     0        0
     0     0        0
     0     0        0
     0     0        0
     0     0        0</programlisting>
<simpara>The cat thread pool API accepts a <literal>thread_pool_patterns</literal> URL parameter for specifying a
comma-separated list of regular expressions to match thread pool names.</simpara>
<programlisting language="sh" linenumbering="unnumbered">% curl 'localhost:9200/_cat/thread_pool/generic?v&amp;h=id,name,active,rejected,completed'
id                     name    active rejected completed
0EWUhXeBQtaVGlexUeVwMg generic      0        0        70</programlisting>
<simpara>Here the host columns and the active, rejected and completed suggest thread pool statistic are displayed.</simpara>
<simpara>All <link linkend="modules-threadpool">built-in thread pools</link> and custom thread pools are available.</simpara>
<bridgehead id="_thread_pool_fields" renderas="sect3">Thread Pool Fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/thread_pool.asciidoc">Edit me</ulink></bridgehead>
<simpara>For each thread pool, you can load details about it by using the field names
in the table below.</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="3">
<colspec colname="col_1" colwidth="33*"/>
<colspec colname="col_2" colwidth="33*"/>
<colspec colname="col_3" colwidth="33*"/>
<thead>
<row>
<entry align="left" valign="top">Field Name </entry>
<entry align="left" valign="top">Alias </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>type</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>t</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The current (*) type of thread pool (<literal>fixed</literal> or <literal>scaling</literal>)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>active</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>a</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The number of active threads in the current thread pool</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>size</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>s</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The number of threads in the current thread pool</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>queue</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>q</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The number of tasks in the queue for the current thread pool</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>queue_size</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>qs</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The maximum number of tasks permitted in the queue for the current thread pool</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>rejected</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>r</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The number of tasks rejected by the thread pool executor</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>largest</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>l</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The highest number of active threads in the current thread pool</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>completed</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>c</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The number of tasks completed by the thread pool executor</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>min</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>mi</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The configured minimum number of active threads allowed in the current thread pool</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>max</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>ma</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The configured maximum number of active threads allowed in the current thread pool</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>keep_alive</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>k</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The configured keep alive time for threads</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<bridgehead id="_other_fields" renderas="sect2">Other Fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/thread_pool.asciidoc">Edit me</ulink></bridgehead>
<simpara>In addition to details about each thread pool, it is also convenient to get an
understanding of where those thread pools reside. As such, you can request
other details like the <literal>ip</literal> of the responding node(s).</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="3">
<colspec colname="col_1" colwidth="33*"/>
<colspec colname="col_2" colwidth="33*"/>
<colspec colname="col_3" colwidth="33*"/>
<thead>
<row>
<entry align="left" valign="top">Field Name </entry>
<entry align="left" valign="top">Alias </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>node_id</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>id</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The unique node ID</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ephemeral_id</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>eid</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The ephemeral node ID</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>pid</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>p</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The process ID of the running node</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>host</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>h</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The hostname for the current node</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ip</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>i</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The IP address for the current node</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>port</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>po</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The bound transport port for the current node</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</chapter>
<chapter id="cat-shards">
<title>cat shards<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/shards.asciidoc">Edit me</ulink></title>
<simpara>The <literal>shards</literal> command is the detailed view of what nodes contain which
shards.  It will tell you if it&#8217;s a primary or replica, the number of
docs, the bytes it takes on disk, and the node where it&#8217;s located.</simpara>
<simpara>Here we see a single index, with three primary shards and no replicas:</simpara>
<programlisting language="sh" linenumbering="unnumbered">% curl 192.168.56.20:9200/_cat/shards
wiki1 0 p STARTED 3014 31.1mb 192.168.56.10 H5dfFeA
wiki1 1 p STARTED 3013 29.6mb 192.168.56.30 bGG90GE
wiki1 2 p STARTED 3973 38.1mb 192.168.56.20 I8hydUG</programlisting>
<bridgehead id="index-pattern" renderas="sect2">Index pattern<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/shards.asciidoc">Edit me</ulink></bridgehead>
<simpara>If you have many shards, you may wish to limit which indices show up
in the output.  You can always do this with <literal>grep</literal>, but you can save
some bandwidth by supplying an index pattern to the end.</simpara>
<programlisting language="sh" linenumbering="unnumbered">% curl 192.168.56.20:9200/_cat/shards/wiki*
wiki2 0 p STARTED 197 3.2mb 192.168.56.10 H5dfFeA
wiki2 1 p STARTED 205 5.9mb 192.168.56.30 bGG90GE
wiki2 2 p STARTED 275 7.8mb 192.168.56.20 I8hydUG</programlisting>
<bridgehead id="relocation" renderas="sect2">Relocation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/shards.asciidoc">Edit me</ulink></bridgehead>
<simpara>Let&#8217;s say you&#8217;ve checked your health and you see two relocating
shards.  Where are they from and where are they going?</simpara>
<programlisting language="sh" linenumbering="unnumbered">% curl 192.168.56.10:9200/_cat/health
1384315316 20:01:56 foo green 3 3 12 6 2 0 0
% curl 192.168.56.10:9200/_cat/shards | fgrep RELO
wiki1 0 r RELOCATING 3014 31.1mb 192.168.56.20 I8hydUG -&gt; 192.168.56.30 bGG90GE
wiki1 1 r RELOCATING 3013 29.6mb 192.168.56.10 H5dfFeA -&gt; 192.168.56.30 bGG90GE</programlisting>
<bridgehead id="states" renderas="sect2">Shard states<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/shards.asciidoc">Edit me</ulink></bridgehead>
<simpara>Before a shard can be used, it goes through an <literal>INITIALIZING</literal> state.
<literal>shards</literal> can show you which ones.</simpara>
<programlisting language="sh" linenumbering="unnumbered">% curl -XPUT 192.168.56.20:9200/_settings -d'{"number_of_replicas":1}'
{"acknowledged":true}
% curl 192.168.56.20:9200/_cat/shards
wiki1 0 p STARTED      3014 31.1mb 192.168.56.10 H5dfFeA
wiki1 0 r INITIALIZING    0 14.3mb 192.168.56.30 bGG90GE
wiki1 1 p STARTED      3013 29.6mb 192.168.56.30 bGG90GE
wiki1 1 r INITIALIZING    0 13.1mb 192.168.56.20 I8hydUG
wiki1 2 r INITIALIZING    0   14mb 192.168.56.10 H5dfFeA
wiki1 2 p STARTED      3973 38.1mb 192.168.56.20 I8hydUG</programlisting>
<simpara>If a shard cannot be assigned, for example you&#8217;ve overallocated the
number of replicas for the number of nodes in the cluster, the shard
will remain <literal>UNASSIGNED</literal> with the <link linkend="reason-unassigned">reason code</link> <literal>ALLOCATION_FAILED</literal>.</simpara>
<programlisting language="sh" linenumbering="unnumbered">% curl -XPUT 192.168.56.20:9200/_settings -d'{"number_of_replicas":3}'
% curl 192.168.56.20:9200/_cat/health
1384316325 20:18:45 foo yellow 3 3 9 3 0 0 3
% curl 192.168.56.20:9200/_cat/shards
wiki1 0 p STARTED    3014 31.1mb 192.168.56.10 H5dfFeA
wiki1 0 r STARTED    3014 31.1mb 192.168.56.30 bGG90GE
wiki1 0 r STARTED    3014 31.1mb 192.168.56.20 I8hydUG
wiki1 0 r UNASSIGNED ALLOCATION_FAILED
wiki1 1 r STARTED    3013 29.6mb 192.168.56.10 H5dfFeA
wiki1 1 p STARTED    3013 29.6mb 192.168.56.30 bGG90GE
wiki1 1 r STARTED    3013 29.6mb 192.168.56.20 I8hydUG
wiki1 1 r UNASSIGNED ALLOCATION_FAILED
wiki1 2 r STARTED    3973 38.1mb 192.168.56.10 H5dfFeA
wiki1 2 r STARTED    3973 38.1mb 192.168.56.30 bGG90GE
wiki1 2 p STARTED    3973 38.1mb 192.168.56.20 I8hydUG
wiki1 2 r UNASSIGNED ALLOCATION_FAILED</programlisting>
<bridgehead id="reason-unassigned" renderas="sect2">Reasons for unassigned shard<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/shards.asciidoc">Edit me</ulink></bridgehead>
<simpara>These are the possible reasons for a shard be in a unassigned state:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>INDEX_CREATED</literal>
</simpara>
</entry>
<entry>
<simpara>
Unassigned as a result of an API creation of an index.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>CLUSTER_RECOVERED</literal>
</simpara>
</entry>
<entry>
<simpara>
Unassigned as a result of a full cluster recovery.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>INDEX_REOPENED</literal>
</simpara>
</entry>
<entry>
<simpara>
Unassigned as a result of opening a closed index.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>DANGLING_INDEX_IMPORTED</literal>
</simpara>
</entry>
<entry>
<simpara>
Unassigned as a result of importing a dangling index.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>NEW_INDEX_RESTORED</literal>
</simpara>
</entry>
<entry>
<simpara>
Unassigned as a result of restoring into a new index.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>EXISTING_INDEX_RESTORED</literal>
</simpara>
</entry>
<entry>
<simpara>
Unassigned as a result of restoring into a closed index.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>REPLICA_ADDED</literal>
</simpara>
</entry>
<entry>
<simpara>
Unassigned as a result of explicit addition of a replica.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>ALLOCATION_FAILED</literal>
</simpara>
</entry>
<entry>
<simpara>
Unassigned as a result of a failed allocation of the shard.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>NODE_LEFT</literal>
</simpara>
</entry>
<entry>
<simpara>
Unassigned as a result of the node hosting it leaving the cluster.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>REROUTE_CANCELLED</literal>
</simpara>
</entry>
<entry>
<simpara>
Unassigned as a result of explicit cancel reroute command.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>REINITIALIZED</literal>
</simpara>
</entry>
<entry>
<simpara>
When a shard moves from started back to initializing, for example, with shadow replicas.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>REALLOCATED_REPLICA</literal>
</simpara>
</entry>
<entry>
<simpara>
A better replica location is identified and causes the existing replica allocation to be cancelled.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</chapter>
<chapter id="cat-segments">
<title>cat segments<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/segments.asciidoc">Edit me</ulink></title>
<simpara>The <literal>segments</literal> command provides low level information about the segments
in the shards of an index. It provides information similar to the
<ulink url="indices-segments.html">_segments</ulink> endpoint. For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cat/segments?v</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT \/test\/test\/1?refresh\n{"test":"test"}\nPUT \/test1\/test\/1?refresh\n{"test":"test"}\n/]</remark>
<simpara>might look like:</simpara>
<programlisting language="txt" linenumbering="unnumbered">index shard prirep ip        segment generation docs.count docs.deleted size size.memory committed searchable version compound
test  3     p      127.0.0.1 _0               0          1            0  3kb        2042 false     true       6.3.0   true
test1 3     p      127.0.0.1 _0               0          1            0  3kb        2042 false     true       6.3.0   true</programlisting>
<remark> TESTRESPONSE[s/3kb/\\d+(\\.\\d+)?[mk]?b/ s/2042/\\d+/ _cat]</remark>
<simpara>The output shows information about index names and shard numbers in the first
two columns.</simpara>
<simpara>If you only want to get information about segments in one particular index,
you can add the index name in the URL, for example <literal>/_cat/segments/test</literal>. Also,
several indexes can be queried like <literal>/_cat/segments/test,test1</literal></simpara>
<simpara>The following columns provide additional monitoring information:</simpara>
<variablelist>
<varlistentry>
<term>
prirep
</term>
<listitem>
<simpara>
Whether this segment belongs to a primary or replica shard.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
ip
</term>
<listitem>
<simpara>
The ip address of the segments shard.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
segment
</term>
<listitem>
<simpara>
A segment name, derived from the segment generation. The name
                is internally used to generate the file names in the directory
                of the shard this segment belongs to.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
generation
</term>
<listitem>
<simpara>
The generation number is incremented with each segment that is written.
                The name of the segment is derived from this generation number.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
docs.count
</term>
<listitem>
<simpara>
The number of non-deleted documents that are stored in this segment.
                Note that these are Lucene documents, so the count will include hidden
                                documents (e.g. from nested types).
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
docs.deleted
</term>
<listitem>
<simpara>
The number of deleted documents that are stored in this segment.
                It is perfectly fine if this number is greater than 0, space is
                going to be reclaimed when this segment gets merged.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
size
</term>
<listitem>
<simpara>
The amount of disk space that this segment uses.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
size.memory
</term>
<listitem>
<simpara>
Segments store some data into memory in order to be searchable efficiently.
                This column shows the number of bytes in memory that are used.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
committed
</term>
<listitem>
<simpara>
Whether the segment has been sync&#8217;ed on disk. Segments that are
                committed would survive a hard reboot. No need to worry in case
                of false, the data from uncommitted segments is also stored in
                the transaction log so that Elasticsearch is able to replay
                changes on the next start.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
searchable
</term>
<listitem>
<simpara>
True if the segment is searchable. A value of false would most
                likely mean that the segment has been written to disk but no
                refresh occurred since then to make it searchable.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
version
</term>
<listitem>
<simpara>
The version of Lucene that has been used to write this segment.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
compound
</term>
<listitem>
<simpara>
Whether the segment is stored in a compound file. When true, this
                means that Lucene merged all files from the segment in a single
                one in order to save file descriptors.
</simpara>
</listitem>
</varlistentry>
</variablelist>
</chapter>
<chapter id="cat-snapshots">
<title>cat snapshots<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/snapshots.asciidoc">Edit me</ulink></title>
<simpara>The <literal>snapshots</literal> command shows all snapshots that belong to a specific repository.
To find a list of available repositories to query, the command <literal>/_cat/repositories</literal> can be used.
Querying the snapshots of a repository named <literal>repo1</literal> then looks as follows.</simpara>
<programlisting language="sh" linenumbering="unnumbered">% curl 'localhost:9200/_cat/snapshots/repo1?v'
id     status start_epoch start_time end_epoch  end_time duration indices successful_shards failed_shards total_shards
snap1  FAILED 1445616705  18:11:45   1445616978 18:16:18     4.6m       1                 4             1            5
snap2 SUCCESS 1445634298  23:04:58   1445634672 23:11:12     6.2m       2                10             0           10</programlisting>
<simpara>Each snapshot contains information about when it was started and stopped.
Start and stop timestamps are available in two formats.
The <literal>HH:MM:SS</literal> output is simply for quick human consumption.
The epoch time retains more information, including date, and is machine sortable if the snapshot process spans days.</simpara>
</chapter>
<chapter id="cat-templates">
<title>cat templates<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cat/templates.asciidoc">Edit me</ulink></title>
<simpara>The <literal>templates</literal> command provides information about existing templates.</simpara>
<programlisting language="sh" linenumbering="unnumbered">% curl 'localhost:9200/_cat/templates?v=true'
name       template order version
template0 te*      0
template1 tea*     1
template2 teak*    2     7</programlisting>
<simpara>The output shows that there are three existing templates,
with template_2 having a version value.</simpara>
<simpara>The endpoint also supports giving a template name or pattern in the url
to filter the results, for example <literal>/_cat/templates/template*</literal> or
<literal>/_cat/templates/template0</literal>.</simpara>
</chapter>
</part>
<part id="cluster">
<title>Cluster APIs <ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster.asciidoc">Edit me</ulink></title>
<partintro>
<bridgehead id="cluster-nodes" renderas="sect1">Node specification<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster.asciidoc">Edit me</ulink></bridgehead>
<simpara>Most cluster level APIs allow to specify which nodes to execute on (for
example, getting the node stats for a node). Nodes can be identified in
the APIs either using their internal node id, the node name, address,
custom attributes, or just the <literal>_local</literal> node receiving the request. For
example, here are some sample executions of nodes info:</simpara>
<programlisting language="js" linenumbering="unnumbered"># Local
GET /_nodes/_local
# Address
GET /_nodes/10.0.0.3,10.0.0.4
GET /_nodes/10.0.0.*
# Names
GET /_nodes/node_name_goes_here
GET /_nodes/node_name_goes_*
# Attributes (set something like node.attr.rack: 2 in the config)
GET /_nodes/rack:2
GET /_nodes/ra*:2
GET /_nodes/ra*:2*</programlisting>
<remark> CONSOLE</remark>
</partintro>
<chapter id="cluster-health">
<title>Cluster Health<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/health.asciidoc">Edit me</ulink></title>
<simpara>The cluster health API allows to get a very simple status on the health
of the cluster. For example, on a quiet single node cluster with a single index
with 5 shards and one replica, this:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _cluster/health</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT test1\n/]</remark>
<simpara>Returns this:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "cluster_name" : "testcluster",
  "status" : "yellow",
  "timed_out" : false,
  "number_of_nodes" : 1,
  "number_of_data_nodes" : 1,
  "active_primary_shards" : 5,
  "active_shards" : 5,
  "relocating_shards" : 0,
  "initializing_shards" : 0,
  "unassigned_shards" : 5,
  "delayed_unassigned_shards": 0,
  "number_of_pending_tasks" : 0,
  "number_of_in_flight_fetch": 0,
  "task_max_waiting_in_queue_millis": 0,
  "active_shards_percent_as_number": 50.0
}</programlisting>
<remark> TESTRESPONSE[s/testcluster/docs_integTest/]</remark>
<remark> TESTRESPONSE[s/"number_of_pending_tasks" : 0,/"number_of_pending_tasks" : $body.number_of_pending_tasks,/]</remark>
<remark> TESTRESPONSE[s/"task_max_waiting_in_queue_millis": 0/"task_max_waiting_in_queue_millis": $body.task_max_waiting_in_queue_millis/]</remark>
<simpara>The API can also be executed against one or more indices to get just the
specified indices health:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cluster/health/test1,test2</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT test1\nPUT test2\n/]</remark>
<simpara>The cluster health status is: <literal>green</literal>, <literal>yellow</literal> or <literal>red</literal>. On the shard
level, a <literal>red</literal> status indicates that the specific shard is not allocated
in the cluster, <literal>yellow</literal> means that the primary shard is allocated but
replicas are not, and <literal>green</literal> means that all shards are allocated. The
index level status is controlled by the worst shard status. The cluster
status is controlled by the worst index status.</simpara>
<simpara>One of the main benefits of the API is the ability to wait until the
cluster reaches a certain high water-mark health level. For example, the
following will wait for 50 seconds for the cluster to reach the <literal>yellow</literal>
level (if it reaches the <literal>green</literal> or <literal>yellow</literal> status before 50 seconds elapse,
it will return at that point):</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cluster/health?wait_for_status=yellow&amp;timeout=50s</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="request-params" renderas="sect2">Request Parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/health.asciidoc">Edit me</ulink></bridgehead>
<simpara>The cluster health API accepts the following request parameters:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>level</literal>
</term>
<listitem>
<simpara>
    Can be one of <literal>cluster</literal>, <literal>indices</literal> or <literal>shards</literal>. Controls the
    details level of the health information returned. Defaults to <literal>cluster</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>wait_for_status</literal>
</term>
<listitem>
<simpara>
    One of <literal>green</literal>, <literal>yellow</literal> or <literal>red</literal>. Will wait (until
    the timeout provided) until the status of the cluster changes to the one
    provided or better, i.e. <literal>green</literal> &gt; <literal>yellow</literal> &gt; <literal>red</literal>. By default, will not
    wait for any status.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>wait_for_no_relocating_shards</literal>
</term>
<listitem>
<simpara>
    A boolean value which controls whether to wait (until the timeout provided)
    for the cluster to have no shard relocations. Defaults to false, which means
    it will not wait for relocating shards.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>wait_for_active_shards</literal>
</term>
<listitem>
<simpara>
    A number controlling to how many active shards to wait for, <literal>all</literal> to wait
    for all shards in the cluster to be active, or <literal>0</literal> to not wait. Defaults to <literal>0</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>wait_for_nodes</literal>
</term>
<listitem>
<simpara>
    The request waits until the specified number <literal>N</literal> of
    nodes is available. It also accepts <literal>&gt;=N</literal>, <literal>&lt;=N</literal>, <literal>&gt;N</literal> and <literal>&lt;N</literal>.
    Alternatively, it is possible to use <literal>ge(N)</literal>, <literal>le(N)</literal>, <literal>gt(N)</literal> and
    <literal>lt(N)</literal> notation.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>timeout</literal>
</term>
<listitem>
<simpara>
    A time based parameter controlling how long to wait if one of
    the wait_for_XXX are provided. Defaults to <literal>30s</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>local</literal>
</term>
<listitem>
<simpara>
    If <literal>true</literal> returns the local node information and does not provide
    the state from master node. Default: <literal>false</literal>.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>The following is an example of getting the cluster health at the
<literal>shards</literal> level:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_cluster/health/twitter?level=shards</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[setup:twitter]</remark>
</chapter>
<chapter id="cluster-state">
<title>Cluster State<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/state.asciidoc">Edit me</ulink></title>
<simpara>The cluster state API allows to get a comprehensive state information of
the whole cluster.</simpara>
<programlisting language="js" linenumbering="unnumbered">$ curl -XGET 'http://localhost:9200/_cluster/state'</programlisting>
<simpara>By default, the cluster state request is routed to the master node, to
ensure that the latest cluster state is returned.
For debugging purposes, you can retrieve the cluster state local to a
particular node by adding <literal>local=true</literal> to the  query string.</simpara>
<bridgehead id="_response_filters" renderas="sect2">Response Filters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/state.asciidoc">Edit me</ulink></bridgehead>
<simpara>As the cluster state can grow (depending on the number of shards and indices, your mapping, templates),
it is possible to filter the cluster state response specifying the parts in the URL.</simpara>
<programlisting language="js" linenumbering="unnumbered">$ curl -XGET 'http://localhost:9200/_cluster/state/{metrics}/{indices}'</programlisting>
<simpara><literal>metrics</literal> can be a comma-separated list of</simpara>
<variablelist>
<varlistentry>
<term>
<literal>version</literal>
</term>
<listitem>
<simpara>
    Shows the cluster state version.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>master_node</literal>
</term>
<listitem>
<simpara>
    Shows the elected <literal>master_node</literal> part of the response
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>nodes</literal>
</term>
<listitem>
<simpara>
    Shows the <literal>nodes</literal> part of the response
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>routing_table</literal>
</term>
<listitem>
<simpara>
    Shows the <literal>routing_table</literal> part of the response. If you supply a comma separated list of indices, the returned output will only contain the indices listed.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>metadata</literal>
</term>
<listitem>
<simpara>
    Shows the <literal>metadata</literal> part of the response. If you supply a comma separated list of indices, the returned output will only contain the indices listed.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>blocks</literal>
</term>
<listitem>
<simpara>
    Shows the <literal>blocks</literal> part of the response
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>A couple of example calls:</simpara>
<programlisting language="js" linenumbering="unnumbered"># return only metadata and routing_table data for specified indices
$ curl -XGET 'http://localhost:9200/_cluster/state/metadata,routing_table/foo,bar'

# return everything for these two indices
$ curl -XGET 'http://localhost:9200/_cluster/state/_all/foo,bar'

# Return only blocks data
$ curl -XGET 'http://localhost:9200/_cluster/state/blocks'</programlisting>
</chapter>
<chapter id="cluster-stats">
<title>Cluster Stats<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/stats.asciidoc">Edit me</ulink></title>
<simpara>The Cluster Stats API allows to retrieve statistics from a cluster wide perspective.
The API returns basic index metrics (shard numbers, store size, memory usage) and
information about the current nodes that form the cluster (number, roles, os, jvm
versions, memory usage, cpu and installed plugins).</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET 'http://localhost:9200/_cluster/stats?human&amp;pretty'</programlisting>
<simpara>Will return, for example:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "timestamp": 1459427693515,
   "cluster_name": "elasticsearch",
   "status": "green",
   "indices": {
      "count": 2,
      "shards": {
         "total": 10,
         "primaries": 10,
         "replication": 0,
         "index": {
            "shards": {
               "min": 5,
               "max": 5,
               "avg": 5
            },
            "primaries": {
               "min": 5,
               "max": 5,
               "avg": 5
            },
            "replication": {
               "min": 0,
               "max": 0,
               "avg": 0
            }
         }
      },
      "docs": {
         "count": 10,
         "deleted": 0
      },
      "store": {
         "size": "16.2kb",
         "size_in_bytes": 16684,
         "throttle_time": "0s",
         "throttle_time_in_millis": 0
      },
      "fielddata": {
         "memory_size": "0b",
         "memory_size_in_bytes": 0,
         "evictions": 0
      },
      "query_cache": {
         "memory_size": "0b",
         "memory_size_in_bytes": 0,
         "total_count": 0,
         "hit_count": 0,
         "miss_count": 0,
         "cache_size": 0,
         "cache_count": 0,
         "evictions": 0
      },
      "completion": {
         "size": "0b",
         "size_in_bytes": 0
      },
      "segments": {
         "count": 4,
         "memory": "8.6kb",
         "memory_in_bytes": 8898,
         "terms_memory": "6.3kb",
         "terms_memory_in_bytes": 6522,
         "stored_fields_memory": "1.2kb",
         "stored_fields_memory_in_bytes": 1248,
         "term_vectors_memory": "0b",
         "term_vectors_memory_in_bytes": 0,
         "norms_memory": "384b",
         "norms_memory_in_bytes": 384,
         "doc_values_memory": "744b",
         "doc_values_memory_in_bytes": 744,
         "index_writer_memory": "0b",
         "index_writer_memory_in_bytes": 0,
         "version_map_memory": "0b",
         "version_map_memory_in_bytes": 0,
         "fixed_bit_set": "0b",
         "fixed_bit_set_memory_in_bytes": 0,
         "file_sizes": {}
      },
      "percolator": {
         "num_queries": 0
      }
   },
   "nodes": {
      "count": {
         "total": 1,
         "data": 1,
         "coordinating_only": 0,
         "master": 1,
         "ingest": 1
      },
      "versions": [
         "5.1.1"
      ],
      "os": {
         "available_processors": 8,
         "allocated_processors": 8,
         "names": [
            {
               "name": "Mac OS X",
               "count": 1
            }
         ],
         "mem" : {
            "total" : "16gb",
            "total_in_bytes" : 17179869184,
            "free" : "78.1mb",
            "free_in_bytes" : 81960960,
            "used" : "15.9gb",
            "used_in_bytes" : 17097908224,
            "free_percent" : 0,
            "used_percent" : 100
         }
      },
      "process": {
         "cpu": {
            "percent": 9
         },
         "open_file_descriptors": {
            "min": 268,
            "max": 268,
            "avg": 268
         }
      },
      "jvm": {
         "max_uptime": "13.7s",
         "max_uptime_in_millis": 13737,
         "versions": [
            {
               "version": "1.8.0_74",
               "vm_name": "Java HotSpot(TM) 64-Bit Server VM",
               "vm_version": "25.74-b02",
               "vm_vendor": "Oracle Corporation",
               "count": 1
            }
         ],
         "mem": {
            "heap_used": "57.5mb",
            "heap_used_in_bytes": 60312664,
            "heap_max": "989.8mb",
            "heap_max_in_bytes": 1037959168
         },
         "threads": 90
      },
      "fs": {
         "total": "200.6gb",
         "total_in_bytes": 215429193728,
         "free": "32.6gb",
         "free_in_bytes": 35064553472,
         "available": "32.4gb",
         "available_in_bytes": 34802409472
      },
      "plugins": [
         // all plugins installed on nodes
         {
            "name": "analysis-stempel",
            "version": "5.1.1",
            "description": "The Stempel (Polish) Analysis plugin integrates Lucene stempel (polish) analysis module into elasticsearch.",
            "classname": "org.elasticsearch.plugin.analysis.stempel.AnalysisStempelPlugin"
         }
      ]
   }
}</programlisting>
</chapter>
<chapter id="cluster-pending">
<title>Pending cluster tasks<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/pending.asciidoc">Edit me</ulink></title>
<simpara>The pending cluster tasks API returns a list of any cluster-level changes
(e.g. create index, update mapping, allocate or fail shard) which have not yet
been executed.</simpara>
<note><simpara>This API returns a list of any pending updates to the cluster state. These are distinct from the tasks reported by the
<link linkend="tasks">Task Management API</link> which include periodic tasks and tasks initiated by the user, such as node stats, search queries, or create
index requests. However, if a user-initiated task such as a create index command causes a cluster state update, the activity of this task
might be reported by both task api and pending cluster tasks API.</simpara></note>
<programlisting language="js" linenumbering="unnumbered">$ curl -XGET 'http://localhost:9200/_cluster/pending_tasks'</programlisting>
<simpara>Usually this will return an empty list as cluster-level changes are usually
fast. However if there are tasks queued up, the output will look something
like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "tasks": [
      {
         "insert_order": 101,
         "priority": "URGENT",
         "source": "create-index [foo_9], cause [api]",
         "time_in_queue_millis": 86,
         "time_in_queue": "86ms"
      },
      {
         "insert_order": 46,
         "priority": "HIGH",
         "source": "shard-started ([foo_2][1], node[tMTocMvQQgGCkj7QDHl3OA], [P], s[INITIALIZING]), reason [after recovery from shard_store]",
         "time_in_queue_millis": 842,
         "time_in_queue": "842ms"
      },
      {
         "insert_order": 45,
         "priority": "HIGH",
         "source": "shard-started ([foo_2][0], node[tMTocMvQQgGCkj7QDHl3OA], [P], s[INITIALIZING]), reason [after recovery from shard_store]",
         "time_in_queue_millis": 858,
         "time_in_queue": "858ms"
      }
  ]
}</programlisting>
</chapter>
<chapter id="cluster-reroute">
<title>Cluster Reroute<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/reroute.asciidoc">Edit me</ulink></title>
<simpara>The reroute command allows to explicitly execute a cluster reroute
allocation command including specific commands. For example, a shard can
be moved from one node to another explicitly, an allocation can be
canceled, or an unassigned shard can be explicitly allocated on a
specific node.</simpara>
<simpara>Here is a short example of how a simple reroute API call:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XPOST 'localhost:9200/_cluster/reroute' -d '{
    "commands" : [ {
        "move" :
            {
              "index" : "test", "shard" : 0,
              "from_node" : "node1", "to_node" : "node2"
            }
        },
        {
          "allocate_replica" : {
              "index" : "test", "shard" : 1, "node" : "node3"
          }
        }
    ]
}'</programlisting>
<simpara>An important aspect to remember is the fact that once when an allocation
occurs, the cluster will aim at re-balancing its state back to an even
state. For example, if the allocation includes moving a shard from
<literal>node1</literal> to <literal>node2</literal>, in an <literal>even</literal> state, then another shard will be moved
from <literal>node2</literal> to <literal>node1</literal> to even things out.</simpara>
<simpara>The cluster can be set to disable allocations, which means that only the
explicitly allocations will be performed. Obviously, only once all
commands has been applied, the cluster will aim to be re-balance its
state.</simpara>
<simpara>Another option is to run the commands in <literal>dry_run</literal> (as a URI flag, or in
the request body). This will cause the commands to apply to the current
cluster state, and return the resulting cluster after the commands (and
re-balancing) has been applied.</simpara>
<simpara>If the <literal>explain</literal> parameter is specified, a detailed explanation of why the
commands could or could not be executed is returned.</simpara>
<simpara>The commands supported are:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>move</literal>
</term>
<listitem>
<simpara>
    Move a started shard from one node to another node. Accepts
    <literal>index</literal> and <literal>shard</literal> for index name and shard number, <literal>from_node</literal> for the
    node to move the shard <literal>from</literal>, and <literal>to_node</literal> for the node to move the
    shard to.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>cancel</literal>
</term>
<listitem>
<simpara>
    Cancel allocation of a shard (or recovery). Accepts <literal>index</literal>
    and <literal>shard</literal> for index name and shard number, and <literal>node</literal> for the node to
    cancel the shard allocation on. It also accepts <literal>allow_primary</literal> flag to
    explicitly specify that it is allowed to cancel allocation for a primary
    shard.  This can be used to force resynchronization of existing replicas
    from the primary shard by cancelling them and allowing them to be
    reinitialized through the standard reallocation process.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>allocate_replica</literal>
</term>
<listitem>
<simpara>
    Allocate an unassigned replica shard to a node. Accepts the
    <literal>index</literal> and <literal>shard</literal> for index name and shard number, and <literal>node</literal> to
    allocate the shard to. Takes <link linkend="modules-cluster">allocation deciders</link> into account.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>Two more commands are available that allow the allocation of a primary shard
to a node. These commands should however be used with extreme care, as primary
shard allocation is usually fully automatically handled by Elasticsearch.
Reasons why a primary shard cannot be automatically allocated include the following:</simpara>
<itemizedlist>
<listitem>
<simpara>
A new index was created but there is no node which satisfies the allocation deciders.
</simpara>
</listitem>
<listitem>
<simpara>
An up-to-date shard copy of the data cannot be found on the current data nodes in
the cluster. To prevent data loss, the system does not automatically promote a stale
shard copy to primary.
</simpara>
</listitem>
</itemizedlist>
<simpara>As a manual override, two commands to forcefully allocate primary shards
are available:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>allocate_stale_primary</literal>
</term>
<listitem>
<simpara>
    Allocate a primary shard to a node that holds a stale copy. Accepts the
    <literal>index</literal> and <literal>shard</literal> for index name and shard number, and <literal>node</literal> to
    allocate the shard to. Using this command may lead to data loss
    for the provided shard id. If a node which has the good copy of the
    data rejoins the cluster later on, that data will be overwritten with
    the data of the stale copy that was forcefully allocated with this
    command. To ensure that these implications are well-understood,
    this command requires the special field <literal>accept_data_loss</literal> to be
    explicitly set to <literal>true</literal> for it to work.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>allocate_empty_primary</literal>
</term>
<listitem>
<simpara>
    Allocate an empty primary shard to a node. Accepts the
    <literal>index</literal> and <literal>shard</literal> for index name and shard number, and <literal>node</literal> to
    allocate the shard to. Using this command leads to a complete loss
    of all data that was indexed into this shard, if it was previously
    started. If a node which has a copy of the
    data rejoins the cluster later on, that data will be deleted!
    To ensure that these implications are well-understood,
    this command requires the special field <literal>accept_data_loss</literal> to be
    explicitly set to <literal>true</literal> for it to work.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_retry_failed_shards" renderas="sect2">Retry failed shards<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/reroute.asciidoc">Edit me</ulink></bridgehead>
<simpara>The cluster will attempt to allocate a shard a maximum of
<literal>index.allocation.max_retries</literal> times in a row (defaults to <literal>5</literal>), before giving
up and leaving the shard unallocated. This scenario can be caused by
structural problems such as having an analyzer which refers to a stopwords
file which doesn&#8217;t exist on all nodes.</simpara>
<simpara>Once the problem has been corrected, allocation can be manually retried by
calling the <link linkend="cluster-reroute"><literal>_reroute</literal></link> API with <literal>?retry_failed</literal>, which
will attempt a single retry round for these shards.</simpara>
</chapter>
<chapter id="cluster-update-settings">
<title>Cluster Update Settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/update-settings.asciidoc">Edit me</ulink></title>
<simpara>Allows to update cluster wide specific settings. Settings updated can
either be persistent (applied cross restarts) or transient (will not
survive a full cluster restart). Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XPUT localhost:9200/_cluster/settings -d '{
    "persistent" : {
        "discovery.zen.minimum_master_nodes" : 2
    }
}'</programlisting>
<simpara>Or:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XPUT localhost:9200/_cluster/settings -d '{
    "transient" : {
        "discovery.zen.minimum_master_nodes" : 2
    }
}'</programlisting>
<simpara>The cluster responds with the settings updated. So the response for the
last example will be:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "persistent" : {},
    "transient" : {
        "discovery.zen.minimum_master_nodes" : "2"
    }
}'</programlisting>
<simpara>Resetting persistent or transient settings can be done by assigning a
<literal>null</literal> value. If a transient setting is reset, the persistent setting
is applied if available. Otherwise Elasticsearch will fallback to the setting
defined at the configuration file or, if not existent, to the default
value. Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XPUT localhost:9200/_cluster/settings -d '{
    "transient" : {
        "discovery.zen.minimum_master_nodes" : null
    }
}'</programlisting>
<simpara>Reset settings will not be included in the cluster response. So
the response for the last example will be:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "persistent" : {},
    "transient" : {}
}</programlisting>
<simpara>Settings can also be reset using simple wildcards. For instance to reset
all dynamic <literal>discovery.zen</literal> setting a prefix can be used:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XPUT localhost:9200/_cluster/settings -d '{
    "transient" : {
        "discovery.zen.*" : null
    }
}'</programlisting>
<simpara>Cluster wide settings can be returned using:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET localhost:9200/_cluster/settings</programlisting>
<bridgehead id="_precedence_of_settings" renderas="sect2">Precedence of settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/update-settings.asciidoc">Edit me</ulink></bridgehead>
<simpara>Transient cluster settings take precedence over persistent cluster settings,
which take precedence over settings configured in the <literal>elasticsearch.yml</literal>
config file.</simpara>
<simpara>For this reason it is preferrable to  use the <literal>elasticsearch.yml</literal> file only
for local configurations, and set all cluster-wider settings with the
<literal>settings</literal> API.</simpara>
<simpara>A list of dynamically updatable settings can be found in the
<link linkend="modules">Modules</link> documentation.</simpara>
</chapter>
<chapter id="cluster-nodes-stats">
<title>Nodes Stats<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/nodes-stats.asciidoc">Edit me</ulink></title>
<bridgehead id="_nodes_statistics" renderas="sect2">Nodes statistics<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/nodes-stats.asciidoc">Edit me</ulink></bridgehead>
<simpara>The cluster nodes stats API allows to retrieve one or more (or all) of
the cluster nodes statistics.</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET 'http://localhost:9200/_nodes/stats'
curl -XGET 'http://localhost:9200/_nodes/nodeId1,nodeId2/stats'</programlisting>
<simpara>The first command retrieves stats of all the nodes in the cluster. The
second command selectively retrieves nodes stats of only <literal>nodeId1</literal> and
<literal>nodeId2</literal>. All the nodes selective options are explained
<link linkend="cluster-nodes">here</link>.</simpara>
<simpara>By default, all stats are returned. You can limit this by combining any
of <literal>indices</literal>, <literal>os</literal>, <literal>process</literal>, <literal>jvm</literal>, <literal>transport</literal>, <literal>http</literal>,
<literal>fs</literal>, <literal>breaker</literal> and <literal>thread_pool</literal>. For example:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>indices</literal>
</simpara>
</entry>
<entry>
<simpara>
        Indices stats about size, document count, indexing and
        deletion times, search times, field cache size, merges and flushes
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>fs</literal>
</simpara>
</entry>
<entry>
<simpara>
        File system information, data path, free disk space, read/write
        stats (see <link linkend="fs-info">FS information</link>)
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>http</literal>
</simpara>
</entry>
<entry>
<simpara>
        HTTP connection information
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>jvm</literal>
</simpara>
</entry>
<entry>
<simpara>
        JVM stats, memory pool information, garbage collection, buffer
        pools, number of loaded/unloaded classes
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>os</literal>
</simpara>
</entry>
<entry>
<simpara>
        Operating system stats, load average, mem, swap
        (see <link linkend="os-stats">OS statistics</link>)
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>process</literal>
</simpara>
</entry>
<entry>
<simpara>
        Process statistics, memory consumption, cpu usage, open
        file descriptors (see <link linkend="process-stats">Process statistics</link>)
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>thread_pool</literal>
</simpara>
</entry>
<entry>
<simpara>
        Statistics about each thread pool, including current
        size, queue and rejected tasks
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>transport</literal>
</simpara>
</entry>
<entry>
<simpara>
        Transport statistics about sent and received bytes in
        cluster communication
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>breaker</literal>
</simpara>
</entry>
<entry>
<simpara>
        Statistics about the field data circuit breaker
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>discovery</literal>
</simpara>
</entry>
<entry>
<simpara>
        Statistics about the discovery
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>ingest</literal>
</simpara>
</entry>
<entry>
<simpara>
    Statistics about ingest preprocessing
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<programlisting language="js" linenumbering="unnumbered"># return just indices
curl -XGET 'http://localhost:9200/_nodes/stats/indices'
# return just os and process
curl -XGET 'http://localhost:9200/_nodes/stats/os,process'
# return just process for node with IP address 10.0.0.1
curl -XGET 'http://localhost:9200/_nodes/10.0.0.1/stats/process'</programlisting>
<simpara>All stats can be explicitly requested via <literal>/_nodes/stats/_all</literal> or <literal>/_nodes/stats?metric=_all</literal>.</simpara>
<bridgehead id="fs-info" renderas="sect3">FS information<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/nodes-stats.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>fs</literal> flag can be set to retrieve
information that concern the file system:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>fs.timestamp</literal>
</term>
<listitem>
<simpara>
        Last time the file stores statistics have been refreshed
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fs.total.total_in_bytes</literal>
</term>
<listitem>
<simpara>
        Total size (in bytes) of all file stores
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fs.total.free_in_bytes</literal>
</term>
<listitem>
<simpara>
        Total number of unallocated bytes in all file stores
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fs.total.available_in_bytes</literal>
</term>
<listitem>
<simpara>
        Total number of bytes available to this Java virtual machine on all file stores
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fs.data</literal>
</term>
<listitem>
<simpara>
        List of all file stores
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fs.data.path</literal>
</term>
<listitem>
<simpara>
        Path to the file store
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fs.data.mount</literal>
</term>
<listitem>
<simpara>
        Mount point of the file store (ex: /dev/sda2)
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fs.data.type</literal>
</term>
<listitem>
<simpara>
        Type of the file store (ex: ext4)
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fs.data.total_in_bytes</literal>
</term>
<listitem>
<simpara>
        Total size (in bytes) of the file store
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fs.data.free_in_bytes</literal>
</term>
<listitem>
<simpara>
        Total number of unallocated bytes in the file store
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fs.data.available_in_bytes</literal>
</term>
<listitem>
<simpara>
        Total number of bytes available to this Java virtual machine on this file store
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fs.data.spins</literal> (Linux only)
</term>
<listitem>
<simpara>
        Indicates if the file store is backed by spinning storage.
        <literal>null</literal> means we could not determine it, <literal>true</literal> means the device possibly spins
         and <literal>false</literal> means it does not (ex: solid-state disks).
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fs.io_stats.devices</literal> (Linux only)
</term>
<listitem>
<simpara>
    Array of disk metrics for each device that is backing an
    Elasticsearch data path. These disk metrics are probed periodically
    and averages between the last probe and the current probe are
    computed.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fs.io_stats.devices.device_name</literal> (Linux only)
</term>
<listitem>
<simpara>
    The Linux device name.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fs.io_stats.devices.operations</literal> (Linux only)
</term>
<listitem>
<simpara>
    The total number of read and write operations for the device
    completed since starting Elasticsearch.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fs.io_stats.devices.read_operations</literal> (Linux only)
</term>
<listitem>
<simpara>
    The total number of read operations for the device completed since
    starting Elasticsearch.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fs.io_stats.devices.write_operations</literal> (Linux only)
</term>
<listitem>
<simpara>
    The total number of write operations for the device completed since
    starting Elasticsearch.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fs.io_stats.devices.read_kilobytes</literal> (Linux only)
</term>
<listitem>
<simpara>
    The total number of kilobytes read for the device since starting
    Elasticsearch.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fs.io_stats.devices.write_kilobytes</literal> (Linux only)
</term>
<listitem>
<simpara>
    The total number of kilobytes written for the device since
    starting Elasticsearch.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fs.io_stats.operations</literal> (Linux only)
</term>
<listitem>
<simpara>
    The total number of read and write operations across all devices
    used by Elasticsearch completed since starting Elasticsearch.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fs.io_stats.read_operations</literal> (Linux only)
</term>
<listitem>
<simpara>
    The total number of read operations for across all devices used by
    Elasticsearch completed since starting Elasticsearch.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fs.io_stats.write_operations</literal> (Linux only)
</term>
<listitem>
<simpara>
    The total number of write operations across all devices used by
    Elasticsearch completed since starting Elasticsearch.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fs.io_stats.read_kilobytes</literal> (Linux only)
</term>
<listitem>
<simpara>
    The total number of kilobytes read across all devices used by
    Elasticsearch since starting Elasticsearch.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fs.io_stats.write_kilobytes</literal> (Linux only)
</term>
<listitem>
<simpara>
    The total number of kilobytes written across all devices used by
    Elasticsearch since starting Elasticsearch.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="os-stats" renderas="sect3">Operating System statistics<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/nodes-stats.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>os</literal> flag can be set to retrieve statistics that concern
the operating system:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>os.timestamp</literal>
</term>
<listitem>
<simpara>
        Last time the operating system statistics have been refreshed
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.cpu.percent</literal>
</term>
<listitem>
<simpara>
    Recent CPU usage for the whole system, or -1 if not supported
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.cpu.load_average.1m</literal>
</term>
<listitem>
<simpara>
    One-minute load average on the system (field is not present if
    one-minute load average is not available)
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.cpu.load_average.5m</literal>
</term>
<listitem>
<simpara>
    Five-minute load average on the system (field is not present if
    five-minute load average is not available)
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.cpu.load_average.15m</literal>
</term>
<listitem>
<simpara>
    Fifteen-minute load average on the system (field is not present if
    fifteen-minute load average is not available)
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.mem.total_in_bytes</literal>
</term>
<listitem>
<simpara>
        Total amount of physical memory in bytes
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.mem.free_in_bytes</literal>
</term>
<listitem>
<simpara>
        Amount of free physical memory in bytes
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.mem.free_percent</literal>
</term>
<listitem>
<simpara>
        Percentage of free memory
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.mem.used_in_bytes</literal>
</term>
<listitem>
<simpara>
        Amount of used physical memory in bytes
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.mem.used_percent</literal>
</term>
<listitem>
<simpara>
        Percentage of used memory
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.swap.total_in_bytes</literal>
</term>
<listitem>
<simpara>
        Total amount of swap space in bytes
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.swap.free_in_bytes</literal>
</term>
<listitem>
<simpara>
        Amount of free swap space in bytes
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.swap.used_in_bytes</literal>
</term>
<listitem>
<simpara>
        Amount of used swap space in bytes
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.cgroup.cpuacct.control_group</literal> (Linux only)
</term>
<listitem>
<simpara>
    The <literal>cpuacct</literal> control group to which the Elasticsearch process
    belongs
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.cgroup.cpuacct.usage</literal> (Linux only)
</term>
<listitem>
<simpara>
    The total CPU time (in nanoseconds) consumed by all tasks in the
    same cgroup as the Elasticsearch process
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.cgroup.cpu.control_group</literal> (Linux only)
</term>
<listitem>
<simpara>
    The <literal>cpu</literal> control group to which the Elasticsearch process belongs
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.cgroup.cpu.cfs_period_micros</literal> (Linux only)
</term>
<listitem>
<simpara>
    The period of time (in microseconds) for how regularly all tasks in
    the same cgroup as the Elasticsearch process should have their
    access to CPU resources reallocated.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.cgroup.cpu.cfs_quota_micros</literal> (Linux only)
</term>
<listitem>
<simpara>
    The total amount of time (in microseconds) for which all tasks in
    the same cgroup as the Elasticsearch process can run during one
    period <literal>os.cgroup.cpu.cfs_period_micros</literal>
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.cgroup.cpu.stat.number_of_elapsed_periods</literal> (Linux only)
</term>
<listitem>
<simpara>
    The number of reporting periods (as specified by
    <literal>os.cgroup.cpu.cfs_period_micros</literal>) that have elapsed
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.cgroup.cpu.stat.number_of_times_throttled</literal> (Linux only)
</term>
<listitem>
<simpara>
    The number of times all tasks in the same cgroup as the
    Elasticsearch process have been throttled.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.cgroup.cpu.stat.time_throttled_nanos</literal> (Linux only)
</term>
<listitem>
<simpara>
    The total amount of time (in nanoseconds) for which all tasks in
    the same cgroup as the Elasticsearch process have been throttled.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<note><simpara>For the cgroup stats to be visible, cgroups must be compiled into
the kernal, the <literal>cpu</literal> and <literal>cpuacct</literal> cgroup subsystems must be
configured and stats must be readable from <literal>/sys/fs/cgroup/cpu</literal>
and <literal>/sys/fs/cgroup/cpuacct</literal>.</simpara></note>
<bridgehead id="process-stats" renderas="sect3">Process statistics<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/nodes-stats.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>process</literal> flag can be set to retrieve statistics that concern
the current running process:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>process.timestamp</literal>
</term>
<listitem>
<simpara>
        Last time the process statistics have been refreshed
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>process.open_file_descriptors</literal>
</term>
<listitem>
<simpara>
        Number of opened file descriptors associated with the current process, or -1 if not supported
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>process.max_file_descriptors</literal>
</term>
<listitem>
<simpara>
        Maximum number of file descriptors allowed on the system, or -1 if not supported
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>process.cpu.percent</literal>
</term>
<listitem>
<simpara>
        CPU usage in percent, or -1 if not known at the time the stats are computed
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>process.cpu.total_in_millis</literal>
</term>
<listitem>
<simpara>
        CPU time (in milliseconds) used by the process on which the Java virtual machine is running, or -1 if not supported
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>process.mem.total_virtual_in_bytes</literal>
</term>
<listitem>
<simpara>
        Size in bytes of virtual memory that is guaranteed to be available to the running process
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="node-indices-stats" renderas="sect2">Indices statistics<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/nodes-stats.asciidoc">Edit me</ulink></bridgehead>
<simpara>You can get information about indices stats on node level or on index level.</simpara>
<programlisting language="js" linenumbering="unnumbered"># Node level
curl -XGET 'http://localhost:9200/_nodes/stats/indices/fielddata?fields=field1,field2&amp;pretty'

# Index level
curl -XGET 'http://localhost:9200/_stats/fielddata/?fields=field1,field2&amp;pretty'

# You can use wildcards for field names
curl -XGET 'http://localhost:9200/_nodes/stats/indices/fielddata?fields=field*&amp;pretty'
curl -XGET 'http://localhost:9200/_stats/fielddata/?fields=field*&amp;pretty'</programlisting>
<simpara>Supported metrics are:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>completion</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>docs</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>fielddata</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>flush</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>get</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>indexing</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>merge</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>query_cache</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>recovery</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>refresh</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>request_cache</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>search</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>segments</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>store</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>suggest</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>translog</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>warmer</literal>
</simpara>
</listitem>
</itemizedlist>
<bridgehead id="search-groups" renderas="sect2">Search groups<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/nodes-stats.asciidoc">Edit me</ulink></bridgehead>
<simpara>You can get statistics about search groups for searches executed
on this node.</simpara>
<programlisting language="js" linenumbering="unnumbered"># All groups with all stats
curl -XGET 'http://localhost:9200/_nodes/stats?pretty&amp;groups=_all'

# Some groups from just the indices stats
curl -XGET 'http://localhost:9200/_nodes/stats/indices?pretty&amp;groups=foo,bar'</programlisting>
<bridgehead id="ingest-stats" renderas="sect2">Ingest statistics<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/nodes-stats.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>ingest</literal> flag can be set to retrieve statistics that concern ingest:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>ingest.total.count</literal>
</term>
<listitem>
<simpara>
    The total number of document ingested during the lifetime of this node
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>ingest.total.time_in_millis</literal>
</term>
<listitem>
<simpara>
    The total time spent on ingest preprocessing documents during the lifetime of this node
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>ingest.total.current</literal>
</term>
<listitem>
<simpara>
    The total number of documents currently being ingested.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>ingest.total.failed</literal>
</term>
<listitem>
<simpara>
    The total number ingest preprocessing operations failed during the lifetime of this node
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>On top of these overall ingest statistics, these statistics are also provided on a per pipeline basis.</simpara>
</chapter>
<chapter id="cluster-nodes-info">
<title>Nodes Info<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/nodes-info.asciidoc">Edit me</ulink></title>
<simpara>The cluster nodes info API allows to retrieve one or more (or all) of
the cluster nodes information.</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET 'http://localhost:9200/_nodes'
curl -XGET 'http://localhost:9200/_nodes/nodeId1,nodeId2'</programlisting>
<simpara>The first command retrieves information of all the nodes in the cluster.
The second command selectively retrieves nodes information of only
<literal>nodeId1</literal> and <literal>nodeId2</literal>. All the nodes selective options are explained
<link linkend="cluster-nodes">here</link>.</simpara>
<simpara>By default, it just returns all attributes and core settings for a node:</simpara>
<variablelist id="core-info">
<varlistentry>
<term>
<literal>build_hash</literal>
</term>
<listitem>
<simpara>
        Short hash of the last git commit in this release.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>host</literal>
</term>
<listitem>
<simpara>
        The node&#8217;s host name.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>http_address</literal>
</term>
<listitem>
<simpara>
        Host and port where primary HTTP connections are accepted.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>ip</literal>
</term>
<listitem>
<simpara>
        The node&#8217;s IP address.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>name</literal>
</term>
<listitem>
<simpara>
        The node&#8217;s name.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>total_indexing_buffer</literal>
</term>
<listitem>
<simpara>
        Total heap allowed to be used to hold recently indexed
        documents before they must be written to disk.  This size is
        a shared pool across all shards on this node, and is
        controlled by <link linkend="indexing-buffer">Indexing Buffer settings</link>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>total_indexing_buffer_in_bytes</literal>
</term>
<listitem>
<simpara>
        Same as <literal>total_indexing_buffer</literal>, but expressed in bytes.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>transport_address</literal>
</term>
<listitem>
<simpara>
        Host and port where transport HTTP connections are accepted.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>version</literal>
</term>
<listitem>
<simpara>
        Elasticsearch version running on this node.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>It also allows to get only information on <literal>settings</literal>, <literal>os</literal>, <literal>process</literal>, <literal>jvm</literal>,
<literal>thread_pool</literal>, <literal>transport</literal>, <literal>http</literal>, <literal>plugins</literal>, <literal>ingest</literal> and <literal>indices</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XGET 'http://localhost:9200/_nodes/process'
curl -XGET 'http://localhost:9200/_nodes/_all/process'
curl -XGET 'http://localhost:9200/_nodes/nodeId1,nodeId2/jvm,process'
# same as above
curl -XGET 'http://localhost:9200/_nodes/nodeId1,nodeId2/info/jvm,process'

curl -XGET 'http://localhost:9200/_nodes/nodeId1,nodeId2/_all</programlisting>
<simpara>The <literal>_all</literal> flag can be set to return all the information - or you can simply omit it.</simpara>
<bridgehead id="os-info" renderas="sect3">Operating System information<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/nodes-info.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>os</literal> flag can be set to retrieve information that concern
the operating system:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>os.refresh_interval_in_millis</literal>
</term>
<listitem>
<simpara>
        Refresh interval for the OS statistics
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.name</literal>
</term>
<listitem>
<simpara>
        Name of the operating system (ex: Linux, Windows, Mac OS X)
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.arch</literal>
</term>
<listitem>
<simpara>
        Name of the JVM architecture (ex: amd64, x86)
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.version</literal>
</term>
<listitem>
<simpara>
        Version of the operating system
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.available_processors</literal>
</term>
<listitem>
<simpara>
        Number of processors available to the Java virtual machine
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>os.allocated_processors</literal>
</term>
<listitem>
<simpara>
    The number of processors actually used to calculate thread pool size. This number can be set
    with the <literal>processors</literal> setting of a node and defaults to the number of processors reported by the OS.
    In both cases this number will never be larger than 32.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="process-info" renderas="sect3">Process information<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/nodes-info.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>process</literal> flag can be set to retrieve information that concern
the current running process:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>process.refresh_interval_in_millis</literal>
</term>
<listitem>
<simpara>
        Refresh interval for the process statistics
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>process.id</literal>
</term>
<listitem>
<simpara>
        Process identifier (PID)
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>process.mlockall</literal>
</term>
<listitem>
<simpara>
        Indicates if the process address space has been successfully locked in memory
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="plugins-info" renderas="sect3">Plugins information<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/nodes-info.asciidoc">Edit me</ulink></bridgehead>
<simpara><literal>plugins</literal> - if set, the result will contain details about the loaded
plugins per node:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>name</literal>: plugin name
</simpara>
</listitem>
<listitem>
<simpara>
<literal>description</literal>: plugin description if any
</simpara>
</listitem>
<listitem>
<simpara>
<literal>site</literal>: <literal>true</literal> if the plugin is a site plugin
</simpara>
</listitem>
<listitem>
<simpara>
<literal>jvm</literal>: <literal>true</literal> if the plugin is a plugin running in the JVM
</simpara>
</listitem>
<listitem>
<simpara>
<literal>url</literal>: URL if the plugin is a site plugin
</simpara>
</listitem>
</itemizedlist>
<simpara>The result will look similar to:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "cluster_name" : "test-cluster-MacBook-Air-de-David.local",
  "nodes" : {
    "hJLXmY_NTrCytiIMbX4_1g" : {
      "name" : "node4",
      "transport_address" : "inet[/172.18.58.139:9303]",
      "hostname" : "MacBook-Air-de-David.local",
      "version" : "0.90.0.Beta2-SNAPSHOT",
      "http_address" : "inet[/172.18.58.139:9203]",
      "plugins" : [ {
        "name" : "test-plugin",
        "description" : "test-plugin description",
        "site" : true,
        "jvm" : false
      }, {
        "name" : "test-no-version-plugin",
        "description" : "test-no-version-plugin description",
        "site" : true,
        "jvm" : false
      }, {
        "name" : "dummy",
        "description" : "No description found for dummy.",
        "url" : "/_plugin/dummy/",
        "site" : false,
        "jvm" : true
      } ]
    }
  }
}</programlisting>
<bridgehead id="ingest-info" renderas="sect3">Ingest information<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/nodes-info.asciidoc">Edit me</ulink></bridgehead>
<simpara><literal>ingest</literal> - if set, the result will contain details about the available
processors per node:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>type</literal>: the processor type
</simpara>
</listitem>
</itemizedlist>
<simpara>The result will look similar to:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "cluster_name": "elasticsearch",
  "nodes": {
    "O70_wBv6S9aPPcAKdSUBtw": {
      "ingest": {
        "processors": [
          {
            "type": "date"
          },
          {
            "type": "uppercase"
          },
          {
            "type": "set"
          },
          {
            "type": "lowercase"
          },
          {
            "type": "gsub"
          },
          {
            "type": "convert"
          },
          {
            "type": "remove"
          },
          {
            "type": "fail"
          },
          {
            "type": "foreach"
          },
          {
            "type": "split"
          },
          {
            "type": "trim"
          },
          {
            "type": "rename"
          },
          {
            "type": "join"
          },
          {
            "type": "append"
          }
        ]
      }
    }
  }
}</programlisting>
</chapter>
<chapter id="tasks">
<title>Task Management API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/tasks.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>The Task Management API is new and should still be considered experimental.  The API may change in ways that are not backwards compatible.</simpara></warning>
<bridgehead id="_current_tasks_information" renderas="sect2">Current Tasks Information<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/tasks.asciidoc">Edit me</ulink></bridgehead>
<simpara>The task management API allows to retrieve information about the tasks currently
executing on one or more nodes in the cluster.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _tasks <co id="CO130-1"/>
GET _tasks?nodes=nodeId1,nodeId2 <co id="CO130-2"/>
GET _tasks?nodes=nodeId1,nodeId2&amp;actions=cluster:* <co id="CO130-3"/></programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO130-1">
<para>
Retrieves all tasks currently running on all nodes in the cluster.
</para>
</callout>
<callout arearefs="CO130-2">
<para>
Retrieves all tasks running on nodes <literal>nodeId1</literal> and <literal>nodeId2</literal>.  See <xref linkend="cluster-nodes"/> for more info about how to select individual nodes.
</para>
</callout>
<callout arearefs="CO130-3">
<para>
Retrieves all cluster-related tasks running on nodes <literal>nodeId1</literal> and <literal>nodeId2</literal>.
</para>
</callout>
</calloutlist>
<simpara>The result will look similar to the following:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "nodes" : {
    "oTUltX4IQMOUUVeiohTt8A" : {
      "name" : "H5dfFeA",
      "transport_address" : "127.0.0.1:9300",
      "host" : "127.0.0.1",
      "ip" : "127.0.0.1:9300",
      "tasks" : {
        "oTUltX4IQMOUUVeiohTt8A:124" : {
          "node" : "oTUltX4IQMOUUVeiohTt8A",
          "id" : 124,
          "type" : "direct",
          "action" : "cluster:monitor/tasks/lists[n]",
          "start_time_in_millis" : 1458585884904,
          "running_time_in_nanos" : 47402,
          "cancellable" : false,
          "parent_task_id" : "oTUltX4IQMOUUVeiohTt8A:123"
        },
        "oTUltX4IQMOUUVeiohTt8A:123" : {
          "node" : "oTUltX4IQMOUUVeiohTt8A",
          "id" : 123,
          "type" : "transport",
          "action" : "cluster:monitor/tasks/lists",
          "start_time_in_millis" : 1458585884904,
          "running_time_in_nanos" : 236042,
          "cancellable" : false
        }
      }
    }
  }
}</programlisting>
<simpara>It is also possible to retrieve information for a particular task:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _tasks/task_id:1 <co id="CO131-1"/></programlisting>
<remark> CONSOLE</remark>
<remark> TEST[catch:missing]</remark>
<calloutlist>
<callout arearefs="CO131-1">
<para>
This will return a 404 if the task isn&#8217;t found.
</para>
</callout>
</calloutlist>
<simpara>Or to retrieve all children of a particular task:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _tasks?parent_task_id=parentTaskId:1 <co id="CO132-1"/></programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO132-1">
<para>
This won&#8217;t return a 404 if the parent isn&#8217;t found.
</para>
</callout>
</calloutlist>
<simpara>The task API can be also used to wait for completion of a particular task. The following call will
block for 10 seconds or until the task with id <literal>oTUltX4IQMOUUVeiohTt8A:12345</literal> is completed.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _tasks/oTUltX4IQMOUUVeiohTt8A:12345?wait_for_completion=true&amp;timeout=10s</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[catch:missing]</remark>
<simpara>You can also wait for all tasks for certain action types to finish. This
command will wait for all <literal>reindex</literal> tasks to finish:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _tasks?actions=*reindex&amp;wait_for_completion=true&amp;timeout=10s</programlisting>
<remark> CONSOLE</remark>
<simpara>Tasks can be also listed using _cat version of the list tasks command, which accepts the same arguments
as the standard list tasks command.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _cat/tasks</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="task-cancellation" renderas="sect2">Task Cancellation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/tasks.asciidoc">Edit me</ulink></bridgehead>
<simpara>If a long-running task supports cancellation, it can be cancelled by the following command:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _tasks/task_id:1/_cancel</programlisting>
<remark> CONSOLE</remark>
<simpara>The task cancellation command supports the same task selection parameters as the list tasks command, so multiple tasks
can be cancelled at the same time. For example, the following command will cancel all reindex tasks running on the
nodes <literal>nodeId1</literal> and <literal>nodeId2</literal>.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _tasks/_cancel?nodes=nodeId1,nodeId2&amp;actions=*reindex</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_task_grouping" renderas="sect2">Task Grouping<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/tasks.asciidoc">Edit me</ulink></bridgehead>
<simpara>The task lists returned by task API commands can be grouped either by nodes (default) or by parent tasks using the <literal>group_by</literal> parameter.
The following command will change the grouping to parent tasks:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _tasks?group_by=parents</programlisting>
<remark> CONSOLE</remark>
</chapter>
<chapter id="cluster-nodes-hot-threads">
<title>Nodes hot_threads<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/nodes-hot-threads.asciidoc">Edit me</ulink></title>
<simpara>An API allowing to get the current hot threads on each node in the
cluster. Endpoints are <literal>/_nodes/hot_threads</literal>, and
<literal>/_nodes/{nodesIds}/hot_threads</literal>.</simpara>
<simpara>The output is plain text with a breakdown of each node&#8217;s top hot
threads. Parameters allowed are:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>threads</literal>
</simpara>
</entry>
<entry>
<simpara>
number of hot threads to provide, defaults to 3.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>interval</literal>
</simpara>
</entry>
<entry>
<simpara>
the interval to do the second sampling of threads.
                                Defaults to 500ms.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>type</literal>
</simpara>
</entry>
<entry>
<simpara>
The type to sample, defaults to cpu, but supports wait and
                                block to see hot threads that are in wait or block state.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>ignore_idle_threads</literal>
</simpara>
</entry>
<entry>
<simpara>
If true, known idle threads (e.g. waiting in a socket select, or to
                           get a task from an empty queue) are filtered out.  Defaults to true.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</chapter>
<chapter id="cluster-allocation-explain">
<title>Cluster Allocation Explain API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/cluster/allocation-explain.asciidoc">Edit me</ulink></title>
<simpara>The cluster allocation explanation API is designed to assist in answering the
question "why is this shard unassigned?". To explain the allocation (on
unassigned state) of a shard, issue a request like:</simpara>
<warning role="experimental"><simpara>The cluster allocation explain API is new and should still be considered experimental. The API may change in ways that are not backwards compatible.</simpara></warning>
<programlisting language="js" linenumbering="unnumbered">$ curl -XGET 'http://localhost:9200/_cluster/allocation/explain' -d'{
  "index": "myindex",
  "shard": 0,
  "primary": false
}'</programlisting>
<simpara>Specify the <literal>index</literal> and <literal>shard</literal> id of the shard you would like an explanation
for, as well as the <literal>primary</literal> flag to indicate whether to explain a primary or
replica shard.</simpara>
<simpara>The response looks like:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "shard" : {
    "index" : "myindex",
    "index_uuid" : "KnW0-zELRs6PK84l0r38ZA",
    "id" : 0,
    "primary" : false
  },
  "assigned" : false,                             <co id="CO133-1"/>
  "shard_state_fetch_pending": false,             <co id="CO133-2"/>
  "unassigned_info" : {
    "reason" : "INDEX_CREATED",                   <co id="CO133-3"/>
    "at" : "2016-03-22T20:04:23.620Z"
  },
  "allocation_delay_ms" : 0,                      <co id="CO133-4"/>
  "remaining_delay_ms" : 0,                       <co id="CO133-5"/>
  "nodes" : {
    "V-Spi0AyRZ6ZvKbaI3691w" : {
      "node_name" : "H5dfFeA",
      "node_attributes" : {                       <co id="CO133-6"/>
        "bar" : "baz"
      },
      "store" : {
        "shard_copy" : "NONE"                     <co id="CO133-7"/>
      },
      "final_decision" : "NO",                    <co id="CO133-8"/>
      "final_explanation" : "the shard cannot be assigned because one or more allocation decider returns a 'NO' decision",
      "weight" : 0.06666675,                      <co id="CO133-9"/>
      "decisions" : [ {                           <co id="CO133-10"/>
        "decider" : "filter",
        "decision" : "NO",
        "explanation" : "node does not match index include filters [foo:\"bar\"]"
      } ]
    },
    "Qc6VL8c5RWaw1qXZ0Rg57g" : {
      "node_name" : "bGG90GE",
      "node_attributes" : {
        "bar" : "baz",
        "foo" : "bar"
      },
      "store" : {
        "shard_copy" : "AVAILABLE"
      },
      "final_decision" : "NO",
      "final_explanation" : "the shard cannot be assigned because one or more allocation decider returns a 'NO' decision",
      "weight" : -1.3833332,
      "decisions" : [ {
        "decider" : "same_shard",
        "decision" : "NO",
        "explanation" : "the shard cannot be allocated on the same node id [Qc6VL8c5RWaw1qXZ0Rg57g] on which it already exists"
      } ]
    },
    "PzdyMZGXQdGhqTJHF_hGgA" : {
      "node_name" : "DKDM97B",
      "node_attributes" : { },
      "store" : {
        "shard_copy" : "NONE"
      },
      "final_decision" : "NO",
      "final_explanation" : "the shard cannot be assigned because one or more allocation decider returns a 'NO' decision",
      "weight" : 2.3166666,
      "decisions" : [ {
        "decider" : "filter",
        "decision" : "NO",
        "explanation" : "node does not match index include filters [foo:\"bar\"]"
      } ]
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO133-1">
<para>
Whether the shard is assigned or unassigned
</para>
</callout>
<callout arearefs="CO133-2">
<para>
Whether information about the shard is still being fetched
</para>
</callout>
<callout arearefs="CO133-3">
<para>
Reason for the shard originally becoming unassigned
</para>
</callout>
<callout arearefs="CO133-4">
<para>
Configured delay before the shard can be allocated
</para>
</callout>
<callout arearefs="CO133-5">
<para>
Remaining delay before the shard can be allocated
</para>
</callout>
<callout arearefs="CO133-6">
<para>
User-added attributes the node has
</para>
</callout>
<callout arearefs="CO133-7">
<para>
The shard copy information for this node and error (if applicable)
</para>
</callout>
<callout arearefs="CO133-8">
<para>
Final decision and explanation of whether the shard can be allocated to this node
</para>
</callout>
<callout arearefs="CO133-9">
<para>
Weight for how much the allocator would like to allocate the shard to this node
</para>
</callout>
<callout arearefs="CO133-10">
<para>
List of node decisions factoring into final decision about the shard
</para>
</callout>
</calloutlist>
<simpara>For a shard that is already assigned, the output looks similar to:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "shard" : {
    "index" : "only-foo",
    "index_uuid" : "KnW0-zELRs6PK84l0r38ZA",
    "id" : 0,
    "primary" : true
  },
  "assigned" : true,
  "assigned_node_id" : "Qc6VL8c5RWaw1qXZ0Rg57g",      <co id="CO134-1"/>
  "shard_state_fetch_pending": false,
  "allocation_delay_ms" : 0,
  "remaining_delay_ms" : 0,
  "nodes" : {
    "V-Spi0AyRZ6ZvKbaI3691w" : {
      "node_name" : "bGG90GE",
      "node_attributes" : {
        "bar" : "baz"
      },
      "store" : {
        "shard_copy" : "NONE"
      },
      "final_decision" : "NO",
      "final_explanation" : "the shard cannot be assigned because one or more allocation decider returns a 'NO' decision",
      "weight" : 1.4499999,
      "decisions" : [ {
        "decider" : "filter",
        "decision" : "NO",
        "explanation" : "node does not match index include filters [foo:\"bar\"]"
      } ]
    },
    "Qc6VL8c5RWaw1qXZ0Rg57g" : {
      "node_name" : "I8hydUG",
      "node_attributes" : {
        "bar" : "baz",
        "foo" : "bar"
      },
      "store" : {
        "shard_copy" : "AVAILABLE"
      },
      "final_decision" : "ALREADY_ASSIGNED",        <co id="CO134-2"/>
      "final_explanation" : "the shard is already assigned to this node",
      "weight" : 0.0,
      "decisions" : [ {
        "decider" : "same_shard",
        "decision" : "NO",
        "explanation" : "the shard cannot be allocated on the same node id [Qc6VL8c5RWaw1qXZ0Rg57g] on which it already exists"
      } ]
    },
    "PzdyMZGXQdGhqTJHF_hGgA" : {
      "node_name" : "H5dfFeA",
      "node_attributes" : { },
      "store" : {
        "shard_copy" : "NONE"
      },
      "final_decision" : "NO",
      "final_explanation" : "the shard cannot be assigned because one or more allocation decider returns a 'NO' decision",
      "weight" : 3.6999998,
      "decisions" : [ {
        "decider" : "filter",
        "decision" : "NO",
        "explanation" : "node does not match index include filters [foo:\"bar\"]"
      } ]
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO134-1">
<para>
Node the shard is currently assigned to
</para>
</callout>
<callout arearefs="CO134-2">
<para>
The decision is "ALREADY_ASSIGNED" because the shard is currently assigned to this node
</para>
</callout>
</calloutlist>
<simpara>You can also have Elasticsearch explain the allocation of the first unassigned
shard it finds by sending an empty body, such as:</simpara>
<programlisting language="js" linenumbering="unnumbered">$ curl -XGET 'http://localhost:9200/_cluster/allocation/explain'</programlisting>
<simpara>If you would like to include all decisions that were factored into the final
decision, the <literal>include_yes_decisions</literal> parameter will return all decisions:</simpara>
<programlisting language="js" linenumbering="unnumbered">$ curl -XGET 'http://localhost:9200/_cluster/allocation/explain?include_yes_decisions=true'</programlisting>
<simpara>Additionally, you can return information gathered by the cluster info service
about disk usage and shard sizes by setting the <literal>include_disk_info</literal> parameter to
<literal>true</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">$ curl -XGET 'http://localhost:9200/_cluster/allocation/explain?include_disk_info=true'</programlisting>
</chapter>
</part>
<part id="query-dsl">
<title>Query DSL <ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl.asciidoc">Edit me</ulink></title>
<partintro>
<simpara>Elasticsearch provides a full Query DSL based on JSON to define queries.
Think of the Query DSL as an AST of queries, consisting of two types of
clauses:</simpara>
<variablelist>
<varlistentry>
<term>
Leaf query clauses
</term>
<listitem>
<simpara>
Leaf query clauses look for a particular value in a particular field, such as the
<link linkend="query-dsl-match-query"><literal>match</literal></link>, <link linkend="query-dsl-term-query"><literal>term</literal></link> or
<link linkend="query-dsl-range-query"><literal>range</literal></link> queries.  These queries can be used
by themselves.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Compound query clauses
</term>
<listitem>
<simpara>
Compound query clauses wrap other leaf <emphasis role="strong">or</emphasis> compound queries and are used to combine
multiple queries in a logical fashion (such as the
<link linkend="query-dsl-bool-query"><literal>bool</literal></link> or <link linkend="query-dsl-dis-max-query"><literal>dis_max</literal></link> query),
or to alter their behaviour (such as the
<link linkend="query-dsl-constant-score-query"><literal>constant_score</literal></link> query).
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>Query clauses behave differently depending on whether they are used in
<link linkend="query-filter-context">query context or filter context</link>.</simpara>
</partintro>
<chapter id="query-filter-context">
<title>Query and filter context<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/query_filter_context.asciidoc">Edit me</ulink></title>
<simpara>The behaviour of a query clause depends on whether it is used in <emphasis>query context</emphasis> or
in <emphasis>filter context</emphasis>:</simpara>
<variablelist>
<varlistentry>
<term>
Query context
</term>
<listitem>
<simpara>A query clause used in query context answers the question &#8220;<emphasis>How well does this
document match this query clause?</emphasis>&#8221; Besides deciding whether or not the
document matches, the query clause also calculates a <literal>_score</literal> representing how
well the document matches, relative to other documents.</simpara>
<simpara>Query context is in effect whenever a query clause is passed to a <literal>query</literal> parameter,
such as the <literal>query</literal> parameter in the <link linkend="search-request-query"><literal>search</literal></link> API.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Filter context
</term>
<listitem>
<simpara>In <emphasis>filter</emphasis> context, a query clause answers the question &#8220;<emphasis>Does this document
match this query clause?</emphasis>&#8221;  The answer is a simple Yes or No&#8201;&#8212;&#8201;no scores are
calculated.  Filter context is mostly used for filtering structured data, e.g.</simpara>
<itemizedlist>
<listitem>
<simpara>
<emphasis>Does this <literal>timestamp</literal> fall into the range 2015 to 2016?</emphasis>
</simpara>
</listitem>
<listitem>
<simpara>
<emphasis>Is the <literal>status</literal>  field set to <literal>"published"</literal></emphasis>?
</simpara>
</listitem>
</itemizedlist>
<simpara>Frequently used filters will be cached automatically by Elasticsearch, to
speed up performance.</simpara>
<simpara>Filter context is in effect whenever a query clause is passed to a <literal>filter</literal>
parameter, such as the <literal>filter</literal> or <literal>must_not</literal> parameters in the
<link linkend="query-dsl-bool-query"><literal>bool</literal></link> query, the <literal>filter</literal> parameter in the
<link linkend="query-dsl-constant-score-query"><literal>constant_score</literal></link> query, or the
<link linkend="search-aggregations-bucket-filter-aggregation"><literal>filter</literal></link> aggregation.</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>Below is an example of query clauses being used in query and filter context
in the <literal>search</literal> API.  This query will match documents where all of the following
conditions are met:</simpara>
<itemizedlist>
<listitem>
<simpara>
The <literal>title</literal> field contains the word <literal>search</literal>.
</simpara>
</listitem>
<listitem>
<simpara>
The <literal>content</literal> field contains the word <literal>elasticsearch</literal>.
</simpara>
</listitem>
<listitem>
<simpara>
The <literal>status</literal> field contains the exact word <literal>published</literal>.
</simpara>
</listitem>
<listitem>
<simpara>
The <literal>publish_date</literal> field contains a date from 1 Jan 2015 onwards.
</simpara>
</listitem>
</itemizedlist>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
  "query": { <co id="CO135-1"/>
    "bool": { <co id="CO135-2"/>
      "must": [
        { "match": { "title":   "Search"        }}, <co id="CO135-3"/>
        { "match": { "content": "Elasticsearch" }}  <co id="CO135-4"/>
      ],
      "filter": [ <co id="CO135-5"/>
        { "term":  { "status": "published" }}, <co id="CO135-6"/>
        { "range": { "publish_date": { "gte": "2015-01-01" }}} <co id="CO135-7"/>
      ]
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO135-1">
<para>
The <literal>query</literal> parameter indicates query context.
</para>
</callout>
<callout arearefs="CO135-2 CO135-3 CO135-4">
<para>
The <literal>bool</literal> and two <literal>match</literal> clauses are used in query context,
    which means that they are used to score how well each document
    matches.
</para>
</callout>
<callout arearefs="CO135-5">
<para>
The <literal>filter</literal> parameter indicates filter context.
</para>
</callout>
<callout arearefs="CO135-6 CO135-7">
<para>
The <literal>term</literal> and <literal>range</literal> clauses are used in filter context.
    They will filter out documents which do not match, but they will
    not affect the score for matching documents.
</para>
</callout>
</calloutlist>
<tip><simpara>Use query clauses in query context for conditions which should affect the
score of matching documents (i.e. how well does the document match), and use
all other query clauses in filter context.</simpara></tip>
</chapter>
<chapter id="query-dsl-match-all-query">
<title>Match All Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/match-all-query.asciidoc">Edit me</ulink></title>
<simpara>The most simple query, which matches all documents, giving them all a <literal>_score</literal>
of <literal>1.0</literal>.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "match_all": {}
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The <literal>_score</literal> can be changed with the <literal>boost</literal> parameter:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "match_all": { "boost" : 1.2 }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="query-dsl-match-none-query" renderas="sect1">Match None Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/match-all-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>This is the inverse of the <literal>match_all</literal> query, which matches no documents.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "match_none": {}
    }
}</programlisting>
<remark> CONSOLE</remark>
</chapter>
<chapter id="full-text-queries">
<title>Full text queries<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/full-text-queries.asciidoc">Edit me</ulink></title>
<simpara>The high-level full text queries are usually used for running full text
queries on full text fields like the body of an email. They understand how the
field being queried is <link linkend="analysis">analyzed</link> and will apply each field&#8217;s
<literal>analyzer</literal> (or <literal>search_analyzer</literal>) to the query string before executing.</simpara>
<simpara>The queries in this group are:</simpara>
<variablelist>
<varlistentry>
<term>
<link linkend="query-dsl-match-query"><literal>match</literal> query</link>
</term>
<listitem>
<simpara>
    The standard query for performing full text queries, including fuzzy matching
    and phrase or proximity queries.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-match-query-phrase"><literal>match_phrase</literal> query</link>
</term>
<listitem>
<simpara>
    Like the <literal>match</literal> query but used for matching exact phrases or word proximity matches.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-match-query-phrase-prefix"><literal>match_phrase_prefix</literal> query</link>
</term>
<listitem>
<simpara>
    The poor man&#8217;s <emphasis>search-as-you-type</emphasis>.  Like the <literal>match_phrase</literal> query, but does a wildcard search on the final word.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-multi-match-query"><literal>multi_match</literal> query</link>
</term>
<listitem>
<simpara>
    The multi-field version of the <literal>match</literal> query.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-common-terms-query"><literal>common_terms</literal> query</link>
</term>
<listitem>
<simpara>
    A more specialized query which gives more preference to uncommon words.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-query-string-query"><literal>query_string</literal> query</link>
</term>
<listitem>
<simpara>
    Supports the compact Lucene <link linkend="query-string-syntax">query string syntax</link>,
    allowing you to specify AND|OR|NOT conditions and multi-field search
    within a single query string. For expert users only.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-simple-query-string-query"><literal>simple_query_string</literal></link>
</term>
<listitem>
<simpara>
    A simpler, more robust version of the <literal>query_string</literal> syntax suitable
    for exposing directly to users.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<section id="query-dsl-match-query">
<title>Match Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/match-query.asciidoc">Edit me</ulink></title>
<simpara><literal>match</literal> queries accept text/numerics/dates, analyzes
them, and constructs a query. For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "match" : {
            "message" : "this is a test"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Note, <literal>message</literal> is the name of a field, you can substitute the name of
any field (including <literal>_all</literal>) instead.</simpara>
<section id="query-dsl-match-query-boolean">
<title>match<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/match-query.asciidoc">Edit me</ulink></title>
<simpara>The <literal>match</literal> query is of type <literal>boolean</literal>. It means that the text
provided is analyzed and the analysis process constructs a boolean query
from the provided text. The <literal>operator</literal> flag can be set to <literal>or</literal> or <literal>and</literal>
to control the boolean clauses (defaults to <literal>or</literal>). The minimum number of
optional <literal>should</literal> clauses to match can be set using the
<link linkend="query-dsl-minimum-should-match"><literal>minimum_should_match</literal></link>
parameter.</simpara>
<simpara>The <literal>analyzer</literal> can be set to control which analyzer will perform the
analysis process on the text. It defaults to the field explicit mapping
definition, or the default search analyzer.</simpara>
<simpara>The <literal>lenient</literal> parameter can be set to <literal>true</literal> to ignore exceptions caused by
data-type mismatches,  such as trying to query a numeric field with a text
query string. Defaults to <literal>false</literal>.</simpara>
<section id="query-dsl-match-query-fuzziness">
<title>Fuzziness<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/match-query.asciidoc">Edit me</ulink></title>
<simpara><literal>fuzziness</literal> allows <emphasis>fuzzy matching</emphasis> based on the type of field being queried.
See <xref linkend="fuzziness"/> for allowed settings.</simpara>
<simpara>The <literal>prefix_length</literal> and
<literal>max_expansions</literal> can be set in this case to control the fuzzy process.
If the fuzzy option is set the query will use <literal>top_terms_blended_freqs_${max_expansions}</literal>
as its <link linkend="query-dsl-multi-term-rewrite">rewrite method</link> the <literal>fuzzy_rewrite</literal> parameter allows to control how the query will get
rewritten.</simpara>
<simpara>Fuzzy transpositions (<literal>ab</literal> &#8594; <literal>ba</literal>) are allowed by default but can be disabled
by setting <literal>fuzzy_transpositions</literal> to <literal>false</literal>.</simpara>
<simpara>Here is an example when providing additional parameters (note the slight
change in structure, <literal>message</literal> is the field name):</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "match" : {
            "message" : {
                "query" : "this is a test",
                "operator" : "and"
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="query-dsl-match-query-zero">
<title>Zero terms query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/match-query.asciidoc">Edit me</ulink></title>
<simpara>If the analyzer used removes all tokens in a query like a <literal>stop</literal> filter
does, the default behavior is to match no documents at all. In order to
change that the <literal>zero_terms_query</literal> option can be used, which accepts
<literal>none</literal> (default) and <literal>all</literal> which corresponds to a <literal>match_all</literal> query.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "match" : {
            "message" : {
                "query" : "to be or not to be",
                "operator" : "and",
                "zero_terms_query": "all"
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="query-dsl-match-query-cutoff">
<title>Cutoff frequency<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/match-query.asciidoc">Edit me</ulink></title>
<simpara>The match query supports a <literal>cutoff_frequency</literal> that allows
specifying an absolute or relative document frequency where high
frequency terms are moved into an optional subquery and are only scored
if one of the low frequency (below the cutoff) terms in the case of an
<literal>or</literal> operator or all of the low frequency terms in the case of an <literal>and</literal>
operator match.</simpara>
<simpara>This query allows handling <literal>stopwords</literal> dynamically at runtime, is domain
independent and doesn&#8217;t require a stopword file. It prevents scoring /
iterating high frequency terms and only takes the terms into account if a
more significant / lower frequency term matches a document. Yet, if all
of the query terms are above the given <literal>cutoff_frequency</literal> the query is
automatically transformed into a pure conjunction (<literal>and</literal>) query to
ensure fast execution.</simpara>
<simpara>The <literal>cutoff_frequency</literal> can either be relative to the total number of
documents if in the range <literal>[0..1)</literal> or absolute if greater or equal to
<literal>1.0</literal>.</simpara>
<simpara>Here is an example showing a query composed of stopwords exclusively:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "match" : {
            "message" : {
                "query" : "to be or not to be",
                "cutoff_frequency" : 0.001
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<important><simpara>The <literal>cutoff_frequency</literal> option operates on a per-shard-level. This means
that when trying it out on test indexes with low document numbers you
should follow the advice in <ulink url="https://www.elastic.co/guide/en/elasticsearch/guide/master/relevance-is-broken.html">Relevance is broken</ulink>.</simpara></important>
<sidebar>
<title>Comparison to query_string / field</title>
<simpara>The match family of queries does not go through a "query parsing"
process. It does not support field name prefixes, wildcard characters,
or other "advanced" features. For this reason, chances of it failing are
very small / non existent, and it provides an excellent behavior when it
comes to just analyze and run that text as a query behavior (which is
usually what a text search box does). Also, the <literal>phrase_prefix</literal> type can
provide a great "as you type" behavior to automatically load search
results.</simpara>
</sidebar>
</section>
</section>
</section>
<section id="query-dsl-match-query-phrase">
<title>Match Phrase Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/match-phrase-query.asciidoc">Edit me</ulink></title>
<simpara>The <literal>match_phrase</literal> query analyzes the text and creates a <literal>phrase</literal> query
out of the analyzed text. For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "match_phrase" : {
            "message" : "this is a test"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>A phrase query matches terms up to a configurable <literal>slop</literal>
(which defaults to 0) in any order. Transposed terms have a slop of 2.</simpara>
<simpara>The <literal>analyzer</literal> can be set to control which analyzer will perform the
analysis process on the text. It defaults to the field explicit mapping
definition, or the default search analyzer, for example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "match_phrase" : {
            "message" : {
                "query" : "this is a test",
                "analyzer" : "my_analyzer"
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="query-dsl-match-query-phrase-prefix">
<title>Match Phrase Prefix Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/match-phrase-prefix-query.asciidoc">Edit me</ulink></title>
<simpara>The <literal>match_phrase_prefix</literal> is the same as <literal>match_phrase</literal>, except that it
allows for prefix matches on the last term in the text. For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "match_phrase_prefix" : {
            "message" : "quick brown f"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>It accepts the same parameters as the phrase type. In addition, it also
accepts a <literal>max_expansions</literal> parameter (default <literal>50</literal>) that can control to how
many prefixes the last term will be expanded. It is highly recommended to set
it to an acceptable value to control the execution time of the query. For
example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "match_phrase_prefix" : {
            "message" : {
                "query" : "quick brown f",
                "max_expansions" : 10
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<important>
<simpara>The <literal>match_phrase_prefix</literal> query is a poor-man&#8217;s autocomplete.  It is very easy
to use, which let&#8217;s you get started quickly with <emphasis>search-as-you-type</emphasis> but it&#8217;s
results, which usually are good enough,  can sometimes be confusing.</simpara>
<simpara>Consider the query string <literal>quick brown f</literal>.  This query works by creating a
phrase query out of <literal>quick</literal> and <literal>brown</literal> (i.e. the term <literal>quick</literal> must exist and
must be followed by the term <literal>brown</literal>).  Then it looks at the sorted term
dictionary to find the first 50 terms that begin with <literal>f</literal>, and
adds these terms to the phrase query.</simpara>
<simpara>The problem is that the first 50 terms may not include the term <literal>fox</literal> so the
phase <literal>quick brown fox</literal> will not be found.  This usually isn&#8217;t a problem as
the user will continue to type more letters until the word they are looking
for appears.</simpara>
<simpara>For better solutions for <emphasis>search-as-you-type</emphasis> see the
<link linkend="search-suggesters-completion">completion suggester</link> and
<ulink url="https://www.elastic.co/guide/en/elasticsearch/guide/master/_index_time_search_as_you_type.html">Index-Time Search-as-You-Type</ulink>.</simpara>
</important>
</section>
<section id="query-dsl-multi-match-query">
<title>Multi Match Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/multi-match-query.asciidoc">Edit me</ulink></title>
<simpara>The <literal>multi_match</literal> query builds on the <link linkend="query-dsl-match-query"><literal>match</literal> query</link>
to allow multi-field queries:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
  "query": {
    "multi_match" : {
      "query":    "this is a test", <co id="CO136-1"/>
      "fields": [ "subject", "message" ] <co id="CO136-2"/>
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO136-1">
<para>
The query string.
</para>
</callout>
<callout arearefs="CO136-2">
<para>
The fields to be queried.
</para>
</callout>
</calloutlist>
<bridgehead id="_literal_fields_literal_and_per_field_boosting" renderas="sect3"><literal>fields</literal> and per-field boosting<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/multi-match-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>Fields can be specified with wildcards, eg:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
  "query": {
    "multi_match" : {
      "query":    "Will Smith",
      "fields": [ "title", "*_name" ] <co id="CO137-1"/>
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO137-1">
<para>
Query the <literal>title</literal>, <literal>first_name</literal> and <literal>last_name</literal> fields.
</para>
</callout>
</calloutlist>
<simpara>Individual fields can be boosted with the caret (<literal>^</literal>) notation:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
  "query": {
    "multi_match" : {
      "query" : "this is a test",
      "fields" : [ "subject^3", "message" ] <co id="CO138-1"/>
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO138-1">
<para>
The <literal>subject</literal> field is three times as important as the <literal>message</literal> field.
</para>
</callout>
</calloutlist>
<bridgehead id="multi-match-types" renderas="sect3">Types of <literal>multi_match</literal> query:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/multi-match-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>The way the <literal>multi_match</literal> query is executed internally depends on the <literal>type</literal>
parameter, which can be set to:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>best_fields</literal>
</simpara>
</entry>
<entry>
<simpara>
(<emphasis role="strong">default</emphasis>) Finds documents which match any field, but
                    uses the  <literal>_score</literal> from the best field.  See <xref linkend="type-best-fields"/>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>most_fields</literal>
</simpara>
</entry>
<entry>
<simpara>
Finds documents which match any field and combines
                    the <literal>_score</literal> from each field.  See <xref linkend="type-most-fields"/>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>cross_fields</literal>
</simpara>
</entry>
<entry>
<simpara>
Treats fields with the same <literal>analyzer</literal> as though they
                    were one big field. Looks for each word in <emphasis role="strong">any</emphasis>
                    field. See <xref linkend="type-cross-fields"/>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>phrase</literal>
</simpara>
</entry>
<entry>
<simpara>
Runs a <literal>match_phrase</literal> query on each field and combines
                    the <literal>_score</literal> from each field.  See <xref linkend="type-phrase"/>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>phrase_prefix</literal>
</simpara>
</entry>
<entry>
<simpara>
Runs a <literal>match_phrase_prefix</literal> query on each field and
                    combines the <literal>_score</literal> from each field.  See <xref linkend="type-phrase"/>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<section id="type-best-fields">
<title><literal>best_fields</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/multi-match-query.asciidoc">Edit me</ulink></title>
<simpara>The <literal>best_fields</literal> type is most useful when you are searching for multiple
words best found in the same field. For instance &#8220;brown fox&#8221; in a single
field is more meaningful than &#8220;brown&#8221; in one field and &#8220;fox&#8221; in the other.</simpara>
<simpara>The <literal>best_fields</literal> type generates a <link linkend="query-dsl-match-query"><literal>match</literal> query</link> for
each field and wraps them in a <link linkend="query-dsl-dis-max-query"><literal>dis_max</literal></link> query, to
find the single best matching field.  For instance, this query:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
  "query": {
    "multi_match" : {
      "query":      "brown fox",
      "type":       "best_fields",
      "fields":     [ "subject", "message" ],
      "tie_breaker": 0.3
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>would be executed as:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
  "query": {
    "dis_max": {
      "queries": [
        { "match": { "subject": "brown fox" }},
        { "match": { "message": "brown fox" }}
      ],
      "tie_breaker": 0.3
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Normally the <literal>best_fields</literal> type uses the score of the <emphasis role="strong">single</emphasis> best matching
field, but if <literal>tie_breaker</literal> is specified, then it calculates the score as
follows:</simpara>
<itemizedlist>
<listitem>
<simpara>
the score from the best matching field
</simpara>
</listitem>
<listitem>
<simpara>
plus <literal>tie_breaker * _score</literal> for all other matching fields
</simpara>
</listitem>
</itemizedlist>
<simpara>Also, accepts <literal>analyzer</literal>, <literal>boost</literal>, <literal>operator</literal>, <literal>minimum_should_match</literal>,
<literal>fuzziness</literal>, <literal>lenient</literal>, <literal>prefix_length</literal>, <literal>max_expansions</literal>, <literal>rewrite</literal>, <literal>zero_terms_query</literal>
and <literal>cutoff_frequency</literal>, as explained in <link linkend="query-dsl-match-query">match query</link>.</simpara>
<important id="operator-min">
<title><literal>operator</literal> and <literal>minimum_should_match</literal></title>
<simpara>The <literal>best_fields</literal> and <literal>most_fields</literal> types are <emphasis>field-centric</emphasis>&#8201;&#8212;&#8201;they generate
a <literal>match</literal> query <emphasis role="strong">per field</emphasis>.  This means that the <literal>operator</literal> and
<literal>minimum_should_match</literal> parameters are applied to each field individually,
which is probably not what you want.</simpara>
<simpara>Take this query for example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
  "query": {
    "multi_match" : {
      "query":      "Will Smith",
      "type":       "best_fields",
      "fields":     [ "first_name", "last_name" ],
      "operator":   "and" <co id="CO139-1"/>
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO139-1">
<para>
All terms must be present.
</para>
</callout>
</calloutlist>
<simpara>This query is executed as:</simpara>
<literallayout class="monospaced">  (+first_name:will +first_name:smith)
| (+last_name:will  +last_name:smith)</literallayout>
<simpara>In other words, <emphasis role="strong">all terms</emphasis> must be present <emphasis role="strong">in a single field</emphasis> for a document
to match.</simpara>
<simpara>See <xref linkend="type-cross-fields"/> for a better solution.</simpara>
</important>
</section>
<section id="type-most-fields">
<title><literal>most_fields</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/multi-match-query.asciidoc">Edit me</ulink></title>
<simpara>The <literal>most_fields</literal> type is most useful when querying multiple fields that
contain the same text analyzed in different ways.  For instance, the main
field may contain synonyms, stemming and terms without diacritics. A second
field may contain the original terms, and a third field might contain
shingles. By combining scores from all three fields we can match as many
documents as possible with the main field, but use the second and third fields
to push the most similar results to the top of the list.</simpara>
<simpara>This query:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
  "query": {
    "multi_match" : {
      "query":      "quick brown fox",
      "type":       "most_fields",
      "fields":     [ "title", "title.original", "title.shingles" ]
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>would be executed as:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
  "query": {
    "bool": {
      "should": [
        { "match": { "title":          "quick brown fox" }},
        { "match": { "title.original": "quick brown fox" }},
        { "match": { "title.shingles": "quick brown fox" }}
      ]
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The score from each <literal>match</literal> clause is added together, then divided by the
number of <literal>match</literal> clauses.</simpara>
<simpara>Also, accepts <literal>analyzer</literal>, <literal>boost</literal>, <literal>operator</literal>, <literal>minimum_should_match</literal>,
<literal>fuzziness</literal>, <literal>lenient</literal>, <literal>prefix_length</literal>, <literal>max_expansions</literal>, <literal>rewrite</literal>, <literal>zero_terms_query</literal>
and <literal>cutoff_frequency</literal>, as explained in <link linkend="query-dsl-match-query">match query</link>, but
<emphasis role="strong">see <xref linkend="operator-min"/></emphasis>.</simpara>
</section>
<section id="type-phrase">
<title><literal>phrase</literal> and <literal>phrase_prefix</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/multi-match-query.asciidoc">Edit me</ulink></title>
<simpara>The <literal>phrase</literal> and <literal>phrase_prefix</literal> types behave just like <xref linkend="type-best-fields"/>,
but they use a <literal>match_phrase</literal> or <literal>match_phrase_prefix</literal> query instead of a
<literal>match</literal> query.</simpara>
<simpara>This query:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
  "query": {
    "multi_match" : {
      "query":      "quick brown f",
      "type":       "phrase_prefix",
      "fields":     [ "subject", "message" ]
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>would be executed as:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
  "query": {
    "dis_max": {
      "queries": [
        { "match_phrase_prefix": { "subject": "quick brown f" }},
        { "match_phrase_prefix": { "message": "quick brown f" }}
      ]
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Also, accepts <literal>analyzer</literal>, <literal>boost</literal>, <literal>lenient</literal>, <literal>slop</literal> and <literal>zero_terms_query</literal>  as explained
in <xref linkend="query-dsl-match-query"/>.  Type <literal>phrase_prefix</literal> additionally accepts
<literal>max_expansions</literal>.</simpara>
<important id="phrase-fuzziness">
<title><literal>phrase</literal>, <literal>phrase_prefix</literal> and <literal>fuzziness</literal></title>
<simpara>The <literal>fuzziness</literal> parameter cannot be used with the <literal>phrase</literal> or <literal>phrase_prefix</literal> type.</simpara>
</important>
</section>
<section id="type-cross-fields">
<title><literal>cross_fields</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/multi-match-query.asciidoc">Edit me</ulink></title>
<simpara>The <literal>cross_fields</literal> type is particularly useful with structured documents where
multiple fields <emphasis role="strong">should</emphasis> match.  For instance, when querying the <literal>first_name</literal>
and <literal>last_name</literal> fields for &#8220;Will Smith&#8221;, the best match is likely to have
&#8220;Will&#8221; in one field and &#8220;Smith&#8221; in the other.</simpara>
<sidebar>
<simpara>This sounds like a job for <xref linkend="type-most-fields"/> but there are two problems
with that approach. The first problem is that <literal>operator</literal> and
<literal>minimum_should_match</literal> are applied per-field, instead of per-term (see
<link linkend="operator-min">explanation above</link>).</simpara>
<simpara>The second problem is to do with relevance: the different term frequencies in
the <literal>first_name</literal> and <literal>last_name</literal> fields   can produce unexpected results.</simpara>
<simpara>For instance, imagine we have two people: &#8220;Will Smith&#8221; and &#8220;Smith Jones&#8221;.
&#8220;Smith&#8221; as a last name is very common (and so is of low importance) but
&#8220;Smith&#8221; as a first name is very uncommon (and so is of great importance).</simpara>
<simpara>If we do a search for &#8220;Will Smith&#8221;, the &#8220;Smith Jones&#8221; document will
probably appear above the better matching &#8220;Will Smith&#8221; because the score of
<literal>first_name:smith</literal> has trumped the combined scores of <literal>first_name:will</literal> plus
<literal>last_name:smith</literal>.</simpara>
</sidebar>
<simpara>One way of dealing with these types of queries is simply to index the
<literal>first_name</literal> and <literal>last_name</literal> fields into a single <literal>full_name</literal> field.  Of
course, this can only be done at index time.</simpara>
<simpara>The <literal>cross_field</literal> type tries to solve these problems at query time by taking a
<emphasis>term-centric</emphasis> approach.  It first analyzes the query string into individual
terms, then looks for each term in any of the fields, as though they were one
big field.</simpara>
<simpara>A query like:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
  "query": {
    "multi_match" : {
      "query":      "Will Smith",
      "type":       "cross_fields",
      "fields":     [ "first_name", "last_name" ],
      "operator":   "and"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>is executed as:</simpara>
<literallayout class="monospaced">+(first_name:will  last_name:will)
+(first_name:smith last_name:smith)</literallayout>
<simpara>In other words, <emphasis role="strong">all terms</emphasis> must be present <emphasis role="strong">in at least one field</emphasis> for a
document to match.  (Compare this to
<link linkend="operator-min">the logic used for <literal>best_fields</literal> and <literal>most_fields</literal></link>.)</simpara>
<simpara>That solves one of the two problems. The problem of differing term frequencies
is solved by <emphasis>blending</emphasis> the term frequencies for all fields in order to even
out the differences.</simpara>
<simpara>In practice, <literal>first_name:smith</literal> will be treated as though it has the same
frequencies as <literal>last_name:smith</literal>, plus one. This will make matches on
<literal>first_name</literal> and <literal>last_name</literal> have comparable scores, with a tiny advantage
for <literal>last_name</literal> since it is the most likely field that contains <literal>smith</literal>.</simpara>
<simpara>Note that <literal>cross_fields</literal> is usually only useful on short string fields
that all have a <literal>boost</literal> of <literal>1</literal>. Otherwise boosts, term freqs and length
normalization contribute to the score in such a way that the blending of term
statistics is not meaningful anymore.</simpara>
<simpara>If you run the above query through the <xref linkend="search-validate"/>, it returns this
explanation:</simpara>
<literallayout class="monospaced">+blended("will",  fields: [first_name, last_name])
+blended("smith", fields: [first_name, last_name])</literallayout>
<simpara>Also, accepts <literal>analyzer</literal>, <literal>boost</literal>, <literal>operator</literal>, <literal>minimum_should_match</literal>,
<literal>lenient</literal>, <literal>zero_terms_query</literal> and <literal>cutoff_frequency</literal>, as explained in
<link linkend="query-dsl-match-query">match query</link>.</simpara>
<section id="_literal_cross_field_literal_and_analysis">
<title><literal>cross_field</literal> and analysis<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/multi-match-query.asciidoc">Edit me</ulink></title>
<simpara>The <literal>cross_field</literal> type can only work in term-centric mode on fields that have
the same analyzer. Fields with the same analyzer are grouped together as in
the example above.  If there are multiple groups, they are combined with a
<literal>bool</literal> query.</simpara>
<simpara>For instance, if we have a <literal>first</literal> and <literal>last</literal> field which have
the same analyzer, plus a <literal>first.edge</literal> and <literal>last.edge</literal> which
both use an <literal>edge_ngram</literal> analyzer, this query:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
  "query": {
    "multi_match" : {
      "query":      "Jon",
      "type":       "cross_fields",
      "fields":     [
        "first", "first.edge",
        "last",  "last.edge"
      ]
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>would be executed as:</simpara>
<literallayout class="monospaced">    blended("jon", fields: [first, last])
| (
    blended("j",   fields: [first.edge, last.edge])
    blended("jo",  fields: [first.edge, last.edge])
    blended("jon", fields: [first.edge, last.edge])
)</literallayout>
<simpara>In other words, <literal>first</literal> and <literal>last</literal> would be grouped together and
treated as a single field, and <literal>first.edge</literal> and <literal>last.edge</literal> would be
grouped together and treated as a single field.</simpara>
<simpara>Having multiple groups is fine, but when combined with <literal>operator</literal> or
<literal>minimum_should_match</literal>, it can suffer from the <link linkend="operator-min">same problem</link>
as <literal>most_fields</literal> or <literal>best_fields</literal>.</simpara>
<simpara>You can easily rewrite this query yourself as two separate <literal>cross_fields</literal>
queries combined with a <literal>bool</literal> query, and apply the <literal>minimum_should_match</literal>
parameter to just one of them:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
  "query": {
    "bool": {
      "should": [
        {
          "multi_match" : {
            "query":      "Will Smith",
            "type":       "cross_fields",
            "fields":     [ "first", "last" ],
            "minimum_should_match": "50%" <co id="CO140-1"/>
          }
        },
        {
          "multi_match" : {
            "query":      "Will Smith",
            "type":       "cross_fields",
            "fields":     [ "*.edge" ]
          }
        }
      ]
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO140-1">
<para>
Either <literal>will</literal> or <literal>smith</literal> must be present in either of the <literal>first</literal>
    or <literal>last</literal> fields
</para>
</callout>
</calloutlist>
<simpara>You can force all fields into the same group by specifying the <literal>analyzer</literal>
parameter in the query.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
  "query": {
   "multi_match" : {
      "query":      "Jon",
      "type":       "cross_fields",
      "analyzer":   "standard", <co id="CO141-1"/>
      "fields":     [ "first", "last", "*.edge" ]
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO141-1">
<para>
Use the <literal>standard</literal> analyzer for all fields.
</para>
</callout>
</calloutlist>
<simpara>which will be executed as:</simpara>
<literallayout class="monospaced">blended("will",  fields: [first, first.edge, last.edge, last])
blended("smith", fields: [first, first.edge, last.edge, last])</literallayout>
</section>
<section id="_literal_tie_breaker_literal">
<title><literal>tie_breaker</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/multi-match-query.asciidoc">Edit me</ulink></title>
<simpara>By default, each per-term <literal>blended</literal> query will use the best score returned by
any field in a group, then these scores are added together to give the final
score. The <literal>tie_breaker</literal> parameter can change the default behaviour of the
per-term <literal>blended</literal> queries. It accepts:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>0.0</literal>
</simpara>
</entry>
<entry>
<simpara>
Take the single best score out of (eg) <literal>first_name:will</literal>
                    and <literal>last_name:will</literal> (<emphasis role="strong">default</emphasis>)
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>1.0</literal>
</simpara>
</entry>
<entry>
<simpara>
Add together the scores for (eg) <literal>first_name:will</literal> and
                    <literal>last_name:will</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>0.0 &lt; n &lt; 1.0</literal>
</simpara>
</entry>
<entry>
<simpara>
Take the single best score plus <literal>tie_breaker</literal> multiplied
                    by each of the scores from other matching fields.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<important id="crossfields-fuzziness">
<title><literal>cross_fields</literal> and <literal>fuzziness</literal></title>
<simpara>The <literal>fuzziness</literal> parameter cannot be used with the <literal>cross_fields</literal> type.</simpara>
</important>
</section>
</section>
</section>
<section id="query-dsl-common-terms-query">
<title>Common Terms Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/common-terms-query.asciidoc">Edit me</ulink></title>
<simpara>The <literal>common</literal> terms query is a modern alternative to stopwords which
improves the precision and recall of search results (by taking stopwords
into account), without sacrificing performance.</simpara>
<bridgehead id="_the_problem" renderas="sect3">The problem<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/common-terms-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>Every term in a query has a cost. A search for <literal>"The brown fox"</literal>
requires three term queries, one for each of <literal>"the"</literal>, <literal>"brown"</literal> and
<literal>"fox"</literal>, all of which are executed against all documents in the index.
The query for <literal>"the"</literal> is likely to match many documents and thus has a
much smaller impact on relevance than the other two terms.</simpara>
<simpara>Previously, the solution to this problem was to ignore terms with high
frequency. By treating <literal>"the"</literal> as a <emphasis>stopword</emphasis>, we reduce the index size
and reduce the number of term queries that need to be executed.</simpara>
<simpara>The problem with this approach is that, while stopwords have a small
impact on relevance, they are still important. If we remove stopwords,
we lose precision, (eg we are unable to distinguish between <literal>"happy"</literal>
and <literal>"not happy"</literal>) and we lose recall (eg text like <literal>"The The"</literal> or
<literal>"To be or not to be"</literal> would simply not exist in the index).</simpara>
<bridgehead id="_the_solution" renderas="sect3">The solution<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/common-terms-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>common</literal> terms query divides the query terms into two groups: more
important (ie <emphasis>low frequency</emphasis> terms) and less important (ie <emphasis>high
frequency</emphasis> terms which would previously have been stopwords).</simpara>
<simpara>First it searches for documents which match the more important terms.
These are the terms which appear in fewer documents and have a greater
impact on relevance.</simpara>
<simpara>Then, it executes a second query for the less important terms&#8201;&#8212;&#8201;terms
which appear frequently and have a low impact on relevance. But instead
of calculating the relevance score for <emphasis role="strong">all</emphasis> matching documents, it only
calculates the <literal>_score</literal> for documents already matched by the first
query. In this way the high frequency terms can improve the relevance
calculation without paying the cost of poor performance.</simpara>
<simpara>If a query consists only of high frequency terms, then a single query is
executed as an <literal>AND</literal> (conjunction) query, in other words all terms are
required. Even though each individual term will match many documents,
the combination of terms narrows down the resultset to only the most
relevant. The single query can also be executed as an <literal>OR</literal> with a
specific
<link linkend="query-dsl-minimum-should-match"><literal>minimum_should_match</literal></link>,
in this case a high enough value should probably be used.</simpara>
<simpara>Terms are allocated to the high or low frequency groups based on the
<literal>cutoff_frequency</literal>, which can be specified as an absolute frequency
(<literal>&gt;=1</literal>) or as a relative frequency (<literal>0.0 .. 1.0</literal>). (Remember that document
frequencies are computed on a per shard level as explained in the blog post
<ulink url="https://www.elastic.co/guide/en/elasticsearch/guide/master/relevance-is-broken.html">Relevance is broken</ulink>.)</simpara>
<simpara>Perhaps the most interesting property of this query is that it adapts to
domain specific stopwords automatically. For example, on a video hosting
site, common terms like <literal>"clip"</literal> or <literal>"video"</literal> will automatically behave
as stopwords without the need to maintain a manual list.</simpara>
<bridgehead id="_examples_4" renderas="sect3">Examples<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/common-terms-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>In this example, words that have a document frequency greater than 0.1%
(eg <literal>"this"</literal> and <literal>"is"</literal>) will be treated as <emphasis>common terms</emphasis>.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "common": {
            "body": {
                "query": "this is bonsai cool",
                    "cutoff_frequency": 0.001
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The number of terms which should match can be controlled with the
<link linkend="query-dsl-minimum-should-match"><literal>minimum_should_match</literal></link>
(<literal>high_freq</literal>, <literal>low_freq</literal>), <literal>low_freq_operator</literal> (default <literal>"or"</literal>) and
<literal>high_freq_operator</literal> (default <literal>"or"</literal>) parameters.</simpara>
<simpara>For low frequency terms, set the <literal>low_freq_operator</literal> to <literal>"and"</literal> to make
all terms required:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "common": {
            "body": {
                "query": "nelly the elephant as a cartoon",
                    "cutoff_frequency": 0.001,
                    "low_freq_operator": "and"
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>which is roughly equivalent to:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "bool": {
            "must": [
            { "term": { "body": "nelly"}},
            { "term": { "body": "elephant"}},
            { "term": { "body": "cartoon"}}
            ],
            "should": [
            { "term": { "body": "the"}},
            { "term": { "body": "as"}},
            { "term": { "body": "a"}}
            ]
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Alternatively use
<link linkend="query-dsl-minimum-should-match"><literal>minimum_should_match</literal></link>
to specify a minimum number or percentage of low frequency terms which
must be present, for instance:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "common": {
            "body": {
                "query": "nelly the elephant as a cartoon",
                "cutoff_frequency": 0.001,
                "minimum_should_match": 2
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>which is roughly equivalent to:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "bool": {
            "must": {
                "bool": {
                    "should": [
                    { "term": { "body": "nelly"}},
                    { "term": { "body": "elephant"}},
                    { "term": { "body": "cartoon"}}
                    ],
                    "minimum_should_match": 2
                }
            },
            "should": [
                { "term": { "body": "the"}},
                { "term": { "body": "as"}},
                { "term": { "body": "a"}}
                ]
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>minimum_should_match</simpara>
<simpara>A different
<link linkend="query-dsl-minimum-should-match"><literal>minimum_should_match</literal></link>
can be applied for low and high frequency terms with the additional
<literal>low_freq</literal> and <literal>high_freq</literal> parameters. Here is an example when providing
additional parameters (note the change in structure):</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "common": {
            "body": {
                "query": "nelly the elephant not as a cartoon",
                    "cutoff_frequency": 0.001,
                    "minimum_should_match": {
                        "low_freq" : 2,
                        "high_freq" : 3
                    }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>which is roughly equivalent to:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "bool": {
            "must": {
                "bool": {
                    "should": [
                    { "term": { "body": "nelly"}},
                    { "term": { "body": "elephant"}},
                    { "term": { "body": "cartoon"}}
                    ],
                    "minimum_should_match": 2
                }
            },
            "should": {
                "bool": {
                    "should": [
                    { "term": { "body": "the"}},
                    { "term": { "body": "not"}},
                    { "term": { "body": "as"}},
                    { "term": { "body": "a"}}
                    ],
                    "minimum_should_match": 3
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>In this case it means the high frequency terms have only an impact on
relevance when there are at least three of them. But the most
interesting use of the
<link linkend="query-dsl-minimum-should-match"><literal>minimum_should_match</literal></link>
for high frequency terms is when there are only high frequency terms:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "common": {
            "body": {
                "query": "how not to be",
                    "cutoff_frequency": 0.001,
                    "minimum_should_match": {
                        "low_freq" : 2,
                        "high_freq" : 3
                    }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>which is roughly equivalent to:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "bool": {
            "should": [
            { "term": { "body": "how"}},
            { "term": { "body": "not"}},
            { "term": { "body": "to"}},
            { "term": { "body": "be"}}
            ],
            "minimum_should_match": "3&lt;50%"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The high frequency generated query is then slightly less restrictive
than with an <literal>AND</literal>.</simpara>
<simpara>The <literal>common</literal> terms query also supports <literal>boost</literal>, <literal>analyzer</literal> and
<literal>disable_coord</literal> as parameters.</simpara>
</section>
<section id="query-dsl-query-string-query">
<title>Query String Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/query-string-query.asciidoc">Edit me</ulink></title>
<simpara>A query that uses a query parser in order to parse its content. Here is
an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "query_string" : {
            "default_field" : "content",
            "query" : "this AND that OR thus"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The <literal>query_string</literal> top level parameters include:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Parameter </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>query</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The actual query to be parsed. See <xref linkend="query-string-syntax"/>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>default_field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The default field for query terms if no prefix field
is specified. Defaults to the <literal>index.query.default_field</literal> index
settings, which in turn defaults to <literal>_all</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>default_operator</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The default operator used if no explicit operator
is specified. For example, with a default operator of <literal>OR</literal>, the query
<literal>capital of Hungary</literal> is translated to <literal>capital OR of OR Hungary</literal>, and
with default operator of <literal>AND</literal>, the same query is translated to
<literal>capital AND of AND Hungary</literal>. The default value is <literal>OR</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>analyzer</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The analyzer name used to analyze the query string.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>allow_leading_wildcard</literal></simpara></entry>
<entry align="left" valign="top"><simpara>When set, <literal>*</literal> or <literal>?</literal> are allowed as the first
character. Defaults to <literal>true</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>enable_position_increments</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Set to <literal>true</literal> to enable position
increments in result queries. Defaults to <literal>true</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>fuzzy_max_expansions</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Controls the number of terms fuzzy queries will
expand to. Defaults to <literal>50</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>fuzziness</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Set the fuzziness for fuzzy queries. Defaults
to <literal>AUTO</literal>. See  <xref linkend="fuzziness"/> for allowed settings.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>fuzzy_prefix_length</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Set the prefix length for fuzzy queries. Default
is <literal>0</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>phrase_slop</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Sets the default slop for phrases. If zero, then exact
phrase matches are required. Default value is <literal>0</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>boost</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Sets the boost value of the query. Defaults to <literal>1.0</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>auto_generate_phrase_queries</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Defaults to <literal>false</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>analyze_wildcard</literal></simpara></entry>
<entry align="left" valign="top"><simpara>By default, wildcards terms in a query string are
not analyzed. By setting this value to <literal>true</literal>, a best effort will be
made to analyze those as well.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>max_determinized_states</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Limit on how many automaton states regexp
queries are allowed to create.  This protects against too-difficult
(e.g. exponentially hard) regexps.  Defaults to 10000.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>minimum_should_match</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A value controlling how many "should" clauses
in the resulting boolean query should match. It can be an absolute value
(<literal>2</literal>), a percentage (<literal>30%</literal>) or a
<link linkend="query-dsl-minimum-should-match">combination of both</link>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>lenient</literal></simpara></entry>
<entry align="left" valign="top"><simpara>If set to <literal>true</literal> will cause format based failures (like
providing text to a numeric field) to be ignored.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>time_zone</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Time Zone to be applied to any range query related to dates. See also
<ulink url="http://www.joda.org/joda-time/apidocs/org/joda/time/DateTimeZone.html">JODA timezone</ulink>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>quote_field_suffix</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A suffix to append to fields for quoted parts of
the query string. This allows to use a field that has a different analysis chain
for exact matching. Look <link linkend="mixing-exact-search-with-stemming">here</link> for a
comprehensive example.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>split_on_whitespace</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Whether query text should be split on whitespace prior to analysis.
                        Instead  the queryparser would parse around only real <emphasis>operators</emphasis>.
                        Default to <literal>false</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>all_fields</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Perform the query on all fields detected in the mapping that can
be queried. Will be used by default when the <literal>_all</literal> field is disabled and no
<literal>default_field</literal> is specified (either in the index settings or in the request
body) and no <literal>fields</literal> are specified.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>When a multi term query is being generated, one can control how it gets
rewritten using the
<link linkend="query-dsl-multi-term-rewrite">rewrite</link>
parameter.</simpara>
<bridgehead id="_default_field" renderas="sect3">Default Field<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/query-string-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>When not explicitly specifying the field to search on in the query
string syntax, the <literal>index.query.default_field</literal> will be used to derive
which field to search on. It defaults to <literal>_all</literal> field.</simpara>
<simpara>If the <literal>_all</literal> field is disabled, the <literal>query_string</literal> query will automatically
attempt to determine the existing fields in the index&#8217;s mapping that are
queryable, and perform the search on those fields. Note that this will not
include nested documents, use a nested query to search those documents.</simpara>
<bridgehead id="_multi_field" renderas="sect3">Multi Field<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/query-string-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>query_string</literal> query can also run against multiple fields. Fields can be
provided via the <literal>"fields"</literal> parameter (example below).</simpara>
<simpara>The idea of running the <literal>query_string</literal> query against multiple fields is to
expand each query term to an OR clause like this:</simpara>
<literallayout class="monospaced">field1:query_term OR field2:query_term | ...</literallayout>
<simpara>For example, the following query</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "query_string" : {
            "fields" : ["content", "name"],
            "query" : "this AND that"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>matches the same words as</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "query_string": {
            "query": "(content:this OR name:this) AND (content:that OR name:that)"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Since several queries are generated from the individual search terms,
combining them can be automatically done using either a <literal>dis_max</literal> query or a
simple <literal>bool</literal> query. For example (the <literal>name</literal> is boosted by 5 using <literal>^5</literal>
notation):</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "query_string" : {
            "fields" : ["content", "name^5"],
            "query" : "this AND that OR thus",
            "use_dis_max" : true
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Simple wildcard can also be used to search "within" specific inner
elements of the document. For example, if we have a <literal>city</literal> object with
several fields (or inner object with fields) in it, we can automatically
search on all "city" fields:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "query_string" : {
            "fields" : ["city.*"],
            "query" : "this AND that OR thus",
            "use_dis_max" : true
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Another option is to provide the wildcard fields search in the query
string itself (properly escaping the <literal>*</literal> sign), for example:
<literal>city.\*:something</literal>.</simpara>
<simpara>When running the <literal>query_string</literal> query against multiple fields, the
following additional parameters are allowed:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Parameter </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>use_dis_max</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Should the queries be combined using <literal>dis_max</literal> (set it
to <literal>true</literal>), or a <literal>bool</literal> query (set it to <literal>false</literal>). Defaults to <literal>true</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>tie_breaker</literal></simpara></entry>
<entry align="left" valign="top"><simpara>When using <literal>dis_max</literal>, the disjunction max tie breaker.
Defaults to <literal>0</literal>.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>The fields parameter can also include pattern based field names,
allowing to automatically expand to the relevant fields (dynamically
introduced fields included). For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "query_string" : {
            "fields" : ["content", "name.*^5"],
            "query" : "this AND that OR thus",
            "use_dis_max" : true
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<section id="query-string-syntax">
<title>Query string syntax<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/query-string-syntax.asciidoc">Edit me</ulink></title>
<simpara>The query string &#8220;mini-language&#8221; is used by the
<xref linkend="query-dsl-query-string-query"/> and by the
<literal>q</literal> query string parameter in the <link linkend="search-search"><literal>search</literal> API</link>.</simpara>
<simpara>The query string is parsed into a series of <emphasis>terms</emphasis> and <emphasis>operators</emphasis>. A
term can be a single word&#8201;&#8212;&#8201;<literal>quick</literal> or <literal>brown</literal>&#8201;&#8212;&#8201;or a phrase, surrounded by
double quotes&#8201;&#8212;&#8201;<literal>"quick brown"</literal>&#8201;&#8212;&#8201;which searches for all the words in the
phrase, in the same order.</simpara>
<simpara>Operators allow you to customize the search&#8201;&#8212;&#8201;the available options are
explained below.</simpara>
<section id="_field_names">
<title>Field names<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/query-string-syntax.asciidoc">Edit me</ulink></title>
<simpara>As mentioned in <xref linkend="query-dsl-query-string-query"/>, the <literal>default_field</literal> is searched for the
search terms, but it is possible to specify other fields in the query syntax:</simpara>
<itemizedlist>
<listitem>
<simpara>
where the <literal>status</literal> field contains <literal>active</literal>
</simpara>
<literallayout class="monospaced">status:active</literallayout>
</listitem>
<listitem>
<simpara>
where the <literal>title</literal> field contains <literal>quick</literal> or <literal>brown</literal>.
  If you omit the OR operator the default operator will be used
</simpara>
<literallayout class="monospaced">title:(quick OR brown)
title:(quick brown)</literallayout>
</listitem>
<listitem>
<simpara>
where the <literal>author</literal> field contains the exact phrase <literal>"john smith"</literal>
</simpara>
<literallayout class="monospaced">author:"John Smith"</literallayout>
</listitem>
<listitem>
<simpara>
where any of the fields <literal>book.title</literal>, <literal>book.content</literal> or <literal>book.date</literal> contains
  <literal>quick</literal> or <literal>brown</literal> (note how we need to escape the <literal>*</literal> with a backslash):
</simpara>
<literallayout class="monospaced">book.\*:(quick brown)</literallayout>
</listitem>
<listitem>
<simpara>
where the field <literal>title</literal> has any non-null value:
</simpara>
<literallayout class="monospaced">_exists_:title</literallayout>
</listitem>
</itemizedlist>
</section>
<section id="_wildcards">
<title>Wildcards<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/query-string-syntax.asciidoc">Edit me</ulink></title>
<simpara>Wildcard searches can be run on individual terms, using <literal>?</literal> to replace
a single character, and <literal>*</literal> to replace zero or more characters:</simpara>
<literallayout class="monospaced">qu?ck bro*</literallayout>
<simpara>Be aware that wildcard queries can use an enormous amount of memory and
perform very badly&#8201;&#8212;&#8201;just think how many terms need to be queried to
match the query string <literal>"a* b* c*"</literal>.</simpara>
<warning>
<simpara>Allowing a wildcard at the beginning of a word (eg <literal>"*ing"</literal>) is particularly
heavy, because all terms in the index need to be examined, just in case
they match.  Leading wildcards can be disabled by setting
<literal>allow_leading_wildcard</literal> to <literal>false</literal>.</simpara>
</warning>
<simpara>Only parts of the analysis chain that operate at the character level are
applied. So for instance, if the analyzer performs both lowercasing and
stemming, only the lowercasing will be applied: it would be wrong to perform
stemming on a word that is missing some of its letters.</simpara>
<simpara>By setting <literal>analyze_wildcard</literal> to true, queries that end with a <literal>*</literal> will be
analyzed and a boolean query will be built out of the different tokens, by
ensuring exact matches on the first N-1 tokens, and prefix match on the last
token.</simpara>
</section>
<section id="_regular_expressions">
<title>Regular expressions<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/query-string-syntax.asciidoc">Edit me</ulink></title>
<simpara>Regular expression patterns can be embedded in the query string by
wrapping them in forward-slashes (<literal>"/"</literal>):</simpara>
<literallayout class="monospaced">name:/joh?n(ath[oa]n)/</literallayout>
<simpara>The supported regular expression syntax is explained in <xref linkend="regexp-syntax"/>.</simpara>
<warning>
<simpara>The <literal>allow_leading_wildcard</literal> parameter does not have any control over
regular expressions.  A query string such as the following would force
Elasticsearch to visit every term in the index:</simpara>
<literallayout class="monospaced">/.*n/</literallayout>
<simpara>Use with caution!</simpara>
</warning>
</section>
<section id="_fuzziness">
<title>Fuzziness<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/query-string-syntax.asciidoc">Edit me</ulink></title>
<simpara>We can search for terms that are
similar to, but not exactly like our search terms, using the &#8220;fuzzy&#8221;
operator:</simpara>
<literallayout class="monospaced">quikc~ brwn~ foks~</literallayout>
<simpara>This uses the
<ulink url="http://en.wikipedia.org/wiki/Damerau-Levenshtein_distance">Damerau-Levenshtein distance</ulink>
to find all terms with a maximum of
two changes, where a change is the insertion, deletion
or substitution of a single character, or transposition of two adjacent
characters.</simpara>
<simpara>The default <emphasis>edit distance</emphasis> is <literal>2</literal>, but an edit distance of <literal>1</literal> should be
sufficient to catch 80% of all human misspellings. It can be specified as:</simpara>
<literallayout class="monospaced">quikc~1</literallayout>
</section>
<section id="_proximity_searches">
<title>Proximity searches<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/query-string-syntax.asciidoc">Edit me</ulink></title>
<simpara>While a phrase query (eg <literal>"john smith"</literal>) expects all of the terms in exactly
the same order, a proximity query allows the specified words to be further
apart or in a different order.  In the same way that fuzzy queries can
specify a maximum edit distance for characters in a word, a proximity search
allows us to specify a maximum edit distance of words in a phrase:</simpara>
<literallayout class="monospaced">"fox quick"~5</literallayout>
<simpara>The closer the text in a field is to the original order specified in the
query string, the more relevant that document is considered to be. When
compared to the above example query, the phrase <literal>"quick fox"</literal> would be
considered more relevant than <literal>"quick brown fox"</literal>.</simpara>
</section>
<section id="_ranges">
<title>Ranges<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/query-string-syntax.asciidoc">Edit me</ulink></title>
<simpara>Ranges can be specified for date, numeric or string fields. Inclusive ranges
are specified with square brackets <literal>[min TO max]</literal> and exclusive ranges with
curly brackets <literal>{min TO max}</literal>.</simpara>
<itemizedlist>
<listitem>
<simpara>
All days in 2012:
</simpara>
<literallayout class="monospaced">date:[2012-01-01 TO 2012-12-31]</literallayout>
</listitem>
<listitem>
<simpara>
Numbers 1..5
</simpara>
<literallayout class="monospaced">count:[1 TO 5]</literallayout>
</listitem>
<listitem>
<simpara>
Tags between <literal>alpha</literal> and <literal>omega</literal>, excluding <literal>alpha</literal> and <literal>omega</literal>:
</simpara>
<literallayout class="monospaced">tag:{alpha TO omega}</literallayout>
</listitem>
<listitem>
<simpara>
Numbers from 10 upwards
</simpara>
<literallayout class="monospaced">count:[10 TO *]</literallayout>
</listitem>
<listitem>
<simpara>
Dates before 2012
</simpara>
<literallayout class="monospaced">date:{* TO 2012-01-01}</literallayout>
</listitem>
</itemizedlist>
<simpara>Curly and square brackets can be combined:</simpara>
<itemizedlist>
<listitem>
<simpara>
Numbers from 1 up to but not including 5
</simpara>
<literallayout class="monospaced">count:[1 TO 5}</literallayout>
</listitem>
</itemizedlist>
<simpara>Ranges with one side unbounded can use the following syntax:</simpara>
<literallayout class="monospaced">age:&gt;10
age:&gt;=10
age:&lt;10
age:&lt;=10</literallayout>
<note>
<simpara>To combine an upper and lower bound with the simplified syntax, you
would need to join two clauses with an <literal>AND</literal> operator:</simpara>
<literallayout class="monospaced">age:(&gt;=10 AND &lt;20)
age:(+&gt;=10 +&lt;20)</literallayout>
</note>
<simpara>The parsing of ranges in query strings can be complex and error prone. It is
much more reliable to use an explicit <link linkend="query-dsl-range-query"><literal>range</literal> query</link>.</simpara>
</section>
<section id="_boosting">
<title>Boosting<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/query-string-syntax.asciidoc">Edit me</ulink></title>
<simpara>Use the <emphasis>boost</emphasis> operator <literal>^</literal> to make one term more relevant than another.
For instance, if we want to find all documents about foxes, but we are
especially interested in quick foxes:</simpara>
<literallayout class="monospaced">quick^2 fox</literallayout>
<simpara>The default <literal>boost</literal> value is 1, but can be any positive floating point number.
Boosts between 0 and 1 reduce relevance.</simpara>
<simpara>Boosts can also be applied to phrases or to groups:</simpara>
<literallayout class="monospaced">"john smith"^2   (foo bar)^4</literallayout>
</section>
<section id="_boolean_operators">
<title>Boolean operators<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/query-string-syntax.asciidoc">Edit me</ulink></title>
<simpara>By default, all terms are optional, as long as one term matches.  A search
for <literal>foo bar baz</literal> will find any document that contains one or more of
<literal>foo</literal> or <literal>bar</literal> or <literal>baz</literal>.  We have already discussed the <literal>default_operator</literal>
above which allows you to force all terms to be required, but there are
also <emphasis>boolean operators</emphasis> which can be used in the query string itself
to provide more control.</simpara>
<simpara>The preferred operators are <literal>+</literal> (this term <emphasis role="strong">must</emphasis> be present) and <literal>-</literal>
(this term <emphasis role="strong">must not</emphasis> be present). All other terms are optional.
For example, this query:</simpara>
<literallayout class="monospaced">quick brown +fox -news</literallayout>
<simpara>states that:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>fox</literal> must be present
</simpara>
</listitem>
<listitem>
<simpara>
<literal>news</literal> must not be present
</simpara>
</listitem>
<listitem>
<simpara>
<literal>quick</literal> and <literal>brown</literal> are optional&#8201;&#8212;&#8201;their presence increases the relevance
</simpara>
</listitem>
</itemizedlist>
<simpara>The familiar operators <literal>AND</literal>, <literal>OR</literal> and <literal>NOT</literal> (also written <literal>&amp;&amp;</literal>, <literal>||</literal> and <literal>!</literal>)
are also supported.  However, the effects of these operators can be more
complicated than is obvious at first glance.  <literal>NOT</literal> takes precedence over
<literal>AND</literal>, which takes precedence over <literal>OR</literal>.  While the <literal>+</literal> and <literal>-</literal> only affect
the term to the right of the operator, <literal>AND</literal> and <literal>OR</literal> can affect the terms to
the left and right.</simpara>
<sidebar>
<simpara>Rewriting the above query using <literal>AND</literal>, <literal>OR</literal> and <literal>NOT</literal> demonstrates the
complexity:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>quick OR brown AND fox AND NOT news</literal>
</term>
<listitem>
<simpara>
This is incorrect, because <literal>brown</literal> is now a required term.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>(quick OR brown) AND fox AND NOT news</literal>
</term>
<listitem>
<simpara>
This is incorrect because at least one of <literal>quick</literal> or <literal>brown</literal> is now required
and the search for those terms would be scored differently from the original
query.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>((quick AND fox) OR (brown AND fox) OR fox) AND NOT news</literal>
</term>
<listitem>
<simpara>
This form now replicates the logic from the original query correctly, but
the relevance scoring bears little resemblance to the original.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>In contrast, the same query rewritten using the <link linkend="query-dsl-match-query"><literal>match</literal> query</link>
would look like this:</simpara>
<literallayout class="monospaced">{
    "bool": {
        "must":     { "match": "fox"         },
        "should":   { "match": "quick brown" },
        "must_not": { "match": "news"        }
    }
}</literallayout>
</sidebar>
</section>
<section id="_grouping">
<title>Grouping<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/query-string-syntax.asciidoc">Edit me</ulink></title>
<simpara>Multiple terms or clauses can be grouped together with parentheses, to form
sub-queries:</simpara>
<literallayout class="monospaced">(quick OR brown) AND fox</literallayout>
<simpara>Groups can be used to target a particular field, or to boost the result
of a sub-query:</simpara>
<literallayout class="monospaced">status:(active OR pending) title:(full text search)^2</literallayout>
</section>
<section id="_reserved_characters">
<title>Reserved characters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/query-string-syntax.asciidoc">Edit me</ulink></title>
<simpara>If you need to use any of the characters which function as operators in your
query itself (and not as operators), then you should escape them with
a leading backslash. For instance, to search for <literal>(1+1)=2</literal>, you would
need to write your query as <literal>\(1\+1\)\=2</literal>.</simpara>
<simpara>The reserved characters are:  <literal>+ - = &amp;&amp; || &gt; &lt; ! ( ) { } [ ] ^ " ~ * ? : \ /</literal></simpara>
<simpara>Failing to escape these special characters correctly could lead to a syntax
error which prevents your query from running.</simpara>
<sidebar>
<title>Watch this space</title>
<simpara>A space may also be a reserved character.  For instance, if you have a
synonym list which converts <literal>"wi fi"</literal> to <literal>"wifi"</literal>, a <literal>query_string</literal> search
for <literal>"wi fi"</literal> would fail. The query string parser would interpret your
query as a search for <literal>"wi OR fi"</literal>, while the token stored in your
index is actually <literal>"wifi"</literal>.  The option <literal>split_on_whitespace=false</literal> will protect it from
being touched by the query string parser and will let the analysis run on the entire input (<literal>"wi fi"</literal>).</simpara>
</sidebar>
</section>
<section id="_empty_query">
<title>Empty Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/query-string-syntax.asciidoc">Edit me</ulink></title>
<simpara>If the query string is empty or only contains whitespaces the query will
yield an empty result set.</simpara>
</section>
</section>
</section>
<section id="query-dsl-simple-query-string-query">
<title>Simple Query String Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/simple-query-string-query.asciidoc">Edit me</ulink></title>
<simpara>A query that uses the SimpleQueryParser to parse its context. Unlike the
regular <literal>query_string</literal> query, the <literal>simple_query_string</literal> query will never
throw an exception, and discards invalid parts of the query. Here is
an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
  "query": {
    "simple_query_string" : {
        "query": "\"fried eggs\" +(eggplant | potato) -frittata",
        "analyzer": "snowball",
        "fields": ["body^5","_all"],
        "default_operator": "and"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The <literal>simple_query_string</literal> top level parameters include:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Parameter </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>query</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The actual query to be parsed. See below for syntax.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>fields</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The fields to perform the parsed query against. Defaults to the
<literal>index.query.default_field</literal> index settings, which in turn defaults to <literal>_all</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>default_operator</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The default operator used if no explicit operator
is specified. For example, with a default operator of <literal>OR</literal>, the query
<literal>capital of Hungary</literal> is translated to <literal>capital OR of OR Hungary</literal>, and
with default operator of <literal>AND</literal>, the same query is translated to
<literal>capital AND of AND Hungary</literal>. The default value is <literal>OR</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>analyzer</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The analyzer used to analyze each term of the query when
creating composite queries.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>flags</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Flags specifying which features of the <literal>simple_query_string</literal> to
enable. Defaults to <literal>ALL</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>analyze_wildcard</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Whether terms of prefix queries should be automatically
analyzed or not. If <literal>true</literal> a best effort will be made to analyze the prefix. However,
some analyzers will be not able to provide a meaningful results
based just on the prefix of a term. Defaults to <literal>false</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>lenient</literal></simpara></entry>
<entry align="left" valign="top"><simpara>If set to <literal>true</literal> will cause format based failures
(like providing text to a numeric field) to be ignored.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>minimum_should_match</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The minimum number of clauses that must match for a
 document to be returned. See the
 <link linkend="query-dsl-minimum-should-match"><literal>minimum_should_match</literal></link> documentation for the
 full list of options.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>quote_field_suffix</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A suffix to append to fields for quoted parts of
the query string. This allows to use a field that has a different analysis chain
for exact matching. Look <link linkend="mixing-exact-search-with-stemming">here</link> for a
comprehensive example.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>all_fields</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Perform the query on all fields detected in the mapping that can
be queried. Will be used by default when the <literal>_all</literal> field is disabled and no
<literal>default_field</literal> is specified index settings, and no <literal>fields</literal> are specified.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<bridgehead id="_simple_query_string_syntax" renderas="sect4">Simple Query String Syntax<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/simple-query-string-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>simple_query_string</literal> supports the following special characters:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>+</literal> signifies AND operation
</simpara>
</listitem>
<listitem>
<simpara>
<literal>|</literal> signifies OR operation
</simpara>
</listitem>
<listitem>
<simpara>
<literal>-</literal> negates a single token
</simpara>
</listitem>
<listitem>
<simpara>
<literal>"</literal> wraps a number of tokens to signify a phrase for searching
</simpara>
</listitem>
<listitem>
<simpara>
<literal>*</literal> at the end of a term signifies a prefix query
</simpara>
</listitem>
<listitem>
<simpara>
<literal>(</literal> and <literal>)</literal> signify precedence
</simpara>
</listitem>
<listitem>
<simpara>
<literal>~N</literal> after a word signifies edit distance (fuzziness)
</simpara>
</listitem>
<listitem>
<simpara>
<literal>~N</literal> after a phrase signifies slop amount
</simpara>
</listitem>
</itemizedlist>
<simpara>In order to search for any of these special characters, they will need to
be escaped with <literal>\</literal>.</simpara>
<bridgehead id="_default_field_2" renderas="sect3">Default Field<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/simple-query-string-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>When not explicitly specifying the field to search on in the query
string syntax, the <literal>index.query.default_field</literal> will be used to derive
which field to search on. It defaults to <literal>_all</literal> field.</simpara>
<simpara>If the <literal>_all</literal> field is disabled and no <literal>fields</literal> are specified in the request`,
the <literal>simple_query_string</literal> query will automatically attempt to determine the
existing fields in the index&#8217;s mapping that are queryable, and perform the
search on those fields.</simpara>
<bridgehead id="_multi_field_2" renderas="sect3">Multi Field<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/simple-query-string-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>The fields parameter can also include pattern based field names,
allowing to automatically expand to the relevant fields (dynamically
introduced fields included). For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "simple_query_string" : {
            "fields" : ["content", "name.*^5"],
            "query" : "foo bar baz"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_flags" renderas="sect3">Flags<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/simple-query-string-query.asciidoc">Edit me</ulink></bridgehead>
<simpara><literal>simple_query_string</literal> support multiple flags to specify which parsing features
should be enabled. It is specified as a <literal>|</literal>-delimited string with the
<literal>flags</literal> parameter:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "simple_query_string" : {
            "query" : "foo | bar + baz*",
            "flags" : "OR|AND|PREFIX"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The available flags are: <literal>ALL</literal>, <literal>NONE</literal>, <literal>AND</literal>, <literal>OR</literal>, <literal>NOT</literal>, <literal>PREFIX</literal>, <literal>PHRASE</literal>,
<literal>PRECEDENCE</literal>, <literal>ESCAPE</literal>, <literal>WHITESPACE</literal>, <literal>FUZZY</literal>, <literal>NEAR</literal>, and <literal>SLOP</literal>.</simpara>
</section>
</chapter>
<chapter id="term-level-queries">
<title>Term level queries<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/term-level-queries.asciidoc">Edit me</ulink></title>
<simpara>While the <link linkend="full-text-queries">full text queries</link> will analyze the query
string before executing, the <emphasis>term-level queries</emphasis> operate on the exact terms
that are stored in the inverted index.</simpara>
<simpara>These queries are usually used for structured data like numbers, dates, and
enums, rather than full text fields.  Alternatively, they allow you to craft
low-level queries, foregoing the analysis process.</simpara>
<simpara>The queries in this group are:</simpara>
<variablelist>
<varlistentry>
<term>
<link linkend="query-dsl-term-query"><literal>term</literal> query</link>
</term>
<listitem>
<simpara>
    Find documents which contain the exact term specified in the field
    specified.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-terms-query"><literal>terms</literal> query</link>
</term>
<listitem>
<simpara>
    Find documents which contain any of the exact terms specified in the field
    specified.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-range-query"><literal>range</literal> query</link>
</term>
<listitem>
<simpara>
    Find documents where the field specified contains values (dates, numbers,
    or strings) in the range specified.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-exists-query"><literal>exists</literal> query</link>
</term>
<listitem>
<simpara>
    Find documents where the field specified contains any non-null value.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-prefix-query"><literal>prefix</literal> query</link>
</term>
<listitem>
<simpara>
    Find documents where the field specified contains terms which begin with
    the exact prefix specified.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-wildcard-query"><literal>wildcard</literal> query</link>
</term>
<listitem>
<simpara>
    Find documents where the field specified contains terms which match the
    pattern specified, where the pattern supports single character wildcards
    (<literal>?</literal>) and multi-character wildcards (<literal>*</literal>)
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-regexp-query"><literal>regexp</literal> query</link>
</term>
<listitem>
<simpara>
    Find documents where the field specified contains terms which match the
    <link linkend="regexp-syntax">regular expression</link> specified.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-fuzzy-query"><literal>fuzzy</literal> query</link>
</term>
<listitem>
<simpara>
    Find documents where the field specified contains terms which are fuzzily
    similar to the specified term.  Fuzziness is measured as a
    <ulink url="http://en.wikipedia.org/wiki/Damerau%E2%80%93Levenshtein_distance">Levenshtein edit distance</ulink>
    of 1 or 2.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-type-query"><literal>type</literal> query</link>
</term>
<listitem>
<simpara>
    Find documents of the specified type.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-ids-query"><literal>ids</literal> query</link>
</term>
<listitem>
<simpara>
    Find documents with the specified type and IDs.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<section id="query-dsl-term-query">
<title>Term Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/term-query.asciidoc">Edit me</ulink></title>
<simpara>The <literal>term</literal> query finds documents that contain the <emphasis role="strong">exact</emphasis> term specified
in the inverted index.  For instance:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _search
{
  "query": {
    "term" : { "user" : "Kimchy" } <co id="CO142-1"/>
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO142-1">
<para>
Finds documents which contain the exact term <literal>Kimchy</literal> in the inverted index
    of the <literal>user</literal> field.
</para>
</callout>
</calloutlist>
<simpara>A <literal>boost</literal> parameter can be specified to give this <literal>term</literal> query a higher
relevance score than another query, for instance:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _search
{
  "query": {
    "bool": {
      "should": [
        {
          "term": {
            "status": {
              "value": "urgent",
              "boost": 2.0 <co id="CO143-1"/>
            }
          }
        },
        {
          "term": {
            "status": "normal" <co id="CO143-2"/>
          }
        }
      ]
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO143-1">
<para>
The <literal>urgent</literal> query clause has a boost of <literal>2.0</literal>, meaning it is twice as important
    as the query clause for <literal>normal</literal>.
</para>
</callout>
<callout arearefs="CO143-2">
<para>
The <literal>normal</literal> clause has the default neutral boost of <literal>1.0</literal>.
</para>
</callout>
</calloutlist>
<sidebar>
<title>Why doesn&#8217;t the <literal>term</literal> query match my document?</title>
<simpara>String fields can be of type <literal>text</literal> (treated as full text, like the body of an
email), or <literal>keyword</literal> (treated as exact values, like an email address or a
zip code).  Exact values (like numbers, dates, and keywords) have
the exact value specified in the field added to the inverted index in order
to make them searchable.</simpara>
<simpara>However, <literal>text</literal> fields are <literal>analyzed</literal>. This means that their
values are first passed through an <link linkend="analysis">analyzer</link> to produce a list of
terms, which are then added to the inverted index.</simpara>
<simpara>There are many ways to analyze text: the default
<link linkend="analysis-standard-analyzer"><literal>standard</literal> analyzer</link> drops most punctuation,
breaks up text into individual words, and lower cases them.    For instance,
the <literal>standard</literal> analyzer would turn the string &#8220;Quick Brown Fox!&#8221; into the
terms [<literal>quick</literal>, <literal>brown</literal>, <literal>fox</literal>].</simpara>
<simpara>This analysis process makes it possible to search for individual words
within a big block of full text.</simpara>
<simpara>The <literal>term</literal> query looks for the <emphasis role="strong">exact</emphasis> term in the field&#8217;s inverted index&#8201;&#8212;&#8201;it doesn&#8217;t know anything about the field&#8217;s analyzer.  This makes it useful for
looking up values in keyword fields, or in numeric or date
fields.  When querying full text fields, use the
<link linkend="query-dsl-match-query"><literal>match</literal> query</link> instead, which understands how the field
has been analyzed.</simpara>
<simpara>To demonstrate, try out the example below.  First, create an index, specifying the field mappings, and index a document:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "full_text": {
          "type":  "text" <co id="CO144-1"/>
        },
        "exact_value": {
          "type":  "keyword" <co id="CO144-2"/>
        }
      }
    }
  }
}

PUT my_index/my_type/1
{
  "full_text":   "Quick Foxes!", <co id="CO144-3"/>
  "exact_value": "Quick Foxes!"  <co id="CO144-4"/>
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO144-1">
<para>
The <literal>full_text</literal> field is of type <literal>text</literal> and will be analyzed.
</para>
</callout>
<callout arearefs="CO144-2">
<para>
The <literal>exact_value</literal> field is of type <literal>keyword</literal> and will NOT be analyzed.
</para>
</callout>
<callout arearefs="CO144-3">
<para>
The <literal>full_text</literal> inverted index will contain the terms: [<literal>quick</literal>, <literal>foxes</literal>].
</para>
</callout>
<callout arearefs="CO144-4">
<para>
The <literal>exact_value</literal> inverted index will contain the exact term: [<literal>Quick Foxes!</literal>].
</para>
</callout>
</calloutlist>
<simpara>Now, compare the results for the <literal>term</literal> query and the <literal>match</literal> query:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET my_index/my_type/_search
{
  "query": {
    "term": {
      "exact_value": "Quick Foxes!" <co id="CO145-1"/>
    }
  }
}

GET my_index/my_type/_search
{
  "query": {
    "term": {
      "full_text": "Quick Foxes!" <co id="CO145-2"/>
    }
  }
}

GET my_index/my_type/_search
{
  "query": {
    "term": {
      "full_text": "foxes" <co id="CO145-3"/>
    }
  }
}

GET my_index/my_type/_search
{
  "query": {
    "match": {
      "full_text": "Quick Foxes!" <co id="CO145-4"/>
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<calloutlist>
<callout arearefs="CO145-1">
<para>
This query matches because the <literal>exact_value</literal> field contains the exact
    term <literal>Quick Foxes!</literal>.
</para>
</callout>
<callout arearefs="CO145-2">
<para>
This query does not match, because the <literal>full_text</literal> field only contains
    the terms <literal>quick</literal> and <literal>foxes</literal>. It does not contain the exact term
    <literal>Quick Foxes!</literal>.
</para>
</callout>
<callout arearefs="CO145-3">
<para>
A <literal>term</literal> query for the term <literal>foxes</literal> matches the <literal>full_text</literal> field.
</para>
</callout>
<callout arearefs="CO145-4">
<para>
This <literal>match</literal> query on the <literal>full_text</literal> field first analyzes the query string,
    then looks for documents containing <literal>quick</literal> or <literal>foxes</literal> or both.
</para>
</callout>
</calloutlist>
</sidebar>
</section>
<section id="query-dsl-terms-query">
<title>Terms Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/terms-query.asciidoc">Edit me</ulink></title>
<simpara>Filters documents that have fields that match any of the provided terms
(<emphasis role="strong">not analyzed</emphasis>). For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "constant_score" : {
            "filter" : {
                "terms" : { "user" : ["kimchy", "elasticsearch"]}
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The <literal>terms</literal> query is also aliased with <literal>in</literal> as the filter name for
simpler usage <phrase revisionflag="deleted" revision="5.0.0">Deprecated in 5.0.0. use <literal>terms</literal> instead.</phrase>.</simpara>
<bridgehead id="query-dsl-terms-lookup" renderas="sect4">Terms lookup mechanism<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/terms-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>When it&#8217;s needed to specify a <literal>terms</literal> filter with a lot of terms it can
be beneficial to fetch those term values from a document in an index. A
concrete example would be to filter tweets tweeted by your followers.
Potentially the amount of user ids specified in the terms filter can be
a lot. In this scenario it makes sense to use the terms filter&#8217;s terms
lookup mechanism.</simpara>
<simpara>The terms lookup mechanism supports the following options:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>index</literal>
</simpara>
</entry>
<entry>
<simpara>
    The index to fetch the term values from. Defaults to the
    current index.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>type</literal>
</simpara>
</entry>
<entry>
<simpara>
    The type to fetch the term values from.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>id</literal>
</simpara>
</entry>
<entry>
<simpara>
    The id of the document to fetch the term values from.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>path</literal>
</simpara>
</entry>
<entry>
<simpara>
    The field specified as path to fetch the actual values for the
    <literal>terms</literal> filter.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>routing</literal>
</simpara>
</entry>
<entry>
<simpara>
    A custom routing value to be used when retrieving the
    external terms doc.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>The values for the <literal>terms</literal> filter will be fetched from a field in a
document with the specified id in the specified type and index.
Internally a get request is executed to fetch the values from the
specified path. At the moment for this feature to work the <literal>_source</literal>
needs to be stored.</simpara>
<simpara>Also, consider using an index with a single shard and fully replicated
across all nodes if the "reference" terms data is not large. The lookup
terms filter will prefer to execute the get request on a local node if
possible, reducing the need for networking.</simpara>
<bridgehead id="_terms_lookup_twitter_example" renderas="sect4">Terms lookup twitter example<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/terms-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>At first we index the information for user with id 2, specifically, its
followers, than index a tweet from user with id 1. Finally we search on
all the tweets that match the followers of user 2.</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /users/user/2
{
    "followers" : ["1", "3"]
}

PUT /tweets/tweet/1
{
    "user" : "1"
}

GET /tweets/_search
{
    "query" : {
        "terms" : {
            "user" : {
                "index" : "users",
                "type" : "user",
                "id" : "2",
                "path" : "followers"
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The structure of the external terms document can also include array of
inner objects, for example:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XPUT localhost:9200/users/user/2 -d '{
 "followers" : [
   {
     "id" : "1"
   },
   {
     "id" : "2"
   }
 ]
}'</programlisting>
<simpara>In which case, the lookup path will be <literal>followers.id</literal>.</simpara>
</section>
<section id="query-dsl-range-query">
<title>Range Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/range-query.asciidoc">Edit me</ulink></title>
<simpara>Matches documents with fields that have terms within a certain range.
The type of the Lucene query depends on the field type, for <literal>string</literal>
fields, the <literal>TermRangeQuery</literal>, while for number/date fields, the query is
a <literal>NumericRangeQuery</literal>. The following example returns all documents where
<literal>age</literal> is between <literal>10</literal> and <literal>20</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _search
{
    "query": {
        "range" : {
            "age" : {
                "gte" : 10,
                "lte" : 20,
                "boost" : 2.0
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The <literal>range</literal> query accepts the following parameters:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>gte</literal>
</simpara>
</entry>
<entry>
<simpara>
Greater-than or equal to
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>gt</literal>
</simpara>
</entry>
<entry>
<simpara>
Greater-than
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>lte</literal>
</simpara>
</entry>
<entry>
<simpara>
Less-than or equal to
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>lt</literal>
</simpara>
</entry>
<entry>
<simpara>
Less-than
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>boost</literal>
</simpara>
</entry>
<entry>
<simpara>
Sets the boost value of the query, defaults to <literal>1.0</literal>
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<section id="ranges-on-dates">
<title>Ranges on date fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/range-query.asciidoc">Edit me</ulink></title>
<simpara>When running <literal>range</literal> queries on fields of type <link linkend="date"><literal>date</literal></link>, ranges can be
specified using <xref linkend="date-math"/>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _search
{
    "query": {
        "range" : {
            "date" : {
                "gte" : "now-1d/d",
                "lt" :  "now/d"
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<section id="_date_math_and_rounding">
<title>Date math and rounding<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/range-query.asciidoc">Edit me</ulink></title>
<simpara>When using <link linkend="date-math">date math</link> to round dates to the nearest day, month,
hour, etc, the rounded dates depend on whether the ends of the ranges are
inclusive or exclusive.</simpara>
<simpara>Rounding up moves to the last millisecond of the rounding scope, and rounding
down to the first millisecond of the rounding scope. For example:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>gt</literal>
</simpara>
</entry>
<entry>
<simpara>
    Greater than the date rounded up: <literal>2014-11-18||/M</literal> becomes
    <literal>2014-11-30T23:59:59.999</literal>, ie excluding the entire month.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>gte</literal>
</simpara>
</entry>
<entry>
<simpara>
    Greater than or equal to the date rounded down: <literal>2014-11-18||/M</literal> becomes
    <literal>2014-11-01</literal>, ie including the entire month.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>lt</literal>
</simpara>
</entry>
<entry>
<simpara>
    Less than the date rounded down: <literal>2014-11-18||/M</literal> becomes <literal>2014-11-01</literal>, ie
    excluding the entire month.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>lte</literal>
</simpara>
</entry>
<entry>
<simpara>
    Less than or equal to the date rounded up: <literal>2014-11-18||/M</literal> becomes
    <literal>2014-11-30T23:59:59.999</literal>, ie including the entire month.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
<section id="_date_format_in_range_queries">
<title>Date format in range queries<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/range-query.asciidoc">Edit me</ulink></title>
<simpara>Formatted dates will be parsed using the <link linkend="mapping-date-format"><literal>format</literal></link>
specified on the <link linkend="date"><literal>date</literal></link> field by default, but it can be overridden by
passing the <literal>format</literal> parameter to the <literal>range</literal> query:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _search
{
    "query": {
        "range" : {
            "born" : {
                "gte": "01/01/2012",
                "lte": "2013",
                "format": "dd/MM/yyyy||yyyy"
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="_time_zone_in_range_queries">
<title>Time zone in range queries<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/range-query.asciidoc">Edit me</ulink></title>
<simpara>Dates can be converted from another timezone to UTC either by specifying the
time zone in the date value itself (if the <link linkend="mapping-date-format"><literal>format</literal></link>
accepts it), or it can be specified as the <literal>time_zone</literal> parameter:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _search
{
    "query": {
        "range" : {
            "timestamp" : {
                "gte": "2015-01-01 00:00:00", <co id="CO146-1"/>
                "lte": "now", <co id="CO146-2"/>
                "time_zone": "+01:00"
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO146-1">
<para>
This date will be converted to <literal>2014-12-31T23:00:00 UTC</literal>.
</para>
</callout>
<callout arearefs="CO146-2">
<para>
<literal>now</literal> is not affected by the <literal>time_zone</literal> parameter (dates must be stored as UTC).
</para>
</callout>
</calloutlist>
</section>
</section>
</section>
<section id="query-dsl-exists-query">
<title>Exists Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/exists-query.asciidoc">Edit me</ulink></title>
<simpara>Returns documents that have at least one non-<literal>null</literal> value in the original field:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "exists" : { "field" : "user" }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>For instance, these documents would all match the above query:</simpara>
<programlisting language="js" linenumbering="unnumbered">{ "user": "jane" }
{ "user": "" } <co id="CO147-1"/>
{ "user": "-" } <co id="CO147-2"/>
{ "user": ["jane"] }
{ "user": ["jane", null ] } <co id="CO147-3"/></programlisting>
<calloutlist>
<callout arearefs="CO147-1">
<para>
An empty string is a non-<literal>null</literal> value.
</para>
</callout>
<callout arearefs="CO147-2">
<para>
Even though the <literal>standard</literal> analyzer would emit zero tokens, the original field is non-<literal>null</literal>.
</para>
</callout>
<callout arearefs="CO147-3">
<para>
At least one non-<literal>null</literal> value is required.
</para>
</callout>
</calloutlist>
<simpara>These documents would <emphasis role="strong">not</emphasis> match the above query:</simpara>
<programlisting language="js" linenumbering="unnumbered">{ "user": null }
{ "user": [] } <co id="CO148-1"/>
{ "user": [null] } <co id="CO148-2"/>
{ "foo":  "bar" } <co id="CO148-3"/></programlisting>
<calloutlist>
<callout arearefs="CO148-1">
<para>
This field has no values.
</para>
</callout>
<callout arearefs="CO148-2">
<para>
At least one non-<literal>null</literal> value is required.
</para>
</callout>
<callout arearefs="CO148-3">
<para>
The <literal>user</literal> field is missing completely.
</para>
</callout>
</calloutlist>
<bridgehead id="_literal_null_value_literal_mapping" renderas="sect3"><literal>null_value</literal> mapping<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/exists-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>If the field mapping includes the <link linkend="null-value"><literal>null_value</literal></link> setting
then explicit <literal>null</literal> values are replaced with the specified <literal>null_value</literal>.  For
instance, if the <literal>user</literal> field were mapped as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">  "user": {
    "type": "text",
    "null_value": "_null_"
  }</programlisting>
<simpara>then explicit <literal>null</literal> values would be indexed as the string <literal>_null_</literal>, and the
following docs would match the <literal>exists</literal> filter:</simpara>
<programlisting language="js" linenumbering="unnumbered">{ "user": null }
{ "user": [null] }</programlisting>
<simpara>However, these docs&#8212;without explicit <literal>null</literal> values&#8212;would still have
no values in the <literal>user</literal> field and thus would not match the <literal>exists</literal> filter:</simpara>
<programlisting language="js" linenumbering="unnumbered">{ "user": [] }
{ "foo": "bar" }</programlisting>
<section id="_literal_missing_literal_query">
<title><literal>missing</literal> query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/exists-query.asciidoc">Edit me</ulink></title>
<simpara><emphasis>missing</emphasis> query has been removed because it can be advantageously replaced by an <literal>exists</literal> query inside a must_not
clause as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "bool": {
            "must_not": {
                "exists": {
                    "field": "user"
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>This query returns documents that have no value in the user field.</simpara>
</section>
</section>
<section id="query-dsl-prefix-query">
<title>Prefix Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/prefix-query.asciidoc">Edit me</ulink></title>
<simpara>Matches documents that have fields containing terms with a specified
prefix (<emphasis role="strong">not analyzed</emphasis>). The prefix query maps to Lucene <literal>PrefixQuery</literal>.
The following matches documents where the user field contains a term
that starts with <literal>ki</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{ "query": {
    "prefix" : { "user" : "ki" }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>A boost can also be associated with the query:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{ "query": {
    "prefix" : { "user" :  { "value" : "ki", "boost" : 2.0 } }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Or with the <literal>prefix</literal> <phrase revisionflag="deleted" revision="5.0.0">Deprecated in 5.0.0. Use <literal>value</literal>.</phrase> syntax:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{ "query": {
    "prefix" : { "user" :  { "prefix" : "ki", "boost" : 2.0 } }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[warning:Deprecated field [prefix] used, expected [value] instead]</remark>
<simpara>This multi term query allows you to control how it gets rewritten using the
<link linkend="query-dsl-multi-term-rewrite">rewrite</link>
parameter.</simpara>
</section>
<section id="query-dsl-wildcard-query">
<title>Wildcard Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/wildcard-query.asciidoc">Edit me</ulink></title>
<simpara>Matches documents that have fields matching a wildcard expression (<emphasis role="strong">not
analyzed</emphasis>). Supported wildcards are <literal>*</literal>, which matches any character
sequence (including the empty one), and <literal>?</literal>, which matches any single
character. Note that this query can be slow, as it needs to iterate over many
terms. In order to prevent extremely slow wildcard queries, a wildcard
term should not start with one of the wildcards <literal>*</literal> or <literal>?</literal>. The wildcard
query maps to Lucene <literal>WildcardQuery</literal>.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "wildcard" : { "user" : "ki*y" }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>A boost can also be associated with the query:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "wildcard" : { "user" : { "value" : "ki*y", "boost" : 2.0 } }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Or :</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "wildcard" : { "user" : { "wildcard" : "ki*y", "boost" : 2.0 } }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>This multi term query allows to control how it gets rewritten using the
<link linkend="query-dsl-multi-term-rewrite">rewrite</link>
parameter.</simpara>
</section>
<section id="query-dsl-regexp-query">
<title>Regexp Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/regexp-query.asciidoc">Edit me</ulink></title>
<simpara>The <literal>regexp</literal> query allows you to use regular expression term queries.
See <xref linkend="regexp-syntax"/> for details of the supported regular expression language.
The "term queries" in that first sentence means that Elasticsearch will apply
the regexp to the terms produced by the tokenizer for that field, and not
to the original text of the field.</simpara>
<simpara><emphasis role="strong">Note</emphasis>: The performance of a <literal>regexp</literal> query heavily depends on the
regular expression chosen. Matching everything like <literal>.*</literal> is very slow as
well as using lookaround regular expressions. If possible, you should
try to use a long prefix before your regular expression starts. Wildcard
matchers like <literal>.*?+</literal> will mostly lower performance.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "regexp":{
            "name.first": "s.*y"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Boosting is also supported</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "regexp":{
            "name.first":{
                "value":"s.*y",
                "boost":1.2
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>You can also use special flags</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "regexp":{
            "name.first": {
                "value": "s.*y",
                "flags" : "INTERSECTION|COMPLEMENT|EMPTY"
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Possible flags are <literal>ALL</literal> (default), <literal>ANYSTRING</literal>, <literal>COMPLEMENT</literal>,
<literal>EMPTY</literal>, <literal>INTERSECTION</literal>, <literal>INTERVAL</literal>, or <literal>NONE</literal>. Please check the
<ulink url="http://lucene.apache.org/core/4_9_0/core/org/apache/lucene/util/automaton/RegExp.html">Lucene
documentation</ulink> for their meaning</simpara>
<simpara>Regular expressions are dangerous because it&#8217;s easy to accidentally
create an innocuous looking one that requires an exponential number of
internal determinized automaton states (and corresponding RAM and CPU)
for Lucene to execute.  Lucene prevents these using the
<literal>max_determinized_states</literal> setting (defaults to 10000).  You can raise
this limit to allow more complex regular expressions to execute.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "regexp":{
            "name.first": {
                "value": "s.*y",
                "flags" : "INTERSECTION|COMPLEMENT|EMPTY",
                "max_determinized_states": 20000
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<section id="regexp-syntax">
<title>Regular expression syntax<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/regexp-syntax.asciidoc">Edit me</ulink></title>
<simpara>Regular expression queries are supported by the <literal>regexp</literal> and the <literal>query_string</literal>
queries.  The Lucene regular expression engine
is not Perl-compatible but supports a smaller range of operators.</simpara>
<note>
<simpara>We will not attempt to explain regular expressions, but
just explain the supported operators.</simpara>
</note>
<section id="_standard_operators">
<title>Standard operators<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/regexp-syntax.asciidoc">Edit me</ulink></title>
<variablelist>
<varlistentry>
<term>
Anchoring
</term>
<listitem>
<simpara>Most regular expression engines allow you to match any part of a string.
If you want the regexp pattern to start at the beginning of the string or
finish at the end of the string, then you have to <emphasis>anchor</emphasis> it specifically,
using <literal>^</literal> to indicate the beginning or <literal>$</literal> to indicate the end.</simpara>
<simpara>Lucene&#8217;s patterns are always anchored.  The pattern provided must match
the entire string. For string <literal>"abcde"</literal>:</simpara>
<literallayout class="monospaced">ab.*     # match
abcd     # no match</literallayout>
</listitem>
</varlistentry>
<varlistentry>
<term>
Allowed characters
</term>
<listitem>
<simpara>Any Unicode characters may be used in the pattern, but certain characters
are reserved and must be escaped.  The standard reserved characters are:</simpara>
<literallayout class="monospaced">. ? + * | { } [ ] ( ) " \</literallayout>
<simpara>If you enable optional features (see below) then these characters may
also be reserved:</simpara>
<literallayout class="monospaced"># @ &amp; &lt; &gt;  ~</literallayout>
<simpara>Any reserved character can be escaped with a backslash <literal>"\*"</literal> including
a literal backslash character: <literal>"\\"</literal></simpara>
<simpara>Additionally, any characters (except double quotes) are interpreted literally
when surrounded by double quotes:</simpara>
<literallayout class="monospaced">john"@smith.com"</literallayout>
</listitem>
</varlistentry>
<varlistentry>
<term>
Match any character
</term>
<listitem>
<simpara>The period <literal>"."</literal> can be used to represent any character.  For string <literal>"abcde"</literal>:</simpara>
<literallayout class="monospaced">ab...   # match
a.c.e   # match</literallayout>
</listitem>
</varlistentry>
<varlistentry>
<term>
One-or-more
</term>
<listitem>
<simpara>The plus sign <literal>"+"</literal> can be used to repeat the preceding shortest pattern
once or more times. For string <literal>"aaabbb"</literal>:</simpara>
<literallayout class="monospaced">a+b+        # match
aa+bb+      # match
a+.+        # match
aa+bbb+     # match</literallayout>
</listitem>
</varlistentry>
<varlistentry>
<term>
Zero-or-more
</term>
<listitem>
<simpara>The asterisk <literal>"*"</literal> can be used to match the preceding shortest pattern
zero-or-more times.  For string <literal>"aaabbb</literal>":</simpara>
<literallayout class="monospaced">a*b*        # match
a*b*c*      # match
.*bbb.*     # match
aaa*bbb*    # match</literallayout>
</listitem>
</varlistentry>
<varlistentry>
<term>
Zero-or-one
</term>
<listitem>
<simpara>The question mark <literal>"?"</literal> makes the preceding shortest pattern optional. It
matches zero or one times.  For string <literal>"aaabbb"</literal>:</simpara>
<literallayout class="monospaced">aaa?bbb?    # match
aaaa?bbbb?  # match
.....?.?    # match
aa?bb?      # no match</literallayout>
</listitem>
</varlistentry>
<varlistentry>
<term>
Min-to-max
</term>
<listitem>
<simpara>Curly brackets <literal>"{}"</literal> can be used to specify a minimum and (optionally)
a maximum number of times the preceding shortest pattern can repeat.  The
allowed forms are:</simpara>
<literallayout class="monospaced">{5}     # repeat exactly 5 times
{2,5}   # repeat at least twice and at most 5 times
{2,}    # repeat at least twice</literallayout>
<simpara>For string <literal>"aaabbb"</literal>:</simpara>
<literallayout class="monospaced">a{3}b{3}        # match
a{2,4}b{2,4}    # match
a{2,}b{2,}      # match
.{3}.{3}        # match
a{4}b{4}        # no match
a{4,6}b{4,6}    # no match
a{4,}b{4,}      # no match</literallayout>
</listitem>
</varlistentry>
<varlistentry>
<term>
Grouping
</term>
<listitem>
<simpara>Parentheses <literal>"()"</literal> can be used to form sub-patterns. The quantity operators
listed above operate on the shortest previous pattern, which can be a group.
For string <literal>"ababab"</literal>:</simpara>
<literallayout class="monospaced">(ab)+       # match
ab(ab)+     # match
(..)+       # match
(...)+      # no match
(ab)*       # match
abab(ab)?   # match
ab(ab)?     # no match
(ab){3}     # match
(ab){1,2}   # no match</literallayout>
</listitem>
</varlistentry>
<varlistentry>
<term>
Alternation
</term>
<listitem>
<simpara>The pipe symbol <literal>"|"</literal> acts as an OR operator. The match will succeed if
the pattern on either the left-hand side OR the right-hand side matches.
The alternation applies to the <emphasis>longest pattern</emphasis>, not the shortest.
For string <literal>"aabb"</literal>:</simpara>
<literallayout class="monospaced">aabb|bbaa   # match
aacc|bb     # no match
aa(cc|bb)   # match
a+|b+       # no match
a+b+|b+a+   # match
a+(b|c)+    # match</literallayout>
</listitem>
</varlistentry>
<varlistentry>
<term>
Character classes
</term>
<listitem>
<simpara>Ranges of potential characters may be represented as character classes
by enclosing them in square brackets <literal>"[]"</literal>. A leading <literal>^</literal>
negates the character class. The allowed forms are:</simpara>
<literallayout class="monospaced">[abc]   # 'a' or 'b' or 'c'
[a-c]   # 'a' or 'b' or 'c'
[-abc]  # '-' or 'a' or 'b' or 'c'
[abc\-] # '-' or 'a' or 'b' or 'c'
[^abc]  # any character except 'a' or 'b' or 'c'
[^a-c]  # any character except 'a' or 'b' or 'c'
[^-abc]  # any character except '-' or 'a' or 'b' or 'c'
[^abc\-] # any character except '-' or 'a' or 'b' or 'c'</literallayout>
<simpara>Note that the dash <literal>"-"</literal> indicates a range of characters, unless it is
the first character or if it is escaped with a backslash.</simpara>
<simpara>For string <literal>"abcd"</literal>:</simpara>
<literallayout class="monospaced">ab[cd]+     # match
[a-d]+      # match
[^a-d]+     # no match</literallayout>
</listitem>
</varlistentry>
</variablelist>
</section>
<section id="_optional_operators">
<title>Optional operators<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/regexp-syntax.asciidoc">Edit me</ulink></title>
<simpara>These operators are available by default as the <literal>flags</literal> parameter defaults to <literal>ALL</literal>.
Different flag combinations (concatenated with <literal>"|"</literal>) can be used to enable/disable
specific operators:</simpara>
<literallayout class="monospaced">{
    "regexp": {
        "username": {
            "value": "john~athon&lt;1-5&gt;",
            "flags": "COMPLEMENT|INTERVAL"
        }
    }
}</literallayout>
<variablelist>
<varlistentry>
<term>
Complement
</term>
<listitem>
<simpara>The complement is probably the most useful option. The shortest pattern that
follows a tilde <literal>"~"</literal> is negated.  For instance, `"ab~cd" means:</simpara>
<itemizedlist>
<listitem>
<simpara>
Starts with <literal>a</literal>
</simpara>
</listitem>
<listitem>
<simpara>
Followed by <literal>b</literal>
</simpara>
</listitem>
<listitem>
<simpara>
Followed by a string of any length that it anything but <literal>c</literal>
</simpara>
</listitem>
<listitem>
<simpara>
Ends with <literal>d</literal>
</simpara>
</listitem>
</itemizedlist>
<simpara>For the string <literal>"abcdef"</literal>:</simpara>
<literallayout class="monospaced">ab~df     # match
ab~cf     # match
ab~cdef   # no match
a~(cb)def # match
a~(bc)def # no match</literallayout>
<simpara>Enabled with the <literal>COMPLEMENT</literal> or <literal>ALL</literal> flags.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Interval
</term>
<listitem>
<simpara>The interval option enables the use of numeric ranges, enclosed by angle
brackets <literal>"&lt;&gt;"</literal>. For string: <literal>"foo80"</literal>:</simpara>
<literallayout class="monospaced">foo&lt;1-100&gt;     # match
foo&lt;01-100&gt;    # match
foo&lt;001-100&gt;   # no match</literallayout>
<simpara>Enabled with the <literal>INTERVAL</literal> or <literal>ALL</literal> flags.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Intersection
</term>
<listitem>
<simpara>The ampersand <literal>"&amp;"</literal> joins two patterns in a way that both of them have to
match. For string <literal>"aaabbb"</literal>:</simpara>
<literallayout class="monospaced">aaa.+&amp;.+bbb     # match
aaa&amp;bbb         # no match</literallayout>
<simpara>Using this feature usually means that you should rewrite your regular
expression.</simpara>
<simpara>Enabled with the <literal>INTERSECTION</literal> or <literal>ALL</literal> flags.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Any string
</term>
<listitem>
<simpara>The at sign <literal>"@"</literal> matches any string in its entirety.  This could be combined
with the intersection and complement above to express &#8220;everything except&#8221;.
For instance:</simpara>
<literallayout class="monospaced">@&amp;~(foo.+)      # anything except string beginning with "foo"</literallayout>
<simpara>Enabled with the <literal>ANYSTRING</literal> or <literal>ALL</literal> flags.</simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
</section>
</section>
<section id="query-dsl-fuzzy-query">
<title>Fuzzy Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/fuzzy-query.asciidoc">Edit me</ulink></title>
<warning revisionflag="deleted" revision="5.0.0"><title>Deprecated in 5.0.0.</title><simpara> Will be removed in 6.0. Use match queries with fuzziness instead.</simpara></warning>
<simpara>The fuzzy query uses similarity based on Levenshtein edit distance.</simpara>
<section id="_string_fields">
<title>String fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/fuzzy-query.asciidoc">Edit me</ulink></title>
<simpara>The <literal>fuzzy</literal> query generates all possible matching terms that are within  the
maximum edit distance specified in <literal>fuzziness</literal> and then checks the term
dictionary to find out which of those generated terms actually exist in the
index.</simpara>
<simpara>Here is a simple example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
       "fuzzy" : { "user" : "ki" }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[warning:fuzzy query is deprecated. Instead use the [match] query with fuzziness parameter]</remark>
<simpara>Or with more advanced settings:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "fuzzy" : {
            "user" : {
                "value" :         "ki",
                    "boost" :         1.0,
                    "fuzziness" :     2,
                    "prefix_length" : 0,
                    "max_expansions": 100
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[warning:fuzzy query is deprecated. Instead use the [match] query with fuzziness parameter]</remark>
<bridgehead id="_parameters_6" renderas="sect4">Parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/fuzzy-query.asciidoc">Edit me</ulink></bridgehead>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>fuzziness</literal>
</simpara>
</entry>
<entry>
<simpara>
    The maximum edit distance. Defaults to <literal>AUTO</literal>. See <xref linkend="fuzziness"/>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>prefix_length</literal>
</simpara>
</entry>
<entry>
<simpara>
    The number of initial characters which will not be &#8220;fuzzified&#8221;. This
    helps to reduce the number of terms which must be examined. Defaults
    to <literal>0</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max_expansions</literal>
</simpara>
</entry>
<entry>
<simpara>
    The maximum number of terms that the <literal>fuzzy</literal> query will expand to.
    Defaults to <literal>50</literal>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<warning><simpara>This query can be very heavy if <literal>prefix_length</literal> is set to <literal>0</literal> and if
<literal>max_expansions</literal> is set to a high number. It could result in every term in the
index being examined!</simpara></warning>
</section>
</section>
<section id="query-dsl-type-query">
<title>Type Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/type-query.asciidoc">Edit me</ulink></title>
<simpara>Filters documents matching the provided document / mapping type.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "type" : {
            "value" : "my_type"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="query-dsl-ids-query">
<title>Ids Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/ids-query.asciidoc">Edit me</ulink></title>
<simpara>Filters documents that only have the provided ids. Note, this query
uses the <link linkend="mapping-uid-field">_uid</link> field.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "ids" : {
            "type" : "my_type",
            "values" : ["1", "4", "100"]
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The <literal>type</literal> is optional and can be omitted, and can also accept an array
of values. If no type is specified, all types defined in the index mapping are tried.</simpara>
</section>
</chapter>
<chapter id="compound-queries">
<title>Compound queries<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/compound-queries.asciidoc">Edit me</ulink></title>
<simpara>Compound queries wrap other compound or leaf queries, either to combine their
results and scores, to change their behaviour, or to switch from query to
filter context.</simpara>
<simpara>The queries in this group are:</simpara>
<variablelist>
<varlistentry>
<term>
<link linkend="query-dsl-constant-score-query"><literal>constant_score</literal> query</link>
</term>
<listitem>
<simpara>
A query which wraps another query, but executes it in filter context.  All
matching documents are given the same &#8220;constant&#8221; <literal>_score</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-bool-query"><literal>bool</literal> query</link>
</term>
<listitem>
<simpara>
The default query for combining multiple leaf or compound query clauses, as
<literal>must</literal>, <literal>should</literal>, <literal>must_not</literal>, or <literal>filter</literal> clauses.  The <literal>must</literal> and <literal>should</literal>
clauses have their scores combined&#8201;&#8212;&#8201;the more matching clauses, the better&#8201;&#8212;&#8201;while the <literal>must_not</literal> and <literal>filter</literal> clauses are executed in filter context.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-dis-max-query"><literal>dis_max</literal> query</link>
</term>
<listitem>
<simpara>
A query which accepts multiple queries, and returns any documents which match
any of the query clauses.  While the <literal>bool</literal> query combines the scores from all
matching queries, the <literal>dis_max</literal> query uses the score of the single best-
matching query clause.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-function-score-query"><literal>function_score</literal> query</link>
</term>
<listitem>
<simpara>
Modify the scores returned by the main query with functions to take into
account factors like popularity, recency, distance, or custom algorithms
implemented with scripting.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-boosting-query"><literal>boosting</literal> query</link>
</term>
<listitem>
<simpara>
Return documents which match a <literal>positive</literal> query, but reduce the score of
documents which also match a <literal>negative</literal> query.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-indices-query"><literal>indices</literal> query</link>
</term>
<listitem>
<simpara>
Execute one query for the specified indices, and another for other indices.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<section id="query-dsl-constant-score-query">
<title>Constant Score Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/constant-score-query.asciidoc">Edit me</ulink></title>
<simpara>A query that wraps another query and simply returns a
constant score equal to the query boost for every document in the
filter. Maps to Lucene <literal>ConstantScoreQuery</literal>.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "constant_score" : {
            "filter" : {
                "term" : { "user" : "kimchy"}
            },
            "boost" : 1.2
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="query-dsl-bool-query">
<title>Bool Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/bool-query.asciidoc">Edit me</ulink></title>
<simpara>A query that matches documents matching boolean combinations of other
queries. The bool query maps to Lucene <literal>BooleanQuery</literal>. It is built using
one or more boolean clauses, each clause with a typed occurrence. The
occurrence types are:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Occur </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>must</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The clause (query) must appear in matching documents and will
contribute to the score.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>filter</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The clause (query) must appear in matching documents. However unlike
<literal>must</literal> the score of the query will be ignored.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>should</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The clause (query) should appear in the matching document. In
a boolean query with no <literal>must</literal> or <literal>filter</literal> clauses, one or more <literal>should</literal> clauses
must match a document. The minimum number of should clauses to match can
be set using the
<link linkend="query-dsl-minimum-should-match"><literal>minimum_should_match</literal></link>
parameter.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>must_not</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The clause (query) must not appear in the matching
documents.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<important>
<title>Bool query in filter context</title>
<simpara>If this query is used in a filter context and it has <literal>should</literal>
clauses then at least one <literal>should</literal> clause is required to match.</simpara>
</important>
<simpara>The bool query also supports <literal>disable_coord</literal> parameter (defaults to
<literal>false</literal>). Basically the coord similarity computes a score factor based
on the fraction of all query terms that a document contains. See Lucene
<literal>BooleanQuery</literal> for more details.</simpara>
<simpara>The <literal>bool</literal> query takes a <emphasis>more-matches-is-better</emphasis> approach, so the score from
each matching <literal>must</literal> or <literal>should</literal> clause will be added together to provide the
final <literal>_score</literal> for each document.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _search
{
  "query": {
    "bool" : {
      "must" : {
        "term" : { "user" : "kimchy" }
      },
      "filter": {
        "term" : { "tag" : "tech" }
      },
      "must_not" : {
        "range" : {
          "age" : { "from" : 10, "to" : 20 }
        }
      },
      "should" : [
        { "term" : { "tag" : "wow" } },
        { "term" : { "tag" : "elasticsearch" } }
      ],
      "minimum_should_match" : 1,
      "boost" : 1.0
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<section id="_scoring_with_literal_bool_filter_literal">
<title>Scoring with <literal>bool.filter</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/bool-query.asciidoc">Edit me</ulink></title>
<simpara>Queries specified under the <literal>filter</literal> element have no effect on scoring&#8201;&#8212;&#8201;scores are returned as <literal>0</literal>.  Scores are only affected by the query that has
been specified.  For instance, all three of the following queries return
all documents where the <literal>status</literal> field contains the term <literal>active</literal>.</simpara>
<simpara>This first query assigns a score of <literal>0</literal> to all documents, as no scoring
query has been specified:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _search
{
  "query": {
    "bool": {
      "filter": {
        "term": {
          "status": "active"
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>This <literal>bool</literal> query has a <literal>match_all</literal> query, which assigns a score of <literal>1.0</literal> to
all documents.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _search
{
  "query": {
    "bool": {
      "must": {
        "match_all": {}
      },
      "filter": {
        "term": {
          "status": "active"
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>This <literal>constant_score</literal> query behaves in exactly the same way as the second example above.
The <literal>constant_score</literal> query assigns a score of <literal>1.0</literal> to all documents matched
by the filter.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _search
{
  "query": {
    "constant_score": {
      "filter": {
        "term": {
          "status": "active"
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="_using_named_queries_to_see_which_clauses_matched">
<title>Using named queries to see which clauses matched<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/bool-query.asciidoc">Edit me</ulink></title>
<simpara>If you need to know which of the clauses in the bool query matched the documents
returned from the query, you can use
<link linkend="search-request-named-queries-and-filters">named queries</link> to assign a name to
each clause.</simpara>
</section>
</section>
<section id="query-dsl-dis-max-query">
<title>Dis Max Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/dis-max-query.asciidoc">Edit me</ulink></title>
<simpara>A query that generates the union of documents produced by its
subqueries, and that scores each document with the maximum score for
that document as produced by any subquery, plus a tie breaking increment
for any additional matching subqueries.</simpara>
<simpara>This is useful when searching for a word in multiple fields with
different boost factors (so that the fields cannot be combined
equivalently into a single search field). We want the primary score to
be the one associated with the highest boost, not the sum of the field
scores (as Boolean Query would give). If the query is "albino elephant"
this ensures that "albino" matching one field and "elephant" matching
another gets a higher score than "albino" matching both fields. To get
this result, use both Boolean Query and DisjunctionMax Query: for each
term a DisjunctionMaxQuery searches for it in each field, while the set
of these DisjunctionMaxQuery&#8217;s is combined into a BooleanQuery.</simpara>
<simpara>The tie breaker capability allows results that include the same term in
multiple fields to be judged better than results that include this term
in only the best of those multiple fields, without confusing this with
the better case of two different terms in the multiple fields.The
default <literal>tie_breaker</literal> is <literal>0.0</literal>.</simpara>
<simpara>This query maps to Lucene <literal>DisjunctionMaxQuery</literal>.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "dis_max" : {
            "tie_breaker" : 0.7,
                "boost" : 1.2,
                "queries" : [
                {
                    "term" : { "age" : 34 }
                },
                {
                    "term" : { "age" : 35 }
                }
                ]
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="query-dsl-function-score-query">
<title>Function Score Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/function-score-query.asciidoc">Edit me</ulink></title>
<simpara>The <literal>function_score</literal> allows you to modify the score of documents that are
retrieved by a query. This can be useful if, for example, a score
function is computationally expensive and it is sufficient to compute
the score on a filtered set of documents.</simpara>
<simpara>To use <literal>function_score</literal>, the user has to define a query and one or
more functions, that compute a new score for each document returned
by the query.</simpara>
<simpara><literal>function_score</literal> can be used with only one function like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "function_score": {
            "query": { "match_all": {} },
            "boost": "5",
            "random_score": {}, <co id="CO149-1"/>
            "boost_mode":"multiply"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO149-1">
<para>
See <xref linkend="score-functions"/> for a list of supported functions.
</para>
</callout>
</calloutlist>
<simpara>Furthermore, several functions can be combined. In this case one can
optionally choose to apply the function only if a document matches a
given filtering query</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "function_score": {
          "query": { "match_all": {} },
          "boost": "5", <co id="CO150-1"/>
          "functions": [
              {
                  "filter": { "match": { "test": "bar" } },
                  "random_score": {}, <co id="CO150-2"/>
                  "weight": 23
              },
              {
                  "filter": { "match": { "test": "cat" } },
                  "weight": 42
              }
          ],
          "max_boost": 42,
          "score_mode": "max",
          "boost_mode": "multiply",
          "min_score" : 42
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO150-1">
<para>
Boost for the whole query.
</para>
</callout>
<callout arearefs="CO150-2">
<para>
See <xref linkend="score-functions"/> for a list of supported functions.
</para>
</callout>
</calloutlist>
<note><simpara>The scores produced by the filtering query of each function do not matter.</simpara></note>
<simpara>If no filter is given with a function this is equivalent to specifying
<literal>"match_all": {}</literal></simpara>
<simpara>First, each document is scored by the defined functions. The parameter
<literal>score_mode</literal> specifies how the computed scores are combined:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>multiply</literal>
</simpara>
</entry>
<entry>
<simpara>
scores are multiplied (default)
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>sum</literal>
</simpara>
</entry>
<entry>
<simpara>
scores are summed
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>avg</literal>
</simpara>
</entry>
<entry>
<simpara>
scores are averaged
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>first</literal>
</simpara>
</entry>
<entry>
<simpara>
the first function that has a matching filter
                is applied
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max</literal>
</simpara>
</entry>
<entry>
<simpara>
maximum score is used
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>min</literal>
</simpara>
</entry>
<entry>
<simpara>
minimum score is used
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>Because scores can be on different scales (for example, between 0 and 1 for decay functions but arbitrary for <literal>field_value_factor</literal>) and also
because sometimes a different impact of functions on the score is desirable, the score of each function can be adjusted with a user defined
<literal>weight</literal>. The <literal>weight</literal> can be defined per function in the <literal>functions</literal> array (example above) and is multiplied with the score computed by
the respective function.
If weight is given without any other function declaration, <literal>weight</literal> acts as a function that simply returns the <literal>weight</literal>.</simpara>
<simpara>In case <literal>score_mode</literal> is set to <literal>avg</literal> the individual scores will be combined by a <emphasis role="strong">weighted</emphasis> average.
For example, if two functions return score 1 and 2 and their respective weights are 3 and 4, then their scores will be combined as
<literal>(1*3+2*4)/(3+4)</literal> and <emphasis role="strong">not</emphasis> <literal>(1*3+2*4)/2</literal>.</simpara>
<simpara>The new score can be restricted to not exceed a certain limit by setting
the <literal>max_boost</literal> parameter. The default for <literal>max_boost</literal> is FLT_MAX.</simpara>
<simpara>The newly computed score is combined with the score of the
query. The parameter <literal>boost_mode</literal> defines how:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>multiply</literal>
</simpara>
</entry>
<entry>
<simpara>
query score and function score is multiplied (default)
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>replace</literal>
</simpara>
</entry>
<entry>
<simpara>
only function score is used, the query score is ignored
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>sum</literal>
</simpara>
</entry>
<entry>
<simpara>
query score and function score are added
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>avg</literal>
</simpara>
</entry>
<entry>
<simpara>
average
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max</literal>
</simpara>
</entry>
<entry>
<simpara>
max of query score and function score
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>min</literal>
</simpara>
</entry>
<entry>
<simpara>
min of query score and function score
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>By default, modifying the score does not change which documents match. To exclude
documents that do not meet a certain score threshold the <literal>min_score</literal> parameter can be set to the desired score threshold.</simpara>
<simpara id="score-functions">The <literal>function_score</literal> query provides several types of score functions.</simpara>
<itemizedlist>
<listitem>
<simpara>
<link linkend="function-script-score"><literal>script_score</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="function-weight"><literal>weight</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="function-random"><literal>random_score</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="function-field-value-factor"><literal>field_value_factor</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="function-decay">decay functions</link>: <literal>gauss</literal>, <literal>linear</literal>, <literal>exp</literal>
</simpara>
</listitem>
</itemizedlist>
<section id="function-script-score">
<title>Script score<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/function-score-query.asciidoc">Edit me</ulink></title>
<simpara>The <literal>script_score</literal> function allows you to wrap another query and customize
the scoring of it optionally with a computation derived from other numeric
field values in the doc using a script expression. Here is a
simple sample:</simpara>
<programlisting language="js" linenumbering="unnumbered">"script_score" : {
    "script" : {
      "lang": "painless",
      "inline": "_score * doc['my_numeric_field'].value"
    }
}</programlisting>
<simpara>On top of the different scripting field values and expression, the
<literal>_score</literal> script parameter can be used to retrieve the score based on the
wrapped query.</simpara>
<simpara>Scripts are cached for faster execution. If the script has parameters
that it needs to take into account, it is preferable to reuse the same
script, and provide parameters to it:</simpara>
<programlisting language="js" linenumbering="unnumbered">"script_score": {
    "script": {
        "lang": "painless",
        "params": {
            "param1": value1,
            "param2": value2
        },
        "inline": "_score * doc['my_numeric_field'].value / Math.pow(params.param1, params.param2)"
    }
}</programlisting>
<simpara>Note that unlike the <literal>custom_score</literal> query, the
score of the query is multiplied with the result of the script scoring. If
you wish to inhibit this, set <literal>"boost_mode": "replace"</literal></simpara>
</section>
<section id="function-weight">
<title>Weight<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/function-score-query.asciidoc">Edit me</ulink></title>
<simpara>The <literal>weight</literal> score allows you to multiply the score by the provided
<literal>weight</literal>. This can sometimes be desired since boost value set on
specific queries gets normalized, while for this score function it does
not. The number value is of type float.</simpara>
<programlisting language="js" linenumbering="unnumbered">"weight" : number</programlisting>
</section>
<section id="function-random">
<title>Random<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/function-score-query.asciidoc">Edit me</ulink></title>
<simpara>The <literal>random_score</literal> generates scores using a hash of the <literal>_uid</literal> field,
with a <literal>seed</literal> for variation. If <literal>seed</literal> is not specified, the current
time is used.</simpara>
<note><simpara>Using this feature will load field data for <literal>_uid</literal>, which can
be a memory intensive operation since the values are unique.</simpara></note>
<programlisting language="js" linenumbering="unnumbered">"random_score": {
    "seed" : number
}</programlisting>
</section>
<section id="function-field-value-factor">
<title>Field Value factor<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/function-score-query.asciidoc">Edit me</ulink></title>
<simpara>The <literal>field_value_factor</literal> function allows you to use a field from a document to
influence the score. It&#8217;s similar to using the <literal>script_score</literal> function, however,
it avoids the overhead of scripting. If used on a multi-valued field, only the
first value of the field is used in calculations.</simpara>
<simpara>As an example, imagine you have a document indexed with a numeric <literal>popularity</literal>
field and wish to influence the score of a document with this field, an example
doing so would look like:</simpara>
<programlisting language="js" linenumbering="unnumbered">"field_value_factor": {
  "field": "popularity",
  "factor": 1.2,
  "modifier": "sqrt",
  "missing": 1
}</programlisting>
<simpara>Which will translate into the following formula for scoring:</simpara>
<simpara><literal>sqrt(1.2 * doc['popularity'].value)</literal></simpara>
<simpara>There are a number of options for the <literal>field_value_factor</literal> function:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>field</literal>
</simpara>
</entry>
<entry>
<simpara>
    Field to be extracted from the document.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>factor</literal>
</simpara>
</entry>
<entry>
<simpara>
    Optional factor to multiply the field value with, defaults to <literal>1</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>modifier</literal>
</simpara>
</entry>
<entry>
<simpara>
    Modifier to apply to the field value, can be one of: <literal>none</literal>, <literal>log</literal>,
    <literal>log1p</literal>, <literal>log2p</literal>, <literal>ln</literal>, <literal>ln1p</literal>, <literal>ln2p</literal>, <literal>square</literal>, <literal>sqrt</literal>, or <literal>reciprocal</literal>.
    Defaults to <literal>none</literal>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top"> Modifier </entry>
<entry align="left" valign="top"> Meaning</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>none</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Do not apply any multiplier to the field value</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>log</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Take the <ulink url="https://en.wikipedia.org/wiki/Logarithm">logarithm</ulink> of the field value</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>log1p</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Add 1 to the field value and take the logarithm</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>log2p</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Add 2 to the field value and take the logarithm</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ln</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Take the <ulink url="https://en.wikipedia.org/wiki/Natural_logarithm">natural logarithm</ulink> of the field value</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ln1p</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Add 1 to the field value and take the natural logarithm</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ln2p</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Add 2 to the field value and take the natural logarithm</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>square</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Square the field value (multiply it by itself)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>sqrt</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Take the <ulink url="https://en.wikipedia.org/wiki/Square_root">square root</ulink> of the field value</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>reciprocal</literal></simpara></entry>
<entry align="left" valign="top"><simpara><ulink url="https://en.wikipedia.org/wiki/Multiplicative_inverse">Reciprocate</ulink> the field value, same as <literal>1/x</literal> where <literal>x</literal> is the field&#8217;s value</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<variablelist>
<varlistentry>
<term>
<literal>missing</literal>
</term>
<listitem>
<simpara>
    Value used if the document doesn&#8217;t have that field. The modifier
    and factor are still applied to it as though it were read from the document.
</simpara>
<literallayout class="monospaced">Keep in mind that taking the log() of 0, or the square root of a negative number
is an illegal operation, and an exception will be thrown. Be sure to limit the
values of the field with a range filter to avoid this, or use `log1p` and
`ln1p`.</literallayout>
</listitem>
</varlistentry>
</variablelist>
</section>
<section id="function-decay">
<title>Decay functions<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/function-score-query.asciidoc">Edit me</ulink></title>
<simpara>Decay functions score a document with a function that decays depending
on the distance of a numeric field value of the document from a user
given origin. This is similar to a range query, but with smooth edges
instead of boxes.</simpara>
<simpara>To use distance scoring on a query that has numerical fields, the user
has to define an <literal>origin</literal> and a <literal>scale</literal> for each field. The <literal>origin</literal>
is needed to define the &#8220;central point&#8221; from which the distance
is calculated, and the <literal>scale</literal> to define the rate of decay. The
decay function is specified as</simpara>
<programlisting language="js" linenumbering="unnumbered">"DECAY_FUNCTION": { <co id="CO151-1"/>
    "FIELD_NAME": { <co id="CO151-2"/>
          "origin": "11, 12",
          "scale": "2km",
          "offset": "0km",
          "decay": 0.33
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO151-1">
<para>
The <literal>DECAY_FUNCTION</literal> should be one of <literal>linear</literal>, <literal>exp</literal>, or <literal>gauss</literal>.
</para>
</callout>
<callout arearefs="CO151-2">
<para>
The specified field must be a numeric, date, or geo-point field.
</para>
</callout>
</calloutlist>
<simpara>In the above example, the field is a <link linkend="geo-point"><literal>geo_point</literal></link> and origin can be provided in geo format. <literal>scale</literal> and <literal>offset</literal> must be given with a unit in this case. If your field is a date field, you can set <literal>scale</literal> and <literal>offset</literal> as days, weeks, and so on. Example:</simpara>
<programlisting language="js" linenumbering="unnumbered">    "gauss": {
        "date": {
              "origin": "2013-09-17", <co id="CO152-1"/>
              "scale": "10d",
              "offset": "5d", <co id="CO152-2"/>
              "decay" : 0.5 <co id="CO152-3"/>
        }
    }</programlisting>
<calloutlist>
<callout arearefs="CO152-1">
<para>
The date format of the origin depends on the <link linkend="mapping-date-format"><literal>format</literal></link> defined in
    your mapping. If you do not define the origin, the current time is used.
</para>
</callout>
<callout arearefs="CO152-2 CO152-3">
<para>
The <literal>offset</literal> and <literal>decay</literal> parameters are optional.
</para>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>origin</literal>
</simpara>
</entry>
<entry>
<simpara>
    The point of origin used for calculating distance. Must be given as a
    number for numeric field, date for date fields and geo point for geo fields.
    Required for geo and numeric field. For date fields the default is <literal>now</literal>. Date
    math (for example <literal>now-1h</literal>) is supported for origin.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>scale</literal>
</simpara>
</entry>
<entry>
<simpara>
    Required for all types. Defines the distance from origin + offset at which the computed
    score will equal <literal>decay</literal> parameter. For geo fields: Can be defined as number+unit (1km, 12m,&#8230;).
    Default unit is meters. For date fields: Can to be defined as a number+unit ("1h", "10d",&#8230;).
    Default unit is milliseconds. For numeric field: Any number.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>offset</literal>
</simpara>
</entry>
<entry>
<simpara>
    If an <literal>offset</literal> is defined, the decay function will only compute the
    decay function for documents with a distance greater that the defined
    <literal>offset</literal>. The default is 0.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>decay</literal>
</simpara>
</entry>
<entry>
<simpara>
    The <literal>decay</literal> parameter defines how documents are scored at the distance
    given at <literal>scale</literal>. If no <literal>decay</literal> is defined, documents at the distance
    <literal>scale</literal> will be scored 0.5.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</callout>
</calloutlist>
<simpara>In the first example, your documents might represents hotels and contain a geo
location field. You want to compute a decay function depending on how
far the hotel is from a given location. You might not immediately see
what scale to choose for the gauss function, but you can say something
like: "At a distance of 2km from the desired location, the score should
be reduced to one third."
The parameter "scale" will then be adjusted automatically to assure that
the score function computes a score of 0.33 for hotels that are 2km away
from the desired location.</simpara>
<simpara>In the second example, documents with a field value between 2013-09-12 and 2013-09-22 would get a weight of 1.0 and documents which are 15 days from that date a weight of 0.5.</simpara>
<section id="_supported_decay_functions">
<title>Supported decay functions<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/function-score-query.asciidoc">Edit me</ulink></title>
<simpara>The <literal>DECAY_FUNCTION</literal> determines the shape of the decay:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>gauss</literal>
</term>
<listitem>
<simpara>Normal decay, computed as:</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/Gaussian.png"/>
  </imageobject>
  <textobject><phrase>images/Gaussian.png</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>where <inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/sigma.png"/>
  </imageobject>
  <textobject><phrase>images/sigma.png</phrase></textobject>
</inlinemediaobject> is computed to assure that the score takes the value <literal>decay</literal> at distance <literal>scale</literal> from <literal>origin</literal>+-<literal>offset</literal></simpara>
<remark> \sigma^2 = -scale^2/(2 \cdot ln(decay))</remark>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/sigma_calc.png"/>
  </imageobject>
  <textobject><phrase>images/sigma_calc.png</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>See <xref linkend="gauss-decay"/> for graphs demonstrating the curve generated by the <literal>gauss</literal> function.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>exp</literal>
</term>
<listitem>
<simpara>Exponential decay, computed as:</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/Exponential.png"/>
  </imageobject>
  <textobject><phrase>images/Exponential.png</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>where again the parameter <inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/lambda.png"/>
  </imageobject>
  <textobject><phrase>images/lambda.png</phrase></textobject>
</inlinemediaobject> is computed to assure that the score takes the value <literal>decay</literal> at distance <literal>scale</literal> from <literal>origin</literal>+-<literal>offset</literal></simpara>
<remark> \lambda = ln(decay)/scale</remark>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/lambda_calc.png"/>
  </imageobject>
  <textobject><phrase>images/lambda_calc.png</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>See <xref linkend="exp-decay"/> for graphs demonstrating the curve generated by the <literal>exp</literal> function.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>linear</literal>
</term>
<listitem>
<simpara>Linear decay, computed as:</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/Linear.png"/>
  </imageobject>
  <textobject><phrase>images/Linear.png</phrase></textobject>
</inlinemediaobject>.</simpara>
<simpara>where again the parameter <literal>s</literal> is computed to assure that the score takes the value <literal>decay</literal> at distance <literal>scale</literal> from <literal>origin</literal>+-<literal>offset</literal></simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/s_calc.png"/>
  </imageobject>
  <textobject><phrase>images/s_calc.png</phrase></textobject>
</inlinemediaobject></simpara>
<simpara>In contrast to the normal and exponential decay, this function actually
sets the score to 0 if the field value exceeds twice the user given
scale value.</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>For single functions the three decay functions together with their parameters can be visualized like this (the field in this example called "age"):</simpara>
<simpara><inlinemediaobject>
  <imageobject>
  <imagedata fileref="images/decay_2d.png" contentwidth="600"/>
  </imageobject>
  <textobject><phrase>images/decay_2d.png</phrase></textobject>
</inlinemediaobject></simpara>
</section>
<section id="_multi_values_fields">
<title>Multi-values fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/function-score-query.asciidoc">Edit me</ulink></title>
<simpara>If a field used for computing the decay contains multiple values, per default the value closest to the origin is chosen for determining the distance.
This can be changed by setting <literal>multi_value_mode</literal>.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>min</literal>
</simpara>
</entry>
<entry>
<simpara>
Distance is the minimum distance
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max</literal>
</simpara>
</entry>
<entry>
<simpara>
Distance is the maximum distance
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>avg</literal>
</simpara>
</entry>
<entry>
<simpara>
Distance is the average distance
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>sum</literal>
</simpara>
</entry>
<entry>
<simpara>
Distance is the sum of all distances
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>Example:</simpara>
<programlisting language="js" linenumbering="unnumbered">    "DECAY_FUNCTION": {
        "FIELD_NAME": {
              "origin": ...,
              "scale": ...
        },
        "multi_value_mode": "avg"
    }</programlisting>
</section>
</section>
<section id="_detailed_example">
<title>Detailed example<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/function-score-query.asciidoc">Edit me</ulink></title>
<simpara>Suppose you are searching for a hotel in a certain town. Your budget is
limited. Also, you would like the hotel to be close to the town center,
so the farther the hotel is from the desired location the less likely
you are to check in.</simpara>
<simpara>You would like the query results that match your criterion (for
example, "hotel, Nancy, non-smoker") to be scored with respect to
distance to the town center and also the price.</simpara>
<simpara>Intuitively, you would like to define the town center as the origin and
maybe you are willing to walk 2km to the town center from the hotel.<?asciidoc-br?>
In this case your <emphasis role="strong">origin</emphasis> for the location field is the town center
and the <emphasis role="strong">scale</emphasis> is ~2km.</simpara>
<simpara>If your budget is low, you would probably prefer something cheap above
something expensive.  For the price field, the <emphasis role="strong">origin</emphasis> would be 0 Euros
and the <emphasis role="strong">scale</emphasis> depends on how much you are willing to pay, for example 20 Euros.</simpara>
<simpara>In this example, the fields might be called "price" for the price of the
hotel and "location" for the coordinates of this hotel.</simpara>
<simpara>The function for <literal>price</literal> in this case would be</simpara>
<programlisting language="js" linenumbering="unnumbered">"gauss": { <co id="CO153-1"/>
    "price": {
          "origin": "0",
          "scale": "20"
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO153-1">
<para>
This decay function could also be <literal>linear</literal> or <literal>exp</literal>.
</para>
</callout>
</calloutlist>
<simpara>and for <literal>location</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">"gauss": { <co id="CO154-1"/>
    "location": {
          "origin": "11, 12",
          "scale": "2km"
    }
}</programlisting>
<calloutlist>
<callout arearefs="CO154-1">
<para>
This decay function could also be <literal>linear</literal> or <literal>exp</literal>.
</para>
</callout>
</calloutlist>
<simpara>Suppose you want to multiply these two functions on the original score,
the request would look like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "function_score": {
          "functions": [
            {
              "gauss": {
                "price": {
                  "origin": "0",
                  "scale": "20"
                }
              }
            },
            {
              "gauss": {
                "location": {
                  "origin": "11, 12",
                  "scale": "2km"
                }
              }
            }
          ],
          "query": {
            "match": {
              "properties": "balcony"
            }
          },
          "score_mode": "multiply"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Next, we show how the computed score looks like for each of the three
possible decay functions.</simpara>
<section id="gauss-decay">
<title>Normal decay, keyword <literal>gauss</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/function-score-query.asciidoc">Edit me</ulink></title>
<simpara>When choosing <literal>gauss</literal> as the decay function in the above example, the
contour and surface plot of the multiplier looks like this:</simpara>
<informalfigure>
<mediaobject>
  <imageobject>
  <imagedata fileref="https://f.cloud.github.com/assets/4320215/768157/cd0e18a6-e898-11e2-9b3c-f0145078bd6f.png" contentwidth="700px"/>
  </imageobject>
  <textobject><phrase>https://f.cloud.github.com/assets/4320215/768157/cd0e18a6-e898-11e2-9b3c-f0145078bd6f.png</phrase></textobject>
</mediaobject>
</informalfigure>
<informalfigure>
<mediaobject>
  <imageobject>
  <imagedata fileref="https://f.cloud.github.com/assets/4320215/768160/ec43c928-e898-11e2-8e0d-f3c4519dbd89.png" contentwidth="700px"/>
  </imageobject>
  <textobject><phrase>https://f.cloud.github.com/assets/4320215/768160/ec43c928-e898-11e2-8e0d-f3c4519dbd89.png</phrase></textobject>
</mediaobject>
</informalfigure>
<simpara>Suppose your original search results matches three hotels :</simpara>
<itemizedlist>
<listitem>
<simpara>
"Backback Nap"
</simpara>
</listitem>
<listitem>
<simpara>
"Drink n Drive"
</simpara>
</listitem>
<listitem>
<simpara>
"BnB Bellevue".
</simpara>
</listitem>
</itemizedlist>
<simpara>"Drink n Drive" is pretty far from your defined location (nearly 2 km)
and is not too cheap (about 13 Euros) so it gets a low factor a factor
of 0.56. "BnB Bellevue" and "Backback Nap" are both pretty close to the
defined location but "BnB Bellevue" is cheaper, so it gets a multiplier
of 0.86 whereas "Backpack Nap" gets a value of 0.66.</simpara>
</section>
<section id="exp-decay">
<title>Exponential decay, keyword <literal>exp</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/function-score-query.asciidoc">Edit me</ulink></title>
<simpara>When choosing <literal>exp</literal> as the decay function in the above example, the
contour and surface plot of the multiplier looks like this:</simpara>
<informalfigure>
<mediaobject>
  <imageobject>
  <imagedata fileref="https://f.cloud.github.com/assets/4320215/768161/082975c0-e899-11e2-86f7-174c3a729d64.png" contentwidth="700px"/>
  </imageobject>
  <textobject><phrase>https://f.cloud.github.com/assets/4320215/768161/082975c0-e899-11e2-86f7-174c3a729d64.png</phrase></textobject>
</mediaobject>
</informalfigure>
<informalfigure>
<mediaobject>
  <imageobject>
  <imagedata fileref="https://f.cloud.github.com/assets/4320215/768162/0b606884-e899-11e2-907b-aefc77eefef6.png" contentwidth="700px"/>
  </imageobject>
  <textobject><phrase>https://f.cloud.github.com/assets/4320215/768162/0b606884-e899-11e2-907b-aefc77eefef6.png</phrase></textobject>
</mediaobject>
</informalfigure>
</section>
<section id="linear-decay">
<title>Linear decay, keyword <literal>linear</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/function-score-query.asciidoc">Edit me</ulink></title>
<simpara>When choosing <literal>linear</literal> as the decay function in the above example, the
contour and surface plot of the multiplier looks like this:</simpara>
<informalfigure>
<mediaobject>
  <imageobject>
  <imagedata fileref="https://f.cloud.github.com/assets/4320215/768164/1775b0ca-e899-11e2-9f4a-776b406305c6.png" contentwidth="700px"/>
  </imageobject>
  <textobject><phrase>https://f.cloud.github.com/assets/4320215/768164/1775b0ca-e899-11e2-9f4a-776b406305c6.png</phrase></textobject>
</mediaobject>
</informalfigure>
<informalfigure>
<mediaobject>
  <imageobject>
  <imagedata fileref="https://f.cloud.github.com/assets/4320215/768165/19d8b1aa-e899-11e2-91bc-6b0553e8d722.png" contentwidth="700px"/>
  </imageobject>
  <textobject><phrase>https://f.cloud.github.com/assets/4320215/768165/19d8b1aa-e899-11e2-91bc-6b0553e8d722.png</phrase></textobject>
</mediaobject>
</informalfigure>
</section>
</section>
<section id="_supported_fields_for_decay_functions">
<title>Supported fields for decay functions<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/function-score-query.asciidoc">Edit me</ulink></title>
<simpara>Only numeric, date, and geo-point fields are supported.</simpara>
</section>
<section id="_what_if_a_field_is_missing">
<title>What if a field is missing?<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/function-score-query.asciidoc">Edit me</ulink></title>
<simpara>If the numeric field is missing in the document, the function will
return 1.</simpara>
</section>
</section>
<section id="query-dsl-boosting-query">
<title>Boosting Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/boosting-query.asciidoc">Edit me</ulink></title>
<simpara>The <literal>boosting</literal> query can be used to effectively demote results that
match a given query. Unlike the "NOT" clause in bool query, this still
selects documents that contain undesirable terms, but reduces their
overall score.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "boosting" : {
            "positive" : {
                "term" : {
                    "field1" : "value1"
                }
            },
            "negative" : {
                 "term" : {
                     "field2" : "value2"
                }
            },
            "negative_boost" : 0.2
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="query-dsl-indices-query">
<title>Indices Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/indices-query.asciidoc">Edit me</ulink></title>
<warning revisionflag="deleted" revision="5.0.0"><title>Deprecated in 5.0.0.</title><simpara> Search on the <emphasis>_index</emphasis> field instead.</simpara></warning>
<simpara>The <literal>indices</literal> query is useful in cases where a search is executed across
multiple indices. It allows to specify a list of index names and an inner
query that is only executed for indices matching names on that list.
For other indices that are searched, but that don&#8217;t match entries
on the list, the alternative <literal>no_match_query</literal> is executed.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "indices" : {
            "indices" : ["index1", "index2"],
            "query" : { "term" : { "tag" : "wow" } },
            "no_match_query" : { "term" : { "tag" : "kow" } }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[warning:indices query is deprecated. Instead search on the '_index' field]</remark>
<simpara>You can use the <literal>index</literal> field to provide a single index.</simpara>
<simpara><literal>no_match_query</literal> can also have "string" value of <literal>none</literal> (to match no
documents), and <literal>all</literal> (to match all). Defaults to <literal>all</literal>.</simpara>
<simpara><literal>query</literal> is mandatory, as well as <literal>indices</literal> (or <literal>index</literal>).</simpara>
</section>
</chapter>
<chapter id="joining-queries">
<title>Joining queries<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/joining-queries.asciidoc">Edit me</ulink></title>
<simpara>Performing full SQL-style joins in a distributed system like Elasticsearch is
prohibitively expensive.  Instead, Elasticsearch offers two forms of join
which are designed to scale horizontally.</simpara>
<variablelist>
<varlistentry>
<term>
<link linkend="query-dsl-nested-query"><literal>nested</literal> query</link>
</term>
<listitem>
<simpara>
Documents may contain fields of type <link linkend="nested"><literal>nested</literal></link>. These
fields are used to index arrays of objects, where each object can be queried
(with the <literal>nested</literal> query) as an independent document.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-has-child-query"><literal>has_child</literal></link> and <link linkend="query-dsl-has-parent-query"><literal>has_parent</literal></link> queries
</term>
<listitem>
<simpara>
A <link linkend="mapping-parent-field">parent-child relationship</link> can exist between two
document types within a single index. The <literal>has_child</literal> query returns parent
documents whose child documents match the specified query, while the
<literal>has_parent</literal> query returns child documents whose parent document matches the
specified query.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>Also see the <link linkend="query-dsl-terms-lookup">terms-lookup mechanism</link> in the <literal>terms</literal>
query, which allows you to build a <literal>terms</literal> query from values contained in
another document.</simpara>
<section id="query-dsl-nested-query">
<title>Nested Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/nested-query.asciidoc">Edit me</ulink></title>
<simpara>Nested query allows to query nested objects / docs (see
<link linkend="nested">nested mapping</link>). The
query is executed against the nested objects / docs as if they were
indexed as separate docs (they are, internally) and resulting in the
root parent doc (or parent nested mapping). Here is a sample mapping we
will work with:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /my_index
{
    "mappings": {
        "type1" : {
            "properties" : {
                "obj1" : {
                    "type" : "nested"
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TESTSETUP</remark>
<simpara>And here is a sample nested query usage:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "nested" : {
            "path" : "obj1",
            "score_mode" : "avg",
            "query" : {
                "bool" : {
                    "must" : [
                    { "match" : {"obj1.name" : "blue"} },
                    { "range" : {"obj1.count" : {"gt" : 5}} }
                    ]
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The query <literal>path</literal> points to the nested object path, and the <literal>query</literal>
includes the query that will run on the nested docs matching the
direct path, and joining with the root parent docs. Note that any
fields referenced inside the query must use the complete path (fully
qualified).</simpara>
<simpara>The <literal>score_mode</literal> allows to set how inner children matching affects
scoring of parent. It defaults to <literal>avg</literal>, but can be <literal>sum</literal>, <literal>min</literal>,
<literal>max</literal> and <literal>none</literal>.</simpara>
<simpara>There is also an <literal>ignore_unmapped</literal> option which, when set to <literal>true</literal> will
ignore an unmapped <literal>path</literal> and will not match any documents for this query.
This can be useful when querying multiple indexes which might have different
mappings. When set to <literal>false</literal> (the default value) the query will throw an
exception if the <literal>path</literal> is not mapped.</simpara>
<simpara>Multi level nesting is automatically supported, and detected, resulting
in an inner nested query to automatically match the relevant nesting
level (and not root) if it exists within another nested query.</simpara>
</section>
<section id="query-dsl-has-child-query">
<title>Has Child Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/has-child-query.asciidoc">Edit me</ulink></title>
<simpara>The <literal>has_child</literal> filter accepts a query and the child type to run against, and
results in parent documents that have child docs matching the query. Here is
an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "has_child" : {
            "type" : "blog_tag",
                "query" : {
                    "term" : {
                        "tag" : "something"
                    }
                }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_scoring_capabilities" renderas="sect3">Scoring capabilities<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/has-child-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>has_child</literal> also has scoring support. The
supported score modes are <literal>min</literal>, <literal>max</literal>, <literal>sum</literal>, <literal>avg</literal> or <literal>none</literal>. The default is
<literal>none</literal> and yields the same behaviour as in previous versions. If the
score mode is set to another value than <literal>none</literal>, the scores of all the
matching child documents are aggregated into the associated parent
documents. The score type can be specified with the <literal>score_mode</literal> field
inside the <literal>has_child</literal> query:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "has_child" : {
            "type" : "blog_tag",
                "score_mode" : "min",
                "query" : {
                    "term" : {
                        "tag" : "something"
                    }
                }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_min_max_children" renderas="sect3">Min/Max Children<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/has-child-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>has_child</literal> query allows you to specify that a minimum and/or maximum
number of children are required to match for the parent doc to be considered
a match:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "has_child" : {
            "type" : "blog_tag",
            "score_mode" : "min",
            "min_children": 2, <co id="CO155-1"/>
            "max_children": 10, <co id="CO155-2"/>
            "query" : {
                "term" : {
                    "tag" : "something"
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO155-1 CO155-2">
<para>
Both <literal>min_children</literal> and <literal>max_children</literal> are optional.
</para>
</callout>
</calloutlist>
<simpara>The  <literal>min_children</literal> and <literal>max_children</literal> parameters can be combined with
the <literal>score_mode</literal> parameter.</simpara>
<bridgehead id="_ignore_unmapped" renderas="sect3">Ignore Unmapped<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/has-child-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>When set to <literal>true</literal> the <literal>ignore_unmapped</literal> option will ignore an unmapped <literal>type</literal>
and will not match any documents for this query. This can be useful when
querying multiple indexes which might have different mappings. When set to
<literal>false</literal> (the default value) the query will throw an exception if the <literal>type</literal>
is not mapped.</simpara>
<bridgehead id="_sorting" renderas="sect3">Sorting<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/has-child-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>Parent documents can&#8217;t be sorted by fields in matching child documents via the
regular sort options. If you need to sort parent document by field in the child
documents then you can should use the <literal>function_score</literal> query and then just sort
by <literal>_score</literal>.</simpara>
<simpara>Sorting blogs by child documents' <literal>click_count</literal> field:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "has_child" : {
            "type" : "blog_tag",
            "score_mode" : "max",
            "query" : {
                "function_score" : {
                    "script_score": {
                        "script": "_score * doc['click_count'].value"
                    }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="query-dsl-has-parent-query">
<title>Has Parent Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/has-parent-query.asciidoc">Edit me</ulink></title>
<simpara>The <literal>has_parent</literal> query accepts a query and a parent type. The query is
executed in the parent document space, which is specified by the parent
type. This query returns child documents which associated parents have
matched. For the rest <literal>has_parent</literal> query has the same options and works
in the same manner as the <literal>has_child</literal> query.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "has_parent" : {
            "parent_type" : "blog",
                "query" : {
                    "term" : {
                        "tag" : "something"
                    }
                }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_scoring_capabilities_2" renderas="sect3">Scoring capabilities<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/has-parent-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>has_parent</literal> also has scoring support. The default is <literal>false</literal> which
ignores the score from the parent document. The score is in this
case equal to the boost on the <literal>has_parent</literal> query (Defaults to 1). If
the score is set to <literal>true</literal>, then the score of the matching parent
document is aggregated into the child documents belonging to the
matching parent document. The score mode can be specified with the
<literal>score</literal> field inside the <literal>has_parent</literal> query:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "has_parent" : {
            "parent_type" : "blog",
                "score" : true,
                "query" : {
                    "term" : {
                        "tag" : "something"
                    }
                }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_ignore_unmapped_2" renderas="sect3">Ignore Unmapped<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/has-parent-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>When set to <literal>true</literal> the <literal>ignore_unmapped</literal> option will ignore an unmapped <literal>type</literal>
and will not match any documents for this query. This can be useful when
querying multiple indexes which might have different mappings. When set to
<literal>false</literal> (the default value) the query will throw an exception if the <literal>type</literal>
is not mapped.</simpara>
<bridgehead id="_sorting_2" renderas="sect3">Sorting<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/has-parent-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>Child documents can&#8217;t be sorted by fields in matching parent documents via the
regular sort options. If you need to sort child documents by field in the parent
documents then you can should use the <literal>function_score</literal> query and then just sort
by <literal>_score</literal>.</simpara>
<simpara>Sorting tags by parent document' <literal>view_count</literal> field:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "has_parent" : {
            "parent_type" : "blog",
            "score" : true,
            "query" : {
                "function_score" : {
                    "script_score": {
                        "script": "_score * doc['view_count'].value"
                    }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="query-dsl-parent-id-query">
<title>Parent Id Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/parent-id-query.asciidoc">Edit me</ulink></title>
<note revisionflag="added" revision="5.0.0"><simpara>Added in 5.0.0.</simpara></note>
<simpara>The <literal>parent_id</literal> query can be used to find child documents which belong to a particular parent.
Given the following mapping definition:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /my_index
{
    "mappings": {
        "blog_post": {
            "properties": {
                "name": {
                    "type": "keyword"
                }
            }
        },
        "blog_tag": {
            "_parent": {
                "type": "blog_post"
            },
            "_routing": {
                "required": true
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TESTSETUP</remark>
<programlisting language="js" linenumbering="unnumbered">GET /my_index/_search
{
    "query": {
        "parent_id" : {
            "type" : "blog_tag",
                "id" : "1"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above is functionally equivalent to using the following
<link linkend="query-dsl-has-parent-query"><literal>has_parent</literal></link> query, but performs
better as it does not need to do a join:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /my_index/_search
{
  "query": {
    "has_parent": {
      "parent_type": "blog_post",
        "query": {
          "term": {
            "_id": "1"
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<section id="_parameters_7">
<title>Parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/parent-id-query.asciidoc">Edit me</ulink></title>
<simpara>This query has two required parameters:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>type</literal>
</simpara>
</entry>
<entry>
<simpara>
The <emphasis role="strong">child</emphasis> type. This must be a type with <literal>_parent</literal> field.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>id</literal>
</simpara>
</entry>
<entry>
<simpara>
The required parent id select documents must referrer to.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>ignore_unmapped</literal>
</simpara>
</entry>
<entry>
<simpara>
When set to <literal>true</literal> this will ignore an unmapped <literal>type</literal> and will not match any
documents for this query. This can be useful when querying multiple indexes
which might have different mappings. When set to <literal>false</literal> (the default value)
the query will throw an exception if the <literal>type</literal> is not mapped.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
</section>
</chapter>
<chapter id="geo-queries">
<title>Geo queries<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-queries.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch supports two types of geo data:
<link linkend="geo-point"><literal>geo_point</literal></link> fields which support lat/lon pairs, and
<link linkend="geo-shape"><literal>geo_shape</literal></link> fields, which support points,
lines, circles, polygons, multi-polygons etc.</simpara>
<simpara>The queries in this group are:</simpara>
<variablelist>
<varlistentry>
<term>
<link linkend="query-dsl-geo-shape-query"><literal>geo_shape</literal></link> query
</term>
<listitem>
<simpara>
    Find document with geo-shapes which either intersect, are contained by, or
    do not intersect with the specified geo-shape.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-geo-bounding-box-query"><literal>geo_bounding_box</literal></link> query
</term>
<listitem>
<simpara>
    Finds documents with geo-points that fall into the specified rectangle.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-geo-distance-query"><literal>geo_distance</literal></link> query
</term>
<listitem>
<simpara>
    Finds document with geo-points within the specified distance of a central
    point.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-geo-distance-range-query"><literal>geo_distance_range</literal></link> query
</term>
<listitem>
<simpara>
    Like the <literal>geo_point</literal> query, but the range starts at a specified distance
    from the central point.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-geo-polygon-query"><literal>geo_polygon</literal></link> query
</term>
<listitem>
<simpara>
    Find documents with geo-points within the specified polygon.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<section id="query-dsl-geo-shape-query">
<title>GeoShape Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-shape-query.asciidoc">Edit me</ulink></title>
<simpara>Filter documents indexed using the <literal>geo_shape</literal> type.</simpara>
<simpara>Requires the <link linkend="geo-shape"><literal>geo_shape</literal> Mapping</link>.</simpara>
<simpara>The <literal>geo_shape</literal> query uses the same grid square representation as the
geo_shape mapping to find documents that have a shape that intersects
with the query shape. It will also use the same PrefixTree configuration
as defined for the field mapping.</simpara>
<simpara>The query supports two ways of defining the query shape, either by
providing a whole shape definition, or by referencing the name of a shape
pre-indexed in another index. Both formats are defined below with
examples.</simpara>
<section id="_inline_shape_definition">
<title>Inline Shape Definition<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-shape-query.asciidoc">Edit me</ulink></title>
<simpara>Similar to the <literal>geo_shape</literal> type, the <literal>geo_shape</literal> Filter uses
<ulink url="http://www.geojson.org">GeoJSON</ulink> to represent shapes.</simpara>
<simpara>Given a document that looks like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "name": "Wind &amp; Wetter, Berlin, Germany",
        "location": {
            "type": "Point",
            "coordinates": [13.400544, 52.530286]
        }
}</programlisting>
<simpara>The following query will find the point using the Elasticsearch&#8217;s
<literal>envelope</literal> GeoJSON extension:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query":{
        "bool": {
            "must": {
                "match_all": {}
            },
            "filter": {
                "geo_shape": {
                    "location": {
                        "shape": {
                            "type": "envelope",
                            "coordinates" : [[13.0, 53.0], [14.0, 52.0]]
                        },
                        "relation": "within"
                    }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="_pre_indexed_shape">
<title>Pre-Indexed Shape<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-shape-query.asciidoc">Edit me</ulink></title>
<simpara>The Query also supports using a shape which has already been indexed in
another index and/or index type. This is particularly useful for when
you have a pre-defined list of shapes which are useful to your
application and you want to reference this using a logical name (for
example <emphasis>New Zealand</emphasis>) rather than having to provide their coordinates
each time. In this situation it is only necessary to provide:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>id</literal> - The ID of the document that containing the pre-indexed shape.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>index</literal> - Name of the index where the pre-indexed shape is. Defaults
to <emphasis>shapes</emphasis>.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>type</literal> - Index type where the pre-indexed shape is.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>path</literal> - The field specified as path containing the pre-indexed shape.
Defaults to <emphasis>shape</emphasis>.
</simpara>
</listitem>
</itemizedlist>
<simpara>The following is an example of using the Filter with a pre-indexed
shape:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "bool": {
            "must": {
                "match_all": {}
            },
                "filter": {
                    "geo_shape": {
                        "location": {
                            "indexed_shape": {
                                "id": "DEU",
                                "type": "countries",
                                "index": "shapes",
                                "path": "location"
                            }
                        }
                    }
                }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="_spatial_relations">
<title>Spatial Relations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-shape-query.asciidoc">Edit me</ulink></title>
<simpara>The <link linkend="spatial-strategy">geo_shape strategy</link> mapping parameter determines
which spatial relation operators may be used at search time.</simpara>
<simpara>The following is a complete list of spatial relation operators available:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>INTERSECTS</literal> - (default) Return all documents whose <literal>geo_shape</literal> field
intersects the query geometry.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>DISJOINT</literal> - Return all documents whose <literal>geo_shape</literal> field
has nothing in common with the query geometry.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>WITHIN</literal> - Return all documents whose <literal>geo_shape</literal> field
is within the query geometry.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>CONTAINS</literal> - Return all documents whose <literal>geo_shape</literal> field
contains the query geometry.
</simpara>
</listitem>
</itemizedlist>
<bridgehead id="_ignore_unmapped_3" renderas="sect3">Ignore Unmapped<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-shape-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>When set to <literal>true</literal> the <literal>ignore_unmapped</literal> option will ignore an unmapped field
and will not match any documents for this query. This can be useful when
querying multiple indexes which might have different mappings. When set to
<literal>false</literal> (the default value) the query will throw an exception if the field
is not mapped.</simpara>
</section>
</section>
<section id="query-dsl-geo-bounding-box-query">
<title>Geo Bounding Box Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-bounding-box-query.asciidoc">Edit me</ulink></title>
<simpara>A query allowing to filter hits based on a point location using a
bounding box. Assuming the following indexed document:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /my_locations
{
    "mappings": {
        "location": {
            "properties": {
                "pin": {
                    "properties": {
                        "location": {
                            "type": "geo_point"
                        }
                    }
                }
            }
        }
    }
}

PUT /my_locations/location/1
{
    "pin" : {
        "location" : {
            "lat" : 40.12,
            "lon" : -71.34
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TESTSETUP</remark>
<simpara>Then the following simple query can be executed with a
<literal>geo_bounding_box</literal> filter:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "bool" : {
            "must" : {
                "match_all" : {}
            },
            "filter" : {
                "geo_bounding_box" : {
                    "pin.location" : {
                        "top_left" : {
                            "lat" : 40.73,
                            "lon" : -74.1
                        },
                        "bottom_right" : {
                            "lat" : 40.01,
                            "lon" : -71.12
                        }
                    }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_query_options" renderas="sect3">Query Options<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-bounding-box-query.asciidoc">Edit me</ulink></bridgehead>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Option </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>_name</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Optional name field to identify the filter</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ignore_malformed</literal></simpara></entry>
<entry align="left" valign="top"><simpara><phrase revisionflag="deleted" revision="5.0.0">Deprecated in 5.0.0. Use <literal>validation_method</literal> instead.</phrase> Set to <literal>true</literal> to
accept geo points with invalid latitude or longitude (default is <literal>false</literal>).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>validation_method</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Set to <literal>IGNORE_MALFORMED</literal> to
accept geo points with invalid latitude or longitude, set to
<literal>COERCE</literal> to also try to infer correct latitude or longitude. (default is <literal>STRICT</literal>).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>type</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Set to one of <literal>indexed</literal> or <literal>memory</literal> to defines whether this filter will
be executed in memory or indexed. See <link linkend="geo-bbox-type">Type</link> below for further details
Default is <literal>memory</literal>.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<bridgehead id="_accepted_formats" renderas="sect3">Accepted Formats<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-bounding-box-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>In much the same way the geo_point type can accept different
representations of the geo point, the filter can accept it as well:</simpara>
<bridgehead id="_lat_lon_as_properties_2" renderas="sect4">Lat Lon As Properties<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-bounding-box-query.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "bool" : {
            "must" : {
                "match_all" : {}
            },
            "filter" : {
                "geo_bounding_box" : {
                    "pin.location" : {
                        "top_left" : {
                            "lat" : 40.73,
                            "lon" : -74.1
                        },
                        "bottom_right" : {
                            "lat" : 40.01,
                            "lon" : -71.12
                        }
                    }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_lat_lon_as_array_2" renderas="sect4">Lat Lon As Array<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-bounding-box-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>Format in <literal>[lon, lat]</literal>, note, the order of lon/lat here in order to
conform with <ulink url="http://geojson.org/">GeoJSON</ulink>.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "bool" : {
            "must" : {
                "match_all" : {}
            },
            "filter" : {
                "geo_bounding_box" : {
                    "pin.location" : {
                        "top_left" : [-74.1, 40.73],
                        "bottom_right" : [-71.12, 40.01]
                    }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_lat_lon_as_string_2" renderas="sect4">Lat Lon As String<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-bounding-box-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>Format in <literal>lat,lon</literal>.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "bool" : {
            "must" : {
                "match_all" : {}
            },
            "filter" : {
                "geo_bounding_box" : {
                    "pin.location" : {
                        "top_left" : "40.73, -74.1",
                        "bottom_right" : "40.01, -71.12"
                    }
                }
            }
    }
}
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_geohash_2" renderas="sect4">Geohash<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-bounding-box-query.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "bool" : {
            "must" : {
                "match_all" : {}
            },
            "filter" : {
                "geo_bounding_box" : {
                    "pin.location" : {
                        "top_left" : "dr5r9ydj2y73",
                        "bottom_right" : "drj7teegpus6"
                    }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_vertices" renderas="sect3">Vertices<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-bounding-box-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>The vertices of the bounding box can either be set by <literal>top_left</literal> and
<literal>bottom_right</literal> or by <literal>top_right</literal> and <literal>bottom_left</literal> parameters. More
over the names <literal>topLeft</literal>, <literal>bottomRight</literal>, <literal>topRight</literal> and <literal>bottomLeft</literal>
are supported. Instead of setting the values pairwise, one can use
the simple names <literal>top</literal>, <literal>left</literal>, <literal>bottom</literal> and <literal>right</literal> to set the
values separately.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "bool" : {
            "must" : {
                "match_all" : {}
            },
            "filter" : {
                "geo_bounding_box" : {
                    "pin.location" : {
                        "top" : 40.73,
                        "left" : -74.1,
                        "bottom" : 40.01,
                        "right" : -71.12
                    }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_geo_point_type" renderas="sect3">geo_point Type<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-bounding-box-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>The filter <emphasis role="strong">requires</emphasis> the <literal>geo_point</literal> type to be set on the relevant
field.</simpara>
<bridgehead id="_multi_location_per_document" renderas="sect3">Multi Location Per Document<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-bounding-box-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>The filter can work with multiple locations / points per document. Once
a single location / point matches the filter, the document will be
included in the filter</simpara>
<bridgehead id="geo-bbox-type" renderas="sect3">Type<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-bounding-box-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>The type of the bounding box execution by default is set to <literal>memory</literal>,
which means in memory checks if the doc falls within the bounding box
range. In some cases, an <literal>indexed</literal> option will perform faster (but note
that the <literal>geo_point</literal> type must have lat and lon indexed in this case).
Note, when using the indexed option, multi locations per document field
are not supported. Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "bool" : {
            "must" : {
                "match_all" : {}
            },
            "filter" : {
                "geo_bounding_box" : {
                    "pin.location" : {
                        "top_left" : {
                            "lat" : 40.73,
                            "lon" : -74.1
                        },
                        "bottom_right" : {
                            "lat" : 40.10,
                            "lon" : -71.12
                        }
                    },
                    "type" : "indexed"
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_ignore_unmapped_4" renderas="sect3">Ignore Unmapped<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-bounding-box-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>When set to <literal>true</literal> the <literal>ignore_unmapped</literal> option will ignore an unmapped field
and will not match any documents for this query. This can be useful when
querying multiple indexes which might have different mappings. When set to
<literal>false</literal> (the default value) the query will throw an exception if the field
is not mapped.</simpara>
</section>
<section id="query-dsl-geo-distance-query">
<title>Geo Distance Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-distance-query.asciidoc">Edit me</ulink></title>
<simpara>Filters documents that include only hits that exists within a specific
distance from a geo point. Assuming the following mapping and indexed
document:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /my_locations
{
    "mappings": {
        "location": {
            "properties": {
                "pin": {
                    "properties": {
                        "location": {
                            "type": "geo_point"
                        }
                    }
                }
            }
        }
    }
}

PUT /my_locations/location/1
{
    "pin" : {
        "location" : {
            "lat" : 40.12,
            "lon" : -71.34
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TESTSETUP</remark>
<simpara>Then the following simple query can be executed with a <literal>geo_distance</literal>
filter:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /my_locations/location/_search
{
    "query": {
        "bool" : {
            "must" : {
                "match_all" : {}
            },
            "filter" : {
                "geo_distance" : {
                    "distance" : "200km",
                    "pin.location" : {
                        "lat" : 40,
                        "lon" : -70
                    }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_accepted_formats_2" renderas="sect3">Accepted Formats<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-distance-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>In much the same way the <literal>geo_point</literal> type can accept different
representations of the geo point, the filter can accept it as well:</simpara>
<bridgehead id="_lat_lon_as_properties_3" renderas="sect4">Lat Lon As Properties<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-distance-query.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">GET /my_locations/location/_search
{
    "query": {
        "bool" : {
            "must" : {
                "match_all" : {}
            },
            "filter" : {
                "geo_distance" : {
                    "distance" : "12km",
                    "pin.location" : {
                        "lat" : 40,
                        "lon" : -70
                    }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_lat_lon_as_array_3" renderas="sect4">Lat Lon As Array<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-distance-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>Format in <literal>[lon, lat]</literal>, note, the order of lon/lat here in order to
conform with <ulink url="http://geojson.org/">GeoJSON</ulink>.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /my_locations/location/_search
{
    "query": {
        "bool" : {
            "must" : {
                "match_all" : {}
            },
            "filter" : {
                "geo_distance" : {
                    "distance" : "12km",
                    "pin.location" : [-70, 40]
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_lat_lon_as_string_3" renderas="sect4">Lat Lon As String<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-distance-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>Format in <literal>lat,lon</literal>.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /my_locations/location/_search
{
    "query": {
        "bool" : {
            "must" : {
                "match_all" : {}
            },
            "filter" : {
                "geo_distance" : {
                    "distance" : "12km",
                    "pin.location" : "40,-70"
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_geohash_3" renderas="sect4">Geohash<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-distance-query.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">GET /my_locations/location/_search
{
    "query": {
        "bool" : {
            "must" : {
                "match_all" : {}
            },
            "filter" : {
                "geo_distance" : {
                    "distance" : "12km",
                    "pin.location" : "drm3btev3e86"
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_options_4" renderas="sect3">Options<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-distance-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>The following are options allowed on the filter:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>distance</literal>
</simpara>
</entry>
<entry>
<simpara>
    The radius of the circle centred on the specified location. Points which
    fall into this circle are considered to be matches. The <literal>distance</literal> can be
    specified in various units. See <xref linkend="distance-units"/>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>distance_type</literal>
</simpara>
</entry>
<entry>
<simpara>
    How to compute the distance. Can either be <literal>sloppy_arc</literal> (default), <literal>arc</literal> (slightly more precise but significantly slower) or <literal>plane</literal> (faster, but inaccurate on long distances and close to the poles).
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>optimize_bbox</literal>
</simpara>
</entry>
<entry>
<simpara>
    Whether to use the optimization of first running a bounding box check
    before the distance check. Defaults to <literal>memory</literal> which will do in memory
    checks. Can also have values of <literal>indexed</literal> to use indexed value check (make
    sure the <literal>geo_point</literal> type index lat lon in this case), or <literal>none</literal> which
    disables bounding box optimization. <phrase revisionflag="deleted" revision="2.2">Deprecated in 2.2.</phrase>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>_name</literal>
</simpara>
</entry>
<entry>
<simpara>
    Optional name field to identify the query
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>ignore_malformed</literal>
</simpara>
</entry>
<entry>
<simpara>
    <phrase revisionflag="deleted" revision="5.0.0">Deprecated in 5.0.0. Use <literal>validation_method</literal> instead.</phrase> Set to <literal>true</literal> to accept geo points with invalid latitude or
    longitude (default is <literal>false</literal>).
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>validation_method</literal>
</simpara>
</entry>
<entry>
<simpara>
    Set to <literal>IGNORE_MALFORMED</literal> to accept geo points with invalid latitude or
    longitude, set to <literal>COERCE</literal> to additionally try and infer correct
    coordinates (default is <literal>STRICT</literal>).
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="_geo_point_type_2" renderas="sect3">geo_point Type<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-distance-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>The filter <emphasis role="strong">requires</emphasis> the <literal>geo_point</literal> type to be set on the relevant
field.</simpara>
<bridgehead id="_multi_location_per_document_2" renderas="sect3">Multi Location Per Document<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-distance-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>geo_distance</literal> filter can work with multiple locations / points per
document. Once a single location / point matches the filter, the
document will be included in the filter.</simpara>
<bridgehead id="_ignore_unmapped_5" renderas="sect3">Ignore Unmapped<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-distance-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>When set to <literal>true</literal> the <literal>ignore_unmapped</literal> option will ignore an unmapped field
and will not match any documents for this query. This can be useful when
querying multiple indexes which might have different mappings. When set to
<literal>false</literal> (the default value) the query will throw an exception if the field
is not mapped.</simpara>
</section>
<section id="query-dsl-geo-distance-range-query">
<title>Geo Distance Range Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-distance-range-query.asciidoc">Edit me</ulink></title>
<simpara>Filters documents that exists within a range from a specific point:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "bool" : {
            "must" : {
                "match_all" : {}
            },
            "filter" : {
                "geo_distance_range" : {
                    "from" : "200km",
                    "to" : "400km",
                    "pin.location" : {
                        "lat" : 40,
                        "lon" : -70
                    }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Supports the same point location parameter and query options as the
<link linkend="query-dsl-geo-distance-query">geo_distance</link>
filter. And also support the common parameters for range (lt, lte, gt,
gte, from, to, include_upper and include_lower).</simpara>
<bridgehead id="_ignore_unmapped_6" renderas="sect3">Ignore Unmapped<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-distance-range-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>When set to <literal>true</literal> the <literal>ignore_unmapped</literal> option will ignore an unmapped field
and will not match any documents for this query. This can be useful when
querying multiple indexes which might have different mappings. When set to
<literal>false</literal> (the default value) the query will throw an exception if the field
is not mapped.</simpara>
</section>
<section id="query-dsl-geo-polygon-query">
<title>Geo Polygon Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-polygon-query.asciidoc">Edit me</ulink></title>
<simpara>A query allowing to include hits that only fall within a polygon of
points. Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "bool" : {
            "must" : {
                "match_all" : {}
            },
            "filter" : {
                "geo_polygon" : {
                    "person.location" : {
                        "points" : [
                        {"lat" : 40, "lon" : -70},
                        {"lat" : 30, "lon" : -80},
                        {"lat" : 20, "lon" : -90}
                        ]
                    }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_query_options_2" renderas="sect3">Query Options<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-polygon-query.asciidoc">Edit me</ulink></bridgehead>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Option </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>_name</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Optional name field to identify the filter</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ignore_malformed</literal></simpara></entry>
<entry align="left" valign="top"><simpara><phrase revisionflag="deleted" revision="5.0.0">Deprecated in 5.0.0. Use <literal>validation_method</literal> instead.</phrase> Set to <literal>true</literal> to accept geo points with invalid latitude or
longitude (default is <literal>false</literal>).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>validation_method</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Set to <literal>IGNORE_MALFORMED</literal> to accept geo points with
invalid latitude or longitude, <literal>COERCE</literal> to try and infer correct latitude
or longitude, or <literal>STRICT</literal> (default is <literal>STRICT</literal>).</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<bridgehead id="_allowed_formats" renderas="sect3">Allowed Formats<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-polygon-query.asciidoc">Edit me</ulink></bridgehead>
<bridgehead id="_lat_long_as_array" renderas="sect4">Lat Long as Array<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-polygon-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>Format in <literal>[lon, lat]</literal>, note, the order of lon/lat here in order to
conform with <ulink url="http://geojson.org/">GeoJSON</ulink>.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "bool" : {
            "must" : {
                "match_all" : {}
            },
            "filter" : {
                "geo_polygon" : {
                    "person.location" : {
                        "points" : [
                            [-70, 40],
                            [-80, 30],
                            [-90, 20]
                        ]
                    }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_lat_lon_as_string_4" renderas="sect4">Lat Lon as String<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-polygon-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>Format in <literal>lat,lon</literal>.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "bool" : {
            "must" : {
                "match_all" : {}
            },
            "filter" : {
               "geo_polygon" : {
                    "person.location" : {
                        "points" : [
                            "40, -70",
                            "30, -80",
                            "20, -90"
                        ]
                    }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_geohash_4" renderas="sect4">Geohash<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-polygon-query.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "bool" : {
            "must" : {
                "match_all" : {}
            },
            "filter" : {
               "geo_polygon" : {
                    "person.location" : {
                        "points" : [
                            "drn5x1g8cu2y",
                            "30, -80",
                            "20, -90"
                        ]
                    }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_geo_point_type_3" renderas="sect3">geo_point Type<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-polygon-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>The query <emphasis role="strong">requires</emphasis> the <link linkend="geo-point"><literal>geo_point</literal></link> type to be set on the
relevant field.</simpara>
<bridgehead id="_ignore_unmapped_7" renderas="sect3">Ignore Unmapped<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/geo-polygon-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>When set to <literal>true</literal> the <literal>ignore_unmapped</literal> option will ignore an unmapped field
and will not match any documents for this query. This can be useful when
querying multiple indexes which might have different mappings. When set to
<literal>false</literal> (the default value) the query will throw an exception if the field
is not mapped.</simpara>
</section>
</chapter>
<chapter id="specialized-queries">
<title>Specialized queries<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/special-queries.asciidoc">Edit me</ulink></title>
<simpara>This group contains queries which do not fit into the other groups:</simpara>
<variablelist>
<varlistentry>
<term>
<link linkend="query-dsl-mlt-query"><literal>more_like_this</literal> query</link>
</term>
<listitem>
<simpara>
This query finds documents which are similar to the specified text, document,
or collection of documents.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-template-query"><literal>template</literal> query</link>
</term>
<listitem>
<simpara>
The <literal>template</literal> query accepts a Mustache template (either inline, indexed, or
from a file), and a map of parameters,  and combines the two to generate the
final query to execute.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-script-query"><literal>script</literal> query</link>
</term>
<listitem>
<simpara>
This query allows a script to act as a filter.  Also see the
<link linkend="query-dsl-function-score-query"><literal>function_score</literal> query</link>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-percolate-query"><literal>percolate</literal> query</link>
</term>
<listitem>
<simpara>
This query finds queries that are stored as documents that match with
the specified document.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<section id="query-dsl-mlt-query">
<title>More Like This Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/mlt-query.asciidoc">Edit me</ulink></title>
<simpara>The More Like This Query (MLT Query) finds documents that are "like" a given
set of documents. In order to do so, MLT selects a set of representative terms
of these input documents, forms a query using these terms, executes the query
and returns the results. The user controls the input documents, how the terms
should be selected and how the query is formed. <literal>more_like_this</literal> can be
shortened to <literal>mlt</literal> <phrase revisionflag="deleted" revision="5.0.0">Deprecated in 5.0.0. use <literal>more_like_this</literal> instead.</phrase>.</simpara>
<simpara>The simplest use case consists of asking for documents that are similar to a
provided piece of text. Here, we are asking for all movies that have some text
similar to "Once upon a time" in their "title" and in their "description"
fields, limiting the number of selected terms to 12.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "more_like_this" : {
            "fields" : ["title", "description"],
            "like" : "Once upon a time",
            "min_term_freq" : 1,
            "max_query_terms" : 12
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>A more complicated use case consists of mixing texts with documents already
existing in the index. In this case, the syntax to specify a document is
similar to the one used in the <link linkend="docs-multi-get">Multi GET API</link>.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "more_like_this" : {
            "fields" : ["title", "description"],
            "like" : [
            {
                "_index" : "imdb",
                "_type" : "movies",
                "_id" : "1"
            },
            {
                "_index" : "imdb",
                "_type" : "movies",
                "_id" : "2"
            },
            "and potentially some more text here as well"
            ],
            "min_term_freq" : 1,
            "max_query_terms" : 12
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Finally, users can mix some texts, a chosen set of documents but also provide
documents not necessarily present in the index. To provide documents not
present in the index, the syntax is similar to <link linkend="docs-termvectors-artificial-doc">artificial documents</link>.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "more_like_this" : {
            "fields" : ["name.first", "name.last"],
            "like" : [
            {
                "_index" : "marvel",
                "_type" : "quotes",
                "doc" : {
                    "name": {
                        "first": "Ben",
                        "last": "Grimm"
                    },
                    "tweet": "You got no idea what I'd... what I'd give to be invisible."
                  }
            },
            {
                "_index" : "marvel",
                "_type" : "quotes",
                "_id" : "2"
            }
            ],
            "min_term_freq" : 1,
            "max_query_terms" : 12
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<section id="_how_it_works">
<title>How it Works<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/mlt-query.asciidoc">Edit me</ulink></title>
<simpara>Suppose we wanted to find all documents similar to a given input document.
Obviously, the input document itself should be its best match for that type of
query. And the reason would be mostly, according to
<ulink url="https://lucene.apache.org/core/4_9_0/core/org/apache/lucene/search/similarities/TFIDFSimilarity.html">Lucene scoring formula</ulink>,
due to the terms with the highest tf-idf. Therefore, the terms of the input
document that have the highest tf-idf are good representatives of that
document, and could be used within a disjunctive query (or <literal>OR</literal>) to retrieve similar
documents. The MLT query simply extracts the text from the input document,
analyzes it, usually using the same analyzer at the field, then selects the
top K terms with highest tf-idf to form a disjunctive query of these terms.</simpara>
<important><simpara>The fields on which to perform MLT must be indexed and of type
<literal>string</literal>. Additionally, when using <literal>like</literal> with documents, either <literal>_source</literal>
must be enabled or the fields must be <literal>stored</literal> or store <literal>term_vector</literal>. In
order to speed up analysis, it could help to store term vectors at index time.</simpara></important>
<simpara>For example, if we wish to perform MLT on the "title" and "tags.raw" fields,
we can explicitly store their <literal>term_vector</literal> at index time. We can still
perform MLT on the "description" and "tags" fields, as <literal>_source</literal> is enabled by
default, but there will be no speed up on analysis for these fields.</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /imdb
{
    "mappings": {
        "movies": {
            "properties": {
                "title": {
                    "type": "text",
                    "term_vector": "yes"
                },
                "description": {
                    "type": "text"
                },
                "tags": {
                    "type": "text",
                    "fields" : {
                        "raw": {
                            "type" : "text",
                            "analyzer": "keyword",
                            "term_vector" : "yes"
                        }
                    }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="_parameters_8">
<title>Parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/mlt-query.asciidoc">Edit me</ulink></title>
<simpara>The only required parameter is <literal>like</literal>, all other parameters have sensible
defaults. There are three types of parameters: one to specify the document
input, the other one for term selection and for query formation.</simpara>
<bridgehead id="_document_input_parameters" renderas="sect3">Document Input Parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/mlt-query.asciidoc">Edit me</ulink></bridgehead>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>like</literal>
</simpara>
</entry>
<entry>
<simpara>
The only <emphasis role="strong">required</emphasis> parameter of the MLT query is <literal>like</literal> and follows a
versatile syntax, in which the user can specify free form text and/or a single
or multiple documents (see examples above). The syntax to specify documents is
similar to the one used by the <link linkend="docs-multi-get">Multi GET API</link>. When
specifying documents, the text is fetched from <literal>fields</literal> unless overridden in
each document request. The text is analyzed by the analyzer at the field, but
could also be overridden. The syntax to override the analyzer at the field
follows a similar syntax to the <literal>per_field_analyzer</literal> parameter of the
<link linkend="docs-termvectors-per-field-analyzer">Term Vectors API</link>.
Additionally, to provide documents not necessarily present in the index,
<link linkend="docs-termvectors-artificial-doc">artificial documents</link> are also supported.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>unlike</literal>
</simpara>
</entry>
<entry>
<simpara>
The <literal>unlike</literal> parameter is used in conjunction with <literal>like</literal> in order not to
select terms found in a chosen set of documents. In other words, we could ask
for documents <literal>like: "Apple"</literal>, but <literal>unlike: "cake crumble tree"</literal>. The syntax
is the same as <literal>like</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>fields</literal>
</simpara>
</entry>
<entry>
<simpara>
A list of fields to fetch and analyze the text from. Defaults to the <literal>_all</literal>
field for free text and to all possible fields for document inputs.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>like_text</literal>
</simpara>
</entry>
<entry>
<simpara>
The text to find documents like it.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>ids</literal> or <literal>docs</literal>
</simpara>
</entry>
<entry>
<simpara>
A list of documents following the same syntax as the <link linkend="docs-multi-get">Multi GET API</link>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="mlt-query-term-selection" renderas="sect3">Term Selection Parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/mlt-query.asciidoc">Edit me</ulink></bridgehead>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>max_query_terms</literal>
</simpara>
</entry>
<entry>
<simpara>
The maximum number of query terms that will be selected. Increasing this value
gives greater accuracy at the expense of query execution speed. Defaults to
<literal>25</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>min_term_freq</literal>
</simpara>
</entry>
<entry>
<simpara>
The minimum term frequency below which the terms will be ignored from the
input document. Defaults to <literal>2</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>min_doc_freq</literal>
</simpara>
</entry>
<entry>
<simpara>
The minimum document frequency below which the terms will be ignored from the
input document. Defaults to <literal>5</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max_doc_freq</literal>
</simpara>
</entry>
<entry>
<simpara>
The maximum document frequency above which the terms will be ignored from the
input document. This could be useful in order to ignore highly frequent words
such as stop words. Defaults to unbounded (<literal>0</literal>).
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>min_word_length</literal>
</simpara>
</entry>
<entry>
<simpara>
The minimum word length below which the terms will be ignored. The old name
<literal>min_word_len</literal> is deprecated. Defaults to <literal>0</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max_word_length</literal>
</simpara>
</entry>
<entry>
<simpara>
The maximum word length above which the terms will be ignored. The old name
<literal>max_word_len</literal> is deprecated. Defaults to unbounded (<literal>0</literal>).
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>stop_words</literal>
</simpara>
</entry>
<entry>
<simpara>
An array of stop words. Any word in this set is considered "uninteresting" and
ignored. If the analyzer allows for stop words, you might want to tell MLT to
explicitly ignore them, as for the purposes of document similarity it seems
reasonable to assume that "a stop word is never interesting".
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>analyzer</literal>
</simpara>
</entry>
<entry>
<simpara>
The analyzer that is used to analyze the free form text. Defaults to the
analyzer associated with the first field in <literal>fields</literal>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="_query_formation_parameters" renderas="sect3">Query Formation Parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/mlt-query.asciidoc">Edit me</ulink></bridgehead>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>minimum_should_match</literal>
</simpara>
</entry>
<entry>
<simpara>
After the disjunctive query has been formed, this parameter controls the
number of terms that must match.
The syntax is the same as the <link linkend="query-dsl-minimum-should-match">minimum should match</link>.
(Defaults to <literal>"30%"</literal>).
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>boost_terms</literal>
</simpara>
</entry>
<entry>
<simpara>
Each term in the formed query could be further boosted by their tf-idf score.
This sets the boost factor to use when using this feature. Defaults to
deactivated (<literal>0</literal>). Any other positive value activates terms boosting with the
given boost factor.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>include</literal>
</simpara>
</entry>
<entry>
<simpara>
Specifies whether the input documents should also be included in the search
results returned. Defaults to <literal>false</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>boost</literal>
</simpara>
</entry>
<entry>
<simpara>
Sets the boost value of the whole query. Defaults to <literal>1.0</literal>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
</section>
<section id="query-dsl-template-query">
<title>Template Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/template-query.asciidoc">Edit me</ulink></title>
<warning revisionflag="deleted" revision="5.0.0"><title>Deprecated in 5.0.0.</title><simpara> Use the <xref linkend="search-template"/> API.</simpara></warning>
<simpara>A query that accepts a query template and a map of key/value pairs to fill in
template parameters. Templating is based on Mustache. For simple token substitution all you provide
is a query containing some variable that you want to substitute and the actual
values:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "template": {
            "inline": { "match": { "text": "{{query_string}}" }},
            "params" : {
                "query_string" : "all about search"
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[warning:[template] query is deprecated, use search template api instead]</remark>
<simpara>The above request is translated into:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "match": {
            "text": "all about search"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Alternatively passing the template as an escaped string works as well:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "template": {
            "inline": "{ \"match\": { \"text\": \"{{query_string}}\" }}", <co id="CO156-1"/>
            "params" : {
                "query_string" : "all about search"
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[warning:[template] query is deprecated, use search template api instead]</remark>
<calloutlist>
<callout arearefs="CO156-1">
<para>
New line characters (<literal>\n</literal>) should be escaped as <literal>\\n</literal> or removed,
    and quotes (<literal>"</literal>) should be escaped as <literal>\\"</literal>.
</para>
</callout>
</calloutlist>
<section id="_stored_templates">
<title>Stored templates<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/template-query.asciidoc">Edit me</ulink></title>
<simpara>You can register a template by storing it in the <literal>config/scripts</literal> directory, in a file using the <literal>.mustache</literal> extension.
In order to execute the stored template, reference it by name in the <literal>file</literal>
parameter:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "template": {
            "file": "my_template", <co id="CO157-1"/>
            "params" : {
                "query_string" : "all about search"
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[warning:[template] query is deprecated, use search template api instead]</remark>
<calloutlist>
<callout arearefs="CO157-1">
<para>
Name of the query template in <literal>config/scripts/</literal>, i.e., <literal>my_template.mustache</literal>.
</para>
</callout>
</calloutlist>
<simpara>Alternatively, you can register a query template in the cluster state with:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /_search/template/my_template
{
    "template": { "match": { "text": "{{query_string}}" }}
}</programlisting>
<remark> CONSOLE</remark>
<simpara>and refer to it in the <literal>template</literal> query with the <literal>id</literal> parameter:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "template": {
            "stored": "my_template", <co id="CO158-1"/>
            "params" : {
                "query_string" : "all about search"
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<remark> TEST[warning:[template] query is deprecated, use search template api instead]</remark>
<calloutlist>
<callout arearefs="CO158-1">
<para>
Name of the query template in <literal>config/scripts/</literal>, i.e., <literal>my_template.mustache</literal>.
</para>
</callout>
</calloutlist>
<simpara>There is also a dedicated <literal>template</literal> endpoint, allows you to template an entire search request.
Please see <xref linkend="search-template"/> for more details.</simpara>
</section>
</section>
<section id="query-dsl-script-query">
<title>Script Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/script-query.asciidoc">Edit me</ulink></title>
<simpara>A query allowing to define
<link linkend="modules-scripting">scripts</link> as queries. They are typically used in a filter
context, for example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "bool" : {
            "must" : {
                "script" : {
                    "script" : {
                        "inline": "doc['num1'].value &gt; 1",
                        "lang": "painless"
                     }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_custom_parameters" renderas="sect3">Custom Parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/script-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>Scripts are compiled and cached for faster execution. If the same script
can be used, just with different parameters provider, it is preferable
to use the ability to pass parameters to the script itself, for example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "bool" : {
            "must" : {
                "script" : {
                    "script" : {
                        "inline" : "doc['num1'].value &gt; params.param1",
                        "lang"   : "painless",
                        "params" : {
                            "param1" : 5
                        }
                    }
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="query-dsl-percolate-query">
<title>Percolate Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/percolate-query.asciidoc">Edit me</ulink></title>
<simpara>The <literal>percolate</literal> query can be used to match queries
stored in an index. The <literal>percolate</literal> query itself
contains the document that will be used as query
to match with the stored queries.</simpara>
<bridgehead id="_sample_usage" renderas="sect2">Sample Usage<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/percolate-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>Create an index with two mappings:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /my-index
{
    "mappings": {
        "doctype": {
            "properties": {
                "message": {
                    "type": "text"
                }
            }
        },
        "queries": {
            "properties": {
                "query": {
                    "type": "percolator"
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The <literal>doctype</literal> mapping is the mapping used to preprocess
the document defined in the <literal>percolator</literal> query before it
gets indexed into a temporary index.</simpara>
<simpara>The <literal>queries</literal> mapping is the mapping used for indexing
the query documents. The <literal>query</literal> field will hold a json
object that represents an actual Elasticsearch query. The
<literal>query</literal> field has been configured to use the
<link linkend="percolator">percolator field type</link>. This field type understands
the query dsl and stored the query in such a way that it
can be used later on to match documents defined on the <literal>percolate</literal> query.</simpara>
<simpara>Register a query in the percolator:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /my-index/queries/1?refresh
{
    "query" : {
        "match" : {
            "message" : "bonsai tree"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Match a document to the registered percolator queries:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /my-index/_search
{
    "query" : {
        "percolate" : {
            "field" : "query",
            "document_type" : "doctype",
            "document" : {
                "message" : "A new bonsai tree in the office"
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>The above request will yield the following response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "took": 13,
  "timed_out": false,
  "_shards": {
    "total": 5,
    "successful": 5,
    "failed": 0
  },
  "hits": {
    "total": 1,
    "max_score": 0.5716521,
    "hits": [
      { <co id="CO159-1"/>
        "_index": "my-index",
        "_type": "queries",
        "_id": "1",
        "_score": 0.5716521,
        "_source": {
          "query": {
            "match": {
              "message": "bonsai tree"
            }
          }
        }
      }
    ]
  }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 13,/"took": "$body.took",/]</remark>
<calloutlist>
<callout arearefs="CO159-1">
<para>
The query with id <literal>1</literal> matches our document.
</para>
</callout>
</calloutlist>
<bridgehead id="_parameters_9" renderas="sect3">Parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/percolate-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>The following parameters are required when percolating a document:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>field</literal>
</simpara>
</entry>
<entry>
<simpara>
The field of type <literal>percolator</literal> and that holds the indexed queries. This is a required parameter.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>document_type</literal>
</simpara>
</entry>
<entry>
<simpara>
The type / mapping of the document being percolated. This is a required parameter.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>document</literal>
</simpara>
</entry>
<entry>
<simpara>
The source of the document being percolated.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>Instead of specifying a the source of the document being percolated, the source can also be retrieved from an already
stored document. The <literal>percolate</literal> query will then internally execute a get request to fetch that document.</simpara>
<simpara>In that case the <literal>document</literal> parameter can be substituted with the following parameters:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>index</literal>
</simpara>
</entry>
<entry>
<simpara>
The index the document resides in. This is a required parameter.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>type</literal>
</simpara>
</entry>
<entry>
<simpara>
The type of the document to fetch. This is a required parameter.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>id</literal>
</simpara>
</entry>
<entry>
<simpara>
The id of the document to fetch. This is a required parameter.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>routing</literal>
</simpara>
</entry>
<entry>
<simpara>
Optionally, routing to be used to fetch document to percolate.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>preference</literal>
</simpara>
</entry>
<entry>
<simpara>
Optionally, preference to be used to fetch document to percolate.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>version</literal>
</simpara>
</entry>
<entry>
<simpara>
Optionally, the expected version of the document to be fetched.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="_percolating_an_existing_document" renderas="sect3">Percolating an Existing Document<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/percolate-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>In order to percolate a newly indexed document, the <literal>percolate</literal> query can be used. Based on the response
from an index request, the <literal>_id</literal> and other meta information can be used to immediately percolate the newly added
document.</simpara>
<bridgehead id="_example_2" renderas="sect4">Example<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/percolate-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>Based on the previous example.</simpara>
<simpara>Index the document we want to percolate:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /my-index/message/1
{
  "message" : "A new bonsai tree in the office"
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Index response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "_index": "my-index",
  "_type": "message",
  "_id": "1",
  "_version": 1,
  "_shards": {
    "total": 2,
    "successful": 1,
    "failed": 0
  },
  "created": true,
  "result": "created"
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>Percolating an existing document, using the index response as basis to build to new search request:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /my-index/_search
{
    "query" : {
        "percolate" : {
            "field": "query",
            "document_type" : "doctype",
            "index" : "my-index",
            "type" : "message",
            "id" : "1",
            "version" : 1 <co id="CO160-1"/>
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<calloutlist>
<callout arearefs="CO160-1">
<para>
The version is optional, but useful in certain cases. We can then ensure that we are try to percolate
the document we just have indexed. A change may be made after we have indexed, and if that is the
case the then the search request would fail with a version conflict error.
</para>
</callout>
</calloutlist>
<simpara>The search response returned is identical as in the previous example.</simpara>
<bridgehead id="_percolate_query_and_highlighting" renderas="sect3">Percolate query and highlighting<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/percolate-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>percolate</literal> query is handled in a special way when it comes to highlighting. The queries hits are used
to highlight the document that is provided in the <literal>percolate</literal> query. Whereas with regular highlighting the query in
the search request is used to highlight the hits.</simpara>
<bridgehead id="_example_3" renderas="sect4">Example<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/percolate-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>This example is based on the mapping of the first example.</simpara>
<simpara>Save a query:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /my-index/queries/1?refresh
{
    "query" : {
        "match" : {
            "message" : "brown fox"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Save another query:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /my-index/queries/2?refresh
{
    "query" : {
        "match" : {
            "message" : "lazy dog"
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Execute a search request with the <literal>percolate</literal> query and highlighting enabled:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /my-index/_search
{
    "query" : {
        "percolate" : {
            "field": "query",
            "document_type" : "doctype",
            "document" : {
                "message" : "The quick brown fox jumps over the lazy dog"
            }
        }
    },
    "highlight": {
      "fields": {
        "message": {}
      }
    }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>This will yield the following response.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "took": 7,
  "timed_out": false,
  "_shards": {
    "total": 5,
    "successful": 5,
    "failed": 0
  },
  "hits": {
    "total": 2,
    "max_score": 0.5446649,
    "hits": [
      {
        "_index": "my-index",
        "_type": "queries",
        "_id": "2",
        "_score": 0.5446649,
        "_source": {
          "query": {
            "match": {
              "message": "lazy dog"
            }
          }
        },
        "highlight": {
          "message": [
            "The quick brown fox jumps over the &lt;em&gt;lazy&lt;/em&gt; &lt;em&gt;dog&lt;/em&gt;" <co id="CO161-1"/>
          ]
        }
      },
      {
        "_index": "my-index",
        "_type": "queries",
        "_id": "1",
        "_score": 0.5446649,
        "_source": {
          "query": {
            "match": {
              "message": "brown fox"
            }
          }
        },
        "highlight": {
          "message": [
            "The quick &lt;em&gt;brown&lt;/em&gt; &lt;em&gt;fox&lt;/em&gt; jumps over the lazy dog" <co id="CO161-2"/>
          ]
        }
      }
    ]
  }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 7,/"took": "$body.took",/]</remark>
<calloutlist>
<callout arearefs="CO161-1 CO161-2">
<para>
The terms from each query have been highlighted in the document.
</para>
</callout>
</calloutlist>
<simpara>Instead of the query in the search request highlighting the percolator hits, the percolator queries are highlighting
the document defined in the <literal>percolate</literal> query.</simpara>
<bridgehead id="_how_it_works_under_the_hood" renderas="sect3">How it Works Under the Hood<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/percolate-query.asciidoc">Edit me</ulink></bridgehead>
<simpara>When indexing a document into an index that has the <link linkend="percolator">percolator field type</link> mapping configured, the query
part of the documents gets parsed into a Lucene query and are stored into the Lucene index. A binary representation
of the query gets stored, but also the query&#8217;s terms are analyzed and stored into an indexed field.</simpara>
<simpara>At search time, the document specified in the request gets parsed into a Lucene document and is stored in a in-memory
temporary Lucene index. This in-memory index can just hold this one document and it is optimized for that. After this
a special query is build based on the terms in the in-memory index that select candidate percolator queries based on
their indexed query terms. These queries are then evaluated by the in-memory index if they actually match.</simpara>
<simpara>The selecting of candidate percolator queries matches is an important performance optimization during the execution
of the <literal>percolate</literal> query as it can significantly reduce the number of candidate matches the in-memory index needs to
evaluate. The reason the <literal>percolate</literal> query can do this is because during indexing of the percolator queries the query
terms are being extracted and indexed with the percolator query. Unfortunately the percolator cannot extract terms from
all queries (for example the <literal>wildcard</literal> or <literal>geo_shape</literal> query) and as a result of that in certain cases the percolator
can&#8217;t do the selecting optimization (for example if an unsupported query is defined in a required clause of a boolean query
or the unsupported query is the only query in the percolator document).  These queries are marked by the percolator and
can be found by running the following search:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
  "query": {
    "term" : {
      "query.extraction_result" : "failed"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<note><simpara>The above example assumes that there is a <literal>query</literal> field of type
<literal>percolator</literal> in the mappings.</simpara></note>
</section>
</chapter>
<chapter id="span-queries">
<title>Span queries<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/span-queries.asciidoc">Edit me</ulink></title>
<simpara>Span queries are low-level positional queries which provide expert control
over the order and proximity of the specified terms. These are typically used
to implement very specific queries on legal documents or patents.</simpara>
<simpara>Span queries cannot be mixed with non-span queries (with the exception of the <literal>span_multi</literal> query).</simpara>
<simpara>The queries in this group are:</simpara>
<variablelist>
<varlistentry>
<term>
<link linkend="query-dsl-span-term-query"><literal>span_term</literal> query</link>
</term>
<listitem>
<simpara>
The equivalent of the <link linkend="query-dsl-term-query"><literal>term</literal> query</link> but for use with
other span queries.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-span-multi-term-query"><literal>span_multi</literal> query</link>
</term>
<listitem>
<simpara>
Wraps a <link linkend="query-dsl-term-query"><literal>term</literal></link>, <link linkend="query-dsl-range-query"><literal>range</literal></link>,
<link linkend="query-dsl-prefix-query"><literal>prefix</literal></link>, <link linkend="query-dsl-wildcard-query"><literal>wildcard</literal></link>,
<link linkend="query-dsl-regexp-query"><literal>regexp</literal></link>, or <link linkend="query-dsl-fuzzy-query"><literal>fuzzy</literal></link> query.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-span-first-query"><literal>span_first</literal> query</link>
</term>
<listitem>
<simpara>
Accepts another span query whose matches must appear within the first N
positions of the field.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-span-near-query"><literal>span_near</literal> query</link>
</term>
<listitem>
<simpara>
Accepts multiple span queries whose matches must be within the specified distance of each other, and possibly in the same order.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-span-or-query"><literal>span_or</literal> query</link>
</term>
<listitem>
<simpara>
Combines multiple span queries&#8201;&#8212;&#8201;returns documents which match any of the
specified queries.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-span-not-query"><literal>span_not</literal> query</link>
</term>
<listitem>
<simpara>
Wraps another span query, and excludes any documents which match that query.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-span-containing-query"><literal>span_containing</literal> query</link>
</term>
<listitem>
<simpara>
Accepts a list of span queries, but only returns those spans which also match a second span query.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-span-within-query"><literal>span_within</literal> query</link>
</term>
<listitem>
<simpara>
The result from a single span query is returned as long is its span falls
within the spans returned by a list of other span queries.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-dsl-span-field-masking-query"><literal>field_masking_span</literal> query</link>
</term>
<listitem>
<simpara>
Allows queries like <literal>span-near</literal> or <literal>span-or</literal> across different fields.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<section id="query-dsl-span-term-query">
<title>Span Term Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/span-term-query.asciidoc">Edit me</ulink></title>
<simpara>Matches spans containing a term. The span term query maps to Lucene
<literal>SpanTermQuery</literal>. Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "span_term" : { "user" : "kimchy" }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>A boost can also be associated with the query:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
       "span_term" : { "user" : { "value" : "kimchy", "boost" : 2.0 } }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Or :</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "span_term" : { "user" : { "term" : "kimchy", "boost" : 2.0 } }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="query-dsl-span-multi-term-query">
<title>Span Multi Term Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/span-multi-term-query.asciidoc">Edit me</ulink></title>
<simpara>The <literal>span_multi</literal> query allows you to wrap a <literal>multi term query</literal> (one of wildcard,
fuzzy, prefix, term, range or regexp query) as a <literal>span query</literal>, so
it can be nested. Example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "span_multi":{
            "match":{
                "prefix" : { "user" :  { "value" : "ki" } }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>A boost can also be associated with the query:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "span_multi":{
            "match":{
                "prefix" : { "user" :  { "value" : "ki", "boost" : 1.08 } }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="query-dsl-span-first-query">
<title>Span First Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/span-first-query.asciidoc">Edit me</ulink></title>
<simpara>Matches spans near the beginning of a field. The span first query maps
to Lucene <literal>SpanFirstQuery</literal>. Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "span_first" : {
            "match" : {
                "span_term" : { "user" : "kimchy" }
            },
            "end" : 3
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The <literal>match</literal> clause can be any other span type query. The <literal>end</literal> controls
the maximum end position permitted in a match.</simpara>
</section>
<section id="query-dsl-span-near-query">
<title>Span Near Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/span-near-query.asciidoc">Edit me</ulink></title>
<simpara>Matches spans which are near one another. One can specify <emphasis>slop</emphasis>, the
maximum number of intervening unmatched positions, as well as whether
matches are required to be in-order. The span near query maps to Lucene
<literal>SpanNearQuery</literal>. Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "span_near" : {
            "clauses" : [
                { "span_term" : { "field" : "value1" } },
                { "span_term" : { "field" : "value2" } },
                { "span_term" : { "field" : "value3" } }
            ],
            "slop" : 12,
            "in_order" : false
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The <literal>clauses</literal> element is a list of one or more other span type queries
and the <literal>slop</literal> controls the maximum number of intervening unmatched
positions permitted.</simpara>
</section>
<section id="query-dsl-span-or-query">
<title>Span Or Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/span-or-query.asciidoc">Edit me</ulink></title>
<simpara>Matches the union of its span clauses. The span or query maps to Lucene
<literal>SpanOrQuery</literal>. Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "span_or" : {
            "clauses" : [
                { "span_term" : { "field" : "value1" } },
                { "span_term" : { "field" : "value2" } },
                { "span_term" : { "field" : "value3" } }
            ]
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The <literal>clauses</literal> element is a list of one or more other span type queries.</simpara>
</section>
<section id="query-dsl-span-not-query">
<title>Span Not Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/span-not-query.asciidoc">Edit me</ulink></title>
<simpara>Removes matches which overlap with another span query. The span not
query maps to Lucene <literal>SpanNotQuery</literal>. Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "span_not" : {
            "include" : {
                "span_term" : { "field1" : "hoya" }
            },
            "exclude" : {
                "span_near" : {
                    "clauses" : [
                        { "span_term" : { "field1" : "la" } },
                        { "span_term" : { "field1" : "hoya" } }
                    ],
                    "slop" : 0,
                    "in_order" : true
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The <literal>include</literal> and <literal>exclude</literal> clauses can be any span type query. The
<literal>include</literal> clause is the span query whose matches are filtered, and the
<literal>exclude</literal> clause is the span query whose matches must not overlap those
returned.</simpara>
<simpara>In the above example all documents with the term hoya are filtered except the ones that have <emphasis>la</emphasis> preceding them.</simpara>
<simpara>Other top level options:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>pre</literal>
</simpara>
</entry>
<entry>
<simpara>
If set the amount of tokens before the include span can&#8217;t have overlap with the exclude span.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>post</literal>
</simpara>
</entry>
<entry>
<simpara>
If set the amount of tokens after the include span can&#8217;t have overlap with the exclude span.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>dist</literal>
</simpara>
</entry>
<entry>
<simpara>
If set the amount of tokens from within the include span can&#8217;t have overlap with the exclude span. Equivalent
            of setting both <literal>pre</literal> and <literal>post</literal>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
<section id="query-dsl-span-containing-query">
<title>Span Containing Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/span-containing-query.asciidoc">Edit me</ulink></title>
<simpara>Returns matches which enclose another span query. The span containing
query maps to Lucene <literal>SpanContainingQuery</literal>. Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "span_containing" : {
            "little" : {
                "span_term" : { "field1" : "foo" }
            },
            "big" : {
                "span_near" : {
                    "clauses" : [
                        { "span_term" : { "field1" : "bar" } },
                        { "span_term" : { "field1" : "baz" } }
                    ],
                    "slop" : 5,
                    "in_order" : true
                }
            }
        }
    }
}</programlisting>
<remark>  CONSOLE</remark>
<simpara>The <literal>big</literal> and <literal>little</literal> clauses can be any span type query. Matching
spans from <literal>big</literal> that contain matches from <literal>little</literal> are returned.</simpara>
</section>
<section id="query-dsl-span-within-query">
<title>Span Within Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/span-within-query.asciidoc">Edit me</ulink></title>
<simpara>Returns matches which are enclosed inside another span query. The span within
query maps to Lucene <literal>SpanWithinQuery</literal>. Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
    "query": {
        "span_within" : {
            "little" : {
                "span_term" : { "field1" : "foo" }
            },
            "big" : {
                "span_near" : {
                    "clauses" : [
                        { "span_term" : { "field1" : "bar" } },
                        { "span_term" : { "field1" : "baz" } }
                    ],
                    "slop" : 5,
                    "in_order" : true
                }
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The <literal>big</literal> and <literal>little</literal> clauses can be any span type query. Matching
spans from <literal>little</literal> that are enclosed within <literal>big</literal> are returned.</simpara>
</section>
<section id="query-dsl-span-field-masking-query">
<title>Span Field Masking Query<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/span-field-masking-query.asciidoc">Edit me</ulink></title>
<simpara>Wrapper to allow span queries to participate in composite single-field span queries by <emphasis>lying</emphasis> about their search field. The span field masking query maps to Lucene&#8217;s <literal>SpanFieldMaskingQuery</literal></simpara>
<simpara>This can be used to support queries like <literal>span-near</literal> or <literal>span-or</literal> across different fields, which is not ordinarily permitted.</simpara>
<simpara>Span field masking query is invaluable in conjunction with <emphasis role="strong">multi-fields</emphasis> when same content is indexed with multiple analyzers. For instance we could index a field with the standard analyzer which breaks text up into words, and again with the english analyzer which stems words into their root form.</simpara>
<simpara>Example:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_search
{
  "query": {
    "span_near": {
      "clauses": [
        {
          "span_term": {
            "text": "quick brown"
          }
        },
        {
          "field_masking_span": {
            "query": {
              "span_term": {
                "text.stems": "fox"
              }
            },
            "field": "text"
          }
        }
      ],
      "slop": 5,
      "in_order": false
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Note: as span field masking query returns the masked field, scoring will be done using the norms of the field name supplied. This may lead to unexpected scoring behaviour.</simpara>
</section>
</chapter>
<chapter id="query-dsl-minimum-should-match">
<title>Minimum Should Match<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/minimum-should-match.asciidoc">Edit me</ulink></title>
<simpara>The <literal>minimum_should_match</literal> parameter possible values:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="3">
<colspec colname="col_1" colwidth="33*"/>
<colspec colname="col_2" colwidth="33*"/>
<colspec colname="col_3" colwidth="33*"/>
<thead>
<row>
<entry align="left" valign="top">Type </entry>
<entry align="left" valign="top">Example </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara>Integer</simpara></entry>
<entry align="left" valign="top"><simpara><literal>3</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Indicates a fixed value regardless of the number of
optional clauses.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Negative integer</simpara></entry>
<entry align="left" valign="top"><simpara><literal>-2</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Indicates that the total number of optional
clauses, minus this number should be mandatory.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Percentage</simpara></entry>
<entry align="left" valign="top"><simpara><literal>75%</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Indicates that this percent of the total number of
optional clauses are necessary. The number computed from the percentage
is rounded down and used as the minimum.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Negative percentage</simpara></entry>
<entry align="left" valign="top"><simpara><literal>-25%</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Indicates that this percent of the total
number of optional clauses can be missing. The number computed from the
percentage is rounded down, before being subtracted from the total to
determine the minimum.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Combination</simpara></entry>
<entry align="left" valign="top"><simpara><literal>3&lt;90%</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A positive integer, followed by the less-than
symbol, followed by any of the previously mentioned specifiers is a
conditional specification. It indicates that if the number of optional
clauses is equal to (or less than) the integer, they are all required,
but if it&#8217;s greater than the integer, the specification applies. In this
example: if there are 1 to 3 clauses they are all required, but for 4 or
more clauses only 90% are required.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>Multiple combinations</simpara></entry>
<entry align="left" valign="top"><simpara><literal>2&lt;-25% 9&lt;-3</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Multiple conditional
specifications can be separated by spaces, each one only being valid for
numbers greater than the one before it. In this example: if there are 1
or 2 clauses both are required, if there are 3-9 clauses all but 25% are
required, and if there are more than 9 clauses, all but three are
required.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara><emphasis role="strong">NOTE:</emphasis></simpara>
<simpara>When dealing with percentages, negative values can be used to get
different behavior in edge cases. 75% and -25% mean the same thing when
dealing with 4 clauses, but when dealing with 5 clauses 75% means 3 are
required, but -25% means 4 are required.</simpara>
<simpara>If the calculations based on the specification determine that no
optional clauses are needed, the usual rules about BooleanQueries still
apply at search time (a BooleanQuery containing no required clauses must
still match at least one optional clause)</simpara>
<simpara>No matter what number the calculation arrives at, a value greater than
the number of optional clauses, or a value less than 1 will never be
used. (ie: no matter how low or how high the result of the calculation
result is, the minimum number of required matches will never be lower
than 1 or greater than the number of clauses.</simpara>
</chapter>
<chapter id="query-dsl-multi-term-rewrite">
<title>Multi Term Query Rewrite<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/query-dsl/multi-term-rewrite.asciidoc">Edit me</ulink></title>
<simpara>Multi term queries, like
<link linkend="query-dsl-wildcard-query">wildcard</link> and
<link linkend="query-dsl-prefix-query">prefix</link> are called
multi term queries and end up going through a process of rewrite. This
also happens on the
<link linkend="query-dsl-query-string-query">query_string</link>.
All of those queries allow to control how they will get rewritten using
the <literal>rewrite</literal> parameter:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>constant_score</literal> (default): A rewrite method that performs like
<literal>constant_score_boolean</literal> when there are few matching terms and otherwise
visits all matching terms in sequence and marks documents for that term.
Matching documents are assigned a constant score equal to the query&#8217;s
boost.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>scoring_boolean</literal>: A rewrite method that first translates each term
into a should clause in a boolean query, and keeps the scores as
computed by the query. Note that typically such scores are meaningless
to the user, and require non-trivial CPU to compute, so it&#8217;s almost
always better to use <literal>constant_score_auto</literal>. This rewrite method will hit
too many clauses failure if it exceeds the boolean query limit (defaults
to <literal>1024</literal>).
</simpara>
</listitem>
<listitem>
<simpara>
<literal>constant_score_boolean</literal>: Similar to <literal>scoring_boolean</literal> except scores
are not computed. Instead, each matching document receives a constant
score equal to the query&#8217;s boost. This rewrite method will hit too many
clauses failure if it exceeds the boolean query limit (defaults to
<literal>1024</literal>).
</simpara>
</listitem>
<listitem>
<simpara>
<literal>top_terms_N</literal>: A rewrite method that first translates each term into
should clause in boolean query, and keeps the scores as computed by the
query. This rewrite method only uses the top scoring terms so it will
not overflow boolean max clause count. The <literal>N</literal> controls the size of the
top scoring terms to use.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>top_terms_boost_N</literal>: A rewrite method that first translates each term
into should clause in boolean query, but the scores are only computed as
the boost. This rewrite method only uses the top scoring terms so it
will not overflow the boolean max clause count. The <literal>N</literal> controls the
size of the top scoring terms to use.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>top_terms_blended_freqs_N</literal>: A rewrite method that first translates each
term into should clause in boolean query, but all term queries compute scores
as if they had the same frequency. In practice the frequency which is used
is the maximum frequency of all matching terms. This rewrite method only uses
the top scoring terms so it will not overflow boolean max clause count. The
<literal>N</literal> controls the size of the top scoring terms to use.
</simpara>
</listitem>
</itemizedlist>
</chapter>
</part>
<part id="mapping">
<title>Mapping <ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping.asciidoc">Edit me</ulink></title>
<partintro>
<simpara>Mapping is the process of defining how a document, and the fields it contains,
are stored and indexed.  For instance, use mappings to define:</simpara>
<itemizedlist>
<listitem>
<simpara>
which string fields should be treated as full text fields.
</simpara>
</listitem>
<listitem>
<simpara>
which fields contain numbers, dates, or geolocations.
</simpara>
</listitem>
<listitem>
<simpara>
whether the values of all fields in the document should be
  indexed into the catch-all <link linkend="mapping-all-field"><literal>_all</literal></link> field.
</simpara>
</listitem>
<listitem>
<simpara>
the <link linkend="mapping-date-format">format</link> of date values.
</simpara>
</listitem>
<listitem>
<simpara>
custom rules to control the mapping for
  <link linkend="dynamic-mapping">dynamically added fields</link>.
</simpara>
</listitem>
</itemizedlist>
<bridgehead id="mapping-type" renderas="sect1">Mapping Types<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping.asciidoc">Edit me</ulink></bridgehead>
<simpara>Each index has one or more <emphasis>mapping types</emphasis>, which are used to divide the
documents in an index into logical groups. User documents might be stored in a
<literal>user</literal> type, and blog posts in a <literal>blogpost</literal> type.</simpara>
<simpara>Each mapping type has:</simpara>
<variablelist>
<varlistentry>
<term>
<link linkend="mapping-fields">Meta-fields</link>
</term>
<listitem>
<simpara>
Meta-fields are used to customize how a document&#8217;s metadata associated is
treated. Examples of meta-fields include the document&#8217;s
<link linkend="mapping-index-field"><literal>_index</literal></link>, <link linkend="mapping-type-field"><literal>_type</literal></link>,
<link linkend="mapping-id-field"><literal>_id</literal></link>,  and <link linkend="mapping-source-field"><literal>_source</literal></link> fields.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="mapping-types">Fields</link> or <emphasis>properties</emphasis>
</term>
<listitem>
<simpara>
Each mapping type contains a list of fields or <literal>properties</literal> pertinent to that
type.  A <literal>user</literal> type might contain <literal>title</literal>, <literal>name</literal>, and <literal>age</literal> fields, while a
<literal>blogpost</literal> type might contain <literal>title</literal>, <literal>body</literal>, <literal>user_id</literal> and <literal>created</literal> fields.
Fields with the same name in different mapping types in the same index
<link linkend="field-conflicts">must have the same mapping</link>.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_field_datatypes" renderas="sect1">Field datatypes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping.asciidoc">Edit me</ulink></bridgehead>
<simpara>Each field has a data <literal>type</literal> which can be:</simpara>
<itemizedlist>
<listitem>
<simpara>
a simple type like <link linkend="text"><literal>text</literal></link>, <link linkend="keyword"><literal>keyword</literal></link>, <link linkend="date"><literal>date</literal></link>, <link linkend="number"><literal>long</literal></link>,
  <link linkend="number"><literal>double</literal></link>, <link linkend="boolean"><literal>boolean</literal></link> or <link linkend="ip"><literal>ip</literal></link>.
</simpara>
</listitem>
<listitem>
<simpara>
a type which supports the hierarchical nature of JSON such as
  <link linkend="object"><literal>object</literal></link> or <link linkend="nested"><literal>nested</literal></link>.
</simpara>
</listitem>
<listitem>
<simpara>
or a specialised type like <link linkend="geo-point"><literal>geo_point</literal></link>,
  <link linkend="geo-shape"><literal>geo_shape</literal></link>, or <link linkend="search-suggesters-completion"><literal>completion</literal></link>.
</simpara>
</listitem>
</itemizedlist>
<simpara>It is often useful to index the same field in different ways for different
purposes. For instance, a <literal>string</literal> field could be <link linkend="mapping-index">indexed</link> as
a <literal>text</literal> field for full-text search, and as a <literal>keyword</literal> field for
sorting or aggregations.  Alternatively, you could index a string field with
the <link linkend="analysis-standard-analyzer"><literal>standard</literal> analyzer</link>, the
<link linkend="english-analyzer"><literal>english</literal></link> analyzer, and the
<link linkend="french-analyzer"><literal>french</literal> analyzer</link>.</simpara>
<simpara>This is the purpose of <emphasis>multi-fields</emphasis>.  Most datatypes support multi-fields
via the <xref linkend="multi-fields"/> parameter.</simpara>
<bridgehead id="mapping-limit-settings" renderas="sect2">Settings to prevent mappings explosion<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping.asciidoc">Edit me</ulink></bridgehead>
<simpara>The following settings allow you to limit the number of field mappings that
can be created manually or dynamically, in order to prevent bad documents from
causing a mapping explosion:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>index.mapping.total_fields.limit</literal>
</term>
<listitem>
<simpara>
    The maximum number of fields in an index. The default value is <literal>1000</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>index.mapping.depth.limit</literal>
</term>
<listitem>
<simpara>
    The maximum depth for a field, which is measured as the number of inner
    objects. For instance, if all fields are defined at the root object level,
    then the depth is <literal>1</literal>. If there is one object mapping, then the depth is
    <literal>2</literal>, etc. The default is <literal>20</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>index.mapping.nested_fields.limit</literal>
</term>
<listitem>
<simpara>
    The maximum number of <literal>nested</literal> fields in an index, defaults to <literal>50</literal>.
    Indexing 1 document with 100 nested fields actually indexes 101 documents
    as each nested document is indexed as a separate hidden document.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_dynamic_mapping" renderas="sect1">Dynamic mapping<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping.asciidoc">Edit me</ulink></bridgehead>
<simpara>Fields and mapping types do not need to be defined before being used. Thanks
to <emphasis>dynamic mapping</emphasis>, new mapping types and new field names will be added
automatically, just by indexing a document. New fields can be added both to
the top-level mapping type, and to inner <link linkend="object"><literal>object</literal></link>  and
<link linkend="nested"><literal>nested</literal></link> fields.</simpara>
<simpara>The
<link linkend="dynamic-mapping">dynamic mapping</link> rules can be configured to
customise the mapping that is used for new types and new fields.</simpara>
<bridgehead id="_explicit_mappings" renderas="sect1">Explicit mappings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping.asciidoc">Edit me</ulink></bridgehead>
<simpara>You know more about your data than Elasticsearch can guess, so while dynamic
mapping can be useful to get started, at some point you will want to specify
your own explicit mappings.</simpara>
<simpara>You can create mapping types and field mappings when you
<link linkend="indices-create-index">create an index</link>, and you can add mapping types and
fields to an existing index with the <link linkend="indices-put-mapping">PUT mapping API</link>.</simpara>
<bridgehead id="_updating_existing_mappings" renderas="sect1">Updating existing mappings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping.asciidoc">Edit me</ulink></bridgehead>
<simpara>Other than where documented, <emphasis role="strong">existing type and field mappings cannot be
updated</emphasis>. Changing the mapping would mean invalidating already indexed
documents.  Instead, you should create a new index with the correct mappings
and reindex your data into that index.</simpara>
<bridgehead id="field-conflicts" renderas="sect1">Fields are shared across mapping types<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping.asciidoc">Edit me</ulink></bridgehead>
<simpara>Mapping types are used to group fields, but the fields in each mapping type
are not independent of each other. Fields with:</simpara>
<itemizedlist>
<listitem>
<simpara>
the <emphasis>same name</emphasis>
</simpara>
</listitem>
<listitem>
<simpara>
in the <emphasis>same index</emphasis>
</simpara>
</listitem>
<listitem>
<simpara>
in <emphasis>different mapping types</emphasis>
</simpara>
</listitem>
<listitem>
<simpara>
map to the <emphasis>same field</emphasis> internally,
</simpara>
</listitem>
<listitem>
<simpara>
and <emphasis role="strong">must have the same mapping</emphasis>.
</simpara>
</listitem>
</itemizedlist>
<simpara>If a <literal>title</literal> field exists in both the <literal>user</literal> and <literal>blogpost</literal> mapping types, the
<literal>title</literal> fields must have exactly the same mapping in each type.  The only
exceptions to this rule are the <xref linkend="copy-to"/>, <xref linkend="dynamic"/>, <xref linkend="enabled"/>,
<xref linkend="ignore-above"/>, <xref linkend="include-in-all"/>, and <xref linkend="properties"/> parameters, which may
have different settings per field.</simpara>
<simpara>Usually, fields with the same name also contain the same type of data, so
having the same mapping is not a problem.  When conflicts do arise, these can
be solved by choosing more descriptive names, such as <literal>user_title</literal> and
<literal>blog_title</literal>.</simpara>
<bridgehead id="_example_mapping" renderas="sect1">Example mapping<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping.asciidoc">Edit me</ulink></bridgehead>
<simpara>A mapping for the example described above could be specified when creating the
index, as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index <co id="CO162-1"/>
{
  "mappings": {
    "user": { <co id="CO162-2"/>
      "_all":       { "enabled": false  }, <co id="CO162-3"/>
      "properties": { <co id="CO162-4"/>
        "title":    { "type": "text"  }, <co id="CO162-5"/>
        "name":     { "type": "text"  }, <co id="CO162-6"/>
        "age":      { "type": "integer" }  <co id="CO162-7"/>
      }
    },
    "blogpost": { <co id="CO162-8"/>
      "_all":       { "enabled": false  }, <co id="CO162-9"/>
      "properties": { <co id="CO162-10"/>
        "title":    { "type": "text"  }, <co id="CO162-11"/>
        "body":     { "type": "text"  }, <co id="CO162-12"/>
        "user_id":  {
          "type":   "keyword" <co id="CO162-13"/>
        },
        "created":  {
          "type":   "date", <co id="CO162-14"/>
          "format": "strict_date_optional_time||epoch_millis"
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO162-1">
<para>
Create an index called <literal>my_index</literal>.
</para>
</callout>
<callout arearefs="CO162-2 CO162-8">
<para>
Add mapping types called <literal>user</literal> and <literal>blogpost</literal>.
</para>
</callout>
<callout arearefs="CO162-3 CO162-9">
<para>
Disable the <literal>_all</literal> <link linkend="mapping-fields">meta field</link> for the <literal>user</literal> mapping type.
</para>
</callout>
<callout arearefs="CO162-4 CO162-10">
<para>
Specify fields or <emphasis>properties</emphasis> in each mapping type.
</para>
</callout>
<callout arearefs="CO162-5 CO162-6 CO162-7 CO162-11 CO162-12 CO162-13 CO162-14">
<para>
Specify the data <literal>type</literal> and mapping for each field.
</para>
</callout>
</calloutlist>
</partintro>
<chapter id="mapping-types">
<title>Field datatypes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch supports a number of different datatypes for the fields in a
document:</simpara>
<bridgehead id="_core_datatypes" renderas="sect2">Core datatypes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
string
</term>
<listitem>
<simpara>
<link linkend="text"><literal>text</literal></link> and <link linkend="keyword"><literal>keyword</literal></link>
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<xref linkend="number"/>
</term>
<listitem>
<simpara>
<literal>long</literal>, <literal>integer</literal>, <literal>short</literal>, <literal>byte</literal>, <literal>double</literal>, <literal>float</literal>
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<xref linkend="date"/>
</term>
<listitem>
<simpara>
<literal>date</literal>
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<xref linkend="boolean"/>
</term>
<listitem>
<simpara>
<literal>boolean</literal>
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<xref linkend="binary"/>
</term>
<listitem>
<simpara>
<literal>binary</literal>
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_complex_datatypes" renderas="sect2">Complex datatypes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
<xref linkend="array"/>
</term>
<listitem>
<simpara>
Array support does not require a dedicated <literal>type</literal>
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<xref linkend="object"/>
</term>
<listitem>
<simpara>
<literal>object</literal> for single JSON objects
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<xref linkend="nested"/>
</term>
<listitem>
<simpara>
<literal>nested</literal> for arrays of JSON objects
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_geo_datatypes" renderas="sect2">Geo datatypes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
<xref linkend="geo-point"/>
</term>
<listitem>
<simpara>
<literal>geo_point</literal> for lat/lon points
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<xref linkend="geo-shape"/>
</term>
<listitem>
<simpara>
<literal>geo_shape</literal> for complex shapes like polygons
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_specialised_datatypes" renderas="sect2">Specialised datatypes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
<xref linkend="ip"/>
</term>
<listitem>
<simpara>
<literal>ip</literal> for IPv4 and IPv6 addresses
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="search-suggesters-completion">Completion datatype</link>
</term>
<listitem>
<simpara>
                    <literal>completion</literal> to provide auto-complete suggestions
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<xref linkend="token-count"/>
</term>
<listitem>
<simpara>
<literal>token_count</literal> to count the number of tokens in a string
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/mapper-size.html"><literal>mapper-murmur3</literal></ulink>
</term>
<listitem>
<simpara>
<literal>murmur3</literal> to compute hashes of values at index-time and store them in the index
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
Attachment datatype
</term>
<listitem>
<simpara>
    See the <ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/mapper-attachments.html"><literal>mapper-attachments</literal></ulink> plugin
    which supports indexing <literal>attachments</literal> like Microsoft Office formats, Open
    Document formats, ePub, HTML, etc. into an <literal>attachment</literal> datatype.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<xref linkend="percolator"/>
</term>
<listitem>
<simpara>
Accepts queries from the query-dsl
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_multi_fields" renderas="sect2">Multi-fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types.asciidoc">Edit me</ulink></bridgehead>
<simpara>It is often useful to index the same field in different ways for different
purposes. For instance, a <literal>string</literal> field could be mapped as
a <literal>text</literal> field for full-text search, and as a <literal>keyword</literal> field for
sorting or aggregations.  Alternatively, you could index a text field with
the <link linkend="analysis-standard-analyzer"><literal>standard</literal> analyzer</link>, the
<link linkend="english-analyzer"><literal>english</literal></link> analyzer, and the
<link linkend="french-analyzer"><literal>french</literal> analyzer</link>.</simpara>
<simpara>This is the purpose of <emphasis>multi-fields</emphasis>.  Most datatypes support multi-fields
via the <xref linkend="multi-fields"/> parameter.</simpara>
<section id="array">
<title>Array datatype<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/array.asciidoc">Edit me</ulink></title>
<simpara>In Elasticsearch, there is no dedicated <literal>array</literal> type.  Any field can contain
zero or more values by default, however, all values in the array must be of
the same datatype. For instance:</simpara>
<itemizedlist>
<listitem>
<simpara>
an array of strings: [ <literal>"one"</literal>, <literal>"two"</literal> ]
</simpara>
</listitem>
<listitem>
<simpara>
an array of integers: [ <literal>1</literal>, <literal>2</literal> ]
</simpara>
</listitem>
<listitem>
<simpara>
an array of arrays: [ <literal>1</literal>, [ <literal>2</literal>, <literal>3</literal> ]] which is the equivalent of [ <literal>1</literal>, <literal>2</literal>, <literal>3</literal> ]
</simpara>
</listitem>
<listitem>
<simpara>
an array of objects: [ <literal>{ "name": "Mary", "age": 12 }</literal>, <literal>{ "name": "John", "age": 10 }</literal>]
</simpara>
</listitem>
</itemizedlist>
<note>
<title>Arrays of objects</title>
<simpara>Arrays of objects do not work as you would expect: you cannot query each
object independently of the other objects in the array.  If you need to be
able to do this then you should use the <link linkend="nested"><literal>nested</literal></link> datatype instead
of the <link linkend="object"><literal>object</literal></link> datatype.</simpara>
<simpara>This is explained in more detail in <xref linkend="nested"/>.</simpara>
</note>
<simpara>When adding a field dynamically, the first value in the array determines the
field <literal>type</literal>.  All subsequent values must be of the same datatype or it must
at least be possible to <link linkend="coerce">coerce</link> subsequent values to the same
datatype.</simpara>
<simpara>Arrays with a mixture of datatypes are <emphasis>not</emphasis> supported: [ <literal>10</literal>, <literal>"some string"</literal> ]</simpara>
<simpara>An array may contain <literal>null</literal> values, which are either replaced by the
configured <link linkend="null-value"><literal>null_value</literal></link> or skipped entirely.  An empty array
<literal>[]</literal> is treated as a missing field&#8201;&#8212;&#8201;a field with no values.</simpara>
<simpara>Nothing needs to be pre-configured in order to use arrays in documents, they
are supported out of the box:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index/my_type/1
{
  "message": "some arrays in this document...",
  "tags":  [ "elasticsearch", "wow" ], <co id="CO163-1"/>
  "lists": [ <co id="CO163-2"/>
    {
      "name": "prog_list",
      "description": "programming list"
    },
    {
      "name": "cool_list",
      "description": "cool stuff list"
    }
  ]
}

PUT my_index/my_type/2 <co id="CO163-3"/>
{
  "message": "no arrays in this document...",
  "tags":  "elasticsearch",
  "lists": {
    "name": "prog_list",
    "description": "programming list"
  }
}

GET my_index/_search
{
  "query": {
    "match": {
      "tags": "elasticsearch" <co id="CO163-4"/>
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO163-1">
<para>
The <literal>tags</literal> field is dynamically added as a <literal>string</literal> field.
</para>
</callout>
<callout arearefs="CO163-2">
<para>
The <literal>lists</literal> field is dynamically added as an <literal>object</literal> field.
</para>
</callout>
<callout arearefs="CO163-3">
<para>
The second document contains no arrays, but can be indexed into the same fields.
</para>
</callout>
<callout arearefs="CO163-4">
<para>
The query looks for <literal>elasticsearch</literal> in the <literal>tags</literal> field, and matches both documents.
</para>
</callout>
</calloutlist>
<sidebar>
<title>Multi-value fields and the inverted index</title>
<simpara>The fact that all field types support multi-value fields out of the box is a
consequence of the origins of Lucene.  Lucene was designed to be a full text
search engine.  In order to be able to search for individual words within a
big block of text, Lucene tokenizes the text into individual terms, and
adds each term to the inverted index separately.</simpara>
<simpara>This means that even a simple text field must be able to support multiple
values by default.  When other datatypes were added, such as numbers and
dates, they used the same data structure as strings, and so got multi-values
for free.</simpara>
</sidebar>
</section>
<section id="binary">
<title>Binary datatype<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/binary.asciidoc">Edit me</ulink></title>
<simpara>The <literal>binary</literal> type accepts a binary value as a
<ulink url="https://en.wikipedia.org/wiki/Base64">Base64</ulink> encoded string. The field is not
stored by default and is not searchable:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "name": {
          "type": "text"
        },
        "blob": {
          "type": "binary"
        }
      }
    }
  }
}

PUT my_index/my_type/1
{
  "name": "Some binary blob",
  "blob": "U29tZSBiaW5hcnkgYmxvYg==" <co id="CO164-1"/>
}</programlisting>
<calloutlist>
<callout arearefs="CO164-1">
<para>
The Base64 encoded binary value must not have embedded newlines <literal>\n</literal>.
</para>
</callout>
</calloutlist>
<section id="binary-params">
<title>Parameters for <literal>binary</literal> fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/binary.asciidoc">Edit me</ulink></title>
<simpara>The following parameters are accepted by <literal>binary</literal> fields:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<link linkend="doc-values"><literal>doc_values</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Should the field be stored on disk in a column-stride fashion, so that it
    can later be used for sorting, aggregations, or scripting? Accepts <literal>true</literal>
    (default) or <literal>false</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="mapping-store"><literal>store</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Whether the field value should be stored and retrievable separately from
    the <link linkend="mapping-source-field"><literal>_source</literal></link> field. Accepts <literal>true</literal> or <literal>false</literal>
    (default).
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
</section>
<section id="boolean">
<title>Boolean datatype<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/boolean.asciidoc">Edit me</ulink></title>
<simpara>Boolean fields accept JSON <literal>true</literal> and <literal>false</literal> values, but can also accept
strings and numbers which are interpreted as either true or false:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
False values
</simpara>
</entry>
<entry>
<simpara>
    <literal>false</literal>, <literal>"false"</literal>, <literal>"off"</literal>, <literal>"no"</literal>, <literal>"0"</literal>, <literal>""</literal> (empty string), <literal>0</literal>, <literal>0.0</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
True values
</simpara>
</entry>
<entry>
<simpara>
    Anything that isn&#8217;t false.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<warning revisionflag="deleted" revision="5.1.0"><title>Deprecated in 5.1.0.</title><simpara>While Elasticsearch will currently accept the above values during index time. Searching a boolean field using these pseudo-boolean values is deprecated. Please use "true" or "false" instead..</simpara></warning>
<simpara>For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "is_published": {
          "type": "boolean"
        }
      }
    }
  }
}

POST my_index/my_type/1
{
  "is_published": 1 <co id="CO165-1"/>
}

GET my_index/_search
{
  "query": {
    "term": {
      "is_published": true <co id="CO165-2"/>
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO165-1">
<para>
Indexing a document with <literal>1</literal>, which is interpreted as <literal>true</literal>.
</para>
</callout>
<callout arearefs="CO165-2">
<para>
Searching for documents with a JSON <literal>true</literal>.
</para>
</callout>
</calloutlist>
<simpara>Aggregations like the <link linkend="search-aggregations-bucket-terms-aggregation"><literal>terms</literal> aggregation</link>  use <literal>1</literal> and <literal>0</literal> for the <literal>key</literal>, and the strings <literal>"true"</literal> and
<literal>"false"</literal> for the <literal>key_as_string</literal>. Boolean fields  when used in scripts,
return <literal>1</literal> and <literal>0</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST my_index/my_type/1
{
  "is_published": true
}

POST my_index/my_type/2
{
  "is_published": false
}

GET my_index/_search
{
  "aggs": {
    "publish_state": {
      "terms": {
        "field": "is_published"
      }
    }
  },
  "script_fields": {
    "is_published": {
      "script": {
        "lang": "painless",
        "inline": "doc['is_published'].value"
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<section id="boolean-params">
<title>Parameters for <literal>boolean</literal> fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/boolean.asciidoc">Edit me</ulink></title>
<simpara>The following parameters are accepted by <literal>boolean</literal> fields:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<link linkend="mapping-boost"><literal>boost</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Mapping field-level query time boosting. Accepts a floating point number, defaults
    to <literal>1.0</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="doc-values"><literal>doc_values</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Should the field be stored on disk in a column-stride fashion, so that it
    can later be used for sorting, aggregations, or scripting? Accepts <literal>true</literal>
    (default) or <literal>false</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="mapping-index"><literal>index</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Should the field be searchable? Accepts <literal>true</literal> (default) and <literal>false</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="null-value"><literal>null_value</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Accepts any of the true or false values listed above. The value is
    substituted for any explicit <literal>null</literal> values.  Defaults to <literal>null</literal>, which
    means the field is treated as missing.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="mapping-store"><literal>store</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Whether the field value should be stored and retrievable separately from
    the <link linkend="mapping-source-field"><literal>_source</literal></link> field. Accepts <literal>true</literal> or <literal>false</literal>
    (default).
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
</section>
<section id="date">
<title>Date datatype<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/date.asciidoc">Edit me</ulink></title>
<simpara>JSON doesn&#8217;t have a date datatype, so dates in Elasticsearch can either be:</simpara>
<itemizedlist>
<listitem>
<simpara>
strings containing formatted dates, e.g. <literal>"2015-01-01"</literal> or <literal>"2015/01/01 12:10:30"</literal>.
</simpara>
</listitem>
<listitem>
<simpara>
a long number representing <emphasis>milliseconds-since-the-epoch</emphasis>.
</simpara>
</listitem>
<listitem>
<simpara>
an integer representing <emphasis>seconds-since-the-epoch</emphasis>.
</simpara>
</listitem>
</itemizedlist>
<simpara>Internally, dates are converted to UTC (if the time-zone is specified) and
stored as a long number representing milliseconds-since-the-epoch.</simpara>
<simpara>Date formats can be customised, but if no <literal>format</literal> is specified then it uses
the default:</simpara>
<literallayout class="monospaced">"strict_date_optional_time||epoch_millis"</literallayout>
<simpara>This means that it will accept dates with optional timestamps, which conform
to the formats supported by <link linkend="strict-date-time"><literal>strict_date_optional_time</literal></link>
or milliseconds-since-the-epoch.</simpara>
<simpara>For instance:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "date": {
          "type": "date" <co id="CO166-1"/>
        }
      }
    }
  }
}

PUT my_index/my_type/1
{ "date": "2015-01-01" } <co id="CO166-2"/>

PUT my_index/my_type/2
{ "date": "2015-01-01T12:10:30Z" } <co id="CO166-3"/>

PUT my_index/my_type/3
{ "date": 1420070400001 } <co id="CO166-4"/>

GET my_index/_search
{
  "sort": { "date": "asc"} <co id="CO166-5"/>
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO166-1">
<para>
The <literal>date</literal> field uses the default <literal>format</literal>.
</para>
</callout>
<callout arearefs="CO166-2">
<para>
This document uses a plain date.
</para>
</callout>
<callout arearefs="CO166-3">
<para>
This document includes a time.
</para>
</callout>
<callout arearefs="CO166-4">
<para>
This document uses milliseconds-since-the-epoch.
</para>
</callout>
<callout arearefs="CO166-5">
<para>
Note that the <literal>sort</literal> values that are returned are all in milliseconds-since-the-epoch.
</para>
</callout>
</calloutlist>
<section id="multiple-date-formats">
<title>Multiple date formats<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/date.asciidoc">Edit me</ulink></title>
<simpara>Multiple formats can be specified by separating them with <literal>||</literal> as a separator.
Each format will be tried in turn until a matching format is found.  The first
format will be used to convert the <emphasis>milliseconds-since-the-epoch</emphasis> value back
into a string.</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "date": {
          "type":   "date",
          "format": "yyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis"
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="date-params">
<title>Parameters for <literal>date</literal> fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/date.asciidoc">Edit me</ulink></title>
<simpara>The following parameters are accepted by <literal>date</literal> fields:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<link linkend="mapping-boost"><literal>boost</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Mapping field-level query time boosting. Accepts a floating point number, defaults
    to <literal>1.0</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="doc-values"><literal>doc_values</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Should the field be stored on disk in a column-stride fashion, so that it
    can later be used for sorting, aggregations, or scripting? Accepts <literal>true</literal>
    (default) or <literal>false</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="mapping-date-format"><literal>format</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    The date format(s) that can be parsed.  Defaults to
    <literal>strict_date_optional_time||epoch_millis</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="ignore-malformed"><literal>ignore_malformed</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    If <literal>true</literal>, malformed numbers are ignored. If <literal>false</literal> (default), malformed
    numbers throw an exception and reject the whole document.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="include-in-all"><literal>include_in_all</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Whether or not the field value should be included in the
    <link linkend="mapping-all-field"><literal>_all</literal></link> field? Accepts <literal>true</literal> or <literal>false</literal>.  Defaults
    to <literal>false</literal> if <link linkend="mapping-index"><literal>index</literal></link> is set to <literal>false</literal>, or if a parent
    <link linkend="object"><literal>object</literal></link> field sets <literal>include_in_all</literal> to <literal>false</literal>.
    Otherwise defaults to <literal>true</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="mapping-index"><literal>index</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Should the field be searchable? Accepts <literal>true</literal> (default) and <literal>false</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="null-value"><literal>null_value</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Accepts a date value in one of the configured <literal>format</literal>'s as the field
    which is substituted for any explicit <literal>null</literal> values.  Defaults to <literal>null</literal>,
    which means the field is treated as missing.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="mapping-store"><literal>store</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Whether the field value should be stored and retrievable separately from
    the <link linkend="mapping-source-field"><literal>_source</literal></link> field. Accepts <literal>true</literal> or <literal>false</literal>
    (default).
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
</section>
<section id="geo-point">
<title>Geo-point datatype<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/geo-point.asciidoc">Edit me</ulink></title>
<simpara>Fields of type <literal>geo_point</literal> accept latitude-longitude pairs, which can be used:</simpara>
<itemizedlist>
<listitem>
<simpara>
to find geo-points within a <link linkend="query-dsl-geo-bounding-box-query">bounding box</link>,
  within a certain <link linkend="query-dsl-geo-distance-query">distance</link> of a central point,
  or within a <link linkend="query-dsl-geo-polygon-query">polygon</link>.
</simpara>
</listitem>
<listitem>
<simpara>
to aggregate documents by <link linkend="search-aggregations-bucket-geohashgrid-aggregation">geographically</link>
  or by <link linkend="search-aggregations-bucket-geodistance-aggregation">distance</link> from a central point.
</simpara>
</listitem>
<listitem>
<simpara>
to integrate distance into a document&#8217;s <link linkend="query-dsl-function-score-query">relevance score</link>.
</simpara>
</listitem>
<listitem>
<simpara>
to <link linkend="geo-sorting">sort</link> documents by distance.
</simpara>
</listitem>
</itemizedlist>
<simpara>There are four ways that a geo-point may be specified, as demonstrated below:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "location": {
          "type": "geo_point"
        }
      }
    }
  }
}

PUT my_index/my_type/1
{
  "text": "Geo-point as an object",
  "location": { <co id="CO167-1"/>
    "lat": 41.12,
    "lon": -71.34
  }
}

PUT my_index/my_type/2
{
  "text": "Geo-point as a string",
  "location": "41.12,-71.34" <co id="CO167-2"/>
}

PUT my_index/my_type/3
{
  "text": "Geo-point as a geohash",
  "location": "drm3btev3e86" <co id="CO167-3"/>
}

PUT my_index/my_type/4
{
  "text": "Geo-point as an array",
  "location": [ -71.34, 41.12 ] <co id="CO167-4"/>
}

GET my_index/_search
{
  "query": {
    "geo_bounding_box": { <co id="CO167-5"/>
      "location": {
        "top_left": {
          "lat": 42,
          "lon": -72
        },
        "bottom_right": {
          "lat": 40,
          "lon": -74
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO167-1">
<para>
Geo-point expressed as an object, with <literal>lat</literal> and <literal>lon</literal> keys.
</para>
</callout>
<callout arearefs="CO167-2">
<para>
Geo-point expressed as a string with the format: <literal>"lat,lon"</literal>.
</para>
</callout>
<callout arearefs="CO167-3">
<para>
Geo-point expressed as a geohash.
</para>
</callout>
<callout arearefs="CO167-4">
<para>
Geo-point expressed as an array with the format: [ <literal>lon</literal>, <literal>lat</literal>]
</para>
</callout>
<callout arearefs="CO167-5">
<para>
A geo-bounding box query which finds all geo-points that fall inside the box.
</para>
</callout>
</calloutlist>
<important>
<title>Geo-points expressed as an array or string</title>
<simpara>Please note that string geo-points are ordered as <literal>lat,lon</literal>, while array
geo-points are ordered as the reverse: <literal>lon,lat</literal>.</simpara>
<simpara>Originally, <literal>lat,lon</literal> was used for both array and string, but the array
format was changed early on to conform to the format used by GeoJSON.</simpara>
</important>
<section id="geo-point-params">
<title>Parameters for <literal>geo_point</literal> fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/geo-point.asciidoc">Edit me</ulink></title>
<simpara>The following parameters are accepted by <literal>geo_point</literal> fields:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<link linkend="ignore-malformed"><literal>ignore_malformed</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    If <literal>true</literal>, malformed geo-points are ignored. If <literal>false</literal> (default),
    malformed geo-points throw an exception and reject the whole document.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
<section id="_using_geo_points_in_scripts">
<title>Using geo-points in scripts<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/geo-point.asciidoc">Edit me</ulink></title>
<simpara>When accessing the value of a geo-point in a script, the value is returned as
a <literal>GeoPoint</literal> object, which allows access to the <literal>.lat</literal> and <literal>.lon</literal> values
respectively:</simpara>
<programlisting language="js" linenumbering="unnumbered">geopoint = doc['location'].value;
lat      = geopoint.lat;
lon      = geopoint.lon;</programlisting>
<simpara>For performance reasons, it is better to access the lat/lon values directly:</simpara>
<programlisting language="js" linenumbering="unnumbered">lat      = doc['location'].lat;
lon      = doc['location'].lon;</programlisting>
</section>
</section>
<section id="geo-shape">
<title>Geo-Shape datatype<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/geo-shape.asciidoc">Edit me</ulink></title>
<simpara>The <literal>geo_shape</literal> datatype facilitates the indexing of and searching
with arbitrary geo shapes such as rectangles and polygons. It should be
used when either the data being indexed or the queries being executed
contain shapes other than just points.</simpara>
<simpara>You can query documents using this type using
<link linkend="query-dsl-geo-shape-query">geo_shape Query</link>.</simpara>
<bridgehead id="geo-shape-mapping-options" renderas="sect3">Mapping Options<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/geo-shape.asciidoc">Edit me</ulink></bridgehead>
<simpara>The geo_shape mapping maps geo_json geometry objects to the geo_shape
type. To enable it, users must explicitly map fields to the geo_shape
type.</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="3">
<colspec colname="col_1" colwidth="33*"/>
<colspec colname="col_2" colwidth="33*"/>
<colspec colname="col_3" colwidth="33*"/>
<thead>
<row>
<entry align="left" valign="top">Option </entry>
<entry align="left" valign="top">Description</entry>
<entry align="left" valign="top"> Default</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>tree</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Name of the PrefixTree implementation to be used: <literal>geohash</literal> for
GeohashPrefixTree and <literal>quadtree</literal> for QuadPrefixTree.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>geohash</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>precision</literal></simpara></entry>
<entry align="left" valign="top"><simpara>This parameter may be used instead of <literal>tree_levels</literal> to set
an appropriate value for the <literal>tree_levels</literal> parameter. The value
specifies the desired precision and Elasticsearch will calculate the
best tree_levels value to honor this precision. The value should be a
number followed by an optional distance unit. Valid distance units
include: <literal>in</literal>, <literal>inch</literal>, <literal>yd</literal>, <literal>yard</literal>, <literal>mi</literal>, <literal>miles</literal>, <literal>km</literal>, <literal>kilometers</literal>,
<literal>m</literal>,<literal>meters</literal>, <literal>cm</literal>,<literal>centimeters</literal>, <literal>mm</literal>, <literal>millimeters</literal>.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>meters</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>tree_levels</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Maximum number of layers to be used by the PrefixTree.
This can be used to control the precision of shape representations and
therefore how many terms are indexed. Defaults to the default value of
the chosen PrefixTree implementation. Since this parameter requires a
certain level of understanding of the underlying implementation, users
may use the <literal>precision</literal> parameter instead. However, Elasticsearch only
uses the tree_levels parameter internally and this is what is returned
via the mapping API even if you use the precision parameter.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>50m</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>strategy</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The strategy parameter defines the approach for how to
represent shapes at indexing and search time. It also influences the
capabilities available so it is recommended to let Elasticsearch set
this parameter automatically. There are two strategies available:
<literal>recursive</literal> and <literal>term</literal>. Term strategy supports point types only (the
<literal>points_only</literal> parameter will be automatically set to true) while
Recursive strategy supports all shape types. (IMPORTANT: see
<link linkend="prefix-trees">Prefix trees</link> for more detailed information)</simpara></entry>
<entry align="left" valign="top"><simpara><literal>recursive</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>distance_error_pct</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Used as a hint to the PrefixTree about how
precise it should be. Defaults to 0.025 (2.5%) with 0.5 as the maximum
supported value. PERFORMANCE NOTE: This value will default to 0 if a <literal>precision</literal> or
<literal>tree_level</literal> definition is explicitly defined. This guarantees spatial precision
at the level defined in the mapping. This can lead to significant memory usage
for high resolution shapes with low error (e.g., large shapes at 1m with &lt; 0.001 error).
To improve indexing performance (at the cost of query accuracy) explicitly define
<literal>tree_level</literal> or <literal>precision</literal> along with a reasonable <literal>distance_error_pct</literal>, noting
that large shapes will have greater false positives.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>0.025</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>orientation</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Optionally define how to interpret vertex order for
polygons / multipolygons.  This parameter defines one of two coordinate
system rules (Right-hand or Left-hand) each of which can be specified in three
different ways. 1. Right-hand rule: <literal>right</literal>, <literal>ccw</literal>, <literal>counterclockwise</literal>,
2. Left-hand rule: <literal>left</literal>, <literal>cw</literal>, <literal>clockwise</literal>. The default orientation
(<literal>counterclockwise</literal>) complies with the OGC standard which defines
outer ring vertices in counterclockwise order with inner ring(s) vertices (holes)
in clockwise order. Setting this parameter in the geo_shape mapping explicitly
sets vertex order for the coordinate list of a geo_shape field but can be
overridden in each individual GeoJSON document.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>ccw</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>points_only</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Setting this option to <literal>true</literal> (defaults to <literal>false</literal>) configures
the <literal>geo_shape</literal> field type for point shapes only (NOTE: Multi-Points are not
yet supported). This optimizes index and search performance for the <literal>geohash</literal> and
<literal>quadtree</literal> when it is known that only points will be indexed. At present geo_shape
queries can not be executed on <literal>geo_point</literal> field types. This option bridges the gap
by improving point performance on a <literal>geo_shape</literal> field so that <literal>geo_shape</literal> queries are
optimal on a point only field.</simpara></entry>
<entry align="left" valign="top"><simpara><literal>false</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<bridgehead id="prefix-trees" renderas="sect3">Prefix trees<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/geo-shape.asciidoc">Edit me</ulink></bridgehead>
<simpara>To efficiently represent shapes in the index, Shapes are converted into
a series of hashes representing grid squares (commonly referred to as "rasters")
using implementations of a PrefixTree. The tree notion comes from the fact that
the PrefixTree uses multiple grid layers, each with an increasing level of
precision to represent the Earth. This can be thought of as increasing the level
of detail of a map or image at higher zoom levels.</simpara>
<simpara>Multiple PrefixTree implementations are provided:</simpara>
<itemizedlist>
<listitem>
<simpara>
GeohashPrefixTree - Uses
<ulink url="http://en.wikipedia.org/wiki/Geohash">geohashes</ulink> for grid squares.
Geohashes are base32 encoded strings of the bits of the latitude and
longitude interleaved. So the longer the hash, the more precise it is.
Each character added to the geohash represents another tree level and
adds 5 bits of precision to the geohash. A geohash represents a
rectangular area and has 32 sub rectangles. The maximum amount of levels
in Elasticsearch is 24.
</simpara>
</listitem>
<listitem>
<simpara>
QuadPrefixTree - Uses a
<ulink url="http://en.wikipedia.org/wiki/Quadtree">quadtree</ulink> for grid squares.
Similar to geohash, quad trees interleave the bits of the latitude and
longitude the resulting hash is a bit set. A tree level in a quad tree
represents 2 bits in this bit set, one for each coordinate. The maximum
amount of levels for the quad trees in Elasticsearch is 50.
</simpara>
</listitem>
</itemizedlist>
<bridgehead id="spatial-strategy" renderas="sect4">Spatial strategies<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/geo-shape.asciidoc">Edit me</ulink></bridgehead>
<simpara>The PrefixTree implementations rely on a SpatialStrategy for decomposing
the provided Shape(s) into approximated grid squares. Each strategy answers
the following:</simpara>
<itemizedlist>
<listitem>
<simpara>
What type of Shapes can be indexed?
</simpara>
</listitem>
<listitem>
<simpara>
What types of Query Operations and Shapes can be used?
</simpara>
</listitem>
<listitem>
<simpara>
Does it support more than one Shape per field?
</simpara>
</listitem>
</itemizedlist>
<simpara>The following Strategy implementations (with corresponding capabilities)
are provided:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top">Strategy </entry>
<entry align="left" valign="top">Supported Shapes </entry>
<entry align="left" valign="top">Supported Queries </entry>
<entry align="left" valign="top">Multiple Shapes</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>recursive</literal></simpara></entry>
<entry align="left" valign="top"><simpara><link linkend="input-structure">All</link></simpara></entry>
<entry align="left" valign="top"><simpara><literal>INTERSECTS</literal>, <literal>DISJOINT</literal>, <literal>WITHIN</literal>, <literal>CONTAINS</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>term</literal></simpara></entry>
<entry align="left" valign="top"><simpara><link linkend="point">Points</link></simpara></entry>
<entry align="left" valign="top"><simpara><literal>INTERSECTS</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Yes</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<bridgehead id="_accuracy" renderas="sect4">Accuracy<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/geo-shape.asciidoc">Edit me</ulink></bridgehead>
<simpara>Geo_shape does not provide 100% accuracy and depending on how it is
configured it may return some false positives or false negatives for
certain queries. To mitigate this, it is important to select an
appropriate value for the tree_levels parameter and to adjust
expectations accordingly. For example, a point may be near the border of
a particular grid cell and may thus not match a query that only matches the
cell right next to it&#8201;&#8212;&#8201;even though the shape is very close to the point.</simpara>
<bridgehead id="_example_4" renderas="sect4">Example<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/geo-shape.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">{
    "properties": {
        "location": {
            "type": "geo_shape",
            "tree": "quadtree",
            "precision": "1m"
        }
    }
}</programlisting>
<simpara>This mapping maps the location field to the geo_shape type using the
quad_tree implementation and a precision of 1m. Elasticsearch translates
this into a tree_levels setting of 26.</simpara>
<bridgehead id="_performance_considerations" renderas="sect4">Performance considerations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/geo-shape.asciidoc">Edit me</ulink></bridgehead>
<simpara>Elasticsearch uses the paths in the prefix tree as terms in the index
and in queries. The higher the level is (and thus the precision), the
more terms are generated. Of course, calculating the terms, keeping them in
memory, and storing them on disk all have a price. Especially with higher
tree levels, indices can become extremely large even with a modest
amount of data. Additionally, the size of the features also matters.
Big, complex polygons can take up a lot of space at higher tree levels.
Which setting is right depends on the use case. Generally one trades off
accuracy against index size and query performance.</simpara>
<simpara>The defaults in Elasticsearch for both implementations are a compromise
between index size and a reasonable level of precision of 50m at the
equator. This allows for indexing tens of millions of shapes without
overly bloating the resulting index too much relative to the input size.</simpara>
<bridgehead id="input-structure" renderas="sect3">Input Structure<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/geo-shape.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <ulink url="http://www.geojson.org">GeoJSON</ulink> format is used to represent
<ulink url="http://geojson.org/geojson-spec.html#geometry-objects">shapes</ulink> as input
as follows:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="3">
<colspec colname="col_1" colwidth="33*"/>
<colspec colname="col_2" colwidth="33*"/>
<colspec colname="col_3" colwidth="33*"/>
<thead>
<row>
<entry align="left" valign="top">GeoJSON Type </entry>
<entry align="left" valign="top">Elasticsearch Type </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>Point</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>point</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A single geographic coordinate.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>LineString</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>linestring</literal></simpara></entry>
<entry align="left" valign="top"><simpara>An arbitrary line given two or more points.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>Polygon</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>polygon</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A <emphasis>closed</emphasis> polygon whose first and last point
must match, thus requiring <literal>n + 1</literal> vertices to create an <literal>n</literal>-sided
polygon and a minimum of <literal>4</literal> vertices.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>MultiPoint</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>multipoint</literal></simpara></entry>
<entry align="left" valign="top"><simpara>An array of unconnected, but likely related
points.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>MultiLineString</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>multilinestring</literal></simpara></entry>
<entry align="left" valign="top"><simpara>An array of separate linestrings.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>MultiPolygon</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>multipolygon</literal></simpara></entry>
<entry align="left" valign="top"><simpara>An array of separate polygons.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>GeometryCollection</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>geometrycollection</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A GeoJSON shape similar to the
<literal>multi*</literal> shapes except that multiple types can coexist (e.g., a Point
and a LineString).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>N/A</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>envelope</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A bounding rectangle, or envelope, specified by
specifying only the top left and bottom right points.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>N/A</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>circle</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A circle specified by a center point and radius with
units, which default to <literal>METERS</literal>.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<note>
<simpara>For all types, both the inner <literal>type</literal> and <literal>coordinates</literal> fields are
required.</simpara>
<simpara>In GeoJSON, and therefore Elasticsearch, the correct <emphasis role="strong">coordinate
order is longitude, latitude (X, Y)</emphasis> within coordinate arrays. This
differs from many Geospatial APIs (e.g., Google Maps) that generally
use the colloquial latitude, longitude (Y, X).</simpara>
</note>
<bridgehead id="point" renderas="sect4"><ulink url="http://geojson.org/geojson-spec.html#id2">Point</ulink><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/geo-shape.asciidoc">Edit me</ulink></bridgehead>
<simpara>A point is a single geographic coordinate, such as the location of a
building or the current position given by a smartphone&#8217;s Geolocation
API.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "location" : {
        "type" : "point",
        "coordinates" : [-77.03653, 38.897676]
    }
}</programlisting>
<bridgehead id="_ulink_url_http_geojson_org_geojson_spec_html_id3_linestring_ulink" renderas="sect4"><ulink url="http://geojson.org/geojson-spec.html#id3">LineString</ulink><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/geo-shape.asciidoc">Edit me</ulink></bridgehead>
<simpara>A <literal>linestring</literal> defined by an array of two or more positions. By
specifying only two points, the <literal>linestring</literal> will represent a straight
line.  Specifying more than two points creates an arbitrary path.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "location" : {
        "type" : "linestring",
        "coordinates" : [[-77.03653, 38.897676], [-77.009051, 38.889939]]
    }
}</programlisting>
<simpara>The above <literal>linestring</literal> would draw a straight line starting at the White
House to the US Capitol Building.</simpara>
<bridgehead id="_ulink_url_http_www_geojson_org_geojson_spec_html_id4_polygon_ulink" renderas="sect4"><ulink url="http://www.geojson.org/geojson-spec.html#id4">Polygon</ulink><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/geo-shape.asciidoc">Edit me</ulink></bridgehead>
<simpara>A polygon is defined by a list of a list of points. The first and last
points in each (outer) list must be the same (the polygon must be
closed).</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "location" : {
        "type" : "polygon",
        "coordinates" : [
            [ [100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0, 1.0], [100.0, 0.0] ]
        ]
    }
}</programlisting>
<simpara>The first array represents the outer boundary of the polygon, the other
arrays represent the interior shapes ("holes"):</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "location" : {
        "type" : "polygon",
        "coordinates" : [
            [ [100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0, 1.0], [100.0, 0.0] ],
            [ [100.2, 0.2], [100.8, 0.2], [100.8, 0.8], [100.2, 0.8], [100.2, 0.2] ]
        ]
    }
}</programlisting>
<simpara><emphasis role="strong">IMPORTANT NOTE:</emphasis> GeoJSON does not mandate a specific order for vertices thus ambiguous
polygons around the dateline and poles are possible. To alleviate ambiguity
the Open Geospatial Consortium (OGC)
<ulink url="http://www.opengeospatial.org/standards/sfa">Simple Feature Access</ulink> specification
defines the following vertex ordering:</simpara>
<itemizedlist>
<listitem>
<simpara>
Outer Ring - Counterclockwise
</simpara>
</listitem>
<listitem>
<simpara>
Inner Ring(s) / Holes - Clockwise
</simpara>
</listitem>
</itemizedlist>
<simpara>For polygons that do not cross the dateline, vertex order will not matter in
Elasticsearch. For polygons that do cross the dateline, Elasticsearch requires
vertex ordering to comply with the OGC specification. Otherwise, an unintended polygon
may be created and unexpected query/filter results will be returned.</simpara>
<simpara>The following provides an example of an ambiguous polygon.  Elasticsearch will apply
OGC standards to eliminate ambiguity resulting in a polygon that crosses the dateline.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "location" : {
        "type" : "polygon",
        "coordinates" : [
            [ [-177.0, 10.0], [176.0, 15.0], [172.0, 0.0], [176.0, -15.0], [-177.0, -10.0], [-177.0, 10.0] ],
            [ [178.2, 8.2], [-178.8, 8.2], [-180.8, -8.8], [178.2, 8.8] ]
        ]
    }
}</programlisting>
<simpara>An <literal>orientation</literal> parameter can be defined when setting the geo_shape mapping (see <xref linkend="geo-shape-mapping-options"/>). This will define vertex
order for the coordinate list on the mapped geo_shape field. It can also be overridden on each document.  The following is an example for
overriding the orientation on a document:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "location" : {
        "type" : "polygon",
        "orientation" : "clockwise",
        "coordinates" : [
            [ [-177.0, 10.0], [176.0, 15.0], [172.0, 0.0], [176.0, -15.0], [-177.0, -10.0], [-177.0, 10.0] ],
            [ [178.2, 8.2], [-178.8, 8.2], [-180.8, -8.8], [178.2, 8.8] ]
        ]
    }
}</programlisting>
<bridgehead id="_ulink_url_http_www_geojson_org_geojson_spec_html_id5_multipoint_ulink" renderas="sect4"><ulink url="http://www.geojson.org/geojson-spec.html#id5">MultiPoint</ulink><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/geo-shape.asciidoc">Edit me</ulink></bridgehead>
<simpara>A list of geojson points.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "location" : {
        "type" : "multipoint",
        "coordinates" : [
            [102.0, 2.0], [103.0, 2.0]
        ]
    }
}</programlisting>
<bridgehead id="_ulink_url_http_www_geojson_org_geojson_spec_html_id6_multilinestring_ulink" renderas="sect4"><ulink url="http://www.geojson.org/geojson-spec.html#id6">MultiLineString</ulink><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/geo-shape.asciidoc">Edit me</ulink></bridgehead>
<simpara>A list of geojson linestrings.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "location" : {
        "type" : "multilinestring",
        "coordinates" : [
            [ [102.0, 2.0], [103.0, 2.0], [103.0, 3.0], [102.0, 3.0] ],
            [ [100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0, 1.0] ],
            [ [100.2, 0.2], [100.8, 0.2], [100.8, 0.8], [100.2, 0.8] ]
        ]
    }
}</programlisting>
<bridgehead id="_ulink_url_http_www_geojson_org_geojson_spec_html_id7_multipolygon_ulink" renderas="sect4"><ulink url="http://www.geojson.org/geojson-spec.html#id7">MultiPolygon</ulink><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/geo-shape.asciidoc">Edit me</ulink></bridgehead>
<simpara>A list of geojson polygons.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "location" : {
        "type" : "multipolygon",
        "coordinates" : [
            [ [[102.0, 2.0], [103.0, 2.0], [103.0, 3.0], [102.0, 3.0], [102.0, 2.0]] ],

            [ [[100.0, 0.0], [101.0, 0.0], [101.0, 1.0], [100.0, 1.0], [100.0, 0.0]],
              [[100.2, 0.2], [100.8, 0.2], [100.8, 0.8], [100.2, 0.8], [100.2, 0.2]] ]
        ]
    }
}</programlisting>
<bridgehead id="_ulink_url_http_geojson_org_geojson_spec_html_geometrycollection_geometry_collection_ulink" renderas="sect4"><ulink url="http://geojson.org/geojson-spec.html#geometrycollection">Geometry Collection</ulink><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/geo-shape.asciidoc">Edit me</ulink></bridgehead>
<simpara>A collection of geojson geometry objects.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "location" : {
        "type": "geometrycollection",
        "geometries": [
            {
                "type": "point",
                "coordinates": [100.0, 0.0]
            },
            {
                "type": "linestring",
                "coordinates": [ [101.0, 0.0], [102.0, 1.0] ]
            }
        ]
    }
}</programlisting>
<bridgehead id="_envelope" renderas="sect4">Envelope<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/geo-shape.asciidoc">Edit me</ulink></bridgehead>
<simpara>Elasticsearch supports an <literal>envelope</literal> type, which consists of coordinates
for upper left and lower right points of the shape to represent a
bounding rectangle:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "location" : {
        "type" : "envelope",
        "coordinates" : [ [-45.0, 45.0], [45.0, -45.0] ]
    }
}</programlisting>
<bridgehead id="_circle" renderas="sect4">Circle<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/geo-shape.asciidoc">Edit me</ulink></bridgehead>
<simpara>Elasticsearch supports a <literal>circle</literal> type, which consists of a center
point with a radius:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "location" : {
        "type" : "circle",
        "coordinates" : [-45.0, 45.0],
        "radius" : "100m"
    }
}</programlisting>
<simpara>Note: The inner <literal>radius</literal> field is required. If not specified, then
the units of the <literal>radius</literal> will default to <literal>METERS</literal>.</simpara>
<bridgehead id="_sorting_and_retrieving_index_shapes" renderas="sect3">Sorting and Retrieving index Shapes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/geo-shape.asciidoc">Edit me</ulink></bridgehead>
<simpara>Due to the complex input structure and index representation of shapes,
it is not currently possible to sort shapes or retrieve their fields
directly. The geo_shape value is only retrievable through the <literal>_source</literal>
field.</simpara>
</section>
<section id="ip">
<title>IP datatype<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/ip.asciidoc">Edit me</ulink></title>
<simpara>An <literal>ip</literal> field can index/store either <ulink url="https://en.wikipedia.org/wiki/IPv4">IPv4</ulink> or
<ulink url="https://en.wikipedia.org/wiki/IPv6">IPv6</ulink> addresses.</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "ip_addr": {
          "type": "ip"
        }
      }
    }
  }
}

PUT my_index/my_type/1
{
  "ip_addr": "192.168.1.1"
}

GET my_index/_search
{
  "query": {
    "term": {
      "ip_addr": "192.168.0.0/16"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<section id="ip-params">
<title>Parameters for <literal>ip</literal> fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/ip.asciidoc">Edit me</ulink></title>
<simpara>The following parameters are accepted by <literal>ip</literal> fields:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<link linkend="mapping-boost"><literal>boost</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Mapping field-level query time boosting. Accepts a floating point number, defaults
    to <literal>1.0</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="doc-values"><literal>doc_values</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Should the field be stored on disk in a column-stride fashion, so that it
    can later be used for sorting, aggregations, or scripting? Accepts <literal>true</literal>
    (default) or <literal>false</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="include-in-all"><literal>include_in_all</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Whether or not the field value should be included in the
    <link linkend="mapping-all-field"><literal>_all</literal></link> field? Accepts <literal>true</literal> or <literal>false</literal>.  Defaults
    to <literal>false</literal> if <link linkend="mapping-index"><literal>index</literal></link> is set to <literal>false</literal>, or if a parent
    <link linkend="object"><literal>object</literal></link> field sets <literal>include_in_all</literal> to <literal>false</literal>.
    Otherwise defaults to <literal>true</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="mapping-index"><literal>index</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Should the field be searchable? Accepts <literal>true</literal> (default) and <literal>false</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="null-value"><literal>null_value</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Accepts an IPv4 value which is substituted for any explicit <literal>null</literal> values.
    Defaults to <literal>null</literal>, which means the field is treated as missing.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="mapping-store"><literal>store</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Whether the field value should be stored and retrievable separately from
    the <link linkend="mapping-source-field"><literal>_source</literal></link> field. Accepts <literal>true</literal> or <literal>false</literal>
    (default).
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
<section id="_querying_literal_ip_literal_fields">
<title>Querying <literal>ip</literal> fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/ip.asciidoc">Edit me</ulink></title>
<simpara>The most common way to query ip addresses is to use the
<ulink url="https://en.wikipedia.org/wiki/Classless_Inter-Domain_Routing#CIDR_notation">CIDR</ulink>
notation: <literal>[ip_address]/[prefix_length]</literal>. For instance:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET my_index/_search
{
  "query": {
    "term": {
      "ip_addr": "192.168.0.0/16"
    }
  }
}</programlisting>
<simpara>or</simpara>
<programlisting language="js" linenumbering="unnumbered">GET my_index/_search
{
  "query": {
    "term": {
      "ip_addr": "2001:db8::/48"
    }
  }
}</programlisting>
<simpara>Also beware that colons are special characters to the
<link linkend="query-dsl-query-string-query"><literal>query_string</literal></link> query, so ipv6 addresses will
need to be escaped. The easiest way to do so is to put quotes around the
searched value:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET t/_search
{
  "query": {
    "query_string" : {
      "query": "ip_addr:\"2001:db8::/48\""
    }
  }
}</programlisting>
</section>
</section>
<section id="keyword">
<title>Keyword datatype<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/keyword.asciidoc">Edit me</ulink></title>
<simpara>A field to index structured content such as email addresses, hostnames, status
codes, zip codes or tags.</simpara>
<simpara>They are typically used for filtering (<emphasis>Find me all blog posts where
<literal>status</literal> is <literal>published</literal></emphasis>), for sorting, and for aggregations. Keyword
fields are only searchable by their exact value.</simpara>
<simpara>If you need to index full text content such as email bodies or product
descriptions, it is likely that you should rather use a <link linkend="text"><literal>text</literal></link> field.</simpara>
<simpara>Below is an example of a mapping for a keyword field:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "tags": {
          "type":  "keyword"
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<section id="keyword-params">
<title>Parameters for keyword fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/keyword.asciidoc">Edit me</ulink></title>
<simpara>The following parameters are accepted by <literal>keyword</literal> fields:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<link linkend="mapping-boost"><literal>boost</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Mapping field-level query time boosting. Accepts a floating point number, defaults
    to <literal>1.0</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="doc-values"><literal>doc_values</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Should the field be stored on disk in a column-stride fashion, so that it
    can later be used for sorting, aggregations, or scripting? Accepts <literal>true</literal>
    (default) or <literal>false</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="global-ordinals"><literal>eager_global_ordinals</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Should global ordinals be loaded eagerly on refresh? Accepts <literal>true</literal> or <literal>false</literal>
    (default). Enabling this is a good idea on fields that are frequently used for
    terms aggregations.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="multi-fields"><literal>fields</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Multi-fields allow the same string value to be indexed in multiple ways for
    different purposes, such as one field for search and a multi-field for
    sorting and aggregations.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="ignore-above"><literal>ignore_above</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Do not index any string longer than this value.  Defaults to
    <literal>2147483647</literal> so that all values would be accepted.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="include-in-all"><literal>include_in_all</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Whether or not the field value should be included in the
    <link linkend="mapping-all-field"><literal>_all</literal></link> field? Accepts <literal>true</literal> or <literal>false</literal>.  Defaults
    to <literal>false</literal> if <link linkend="mapping-index"><literal>index</literal></link> is set to <literal>no</literal>, or if a parent
    <link linkend="object"><literal>object</literal></link> field sets <literal>include_in_all</literal> to <literal>false</literal>.
    Otherwise defaults to <literal>true</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="mapping-index"><literal>index</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Should the field be searchable? Accepts <literal>true</literal> (default) or <literal>false</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="index-options"><literal>index_options</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    What information should be stored in the index, for scoring purposes.
    Defaults to <literal>docs</literal> but can also be set to <literal>freqs</literal> to take term frequency into account
    when computing scores.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="norms"><literal>norms</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Whether field-length should be taken into account when scoring queries.
    Accepts <literal>true</literal> or <literal>false</literal> (default).
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="null-value"><literal>null_value</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Accepts a string value which is substituted for any explicit <literal>null</literal>
    values.  Defaults to <literal>null</literal>, which means the field is treated as missing.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="mapping-store"><literal>store</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Whether the field value should be stored and retrievable separately from
    the <link linkend="mapping-source-field"><literal>_source</literal></link> field. Accepts <literal>true</literal> or <literal>false</literal>
    (default).
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="search-analyzer"><literal>search_analyzer</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    The <link linkend="analyzer"><literal>analyzer</literal></link> that should be used at search time on
    <link linkend="mapping-index"><literal>analyzed</literal></link> fields. Defaults to the <literal>analyzer</literal> setting.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="similarity"><literal>similarity</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Which scoring algorithm or <emphasis>similarity</emphasis> should be used. Defaults
    to <literal>classic</literal>, which uses TF/IDF.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<note><simpara>Indexes imported from 2.x do not support <literal>keyword</literal>. Instead they will
attempt to downgrade <literal>keyword</literal> into <literal>string</literal>. This allows you to merge modern
mappings with legacy mappings. Long lived indexes will have to be recreated
before upgrading to 6.x but mapping downgrade gives you the opportunity to do
the recreation on your own schedule.</simpara></note>
</section>
</section>
<section id="nested">
<title>Nested datatype<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/nested.asciidoc">Edit me</ulink></title>
<simpara>The <literal>nested</literal> type is a specialised version of the <link linkend="object"><literal>object</literal></link> datatype
that allows arrays of objects to be indexed and queried independently of each
other.</simpara>
<section id="_how_arrays_of_objects_are_flattened">
<title>How arrays of objects are flattened<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/nested.asciidoc">Edit me</ulink></title>
<simpara>Arrays of inner <link linkend="object"><literal>object</literal> fields</link> do not work the way you may expect.
Lucene has no concept of inner objects, so Elasticsearch flattens object
hierarchies into a simple list of field names and values. For instance, the
following document:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index/my_type/1
{
  "group" : "fans",
  "user" : [ <co id="CO168-1"/>
    {
      "first" : "John",
      "last" :  "Smith"
    },
    {
      "first" : "Alice",
      "last" :  "White"
    }
  ]
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO168-1">
<para>
The <literal>user</literal> field is dynamically added as a field of type <literal>object</literal>.
</para>
</callout>
</calloutlist>
<simpara>would be transformed internally into a document that looks more like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "group" :        "fans",
  "user.first" : [ "alice", "john" ],
  "user.last" :  [ "smith", "white" ]
}</programlisting>
<simpara>The <literal>user.first</literal> and <literal>user.last</literal> fields are flattened into multi-value fields,
and the association between <literal>alice</literal> and <literal>white</literal> is lost.  This document would
incorrectly match a query for <literal>alice AND smith</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET my_index/_search
{
  "query": {
    "bool": {
      "must": [
        { "match": { "user.first": "Alice" }},
        { "match": { "user.last":  "Smith" }}
      ]
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
</section>
<section id="_using_literal_nested_literal_fields_for_arrays_of_objects">
<title>Using <literal>nested</literal> fields for arrays of objects<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/nested.asciidoc">Edit me</ulink></title>
<simpara>If you need to index arrays of objects and to maintain the independence of
each object in the array, you should use the <literal>nested</literal> datatype instead of the
<link linkend="object"><literal>object</literal></link> datatype.  Internally, nested objects index each object in
the array as a separate hidden document, meaning that each nested object can be
queried independently of the others, with the <link linkend="query-dsl-nested-query"><literal>nested</literal> query</link>:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "user": {
          "type": "nested" <co id="CO169-1"/>
        }
      }
    }
  }
}

PUT my_index/my_type/1
{
  "group" : "fans",
  "user" : [
    {
      "first" : "John",
      "last" :  "Smith"
    },
    {
      "first" : "Alice",
      "last" :  "White"
    }
  ]
}

GET my_index/_search
{
  "query": {
    "nested": {
      "path": "user",
      "query": {
        "bool": {
          "must": [
            { "match": { "user.first": "Alice" }},
            { "match": { "user.last":  "Smith" }} <co id="CO169-2"/>
          ]
        }
      }
    }
  }
}

GET my_index/_search
{
  "query": {
    "nested": {
      "path": "user",
      "query": {
        "bool": {
          "must": [
            { "match": { "user.first": "Alice" }},
            { "match": { "user.last":  "White" }} <co id="CO169-3"/>
          ]
        }
      },
      "inner_hits": { <co id="CO169-4"/>
        "highlight": {
          "fields": {
            "user.first": {}
          }
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO169-1">
<para>
The <literal>user</literal> field is mapped as type <literal>nested</literal> instead of type <literal>object</literal>.
</para>
</callout>
<callout arearefs="CO169-2">
<para>
This query doesn&#8217;t match because <literal>Alice</literal> and <literal>Smith</literal> are not in the same nested object.
</para>
</callout>
<callout arearefs="CO169-3">
<para>
This query matches because <literal>Alice</literal> and <literal>White</literal> are in the same nested object.
</para>
</callout>
<callout arearefs="CO169-4">
<para>
<literal>inner_hits</literal> allow us to highlight the matching nested documents.
</para>
</callout>
</calloutlist>
<simpara>Nested documents can be:</simpara>
<itemizedlist>
<listitem>
<simpara>
queried with the <link linkend="query-dsl-nested-query"><literal>nested</literal></link> query.
</simpara>
</listitem>
<listitem>
<simpara>
analyzed with the <link linkend="search-aggregations-bucket-nested-aggregation"><literal>nested</literal></link>
  and <link linkend="search-aggregations-bucket-reverse-nested-aggregation"><literal>reverse_nested</literal></link>
  aggregations.
</simpara>
</listitem>
<listitem>
<simpara>
sorted with <link linkend="nested-sorting">nested sorting</link>.
</simpara>
</listitem>
<listitem>
<simpara>
retrieved and highlighted with <link linkend="nested-inner-hits">nested inner hits</link>.
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="nested-params">
<title>Parameters for <literal>nested</literal> fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/nested.asciidoc">Edit me</ulink></title>
<simpara>The following parameters are accepted by <literal>nested</literal> fields:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<link linkend="dynamic"><literal>dynamic</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Whether or not new <literal>properties</literal> should be added dynamically to an existing
    nested object.  Accepts <literal>true</literal> (default), <literal>false</literal> and <literal>strict</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="include-in-all"><literal>include_in_all</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Sets the default <literal>include_in_all</literal> value for all the <literal>properties</literal> within
    the nested object. Nested documents do not have their own <literal>_all</literal> field.
    Instead, values are added to the <literal>_all</literal> field of the main &#8220;root&#8221;
    document.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="properties"><literal>properties</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    The fields within the nested object, which can be of any
    <link linkend="mapping-types">datatype</link>, including <literal>nested</literal>. New properties
    may be added to an existing nested object.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<important>
<simpara>Because nested documents are indexed as separate documents, they can only be
accessed  within the scope of the <literal>nested</literal> query, the
<literal>nested</literal>/<literal>reverse_nested</literal>, or <link linkend="nested-inner-hits">nested inner hits</link>.</simpara>
<simpara>For instance, if a string field within a nested document has
<link linkend="index-options"><literal>index_options</literal></link> set to <literal>offsets</literal> to allow use of the postings
highlighter, these offsets will not be available during the main highlighting
phase.  Instead, highlighting needs to be performed via
<link linkend="nested-inner-hits">nested inner hits</link>.</simpara>
</important>
</section>
<section id="_limiting_the_number_of_literal_nested_literal_fields">
<title>Limiting the number of <literal>nested</literal> fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/nested.asciidoc">Edit me</ulink></title>
<simpara>Indexing a document with 100 nested fields actually indexes 101 documents as each nested
document is indexed as a separate document. To safeguard against ill-defined mappings
the number of nested fields that can be defined per index has been limited to 50. See
<xref linkend="mapping-limit-settings"/>.</simpara>
</section>
</section>
<section id="number">
<title>Numeric datatypes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/numeric.asciidoc">Edit me</ulink></title>
<simpara>The following numeric types are supported:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>long</literal>
</simpara>
</entry>
<entry>
<simpara>
A signed 64-bit integer with a minimum value of <literal>-2<superscript>63</superscript></literal> and a maximum value of <literal>2<superscript>63</superscript>-1</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>integer</literal>
</simpara>
</entry>
<entry>
<simpara>
A signed 32-bit integer with a minimum value of <literal>-2<superscript>31</superscript></literal> and a maximum value of <literal>2<superscript>31</superscript>-1</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>short</literal>
</simpara>
</entry>
<entry>
<simpara>
A signed 16-bit integer with a minimum value of <literal>-32,768</literal> and a maximum value of <literal>32,767</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>byte</literal>
</simpara>
</entry>
<entry>
<simpara>
A signed 8-bit integer with a minimum value of <literal>-128</literal> and a maximum value of <literal>127</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>double</literal>
</simpara>
</entry>
<entry>
<simpara>
A double-precision 64-bit IEEE 754 floating point.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>float</literal>
</simpara>
</entry>
<entry>
<simpara>
A single-precision 32-bit IEEE 754 floating point.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>half_float</literal>
</simpara>
</entry>
<entry>
<simpara>
A half-precision 16-bit IEEE 754 floating point.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>scaled_float</literal>
</simpara>
</entry>
<entry>
<simpara>
A floating point that is backed by a <literal>long</literal> and a fixed scaling factor.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>Below is an example of configuring a mapping with numeric fields:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "number_of_bytes": {
          "type": "integer"
        },
        "time_in_seconds": {
          "type": "float"
        },
        "price": {
          "type": "scaled_float",
          "scaling_factor": 100
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<section id="_which_type_should_i_use">
<title>Which type should I use?<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/numeric.asciidoc">Edit me</ulink></title>
<simpara>As far as integer types (<literal>byte</literal>, <literal>short</literal>, <literal>integer</literal> and <literal>long</literal>) are concerned,
you should pick the smallest type which is enough for your use-case. This will
help indexing and searching be more efficient. Note however that given that
storage is optimized based on the actual values that are stored, picking one
type over another one will have no impact on storage requirements.</simpara>
<simpara>For floating-point types, it is often more efficient to store floating-point
data into an integer using a scaling factor, which is what the <literal>scaled_float</literal>
type does under the hood. For instance, a <literal>price</literal> field could be stored in a
<literal>scaled_float</literal> with a <literal>scaling_factor</literal> of <literal>100</literal>. All APIs would work as if
the field was stored as a double, but under the hood elasticsearch would be
working with the number of cents, <literal>price*100</literal>, which is an integer. This is
mostly helpful to save disk space since integers are way easier to compress
than floating points. <literal>scaled_float</literal> is also fine to use in order to trade
accuracy for disk space. For instance imagine that you are tracking cpu
utilization as a number between <literal>0</literal> and <literal>1</literal>. It usually does not matter much
whether cpu utilization is <literal>12.7%</literal> or <literal>13%</literal>, so you could use a <literal>scaled_float</literal>
with a <literal>scaling_factor</literal> of <literal>100</literal> in order to round cpu utilization to the
closest percent in order to save space.</simpara>
<simpara>If <literal>scaled_float</literal> is not a good fit, then you should pick the smallest type
that is enough for the use-case among the floating-point types: <literal>double</literal>,
<literal>float</literal> and <literal>half_float</literal>. Here is a table that compares these types in order
to help make a decision.</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top">Type </entry>
<entry align="left" valign="top">Minimum value </entry>
<entry align="left" valign="top">Maximum value </entry>
<entry align="left" valign="top">Significant bits / digits</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>double</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>2<superscript>-1074</superscript></literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>(2-2<superscript>-52</superscript>)·2<superscript>1023</superscript></literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>53</literal> / <literal>15.95</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>float</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>2<superscript>-149</superscript></literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>(2-2<superscript>-23</superscript>)·2<superscript>127</superscript></literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>24</literal> / <literal>7.22</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>half_float</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>2<superscript>-24</superscript></literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>65504</literal></simpara></entry>
<entry align="left" valign="top"><simpara><literal>11</literal> / <literal>3.31</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section id="number-params">
<title>Parameters for numeric fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/numeric.asciidoc">Edit me</ulink></title>
<simpara>The following parameters are accepted by numeric types:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<link linkend="coerce"><literal>coerce</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Try to convert strings to numbers and truncate fractions for integers.
    Accepts <literal>true</literal> (default) and <literal>false</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="mapping-boost"><literal>boost</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Mapping field-level query time boosting. Accepts a floating point number, defaults
    to <literal>1.0</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="doc-values"><literal>doc_values</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Should the field be stored on disk in a column-stride fashion, so that it
    can later be used for sorting, aggregations, or scripting? Accepts <literal>true</literal>
    (default) or <literal>false</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="ignore-malformed"><literal>ignore_malformed</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    If <literal>true</literal>, malformed numbers are ignored. If <literal>false</literal> (default), malformed
    numbers throw an exception and reject the whole document.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="include-in-all"><literal>include_in_all</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Whether or not the field value should be included in the
    <link linkend="mapping-all-field"><literal>_all</literal></link> field? Accepts <literal>true</literal> or <literal>false</literal>.  Defaults
    to <literal>false</literal> if <link linkend="mapping-index"><literal>index</literal></link> is set to <literal>false</literal>, or if a parent
    <link linkend="object"><literal>object</literal></link> field sets <literal>include_in_all</literal> to <literal>false</literal>.
    Otherwise defaults to <literal>true</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="mapping-index"><literal>index</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Should the field be searchable? Accepts <literal>true</literal> (default) and <literal>false</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="null-value"><literal>null_value</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Accepts a numeric value of the same <literal>type</literal> as the field which is
    substituted for any explicit <literal>null</literal> values.  Defaults to <literal>null</literal>, which
    means the field is treated as missing.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="mapping-store"><literal>store</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Whether the field value should be stored and retrievable separately from
    the <link linkend="mapping-source-field"><literal>_source</literal></link> field. Accepts <literal>true</literal> or <literal>false</literal>
    (default).
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
<section id="scaled-float-params">
<title>Parameters for <literal>scaled_float</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/numeric.asciidoc">Edit me</ulink></title>
<simpara><literal>scaled_float</literal> accepts an additional parameter:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>scaling_factor</literal>
</simpara>
</entry>
<entry>
<simpara>
    The scaling factor to use when encoding values. Values will be multiplied
    by this factor at index time and rounded to the closest long value. For
    instance, a <literal>scaled_float</literal> with a <literal>scaling_factor</literal> of <literal>10</literal> would internally
    store <literal>2.34</literal> as <literal>23</literal> and all search-time operations (queries, aggregations,
    sorting) will behave as if the document had a value of <literal>2.3</literal>. High values
    of <literal>scaling_factor</literal> improve accuracy but also increase space requirements.
    This parameter is required.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
</section>
<section id="object">
<title>Object datatype<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/object.asciidoc">Edit me</ulink></title>
<simpara>JSON documents are hierarchical in nature: the document may contain inner
objects which, in turn, may contain inner objects themselves:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index/my_type/1
{ <co id="CO170-1"/>
  "region": "US",
  "manager": { <co id="CO170-2"/>
    "age":     30,
    "name": { <co id="CO170-3"/>
      "first": "John",
      "last":  "Smith"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO170-1">
<para>
The outer document is also a JSON object.
</para>
</callout>
<callout arearefs="CO170-2">
<para>
It contains an inner object called <literal>manager</literal>.
</para>
</callout>
<callout arearefs="CO170-3">
<para>
Which in turn contains an inner object called <literal>name</literal>.
</para>
</callout>
</calloutlist>
<simpara>Internally, this document is indexed as a simple, flat list of key-value
pairs, something like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "region":             "US",
  "manager.age":        30,
  "manager.name.first": "John",
  "manager.name.last":  "Smith"
}</programlisting>
<simpara>An explicit mapping for the above document could look like this:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": { <co id="CO171-1"/>
      "properties": {
        "region": {
          "type": "keyword"
        },
        "manager": { <co id="CO171-2"/>
          "properties": {
            "age":  { "type": "integer" },
            "name": { <co id="CO171-3"/>
              "properties": {
                "first": { "type": "text" },
                "last":  { "type": "text" }
              }
            }
          }
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO171-1">
<para>
The mapping type is a type of object, and has a <literal>properties</literal> field.
</para>
</callout>
<callout arearefs="CO171-2">
<para>
The <literal>manager</literal> field is an inner <literal>object</literal> field.
</para>
</callout>
<callout arearefs="CO171-3">
<para>
The <literal>manager.name</literal> field is an inner <literal>object</literal> field within the <literal>manager</literal> field.
</para>
</callout>
</calloutlist>
<simpara>You are not required to set the field <literal>type</literal> to <literal>object</literal> explicitly, as this is the default value.</simpara>
<section id="object-params">
<title>Parameters for <literal>object</literal> fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/object.asciidoc">Edit me</ulink></title>
<simpara>The following parameters are accepted by <literal>object</literal> fields:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<link linkend="dynamic"><literal>dynamic</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Whether or not new <literal>properties</literal> should be added dynamically
    to an existing object.  Accepts <literal>true</literal> (default), <literal>false</literal>
    and <literal>strict</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="enabled"><literal>enabled</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Whether the JSON value given for the object field should be
    parsed and indexed (<literal>true</literal>, default) or completely ignored (<literal>false</literal>).
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="include-in-all"><literal>include_in_all</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Sets the default <literal>include_in_all</literal> value for all the <literal>properties</literal> within
    the object. The object itself is not added to the <literal>_all</literal> field.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="properties"><literal>properties</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    The fields within the object, which can be of any
    <link linkend="mapping-types">datatype</link>, including <literal>object</literal>. New properties
    may be added to an existing object.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<important><simpara>If you need to index arrays of objects instead of single objects,
read <xref linkend="nested"/> first.</simpara></important>
</section>
</section>
<section id="string">
<title>String datatype<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/string.asciidoc">Edit me</ulink></title>
<simpara>The <literal>string</literal> field is unsupported for indexes created in 5.x in favor of the
<literal>text</literal> and <literal>keyword</literal> fields. Attempting to create a string field in an index
created in 5.x will cause Elasticsearch to attempt to upgrade the <literal>string</literal> into
the appropriate <literal>text</literal> or <literal>keyword</literal> field. It will return an HTTP <literal>Warning</literal>
header telling you that <literal>string</literal> is deprecated. This upgrade process isn&#8217;t
always perfect because there are some combinations of features that are
supported by <literal>string</literal> but not <literal>text</literal> or <literal>keyword</literal>. For that reason it is better
to use <literal>text</literal> or <literal>keyword</literal>.</simpara>
<simpara>Indexes imported from 2.x <emphasis role="strong">only</emphasis> support <literal>string</literal> and not <literal>text</literal> or <literal>keyword</literal>.
To ease the migration from 2.x Elasticsearch will downgrade <literal>text</literal> and <literal>keyword</literal>
mappings applied to indexes imported to 2.x into <literal>string</literal>. While long lived
indexes will eventually need to be recreated against 5.x before eventually
upgrading to 6.x, this downgrading smooths the process before you find time for
it.</simpara>
</section>
<section id="text">
<title>Text datatype<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/text.asciidoc">Edit me</ulink></title>
<simpara>A field to index full-text values, such as the body of an email or the
description of a product. These fields are <literal>analyzed</literal>, that is they are passed through an
<link linkend="analysis">analyzer</link> to convert the string into a list of individual terms
before being indexed. The analysis process allows Elasticsearch to search for
individual words <emphasis>within</emphasis>  each full text field.  Text fields are not
used for sorting and seldom used for aggregations (although the
<link linkend="search-aggregations-bucket-significantterms-aggregation">significant terms aggregation</link>
is a notable exception).</simpara>
<simpara>If you need to index structured content such as email addresses, hostnames, status
codes, or tags, it is likely that you should rather use a <link linkend="keyword"><literal>keyword</literal></link> field.</simpara>
<simpara>Below is an example of a mapping for a text field:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "full_name": {
          "type":  "text"
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Sometimes it is useful to have both a full text (<literal>text</literal>) and a keyword
(<literal>keyword</literal>) version of the same field: one for full text search and the
other for aggregations and sorting. This can be achieved with
<link linkend="multi-fields">multi-fields</link>.</simpara>
<section id="text-params">
<title>Parameters for text fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/text.asciidoc">Edit me</ulink></title>
<simpara>The following parameters are accepted by <literal>text</literal> fields:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<link linkend="analyzer"><literal>analyzer</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    The <link linkend="analysis">analyzer</link> which should be used for
    <link linkend="mapping-index"><literal>analyzed</literal></link> string fields, both at index-time and at
    search-time (unless overridden by the  <link linkend="search-analyzer"><literal>search_analyzer</literal></link>).
    Defaults to the default index analyzer, or the
    <link linkend="analysis-standard-analyzer"><literal>standard</literal> analyzer</link>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="mapping-boost"><literal>boost</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Mapping field-level query time boosting. Accepts a floating point number, defaults
    to <literal>1.0</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="global-ordinals"><literal>eager_global_ordinals</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Should global ordinals be loaded eagerly on refresh? Accepts <literal>true</literal> or <literal>false</literal>
    (default). Enabling this is a good idea on fields that are frequently used for
    (significant) terms aggregations.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="fielddata"><literal>fielddata</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Can the field use in-memory fielddata for sorting, aggregations,
    or scripting? Accepts <literal>true</literal> or <literal>false</literal> (default).
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="field-data-filtering"><literal>fielddata_frequency_filter</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Expert settings which allow to decide which values to load in memory when <literal>fielddata</literal>
    is enabled. By default all values are loaded.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="multi-fields"><literal>fields</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Multi-fields allow the same string value to be indexed in multiple ways for
    different purposes, such as one field for search and a multi-field for
    sorting and aggregations, or the same string value analyzed by different
    analyzers.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="include-in-all"><literal>include_in_all</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Whether or not the field value should be included in the
    <link linkend="mapping-all-field"><literal>_all</literal></link> field? Accepts <literal>true</literal> or <literal>false</literal>.  Defaults
    to <literal>false</literal> if <link linkend="mapping-index"><literal>index</literal></link> is set to <literal>no</literal>, or if a parent
    <link linkend="object"><literal>object</literal></link> field sets <literal>include_in_all</literal> to <literal>false</literal>.
    Otherwise defaults to <literal>true</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="mapping-index"><literal>index</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Should the field be searchable? Accepts <literal>true</literal> (default) or <literal>false</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="index-options"><literal>index_options</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    What information should be stored in the index, for search and highlighting purposes.
    Defaults to <literal>positions</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="norms"><literal>norms</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Whether field-length should be taken into account when scoring queries.
    Accepts <literal>true</literal> (default) or <literal>false</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="position-increment-gap"><literal>position_increment_gap</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    The number of fake term position which should be inserted between each
    element of an array of strings. Defaults to the <literal>position_increment_gap</literal>
    configured on the analyzer which defaults to <literal>100</literal>. <literal>100</literal> was chosen because it
    prevents phrase queries with reasonably large slops (less than 100) from
    matching terms across field values.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="mapping-store"><literal>store</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Whether the field value should be stored and retrievable separately from
    the <link linkend="mapping-source-field"><literal>_source</literal></link> field. Accepts <literal>true</literal> or <literal>false</literal>
    (default).
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="search-analyzer"><literal>search_analyzer</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    The <link linkend="analyzer"><literal>analyzer</literal></link> that should be used at search time on
    <link linkend="mapping-index"><literal>analyzed</literal></link> fields. Defaults to the <literal>analyzer</literal> setting.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="search-quote-analyzer"><literal>search_quote_analyzer</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    The <link linkend="analyzer"><literal>analyzer</literal></link> that should be used at search time when a
    phrase is encountered. Defaults to the <literal>search_analyzer</literal> setting.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="similarity"><literal>similarity</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Which scoring algorithm or <emphasis>similarity</emphasis> should be used. Defaults
    to <literal>classic</literal>, which uses TF/IDF.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="term-vector"><literal>term_vector</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Whether term vectors should be stored for an <link linkend="mapping-index"><literal>analyzed</literal></link>
    field. Defaults to <literal>no</literal>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<note><simpara>Indexes imported from 2.x do not support <literal>text</literal>. Instead they will
attempt to downgrade <literal>text</literal> into <literal>string</literal>. This allows you to merge modern
mappings with legacy mappings. Long lived indexes will have to be recreated
before upgrading to 6.x but mapping downgrade gives you the opportunity to do
the recreation on your own schedule.</simpara></note>
</section>
</section>
<section id="token-count">
<title>Token count datatype<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/token-count.asciidoc">Edit me</ulink></title>
<simpara>A field of type <literal>token_count</literal> is really an <link linkend="number"><literal>integer</literal></link> field which
accepts string values, analyzes them, then indexes the number of tokens in the
string.</simpara>
<simpara>For instance:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "name": { <co id="CO172-1"/>
          "type": "text",
          "fields": {
            "length": { <co id="CO172-2"/>
              "type":     "token_count",
              "analyzer": "standard"
            }
          }
        }
      }
    }
  }
}

PUT my_index/my_type/1
{ "name": "John Smith" }

PUT my_index/my_type/2
{ "name": "Rachel Alice Williams" }

GET my_index/_search
{
  "query": {
    "term": {
      "name.length": 3 <co id="CO172-3"/>
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO172-1">
<para>
The <literal>name</literal> field is an analyzed string field which uses the default <literal>standard</literal> analyzer.
</para>
</callout>
<callout arearefs="CO172-2">
<para>
The <literal>name.length</literal> field is a <literal>token_count</literal> <link linkend="multi-fields">multi-field</link> which will index the number of tokens in the <literal>name</literal> field.
</para>
</callout>
<callout arearefs="CO172-3">
<para>
This query matches only the document containing <literal>Rachel Alice Williams</literal>, as it contains three tokens.
</para>
</callout>
</calloutlist>
<note>
<simpara>Technically the <literal>token_count</literal> type sums position increments rather than
counting tokens. This means that even if the analyzer filters out stop
words they are included in the count.</simpara>
</note>
<section id="token-count-params">
<title>Parameters for <literal>token_count</literal> fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/token-count.asciidoc">Edit me</ulink></title>
<simpara>The following parameters are accepted by <literal>token_count</literal> fields:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<link linkend="analyzer"><literal>analyzer</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    The <link linkend="analysis">analyzer</link> which should be used to analyze the string
    value. Required. For best performance, use an analyzer without token
    filters.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="mapping-boost"><literal>boost</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Mapping field-level query time boosting. Accepts a floating point number, defaults
    to <literal>1.0</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="doc-values"><literal>doc_values</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Should the field be stored on disk in a column-stride fashion, so that it
    can later be used for sorting, aggregations, or scripting? Accepts <literal>true</literal>
    (default) or <literal>false</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="mapping-index"><literal>index</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Should the field be searchable? Accepts <literal>not_analyzed</literal> (default) and <literal>no</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="include-in-all"><literal>include_in_all</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Whether or not the field value should be included in the
    <link linkend="mapping-all-field"><literal>_all</literal></link> field? Accepts <literal>true</literal> or <literal>false</literal>.  Defaults
    to <literal>false</literal>. Note: if <literal>true</literal>, it is the string value that is added to <literal>_all</literal>,
    not the calculated token count.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="null-value"><literal>null_value</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Accepts a numeric value of the same <literal>type</literal> as the field which is
    substituted for any explicit <literal>null</literal> values.  Defaults to <literal>null</literal>, which
    means the field is treated as missing.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="mapping-store"><literal>store</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    Whether the field value should be stored and retrievable separately from
    the <link linkend="mapping-source-field"><literal>_source</literal></link> field. Accepts <literal>true</literal> or <literal>false</literal>
    (default).
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
</section>
<section id="percolator">
<title>Percolator type<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/percolator.asciidoc">Edit me</ulink></title>
<simpara>The <literal>percolator</literal> field type parses a json structure into a native query and
stores that query, so that the <link linkend="query-dsl-percolate-query">percolate query</link>
can use it to match provided documents.</simpara>
<simpara>Any field that contains a json object can be configured to be a percolator
field. The percolator field type has no settings. Just configuring the <literal>percolator</literal>
field type is sufficient to instruct Elasticsearch to treat a field as a
query.</simpara>
<simpara>If the following mapping configures the <literal>percolator</literal> field type for the
<literal>query</literal> field:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "properties": {
        "query": {
            "type": "percolator"
        }
    }
}</programlisting>
<simpara>Then the following json snippet can be indexed as a native query:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "query" : {
                "match" : {
                        "field" : "value"
                }
        }
}</programlisting>
<important>
<simpara>Fields referred to in a percolator query must <emphasis role="strong">already</emphasis> exist in the mapping
associated with the index used for percolation. In order to make sure these fields exist,
add or update a mapping via the <link linkend="indices-create-index">create index</link> or <link linkend="indices-put-mapping">put mapping</link> APIs.
Fields referred in a percolator query may exist in any type of the index containing the <literal>percolator</literal> field type.</simpara>
<simpara>Also an index can only contain up to one percolator field mapping. Multiple percolator fields will be rejected by the
put index and put mapping APIs.</simpara>
</important>
<bridgehead id="_dedicated_percolator_index" renderas="sect3">Dedicated Percolator Index<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/percolator.asciidoc">Edit me</ulink></bridgehead>
<simpara>Percolate queries can be added to any index. Instead of adding percolate queries to the index the data resides in,
these queries can also be added to a dedicated index. The advantage of this is that this dedicated percolator index
can have its own index settings (For example the number of primary and replica shards). If you choose to have a dedicated
percolate index, you need to make sure that the mappings from the normal index are also available on the percolate index.
Otherwise percolate queries can be parsed incorrectly.</simpara>
<bridgehead id="_forcing_unmapped_fields_to_be_handled_as_strings" renderas="sect3">Forcing Unmapped Fields to be Handled as Strings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/percolator.asciidoc">Edit me</ulink></bridgehead>
<simpara>In certain cases it is unknown what kind of percolator queries do get registered, and if no field mapping exists for fields
that are referred by percolator queries then adding a percolator query fails. This means the mapping needs to be updated
to have the field with the appropriate settings, and then the percolator query can be added. But sometimes it is sufficient
if all unmapped fields are handled as if these were default string fields. In those cases one can configure the
<literal>index.percolator.map_unmapped_fields_as_string</literal> setting to <literal>true</literal> (default to <literal>false</literal>) and then if a field referred in
a percolator query does not exist, it will be handled as a default string field so that adding the percolator query doesn&#8217;t
fail.</simpara>
<bridgehead id="_limitations_5" renderas="sect3">Limitations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/types/percolator.asciidoc">Edit me</ulink></bridgehead>
<simpara>Because the <literal>percolate</literal> query is processing one document at a time, it doesn&#8217;t support queries and filters that run
against child documents such as <literal>has_child</literal> and <literal>has_parent</literal>.</simpara>
<simpara>The percolator doesn&#8217;t accepts percolator queries containing <literal>range</literal> queries with ranges that are based on current
time (using <literal>now</literal>).</simpara>
<simpara>There are a number of queries that fetch data via a get call during query parsing. For example the <literal>terms</literal> query when
using terms lookup, <literal>template</literal> query when using indexed scripts and <literal>geo_shape</literal> when using pre-indexed shapes. When these
queries are indexed by the <literal>percolator</literal> field type then the get call is executed once. So each time the <literal>percolator</literal>
query evaluates these queries, the fetches terms, shapes etc. as the were upon index time will be used. Important to note
is that fetching of terms that these queries do, happens both each time the percolator query gets indexed on both primary
and replica shards, so the terms that are actually indexed can be different between shard copies, if the source index
changed while indexing.</simpara>
</section>
</chapter>
<chapter id="mapping-fields">
<title>Meta-Fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields.asciidoc">Edit me</ulink></title>
<simpara>Each document has metadata associated with it, such as the <literal>_index</literal>, mapping
<link linkend="mapping-type-field"><literal>_type</literal></link>, and <literal>_id</literal> meta-fields.  The behaviour of some of these meta-fields
can be customised when a mapping type is created.</simpara>
<bridgehead id="_identity_meta_fields" renderas="sect2">Identity meta-fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields.asciidoc">Edit me</ulink></bridgehead>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<link linkend="mapping-index-field"><literal>_index</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    The index to which the document belongs.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="mapping-uid-field"><literal>_uid</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    A composite field consisting of the <literal>_type</literal> and the <literal>_id</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="mapping-type-field"><literal>_type</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    The document&#8217;s <link linkend="mapping-type">mapping type</link>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<link linkend="mapping-id-field"><literal>_id</literal></link>
</simpara>
</entry>
<entry>
<simpara>
    The document&#8217;s ID.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="_document_source_meta_fields" renderas="sect2">Document source meta-fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
<link linkend="mapping-source-field"><literal>_source</literal></link>
</term>
<listitem>
<simpara>
    The original JSON representing the body of the document.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/mapper-size.html"><literal>_size</literal></ulink>
</term>
<listitem>
<simpara>
    The size of the <literal>_source</literal> field in bytes, provided by the
    <ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/mapper-size.html"><literal>mapper-size</literal> plugin</ulink>.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_indexing_meta_fields" renderas="sect2">Indexing meta-fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
<link linkend="mapping-all-field"><literal>_all</literal></link>
</term>
<listitem>
<simpara>
    A <emphasis>catch-all</emphasis>  field that indexes the values of all other fields.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="mapping-field-names-field"><literal>_field_names</literal></link>
</term>
<listitem>
<simpara>
    All fields in the document which contain non-null values.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_routing_meta_fields" renderas="sect2">Routing meta-fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
<link linkend="mapping-parent-field"><literal>_parent</literal></link>
</term>
<listitem>
<simpara>
    Used to create a parent-child relationship between two mapping types.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="mapping-routing-field"><literal>_routing</literal></link>
</term>
<listitem>
<simpara>
    A custom routing value which routes a document to a particular shard.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_other_meta_field" renderas="sect2">Other meta-field<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
<link linkend="mapping-meta-field"><literal>_meta</literal></link>
</term>
<listitem>
<simpara>
    Application specific metadata.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<section id="mapping-all-field">
<title><literal>_all</literal> field<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/all-field.asciidoc">Edit me</ulink></title>
<simpara>The <literal>_all</literal> field is a special <emphasis>catch-all</emphasis> field which concatenates the values
of all of the other fields into one big string, using space as a delimiter, which is then
<link linkend="analysis">analyzed</link> and indexed, but not stored.  This means that it can be
searched, but not retrieved.</simpara>
<simpara>The <literal>_all</literal> field allows you to search for values in documents without knowing
which field contains the value.  This makes it a useful option when getting
started with a new dataset. For instance:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index/user/1 <co id="CO173-1"/>
{
  "first_name":    "John",
  "last_name":     "Smith",
  "date_of_birth": "1970-10-24"
}

GET my_index/_search
{
  "query": {
    "match": {
      "_all": "john smith 1970"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO173-1">
<para>
The <literal>_all</literal> field will contain the terms: [ <literal>"john"</literal>, <literal>"smith"</literal>, <literal>"1970"</literal>, <literal>"10"</literal>, <literal>"24"</literal> ]
</para>
</callout>
</calloutlist>
<note>
<title>All values treated as strings</title>
<simpara>The <literal>date_of_birth</literal> field in the above example is recognised as a <literal>date</literal> field
and so will index a single term representing <literal>1970-10-24 00:00:00 UTC</literal>. The
<literal>_all</literal> field, however, treats all values as strings, so the date value is
indexed as the three string terms: <literal>"1970"</literal>, <literal>"24"</literal>, <literal>"10"</literal>.</simpara>
<simpara>It is important to note that the <literal>_all</literal> field combines the original values
from each field as a string. It does not combine the <emphasis>terms</emphasis> from each field.</simpara>
</note>
<simpara>The <literal>_all</literal> field is just a <link linkend="text"><literal>text</literal></link> field, and accepts the same
parameters that  other string fields accept, including <literal>analyzer</literal>,
<literal>term_vectors</literal>, <literal>index_options</literal>, and <literal>store</literal>.</simpara>
<simpara>The <literal>_all</literal> field can be useful, especially when exploring new data using
simple filtering.  However, by concatenating field values into one big string,
the <literal>_all</literal> field loses the distinction between short fields (more relevant)
and long fields (less relevant). For use cases where search relevance is
important, it is better to query individual fields specifically.</simpara>
<simpara>The <literal>_all</literal> field is not free: it requires extra CPU cycles and uses more disk
space. If not needed, it can be completely <link linkend="disabling-all-field">disabled</link> or
customised on a <link linkend="include-in-all">per-field basis</link>.</simpara>
<section id="querying-all-field">
<title>Using the <literal>_all</literal> field in queries<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/all-field.asciidoc">Edit me</ulink></title>
<simpara>The <link linkend="query-dsl-query-string-query"><literal>query_string</literal></link> and
<link linkend="query-dsl-simple-query-string-query"><literal>simple_query_string</literal></link> queries query
the <literal>_all</literal> field by default, unless another field is specified:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _search
{
  "query": {
    "query_string": {
      "query": "john smith 1970"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The same goes for the <literal>?q=</literal> parameter in <link linkend="search-uri-request">URI search requests</link> (which is rewritten to a <literal>query_string</literal> query internally):</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _search?q=john+smith+1970</programlisting>
<simpara>Other queries, such as the <link linkend="query-dsl-match-query"><literal>match</literal></link> and
<link linkend="query-dsl-term-query"><literal>term</literal></link> queries require you to specify
the <literal>_all</literal> field explicitly, as per the
<link linkend="mapping-all-field">first example</link>.</simpara>
</section>
<section id="disabling-all-field">
<title>Disabling the <literal>_all</literal> field<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/all-field.asciidoc">Edit me</ulink></title>
<simpara>The <literal>_all</literal> field can be completely disabled per-type by setting <literal>enabled</literal> to
<literal>false</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "type_1": { <co id="CO174-1"/>
      "properties": {...}
    },
    "type_2": { <co id="CO174-2"/>
      "_all": {
        "enabled": false
      },
      "properties": {...}
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/\.\.\.//]</remark>
<calloutlist>
<callout arearefs="CO174-1">
<para>
The <literal>_all</literal> field in <literal>type_1</literal> is enabled.
</para>
</callout>
<callout arearefs="CO174-2">
<para>
The <literal>_all</literal> field in <literal>type_2</literal> is completely disabled.
</para>
</callout>
</calloutlist>
<simpara>If the <literal>_all</literal> field is disabled, then URI search requests and the
<literal>query_string</literal> and <literal>simple_query_string</literal> queries will not be able to use it
for queries (see <xref linkend="querying-all-field"/>).  You can configure them to use a
different field with the <literal>index.query.default_field</literal> setting:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "_all": {
        "enabled": false <co id="CO175-1"/>
      },
      "properties": {
        "content": {
          "type": "text"
        }
      }
    }
  },
  "settings": {
    "index.query.default_field": "content" <co id="CO175-2"/>
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO175-1">
<para>
The <literal>_all</literal> field is disabled for the <literal>my_type</literal> type.
</para>
</callout>
<callout arearefs="CO175-2">
<para>
The <literal>query_string</literal> query will default to querying the <literal>content</literal> field in this index.
</para>
</callout>
</calloutlist>
</section>
<section id="excluding-from-all">
<title>Excluding fields from <literal>_all</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/all-field.asciidoc">Edit me</ulink></title>
<simpara>Individual fields can be included or excluded from the <literal>_all</literal> field with the
<link linkend="include-in-all"><literal>include_in_all</literal></link> setting.</simpara>
</section>
<section id="all-field-and-boosting">
<title>Index boosting and the <literal>_all</literal> field<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/all-field.asciidoc">Edit me</ulink></title>
<simpara>Individual fields can be <emphasis>boosted</emphasis> at index time, with the <link linkend="mapping-boost"><literal>boost</literal></link>
parameter. The <literal>_all</literal> field takes these boosts into account:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT myindex
{
  "mappings": {
    "mytype": {
      "properties": {
        "title": { <co id="CO176-1"/>
          "type": "text",
          "boost": 2
        },
        "content": { <co id="CO176-2"/>
          "type": "text"
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO176-1 CO176-2">
<para>
When querying the <literal>_all</literal> field, words that originated in the
    <literal>title</literal> field are twice as relevant as words that originated in
    the <literal>content</literal> field.
</para>
</callout>
</calloutlist>
<warning><simpara>Using index-time boosting with the <literal>_all</literal> field has a significant
impact on query performance. Usually the better solution is to query fields
individually, with optional query time boosting.</simpara></warning>
</section>
<section id="custom-all-fields">
<title>Custom <literal>_all</literal> fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/all-field.asciidoc">Edit me</ulink></title>
<simpara>While there is only a single <literal>_all</literal> field per index, the <link linkend="copy-to"><literal>copy_to</literal></link>
parameter allows the creation of multiple <emphasis>custom <literal>_all</literal> fields</emphasis>. For
instance, <literal>first_name</literal> and <literal>last_name</literal> fields can be combined together into
the <literal>full_name</literal> field:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT myindex
{
  "mappings": {
    "mytype": {
      "properties": {
        "first_name": {
          "type":    "text",
          "copy_to": "full_name" <co id="CO177-1"/>
        },
        "last_name": {
          "type":    "text",
          "copy_to": "full_name" <co id="CO177-2"/>
        },
        "full_name": {
          "type":    "text"
        }
      }
    }
  }
}

PUT myindex/mytype/1
{
  "first_name": "John",
  "last_name": "Smith"
}

GET myindex/_search
{
  "query": {
    "match": {
      "full_name": "John Smith"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO177-1 CO177-2">
<para>
The <literal>first_name</literal> and <literal>last_name</literal> values are copied to the <literal>full_name</literal> field.
</para>
</callout>
</calloutlist>
</section>
<section id="highlighting-all-field">
<title>Highlighting and the <literal>_all</literal> field<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/all-field.asciidoc">Edit me</ulink></title>
<simpara>A field can only be used for <link linkend="search-request-highlighting">highlighting</link>  if
the original string value is available, either from the
<link linkend="mapping-source-field"><literal>_source</literal></link>  field or as a stored field.</simpara>
<simpara>The <literal>_all</literal> field is not present in the <literal>_source</literal> field and it is not stored by
default, and so cannot be highlighted. There are two options. Either
<link linkend="all-field-store">store the <literal>_all</literal> field</link> or highlight the
<link linkend="all-highlight-fields">original fields</link>.</simpara>
<section id="all-field-store">
<title>Store the <literal>_all</literal> field<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/all-field.asciidoc">Edit me</ulink></title>
<simpara>If <literal>store</literal> is set to <literal>true</literal>, then the original field value is retrievable and
can be highlighted:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT myindex
{
  "mappings": {
    "mytype": {
      "_all": {
        "store": true
      }
    }
  }
}

PUT myindex/mytype/1
{
  "first_name": "John",
  "last_name": "Smith"
}

GET _search
{
  "query": {
    "match": {
      "_all": "John Smith"
    }
  },
  "highlight": {
    "fields": {
      "_all": {}
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Of course, storing the <literal>_all</literal> field will use significantly more disk space
and, because it is a combination of other fields, it may result in odd
highlighting results.</simpara>
<simpara>The <literal>_all</literal> field also accepts the <literal>term_vector</literal> and <literal>index_options</literal>
parameters, allowing the use of the fast vector highlighter and the postings
highlighter.</simpara>
</section>
<section id="all-highlight-fields">
<title>Highlight original fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/all-field.asciidoc">Edit me</ulink></title>
<simpara>You can query the <literal>_all</literal> field, but use the original fields for highlighting as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT myindex
{
  "mappings": {
    "mytype": {
      "_all": {}
    }
  }
}

PUT myindex/mytype/1
{
  "first_name": "John",
  "last_name": "Smith"
}

GET _search
{
  "query": {
    "match": {
      "_all": "John Smith" <co id="CO178-1"/>
    }
  },
  "highlight": {
    "fields": {
      "*_name": { <co id="CO178-2"/>
        "require_field_match": false  <co id="CO178-3"/>
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO178-1">
<para>
The query inspects the <literal>_all</literal> field to find matching documents.
</para>
</callout>
<callout arearefs="CO178-2">
<para>
Highlighting is performed on the two name fields, which are available from the <literal>_source</literal>.
</para>
</callout>
<callout arearefs="CO178-3">
<para>
The query wasn&#8217;t run against the name fields, so set <literal>require_field_match</literal> to <literal>false</literal>.
</para>
</callout>
</calloutlist>
</section>
</section>
</section>
<section id="mapping-field-names-field">
<title><literal>_field_names</literal> field<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/field-names-field.asciidoc">Edit me</ulink></title>
<simpara>The <literal>_field_names</literal> field indexes the names of every field in a document that
contains any value other than <literal>null</literal>.  This field is used by the
<link linkend="query-dsl-exists-query"><literal>exists</literal></link> query to find documents that
either have or don&#8217;t have any non-<literal>null</literal> value for a particular field.</simpara>
<simpara>The value of the <literal>_field_name</literal> field is accessible in queries:</simpara>
<programlisting language="js" linenumbering="unnumbered"># Example documents
PUT my_index/my_type/1
{
  "title": "This is a document"
}

PUT my_index/my_type/2?refresh=true
{
  "title": "This is another document",
  "body": "This document has a body"
}

GET my_index/_search
{
  "query": {
    "terms": {
      "_field_names": [ "title" ] <co id="CO179-1"/>
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO179-1">
<para>
Querying on the <literal>_field_names</literal> field (also see the <link linkend="query-dsl-exists-query"><literal>exists</literal></link> query)
</para>
</callout>
</calloutlist>
</section>
<section id="mapping-id-field">
<title><literal>_id</literal> field<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/id-field.asciidoc">Edit me</ulink></title>
<simpara>Each document indexed is associated with a <link linkend="mapping-type-field"><literal>_type</literal></link> (see
<xref linkend="mapping-type"/>) and an <link linkend="mapping-id-field"><literal>_id</literal></link>.  The <literal>_id</literal> field is not
indexed as its value can be derived automatically from the
<link linkend="mapping-uid-field"><literal>_uid</literal></link> field.</simpara>
<simpara>The value of the <literal>_id</literal> field is accessible in certain queries (<literal>term</literal>,
<literal>terms</literal>, <literal>match</literal>, <literal>query_string</literal>, <literal>simple_query_string</literal>), but
<emphasis>not</emphasis> in aggregations, scripts or when sorting, where the <link linkend="mapping-uid-field"><literal>_uid</literal></link>
field should be used instead:</simpara>
<programlisting language="js" linenumbering="unnumbered"># Example documents
PUT my_index/my_type/1
{
  "text": "Document with ID 1"
}

PUT my_index/my_type/2&amp;refresh=true
{
  "text": "Document with ID 2"
}

GET my_index/_search
{
  "query": {
    "terms": {
      "_id": [ "1", "2" ] <co id="CO180-1"/>
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO180-1">
<para>
Querying on the <literal>_id</literal> field (also see the <link linkend="query-dsl-ids-query"><literal>ids</literal> query</link>)
</para>
</callout>
</calloutlist>
</section>
<section id="mapping-index-field">
<title><literal>_index</literal> field<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/index-field.asciidoc">Edit me</ulink></title>
<simpara>When performing queries across multiple indexes, it is sometimes desirable to
add query clauses that are associated with documents of only certain indexes.
The <literal>_index</literal> field allows matching on the index a document was indexed into.
Its value is accessible in <literal>term</literal>, or <literal>terms</literal> queries, aggregations,
scripts, and when sorting:</simpara>
<note><simpara>The <literal>_index</literal> is exposed as a virtual field&#8201;&#8212;&#8201;it is not added to the
Lucene index as a real field.  This means that you can use the <literal>_index</literal> field
in a <literal>term</literal> or <literal>terms</literal> query (or any query that is rewritten to a <literal>term</literal>
query, such as the <literal>match</literal>,  <literal>query_string</literal> or <literal>simple_query_string</literal> query),
but it does not support <literal>prefix</literal>, <literal>wildcard</literal>, <literal>regexp</literal>, or <literal>fuzzy</literal> queries.</simpara></note>
<programlisting language="js" linenumbering="unnumbered"># Example documents
PUT index_1/my_type/1
{
  "text": "Document in index 1"
}

PUT index_2/my_type/2?refresh=true
{
  "text": "Document in index 2"
}

GET index_1,index_2/_search
{
  "query": {
    "terms": {
      "_index": ["index_1", "index_2"] <co id="CO181-1"/>
    }
  },
  "aggs": {
    "indices": {
      "terms": {
        "field": "_index", <co id="CO181-2"/>
        "size": 10
      }
    }
  },
  "sort": [
    {
      "_index": { <co id="CO181-3"/>
        "order": "asc"
      }
    }
  ],
  "script_fields": {
    "index_name": {
      "script": {
        "lang": "painless",
        "inline": "doc['_index']" <co id="CO181-4"/>
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO181-1">
<para>
Querying on the <literal>_index</literal> field
</para>
</callout>
<callout arearefs="CO181-2">
<para>
Aggregating on the <literal>_index</literal> field
</para>
</callout>
<callout arearefs="CO181-3">
<para>
Sorting on the <literal>_index</literal> field
</para>
</callout>
<callout arearefs="CO181-4">
<para>
Accessing the <literal>_index</literal> field in scripts
</para>
</callout>
</calloutlist>
</section>
<section id="mapping-meta-field">
<title><literal>_meta</literal> field<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/meta-field.asciidoc">Edit me</ulink></title>
<simpara>Each mapping type can have custom meta data associated with it. These are not
used at all by Elasticsearch, but can be used to store application-specific
metadata, such as the class that a document belongs to:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "user": {
      "_meta": { <co id="CO182-1"/>
        "class": "MyApp::User",
        "version": {
          "min": "1.0",
          "max": "1.3"
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO182-1">
<para>
This <literal>_meta</literal> info can be retrieved with the
    <link linkend="indices-get-mapping">GET mapping</link> API.
</para>
</callout>
</calloutlist>
<simpara>The <literal>_meta</literal> field can be updated on an existing type using the
<link linkend="indices-put-mapping">PUT mapping</link> API.</simpara>
</section>
<section id="mapping-parent-field">
<title><literal>_parent</literal> field<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/parent-field.asciidoc">Edit me</ulink></title>
<simpara>A parent-child relationship can be established between documents in the same
index by making one mapping type the parent of another:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_parent": {},
    "my_child": {
      "_parent": {
        "type": "my_parent" <co id="CO183-1"/>
      }
    }
  }
}

PUT my_index/my_parent/1 <co id="CO183-2"/>
{
  "text": "This is a parent document"
}

PUT my_index/my_child/2?parent=1 <co id="CO183-3"/>
{
  "text": "This is a child document"
}

PUT my_index/my_child/3?parent=1&amp;refresh=true <co id="CO183-4"/>
{
  "text": "This is another child document"
}

GET my_index/my_parent/_search
{
  "query": {
    "has_child": { <co id="CO183-5"/>
      "type": "my_child",
      "query": {
        "match": {
          "text": "child document"
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO183-1">
<para>
The <literal>my_parent</literal> type is parent to the <literal>my_child</literal> type.
</para>
</callout>
<callout arearefs="CO183-2">
<para>
Index a parent document.
</para>
</callout>
<callout arearefs="CO183-3 CO183-4">
<para>
Index two child documents, specifying the parent document&#8217;s ID.
</para>
</callout>
<callout arearefs="CO183-5">
<para>
Find all parent documents that have children which match the query.
</para>
</callout>
</calloutlist>
<simpara>See the <link linkend="query-dsl-has-child-query"><literal>has_child</literal></link> and
<link linkend="query-dsl-has-parent-query"><literal>has_parent</literal></link> queries,
the <link linkend="search-aggregations-bucket-children-aggregation"><literal>children</literal></link> aggregation,
and <link linkend="parent-child-inner-hits">inner hits</link> for more information.</simpara>
<simpara>The value of the <literal>_parent</literal> field is accessible in queries, aggregations,
and scripts:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET my_index/_search
{
  "query": {
    "terms": {
      "_parent": [ "1" ] <co id="CO184-1"/>
    }
  },
  "aggs": {
    "parents": {
      "terms": {
        "field": "_parent", <co id="CO184-2"/>
        "size": 10
      }
    }
  },
  "script_fields": {
    "parent": {
      "script": {
         "lang": "painless",
         "inline": "doc['_parent']" <co id="CO184-3"/>
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<calloutlist>
<callout arearefs="CO184-1">
<para>
Querying on the <literal>_parent</literal> field (also see the <link linkend="query-dsl-has-parent-query"><literal>has_parent</literal> query</link> and the <link linkend="query-dsl-has-child-query"><literal>has_child</literal> query</link>)
</para>
</callout>
<callout arearefs="CO184-2">
<para>
Aggregating on the <literal>_parent</literal> field (also see the <link linkend="search-aggregations-bucket-children-aggregation"><literal>children</literal></link> aggregation)
</para>
</callout>
<callout arearefs="CO184-3">
<para>
Accessing the <literal>_parent</literal> field in scripts
</para>
</callout>
</calloutlist>
<section id="_parent_child_restrictions">
<title>Parent-child restrictions<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/parent-field.asciidoc">Edit me</ulink></title>
<itemizedlist>
<listitem>
<simpara>
The parent and child types must be different&#8201;&#8212;&#8201;parent-child relationships
  cannot be established between documents of the same type.
</simpara>
</listitem>
<listitem>
<simpara>
The <literal>_parent.type</literal> setting can only point to a type that doesn&#8217;t exist yet.
  This means that a type cannot become a parent type after it has been
  created.
</simpara>
</listitem>
<listitem>
<simpara>
Parent and child documents must be indexed on the same shard.  The <literal>parent</literal>
  ID is used as the <link linkend="mapping-routing-field">routing</link> value for the child,
  to ensure that the child is indexed on the same shard as the parent.
  This means that the same <literal>parent</literal> value needs to be provided when
  <link linkend="docs-get">getting</link>, <link linkend="docs-delete">deleting</link>, or <link linkend="docs-update">updating</link>
  a child document.
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="_global_ordinals">
<title>Global ordinals<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/parent-field.asciidoc">Edit me</ulink></title>
<simpara>Parent-child uses <link linkend="global-ordinals">global ordinals</link> to speed up joins.
Global ordinals need to be rebuilt after any change to a shard. The more
parent id values are stored in a shard, the longer it takes to rebuild the
global ordinals for the <literal>_parent</literal> field.</simpara>
<simpara>Global ordinals, by default, are built lazily: the first parent-child query or
aggregation after a refresh will trigger building of global ordinals. This can
introduce a significant latency spike for your users. You can use
<link linkend="global-ordinals">eager_global_ordinals</link> to shift the cost of building global
ordinals from query time to refresh time, by mapping the <literal>_parent</literal> field as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_parent": {},
    "my_child": {
      "_parent": {
        "type": "my_parent",
        "eager_global_ordinals": true
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The amount of heap used by global ordinals can be checked as follows:</simpara>
<programlisting language="sh" linenumbering="unnumbered"># Per-index
GET _stats/fielddata?human&amp;fields=_parent

# Per-node per-index
GET _nodes/stats/indices/fielddata?human&amp;fields=_parent</programlisting>
<remark> CONSOLE</remark>
</section>
</section>
<section id="mapping-routing-field">
<title><literal>_routing</literal> field<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/routing-field.asciidoc">Edit me</ulink></title>
<simpara>A document is routed to a particular shard in an index using the following
formula:</simpara>
<literallayout class="monospaced">shard_num = hash(_routing) % num_primary_shards</literallayout>
<simpara>The default value used for <literal>_routing</literal> is the document&#8217;s <link linkend="mapping-id-field"><literal>_id</literal></link>
or the document&#8217;s <link linkend="mapping-parent-field"><literal>_parent</literal></link> ID, if present.</simpara>
<simpara>Custom routing patterns can be implemented by specifying a custom <literal>routing</literal>
value per document.  For instance:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index/my_type/1?routing=user1&amp;refresh=true <co id="CO185-1"/>
{
  "title": "This is a document"
}

GET my_index/my_type/1?routing=user1 <co id="CO185-2"/></programlisting>
<remark> CONSOLE</remark>
<remark> TESTSETUP</remark>
<calloutlist>
<callout arearefs="CO185-1">
<para>
This document uses <literal>user1</literal> as its routing value, instead of its ID.
</para>
</callout>
<callout arearefs="CO185-2">
<para>
The same <literal>routing</literal> value needs to be provided when
    <link linkend="docs-get">getting</link>, <link linkend="docs-delete">deleting</link>, or <link linkend="docs-update">updating</link>
    the document.
</para>
</callout>
</calloutlist>
<simpara>The value of the <literal>_routing</literal> field is accessible in queries:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET my_index/_search
{
  "query": {
    "terms": {
      "_routing": [ "user1" ] <co id="CO186-1"/>
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO186-1">
<para>
Querying on the <literal>_routing</literal> field (also see the <link linkend="query-dsl-ids-query"><literal>ids</literal> query</link>)
</para>
</callout>
</calloutlist>
<section id="_searching_with_custom_routing">
<title>Searching with custom routing<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/routing-field.asciidoc">Edit me</ulink></title>
<simpara>Custom routing can reduce the impact of searches.  Instead of having to fan
out a search request to all the shards in an index, the request can be sent to
just the shard that matches the specific routing value (or values):</simpara>
<programlisting language="js" linenumbering="unnumbered">GET my_index/_search?routing=user1,user2 <co id="CO187-1"/>
{
  "query": {
    "match": {
      "title": "document"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO187-1">
<para>
This search request will only be executed on the shards associated with the <literal>user1</literal> and <literal>user2</literal> routing values.
</para>
</callout>
</calloutlist>
</section>
<section id="_making_a_routing_value_required">
<title>Making a routing value required<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/routing-field.asciidoc">Edit me</ulink></title>
<simpara>When using custom routing, it is important to provide the routing value
whenever <link linkend="docs-index_">indexing</link>, <link linkend="docs-get">getting</link>,
<link linkend="docs-delete">deleting</link>, or <link linkend="docs-update">updating</link> a document.</simpara>
<simpara>Forgetting the routing value can lead to a document being indexed on more than
one shard.  As a safeguard, the <literal>_routing</literal> field can be configured to make a
custom <literal>routing</literal> value required for all CRUD operations:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index2
{
  "mappings": {
    "my_type": {
      "_routing": {
        "required": true <co id="CO188-1"/>
      }
    }
  }
}

PUT my_index2/my_type/1 <co id="CO188-2"/>
{
  "text": "No routing value provided"
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[catch:request]</remark>
<calloutlist>
<callout arearefs="CO188-1">
<para>
Routing is required for <literal>my_type</literal> documents.
</para>
</callout>
<callout arearefs="CO188-2">
<para>
This index request throws a <literal>routing_missing_exception</literal>.
</para>
</callout>
</calloutlist>
</section>
<section id="_unique_ids_with_custom_routing">
<title>Unique IDs with custom routing<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/routing-field.asciidoc">Edit me</ulink></title>
<simpara>When indexing documents specifying a custom <literal>_routing</literal>, the uniqueness of the
<literal>_id</literal> is not guaranteed across all of the shards in the index. In fact,
documents with the same <literal>_id</literal> might end up on different shards if indexed with
different <literal>_routing</literal> values.</simpara>
<simpara>It is up to the user to ensure that IDs are unique across the index.</simpara>
</section>
</section>
<section id="mapping-source-field">
<title><literal>_source</literal> field<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/source-field.asciidoc">Edit me</ulink></title>
<simpara>The <literal>_source</literal> field contains the original JSON document body that was passed
at index time.  The <literal>_source</literal> field itself is not indexed (and thus is not
searchable), but it is stored so that it can be returned when executing
<emphasis>fetch</emphasis> requests, like <link linkend="docs-get">get</link> or <link linkend="search-search">search</link>.</simpara>
<section id="_disabling_the_literal__source_literal_field">
<title>Disabling the <literal>_source</literal> field<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/source-field.asciidoc">Edit me</ulink></title>
<simpara>Though very handy to have around, the source field does incur storage overhead
within the index. For this reason, it can be disabled as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT tweets
{
  "mappings": {
    "tweet": {
      "_source": {
        "enabled": false
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<warning>
<title>Think before disabling the <literal>_source</literal> field</title>
<simpara>Users often disable the <literal>_source</literal> field without thinking about the
consequences, and then live to regret it.  If the <literal>_source</literal> field isn&#8217;t
available then a number of features are not supported:</simpara>
<itemizedlist>
<listitem>
<simpara>
The <link linkend="docs-update"><literal>update</literal></link>, <link linkend="docs-update-by-query"><literal>update_by_query</literal></link>,
and <link linkend="docs-reindex"><literal>reindex</literal></link> APIs.
</simpara>
</listitem>
<listitem>
<simpara>
On the fly <link linkend="search-request-highlighting">highlighting</link>.
</simpara>
</listitem>
<listitem>
<simpara>
The ability to reindex from one Elasticsearch index to another, either
  to change mappings or analysis, or to upgrade an index to a new major
  version.
</simpara>
</listitem>
<listitem>
<simpara>
The ability to debug queries or aggregations by viewing the original
  document used at index time.
</simpara>
</listitem>
<listitem>
<simpara>
Potentially in the future, the ability to repair index corruption
  automatically.
</simpara>
</listitem>
</itemizedlist>
</warning>
<tip><simpara>If disk space is a concern, rather increase the
<link linkend="index-codec">compression level</link> instead of disabling the <literal>_source</literal>.</simpara></tip>
<sidebar>
<title>The metrics use case</title>
<simpara>The <emphasis>metrics</emphasis> use case is distinct from other time-based or logging use cases
in that there are many small documents which consist only of numbers, dates,
or keywords.  There are no updates, no highlighting requests, and the data
ages quickly so there is no need to reindex.  Search requests typically use
simple queries to filter the dataset by date or tags, and the results are
returned as aggregations.</simpara>
<simpara>In this case, disabling the <literal>_source</literal> field will save space and reduce I/O.
It is also advisable to disable the <link linkend="mapping-all-field"><literal>_all</literal> field</link> in the
metrics case.</simpara>
</sidebar>
</section>
<section id="include-exclude">
<title>Including / Excluding fields from <literal>_source</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/source-field.asciidoc">Edit me</ulink></title>
<simpara>An expert-only feature is the ability to prune the contents of the <literal>_source</literal>
field after the document has been indexed, but before the <literal>_source</literal> field is
stored.</simpara>
<warning><simpara>Removing fields from the <literal>_source</literal> has similar downsides to disabling
<literal>_source</literal>, especially the fact that you cannot reindex documents from one
Elasticsearch index to another. Consider using
<link linkend="search-request-source-filtering">source filtering</link> instead.</simpara></warning>
<simpara>The <literal>includes</literal>/<literal>excludes</literal> parameters (which also accept wildcards) can be used
as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT logs
{
  "mappings": {
    "event": {
      "_source": {
        "includes": [
          "*.count",
          "meta.*"
        ],
        "excludes": [
          "meta.description",
          "meta.other.*"
        ]
      }
    }
  }
}

PUT logs/event/1
{
  "requests": {
    "count": 10,
    "foo": "bar" <co id="CO189-1"/>
  },
  "meta": {
    "name": "Some metric",
    "description": "Some metric description", <co id="CO189-2"/>
    "other": {
      "foo": "one", <co id="CO189-3"/>
      "baz": "two" <co id="CO189-4"/>
    }
  }
}

GET logs/event/_search
{
  "query": {
    "match": {
      "meta.other.foo": "one" <co id="CO189-5"/>
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO189-1 CO189-2 CO189-3 CO189-4">
<para>
These fields will be removed from the stored <literal>_source</literal> field.
</para>
</callout>
<callout arearefs="CO189-5">
<para>
We can still search on this field, even though it is not in the stored <literal>_source</literal>.
</para>
</callout>
</calloutlist>
</section>
</section>
<section id="mapping-type-field">
<title><literal>_type</literal> field<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/type-field.asciidoc">Edit me</ulink></title>
<simpara>Each document indexed is associated with a <link linkend="mapping-type-field"><literal>_type</literal></link> (see
<xref linkend="mapping-type"/>) and an <link linkend="mapping-id-field"><literal>_id</literal></link>.  The <literal>_type</literal> field is
indexed in order to make searching by type name fast.</simpara>
<simpara>The value of the <literal>_type</literal> field is accessible in queries, aggregations,
scripts, and when sorting:</simpara>
<programlisting language="js" linenumbering="unnumbered"># Example documents
PUT my_index/type_1/1
{
  "text": "Document with type 1"
}

PUT my_index/type_2/2?refresh=true
{
  "text": "Document with type 2"
}

GET my_index/type_*/_search
{
  "query": {
    "terms": {
      "_type": [ "type_1", "type_2" ] <co id="CO190-1"/>
    }
  },
  "aggs": {
    "types": {
      "terms": {
        "field": "_type", <co id="CO190-2"/>
        "size": 10
      }
    }
  },
  "sort": [
    {
      "_type": { <co id="CO190-3"/>
        "order": "desc"
      }
    }
  ],
  "script_fields": {
    "type": {
      "script": {
        "lang": "painless",
        "inline": "doc['_type']" <co id="CO190-4"/>
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO190-1">
<para>
Querying on the <literal>_type</literal> field
</para>
</callout>
<callout arearefs="CO190-2">
<para>
Aggregating on the <literal>_type</literal> field
</para>
</callout>
<callout arearefs="CO190-3">
<para>
Sorting on the <literal>_type</literal> field
</para>
</callout>
<callout arearefs="CO190-4">
<para>
Accessing the <literal>_type</literal> field in scripts
</para>
</callout>
</calloutlist>
</section>
<section id="mapping-uid-field">
<title><literal>_uid</literal> field<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/fields/uid-field.asciidoc">Edit me</ulink></title>
<simpara>Each document indexed is associated with a <link linkend="mapping-type-field"><literal>_type</literal></link> (see
<xref linkend="mapping-type"/>) and an <link linkend="mapping-id-field"><literal>_id</literal></link>.  These values are
combined as <literal>{type}#{id}</literal> and indexed as the <literal>_uid</literal> field.</simpara>
<simpara>The value of the <literal>_uid</literal> field is accessible in queries, aggregations, scripts,
and when sorting:</simpara>
<programlisting language="js" linenumbering="unnumbered"># Example documents
PUT my_index/my_type/1
{
  "text": "Document with ID 1"
}

PUT my_index/my_type/2?refresh=true
{
  "text": "Document with ID 2"
}

GET my_index/_search
{
  "query": {
    "terms": {
      "_uid": [ "my_type#1", "my_type#2" ] <co id="CO191-1"/>
    }
  },
  "aggs": {
    "UIDs": {
      "terms": {
        "field": "_uid", <co id="CO191-2"/>
        "size": 10
      }
    }
  },
  "sort": [
    {
      "_uid": { <co id="CO191-3"/>
        "order": "desc"
      }
    }
  ],
  "script_fields": {
    "UID": {
      "script": {
         "lang": "painless",
         "inline": "doc['_uid']" <co id="CO191-4"/>
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO191-1">
<para>
Querying on the <literal>_uid</literal> field (also see the <link linkend="query-dsl-ids-query"><literal>ids</literal> query</link>)
</para>
</callout>
<callout arearefs="CO191-2">
<para>
Aggregating on the <literal>_uid</literal> field
</para>
</callout>
<callout arearefs="CO191-3">
<para>
Sorting on the <literal>_uid</literal> field
</para>
</callout>
<callout arearefs="CO191-4">
<para>
Accessing the <literal>_uid</literal> field in scripts
</para>
</callout>
</calloutlist>
</section>
</chapter>
<chapter id="mapping-params">
<title>Mapping parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params.asciidoc">Edit me</ulink></title>
<simpara>The following pages provide detailed explanations of the various mapping
parameters that are used by <link linkend="mapping-types">field mappings</link>:</simpara>
<simpara>The following mapping parameters are common to some or all field datatypes:</simpara>
<itemizedlist>
<listitem>
<simpara>
<link linkend="analyzer"><literal>analyzer</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="mapping-boost"><literal>boost</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="coerce"><literal>coerce</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="copy-to"><literal>copy_to</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="doc-values"><literal>doc_values</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="dynamic"><literal>dynamic</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="enabled"><literal>enabled</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="fielddata"><literal>fielddata</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="mapping-date-format"><literal>format</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="ignore-above"><literal>ignore_above</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="ignore-malformed"><literal>ignore_malformed</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="include-in-all"><literal>include_in_all</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="index-options"><literal>index_options</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="mapping-index"><literal>index</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="multi-fields"><literal>fields</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="norms"><literal>norms</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="null-value"><literal>null_value</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="position-increment-gap"><literal>position_increment_gap</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="properties"><literal>properties</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="search-analyzer"><literal>search_analyzer</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="similarity"><literal>similarity</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="mapping-store"><literal>store</literal></link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="term-vector"><literal>term_vector</literal></link>
</simpara>
</listitem>
</itemizedlist>
<section id="analyzer">
<title><literal>analyzer</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/analyzer.asciidoc">Edit me</ulink></title>
<simpara>The values of <link linkend="mapping-index"><literal>analyzed</literal></link> string fields are passed through an
<link linkend="analysis">analyzer</link> to convert the string into a stream of <emphasis>tokens</emphasis> or
<emphasis>terms</emphasis>.  For instance, the string <literal>"The quick Brown Foxes."</literal> may, depending
on which analyzer is used,  be analyzed to the tokens: <literal>quick</literal>, <literal>brown</literal>,
<literal>fox</literal>.  These are the actual terms that are indexed for the field, which makes
it possible to search efficiently for individual words <emphasis>within</emphasis>  big blobs of
text.</simpara>
<simpara>This analysis process needs to happen not just at index time, but also at
query time: the query string needs to be passed through the same (or a
similar) analyzer so that the terms that it tries to find are in the same
format as those that exist in the index.</simpara>
<simpara>Elasticsearch ships with a number of <link linkend="analysis-analyzers">pre-defined analyzers</link>,
which can be used without further configuration.  It also ships with many
<link linkend="analysis-charfilters">character filters</link>, <link linkend="analysis-tokenizers">tokenizers</link>,
and <xref linkend="analysis-tokenfilters"/> which can be combined to configure
custom analyzers per index.</simpara>
<simpara>Analyzers can be specified per-query, per-field or per-index. At index time,
Elasticsearch will look for an analyzer in this order:</simpara>
<itemizedlist>
<listitem>
<simpara>
The <literal>analyzer</literal> defined in the field mapping.
</simpara>
</listitem>
<listitem>
<simpara>
An analyzer named <literal>default</literal> in the index settings.
</simpara>
</listitem>
<listitem>
<simpara>
The <link linkend="analysis-standard-analyzer"><literal>standard</literal></link> analyzer.
</simpara>
</listitem>
</itemizedlist>
<simpara>At query time, there are a few more layers:</simpara>
<itemizedlist>
<listitem>
<simpara>
The <literal>analyzer</literal> defined in a <link linkend="full-text-queries">full-text query</link>.
</simpara>
</listitem>
<listitem>
<simpara>
The <literal>search_analyzer</literal> defined in the field mapping.
</simpara>
</listitem>
<listitem>
<simpara>
The <literal>analyzer</literal> defined in the field mapping.
</simpara>
</listitem>
<listitem>
<simpara>
An analyzer named <literal>default_search</literal> in the index settings.
</simpara>
</listitem>
<listitem>
<simpara>
An analyzer named <literal>default</literal> in the index settings.
</simpara>
</listitem>
<listitem>
<simpara>
The <link linkend="analysis-standard-analyzer"><literal>standard</literal></link> analyzer.
</simpara>
</listitem>
</itemizedlist>
<simpara>The easiest way to specify an analyzer for a particular field is to define it
in the field mapping, as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "text": { <co id="CO192-1"/>
          "type": "text",
          "fields": {
            "english": { <co id="CO192-2"/>
              "type":     "text",
              "analyzer": "english"
            }
          }
        }
      }
    }
  }
}

GET my_index/_analyze <co id="CO192-3"/>
{
  "field": "text",
  "text": "The quick Brown Foxes."
}

GET my_index/_analyze <co id="CO192-4"/>
{
  "field": "text.english",
  "text": "The quick Brown Foxes."
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO192-1">
<para>
The <literal>text</literal> field uses the default <literal>standard</literal> analyzer`.
</para>
</callout>
<callout arearefs="CO192-2">
<para>
The <literal>text.english</literal> <link linkend="multi-fields">multi-field</link> uses the <literal>english</literal> analyzer, which removes stop words and applies stemming.
</para>
</callout>
<callout arearefs="CO192-3">
<para>
This returns the tokens: [ <literal>the</literal>, <literal>quick</literal>, <literal>brown</literal>, <literal>foxes</literal> ].
</para>
</callout>
<callout arearefs="CO192-4">
<para>
This returns the tokens: [ <literal>quick</literal>, <literal>brown</literal>, <literal>fox</literal> ].
</para>
</callout>
</calloutlist>
<section id="search-quote-analyzer">
<title><literal>search_quote_analyzer</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>search_quote_analyzer</literal> setting allows you to specify an analyzer for phrases, this is particularly useful when dealing with disabling
stop words for phrase queries.</simpara>
<simpara>To disable stop words for phrases a field utilising three analyzer settings will be required:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>
An <literal>analyzer</literal> setting for indexing all terms including stop words
</simpara>
</listitem>
<listitem>
<simpara>
A <literal>search_analyzer</literal> setting for non-phrase queries that will remove stop words
</simpara>
</listitem>
<listitem>
<simpara>
A <literal>search_quote_analyzer</literal> setting for phrase queries that will not remove stop words
</simpara>
</listitem>
</orderedlist>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
   "settings":{
      "analysis":{
         "analyzer":{
            "my_analyzer":{ <co id="CO193-1"/>
               "type":"custom",
               "tokenizer":"standard",
               "filter":[
                  "lowercase"
               ]
            },
            "my_stop_analyzer":{ <co id="CO193-2"/>
               "type":"custom",
               "tokenizer":"standard",
               "filter":[
                  "lowercase",
                  "english_stop"
               ]
            }
         },
         "filter":{
            "english_stop":{
               "type":"stop",
               "stopwords":"_english_"
            }
         }
      }
   },
   "mappings":{
      "my_type":{
         "properties":{
            "title": {
               "type":"text",
               "analyzer":"my_analyzer", <co id="CO193-3"/>
               "search_analyzer":"my_stop_analyzer", <co id="CO193-4"/>
               "search_quote_analyzer":"my_analyzer" <co id="CO193-5"/>
            }
         }
      }
   }
}</programlisting>
<remark> CONSOLE</remark>
<programlisting language="js" linenumbering="unnumbered">PUT my_index/my_type/1
{
   "title":"The Quick Brown Fox"
}

PUT my_index/my_type/2
{
   "title":"A Quick Brown Fox"
}

GET my_index/my_type/_search
{
   "query":{
      "query_string":{
         "query":"\"the quick brown fox\"" <co id="CO193-6"/>
      }
   }
}</programlisting>
<calloutlist>
<callout arearefs="CO193-1">
<para>
<literal>my_analyzer</literal> analyzer which tokens all terms including stop words
</para>
</callout>
<callout arearefs="CO193-2">
<para>
<literal>my_stop_analyzer</literal> analyzer which removes stop words
</para>
</callout>
<callout arearefs="CO193-3">
<para>
<literal>analyzer</literal> setting that points to the <literal>my_analyzer</literal> analyzer which will be used at index time
</para>
</callout>
<callout arearefs="CO193-4">
<para>
<literal>search_analyzer</literal> setting that points to the <literal>my_stop_analyzer</literal> and removes stop words for non-phrase queries
</para>
</callout>
<callout arearefs="CO193-5">
<para>
<literal>search_quote_analyzer</literal> setting that points to the <literal>my_analyzer</literal> analyzer and ensures that stop words are not removed from phrase queries
</para>
</callout>
<callout arearefs="CO193-6">
<para>
Since the query is wrapped in quotes it is detected as a phrase query therefore the <literal>search_quote_analyzer</literal> kicks in and ensures the stop words
are not removed from the query. The <literal>my_analyzer</literal> analyzer will then return the following tokens [<literal>the</literal>, <literal>quick</literal>, <literal>brown</literal>, <literal>fox</literal>] which will match one
of the documents. Meanwhile term queries will be analyzed with the <literal>my_stop_analyzer</literal> analyzer which will filter out stop words. So a search for either
<literal>The quick brown fox</literal> or <literal>A quick brown fox</literal> will return both documents since both documents contain the following tokens [<literal>quick</literal>, <literal>brown</literal>, <literal>fox</literal>].
Without the <literal>search_quote_analyzer</literal> it would not be possible to do exact matches for phrase queries as the stop words from phrase queries would be
removed resulting in both documents matching.
</para>
</callout>
</calloutlist>
</section>
</section>
<section id="mapping-boost">
<title><literal>boost</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/boost.asciidoc">Edit me</ulink></title>
<simpara>Individual fields can be <emphasis>boosted</emphasis> automatically&#8201;&#8212;&#8201;count more towards the relevance score&#8201;&#8212;&#8201;at query time, with the <literal>boost</literal> parameter as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "title": {
          "type": "text",
          "boost": 2 <co id="CO194-1"/>
        },
        "content": {
          "type": "text"
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO194-1">
<para>
Matches on the <literal>title</literal> field will have twice the weight as those on the
    <literal>content</literal> field, which has the default <literal>boost</literal> of <literal>1.0</literal>.
</para>
</callout>
</calloutlist>
<note><simpara>The boost is applied only for term queries (prefix, range and fuzzy queries are not <emphasis>boosted</emphasis>).</simpara></note>
<simpara>You can achieve the same effect by using the boost parameter directly in the query, for instance the following query (with field time boost):</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _search
{
    "query": {
        "match" : {
            "title": {
                "query": "quick brown fox"
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>is equivalent to:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _search
{
    "query": {
        "match" : {
            "title": {
                "query": "quick brown fox",
                "boost": 2
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The boost is also applied when it is copied with the
value in the <link linkend="mapping-all-field"><literal>_all</literal></link> field. This means that, when
querying the <literal>_all</literal> field, words that originated from the <literal>title</literal> field will
have a higher score than words that originated in the <literal>content</literal> field.
This functionality comes at a cost: queries on the <literal>_all</literal> field are slower
when field boosting is used.</simpara>
<warning revisionflag="deleted" revision="5.0.0"><title>Deprecated in 5.0.0.</title><simpara> index time boost is deprecated.  Instead, the field mapping boost is applied at query time. For indices created before 5.0.0 the boost will still be applied at index time..</simpara></warning>
<warning>
<title>Why index time boosting is a bad idea</title>
<simpara>We advise against using index time boosting for the following reasons:</simpara>
<itemizedlist>
<listitem>
<simpara>
You cannot change index-time <literal>boost</literal> values without reindexing all of your
  documents.
</simpara>
</listitem>
<listitem>
<simpara>
Every query supports query-time boosting which achieves the same effect. The
  difference is that you can tweak the <literal>boost</literal> value without having to reindex.
</simpara>
</listitem>
<listitem>
<simpara>
Index-time boosts are stored as part of the <link linkend="norms"><literal>norm</literal></link>, which is only one
  byte.  This reduces the resolution of the field length normalization factor
  which can lead to lower quality relevance calculations.
</simpara>
</listitem>
</itemizedlist>
</warning>
</section>
<section id="coerce">
<title><literal>coerce</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/coerce.asciidoc">Edit me</ulink></title>
<simpara>Data is not always clean.  Depending on how it is produced a number might be
rendered in the JSON body as a true JSON number, e.g. <literal>5</literal>, but it might also
be rendered as a string, e.g. <literal>"5"</literal>.  Alternatively, a number that should be
an integer might instead be rendered as a floating point, e.g. <literal>5.0</literal>, or even
<literal>"5.0"</literal>.</simpara>
<simpara>Coercion attempts to clean up dirty values to fit the datatype of a field.
For instance:</simpara>
<itemizedlist>
<listitem>
<simpara>
Strings will be coerced to numbers.
</simpara>
</listitem>
<listitem>
<simpara>
Floating points will be truncated for integer values.
</simpara>
</listitem>
</itemizedlist>
<simpara>For instance:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "number_one": {
          "type": "integer"
        },
        "number_two": {
          "type": "integer",
          "coerce": false
        }
      }
    }
  }
}

PUT my_index/my_type/1
{
  "number_one": "10" <co id="CO195-1"/>
}

PUT my_index/my_type/2
{
  "number_two": "10" <co id="CO195-2"/>
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[catch:request]</remark>
<calloutlist>
<callout arearefs="CO195-1">
<para>
The <literal>number_one</literal> field will contain the integer <literal>10</literal>.
</para>
</callout>
<callout arearefs="CO195-2">
<para>
This document will be rejected because coercion is disabled.
</para>
</callout>
</calloutlist>
<tip><simpara>The <literal>coerce</literal> setting is allowed to have different settings for fields of
the same name in the same index.  Its value can be updated on existing fields
using the <link linkend="indices-put-mapping">PUT mapping API</link>.</simpara></tip>
<section id="coerce-setting">
<title>Index-level default<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/coerce.asciidoc">Edit me</ulink></title>
<simpara>The <literal>index.mapping.coerce</literal> setting can be set on the index level to disable
coercion globally across all mapping types:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "index.mapping.coerce": false
  },
  "mappings": {
    "my_type": {
      "properties": {
        "number_one": {
          "type": "integer",
          "coerce": true
        },
        "number_two": {
          "type": "integer"
        }
      }
    }
  }
}

PUT my_index/my_type/1
{ "number_one": "10" } <co id="CO196-1"/>

PUT my_index/my_type/2
{ "number_two": "10" } <co id="CO196-2"/></programlisting>
<remark> CONSOLE</remark>
<remark> TEST[catch:request]</remark>
<calloutlist>
<callout arearefs="CO196-1">
<para>
The <literal>number_one</literal> field overrides the index level setting to enable coercion.
</para>
</callout>
<callout arearefs="CO196-2">
<para>
This document will be rejected because the <literal>number_two</literal> field inherits the index-level coercion setting.
</para>
</callout>
</calloutlist>
</section>
</section>
<section id="copy-to">
<title><literal>copy_to</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/copy-to.asciidoc">Edit me</ulink></title>
<simpara>The <literal>copy_to</literal> parameter allows you to create custom
<link linkend="mapping-all-field"><literal>_all</literal></link> fields.  In other words, the values of multiple
fields can be copied into a group field, which can then be queried as a single
field.  For instance, the <literal>first_name</literal> and <literal>last_name</literal> fields can be copied to
the <literal>full_name</literal> field as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "first_name": {
          "type": "text",
          "copy_to": "full_name" <co id="CO197-1"/>
        },
        "last_name": {
          "type": "text",
          "copy_to": "full_name" <co id="CO197-2"/>
        },
        "full_name": {
          "type": "text"
        }
      }
    }
  }
}

PUT my_index/my_type/1
{
  "first_name": "John",
  "last_name": "Smith"
}

GET my_index/_search
{
  "query": {
    "match": {
      "full_name": { <co id="CO197-3"/>
        "query": "John Smith",
        "operator": "and"
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO197-1 CO197-2">
<para>
The values of the <literal>first_name</literal> and <literal>last_name</literal> fields are copied to the
     <literal>full_name</literal> field.
</para>
</callout>
<callout arearefs="CO197-3">
<para>
The <literal>first_name</literal> and <literal>last_name</literal> fields can still be queried for the
     first name and last name respectively, but the <literal>full_name</literal> field can be
     queried for both first and last names.
</para>
</callout>
</calloutlist>
<simpara>Some important points:</simpara>
<itemizedlist>
<listitem>
<simpara>
It is the field <emphasis>value</emphasis> which is copied, not the terms (which result from the analysis process).
</simpara>
</listitem>
<listitem>
<simpara>
The original <link linkend="mapping-source-field"><literal>_source</literal></link> field will not be modified to show the copied values.
</simpara>
</listitem>
<listitem>
<simpara>
The same value can be copied to multiple fields, with <literal>"copy_to": [ "field_1", "field_2" ]</literal>
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="doc-values">
<title><literal>doc_values</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/doc-values.asciidoc">Edit me</ulink></title>
<simpara>Most fields are <link linkend="mapping-index">indexed</link> by default, which makes them
searchable. The inverted index allows queries to look up the search term in
unique sorted list of terms, and from that immediately have access to the list
of documents that contain the term.</simpara>
<simpara>Sorting, aggregations, and access to field values in scripts requires a
different data access pattern.  Instead of looking up the term and finding
documents, we need to be able to look up the document and find the terms that
it has in a field.</simpara>
<simpara>Doc values are the on-disk data structure, built at document index time, which
makes this data access pattern possible. They store the same values as the
<literal>_source</literal> but in a column-oriented fashion that is way more efficient for
sorting and aggregations. Doc values are supported on almost all field types,
with the <emphasis>notable exception of <literal>analyzed</literal> string fields</emphasis>.</simpara>
<simpara>All fields which support doc values have them enabled by default. If you are
sure that you don&#8217;t need to sort or aggregate on a field, or access the field
value from a script, you can disable doc values in order to save disk space:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "status_code": { <co id="CO198-1"/>
          "type":       "keyword"
        },
        "session_id": { <co id="CO198-2"/>
          "type":       "keyword",
          "doc_values": false
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO198-1">
<para>
The <literal>status_code</literal> field has <literal>doc_values</literal> enabled by default.
</para>
</callout>
<callout arearefs="CO198-2">
<para>
The <literal>session_id</literal> has <literal>doc_values</literal> disabled, but can still be queried.
</para>
</callout>
</calloutlist>
<tip><simpara>The <literal>doc_values</literal> setting is allowed to have different settings for fields
of the same name in the same index.  It can be disabled (set to <literal>false</literal>) on
existing fields using the <link linkend="indices-put-mapping">PUT mapping API</link>.</simpara></tip>
</section>
<section id="dynamic">
<title><literal>dynamic</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/dynamic.asciidoc">Edit me</ulink></title>
<simpara>By default, fields can be added <emphasis>dynamically</emphasis> to a document, or to
<link linkend="object">inner objects</link> within a document, just by indexing a document
containing the new field.  For instance:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index/my_type/1 <co id="CO199-1"/>
{
  "username": "johnsmith",
  "name": {
    "first": "John",
    "last": "Smith"
  }
}

GET my_index/_mapping <co id="CO199-2"/>

PUT my_index/my_type/2 <co id="CO199-3"/>
{
  "username": "marywhite",
  "email": "mary@white.com",
  "name": {
    "first": "Mary",
    "middle": "Alice",
    "last": "White"
  }
}

GET my_index/_mapping <co id="CO199-4"/></programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO199-1">
<para>
This document introduces the string field <literal>username</literal>, the object field
    <literal>name</literal>, and two string fields under the <literal>name</literal> object which can be
    referred to as <literal>name.first</literal> and <literal>name.last</literal>.
</para>
</callout>
<callout arearefs="CO199-2">
<para>
Check the mapping to verify the above.
</para>
</callout>
<callout arearefs="CO199-3">
<para>
This document adds two string fields: <literal>email</literal> and <literal>name.middle</literal>.
</para>
</callout>
<callout arearefs="CO199-4">
<para>
Check the mapping to verify the changes.
</para>
</callout>
</calloutlist>
<simpara>The details of how new fields are detected and added to the mapping is explained in <xref linkend="dynamic-mapping"/>.</simpara>
<simpara>The <literal>dynamic</literal> setting controls whether new fields can be added dynamically or
not.  It accepts three settings:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>true</literal>
</simpara>
</entry>
<entry>
<simpara>
Newly detected fields are added to the mapping. (default)
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>false</literal>
</simpara>
</entry>
<entry>
<simpara>
Newly detected fields are ignored.  New fields must be added explicitly.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>strict</literal>
</simpara>
</entry>
<entry>
<simpara>
If new fields are detected, an exception is thrown and the document is rejected.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>The <literal>dynamic</literal> setting may be set at the mapping type level, and on each
<link linkend="object">inner object</link>.  Inner objects inherit the setting from their parent
object or from the mapping type.  For instance:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "dynamic": false, <co id="CO200-1"/>
      "properties": {
        "user": { <co id="CO200-2"/>
          "properties": {
            "name": {
              "type": "text"
            },
            "social_networks": { <co id="CO200-3"/>
              "dynamic": true,
              "properties": {}
            }
          }
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO200-1">
<para>
Dynamic mapping is disabled at the type level, so no new top-level fields will be added dynamically.
</para>
</callout>
<callout arearefs="CO200-2">
<para>
The <literal>user</literal> object inherits the type-level setting.
</para>
</callout>
<callout arearefs="CO200-3">
<para>
The <literal>user.social_networks</literal> object enables dynamic mapping, so new fields may be added to this inner object.
</para>
</callout>
</calloutlist>
<tip><simpara>The <literal>dynamic</literal> setting is allowed to have different settings for fields of
the same name in the same index.  Its value can be updated on existing fields
using the <link linkend="indices-put-mapping">PUT mapping API</link>.</simpara></tip>
</section>
<section id="enabled">
<title><literal>enabled</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/enabled.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch tries to index all of the fields you give it, but sometimes you
want to just store the field without indexing it.  For instance, imagine that
you are using Elasticsearch as a web session store.  You may want to index the
session ID and last update time, but you don&#8217;t need to query or run
aggregations on the session data itself.</simpara>
<simpara>The <literal>enabled</literal> setting, which can be applied only to the mapping type and to
<link linkend="object"><literal>object</literal></link> fields, causes Elasticsearch to skip parsing of the
contents of the field entirely.  The JSON can still be retrieved from the
<link linkend="mapping-source-field"><literal>_source</literal></link> field, but it is not searchable or stored
in any other way:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "session": {
      "properties": {
        "user_id": {
          "type":  "keyword"
        },
        "last_updated": {
          "type": "date"
        },
        "session_data": { <co id="CO201-1"/>
          "enabled": false
        }
      }
    }
  }
}

PUT my_index/session/session_1
{
  "user_id": "kimchy",
  "session_data": { <co id="CO201-2"/>
    "arbitrary_object": {
      "some_array": [ "foo", "bar", { "baz": 2 } ]
    }
  },
  "last_updated": "2015-12-06T18:20:22"
}

PUT my_index/session/session_2
{
  "user_id": "jpountz",
  "session_data": "none", <co id="CO201-3"/>
  "last_updated": "2015-12-06T18:22:13"
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO201-1">
<para>
The <literal>session_data</literal> field is disabled.
</para>
</callout>
<callout arearefs="CO201-2">
<para>
Any arbitrary data can be passed to the <literal>session_data</literal> field as it will be entirely ignored.
</para>
</callout>
<callout arearefs="CO201-3">
<para>
The <literal>session_data</literal> will also ignore values that are not JSON objects.
</para>
</callout>
</calloutlist>
<simpara>The entire mapping type may be disabled as well, in which case the document is
stored in the <link linkend="mapping-source-field"><literal>_source</literal></link> field, which means it can be
retrieved, but none of its contents are indexed in any way:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "session": { <co id="CO202-1"/>
      "enabled": false
    }
  }
}

PUT my_index/session/session_1
{
  "user_id": "kimchy",
  "session_data": {
    "arbitrary_object": {
      "some_array": [ "foo", "bar", { "baz": 2 } ]
    }
  },
  "last_updated": "2015-12-06T18:20:22"
}

GET my_index/session/session_1 <co id="CO202-2"/>

GET my_index/_mapping <co id="CO202-3"/></programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO202-1">
<para>
The entire <literal>session</literal> mapping type is disabled.
</para>
</callout>
<callout arearefs="CO202-2">
<para>
The document can be retrieved.
</para>
</callout>
<callout arearefs="CO202-3">
<para>
Checking the mapping reveals that no fields have been added.
</para>
</callout>
</calloutlist>
<tip><simpara>The <literal>enabled</literal> setting is allowed to have different settings for fields of
the same name in the same index.  Its value can be updated on existing fields
using the <link linkend="indices-put-mapping">PUT mapping API</link>.</simpara></tip>
</section>
<section id="fielddata">
<title><literal>fielddata</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/fielddata.asciidoc">Edit me</ulink></title>
<simpara>Most fields are <link linkend="mapping-index">indexed</link> by default, which makes them
searchable. Sorting, aggregations, and accessing field values in scripts,
however, requires a different access pattern from search.</simpara>
<simpara>Search needs to answer the question <emphasis>"Which documents contain this term?"</emphasis>,
while sorting and aggregations need to answer a different question: <emphasis>"What is
the value of this field for <emphasis role="strong">this</emphasis> document?"</emphasis>.</simpara>
<simpara>Most fields can use index-time, on-disk <link linkend="doc-values"><literal>doc_values</literal></link> for this
data access pattern, but <link linkend="text"><literal>text</literal></link> fields do not support <literal>doc_values</literal>.</simpara>
<simpara>Instead, <literal>text</literal> fields use a query-time <emphasis role="strong">in-memory</emphasis> data structure called
<literal>fielddata</literal>.  This data structure is built on demand the first time that a
field is used for aggregations, sorting, or in a script.  It is built by
reading the entire inverted index for each segment from disk, inverting the
term ↔︎ document relationship, and storing the result in memory, in the JVM
heap.</simpara>
<section id="_fielddata_is_disabled_on_literal_text_literal_fields_by_default">
<title>Fielddata is disabled on <literal>text</literal> fields by default<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/fielddata.asciidoc">Edit me</ulink></title>
<simpara>Fielddata can consume a <emphasis role="strong">lot</emphasis> of heap space, especially when loading high
cardinality <literal>text</literal> fields.  Once fielddata has been loaded into the heap, it
remains there for the lifetime of the segment. Also, loading fielddata is an
expensive process which can cause users to experience latency hits.  This is
why fielddata is disabled by default.</simpara>
<simpara>If you try to sort, aggregate, or access values from a script on a <literal>text</literal>
field, you will see this exception:</simpara>
<blockquote>
<simpara>Fielddata is disabled on text fields by default.  Set <literal>fielddata=true</literal> on
[<literal>your_field_name</literal>] in order to load  fielddata in memory by uninverting the
inverted index. Note that this can however use significant memory.</simpara>
</blockquote>
</section>
<section id="before-enabling-fielddata">
<title>Before enabling fielddata<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/fielddata.asciidoc">Edit me</ulink></title>
<simpara>Before you enable fielddata, consider why you are using a <literal>text</literal> field for
aggregations, sorting, or in a script.  It usually doesn&#8217;t make sense to do
so.</simpara>
<simpara>A text field is analyzed before indexing so that a value like
<literal>New York</literal> can be found by searching for <literal>new</literal> or for <literal>york</literal>.  A <literal>terms</literal>
aggregation on this field will return a <literal>new</literal> bucket and a <literal>york</literal> bucket, when
you probably want a single bucket called <literal>New York</literal>.</simpara>
<simpara>Instead, you should have a <literal>text</literal> field for full text searches, and an
unanalyzed <link linkend="keyword"><literal>keyword</literal></link> field with <link linkend="doc-values"><literal>doc_values</literal></link>
enabled for aggregations, as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "my_field": { <co id="CO203-1"/>
          "type": "text",
          "fields": {
            "keyword": { <co id="CO203-2"/>
              "type": "keyword"
            }
          }
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO203-1">
<para>
Use the <literal>my_field</literal> field for searches.
</para>
</callout>
<callout arearefs="CO203-2">
<para>
Use the <literal>my_field.keyword</literal> field for aggregations, sorting, or in scripts.
</para>
</callout>
</calloutlist>
</section>
<section id="_enabling_fielddata_on_literal_text_literal_fields">
<title>Enabling fielddata on <literal>text</literal> fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/fielddata.asciidoc">Edit me</ulink></title>
<simpara>You can enable fielddata on an existing <literal>text</literal> field using the
<link linkend="indices-put-mapping">PUT mapping API</link> as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index/_mapping/my_type
{
  "properties": {
    "my_field": { <co id="CO204-1"/>
      "type":     "text",
      "fielddata": true
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<calloutlist>
<callout arearefs="CO204-1">
<para>
The mapping that you specify for <literal>my_field</literal> should consist of the existing
    mapping for that field, plus the <literal>fielddata</literal> parameter.
</para>
</callout>
</calloutlist>
<tip><simpara>The <literal>fielddata.*</literal> parameter must have the same settings for fields of the
same name in the same index.  Its value can be updated on existing fields
using the <link linkend="indices-put-mapping">PUT mapping API</link>.</simpara></tip>
<sidebar id="global-ordinals">
<title>Global ordinals</title>
<simpara>Global ordinals is a data-structure on top of fielddata and doc values, that
maintains an incremental numbering for each unique term in a lexicographic
order. Each term has a unique number and the number of term <emphasis>A</emphasis> is lower than
the number of term <emphasis>B</emphasis>. Global ordinals are only supported on <link linkend="text"><literal>text</literal></link>
and <link linkend="keyword"><literal>keyword</literal></link> fields.</simpara>
<simpara>Fielddata and doc values also have ordinals, which is a unique numbering for
all terms in a particular segment and field. Global ordinals just build on top
of this, by providing a mapping between the segment ordinals and the global
ordinals, the latter being unique across the entire shard.</simpara>
<simpara>Global ordinals are used for features that use segment ordinals, such as
sorting and the terms aggregation, to improve the execution time. A terms
aggregation relies purely on global ordinals to perform the aggregation at the
shard level, then converts global ordinals to the real term only for the final
reduce phase, which combines results from different shards.</simpara>
<simpara>Global ordinals for a specified field are tied to <emphasis>all the segments of a
shard</emphasis>, while fielddata and doc values ordinals are tied to a single segment.
which is different than for field data for a specific field which is tied to a
single segment. For this reason global ordinals need to be entirely rebuilt
whenever a once new segment becomes visible.</simpara>
<simpara>The loading time of global ordinals depends on the number of terms in a field,
but in general it is low, since it source field data has already been loaded.
The memory overhead of global ordinals is a small because it is very
efficiently compressed. Eager loading of global ordinals can move the loading
time from the first search request, to the refresh itself.</simpara>
</sidebar>
</section>
<section id="field-data-filtering">
<title><literal>fielddata_frequency_filter</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/fielddata.asciidoc">Edit me</ulink></title>
<simpara>Fielddata filtering can be used to reduce the number of terms loaded into
memory, and thus reduce memory usage. Terms can be filtered by <emphasis>frequency</emphasis>:</simpara>
<simpara>The frequency filter allows you to only load terms whose document frequency falls
between a <literal>min</literal> and <literal>max</literal> value, which can be expressed an absolute
number (when the number is bigger than 1.0) or as a percentage
(eg <literal>0.01</literal> is <literal>1%</literal> and <literal>1.0</literal> is <literal>100%</literal>). Frequency is calculated
<emphasis role="strong">per segment</emphasis>. Percentages are based on the number of docs which have a
value for the field, as opposed to all docs in the segment.</simpara>
<simpara>Small segments can be excluded completely by specifying the minimum
number of docs that the segment should contain with <literal>min_segment_size</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "tag": {
          "type": "text",
          "fielddata": true,
          "fielddata_frequency_filter": {
            "min": 0.001,
            "max": 0.1,
            "min_segment_size": 500
          }
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
</section>
</section>
<section id="mapping-date-format">
<title><literal>format</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/format.asciidoc">Edit me</ulink></title>
<simpara>In JSON documents, dates are represented as strings. Elasticsearch uses a set
of preconfigured formats to recognize and parse these strings into a long
value representing <emphasis>milliseconds-since-the-epoch</emphasis> in UTC.</simpara>
<simpara>Besides the <link linkend="built-in-date-formats">built-in formats</link>, your own
<link linkend="custom-date-formats">custom formats</link> can be specified using the familiar
<literal>yyyy/MM/dd</literal> syntax:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "date": {
          "type":   "date",
          "format": "yyyy-MM-dd"
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Many APIs which support date values also support <link linkend="date-math">date math</link>
expressions, such as <literal>now-1m/d</literal>&#8201;&#8212;&#8201;the current time, minus one month, rounded
down to the nearest day.</simpara>
<tip><simpara>The <literal>format</literal> setting must have the same setting for fields of the same
name in the same index.  Its value can be updated on existing fields using the
<link linkend="indices-put-mapping">PUT mapping API</link>.</simpara></tip>
<section id="custom-date-formats">
<title>Custom date formats<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/format.asciidoc">Edit me</ulink></title>
<simpara>Completely customizable date formats are supported.  The syntax for these is explained
<ulink url="http://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html">in the Joda docs</ulink>.</simpara>
</section>
<section id="built-in-date-formats">
<title>Built In Formats<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/format.asciidoc">Edit me</ulink></title>
<simpara>Most of the below dates have a <literal>strict</literal> companion dates, which means, that
year, month and day parts of the week must have prepending zeros in order
to be valid. This means, that a date like <literal>5/11/1</literal> would not be valid, but
you would need to specify the full date, which would be <literal>2005/11/01</literal> in this
example. So instead of <literal>date_optional_time</literal> you would need to specify
<literal>strict_date_optional_time</literal>.</simpara>
<simpara>The following tables lists all the defaults ISO formats supported:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>epoch_millis</literal>
</term>
<listitem>
<simpara>
    A formatter for the number of milliseconds since the epoch. Note, that
    this timestamp is subject to the limits of a Java <literal>Long.MIN_VALUE</literal> and
    <literal>Long.MAX_VALUE</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>epoch_second</literal>
</term>
<listitem>
<simpara>
    A formatter for the number of seconds since the epoch. Note, that this
    timestamp is subject to the limits of a Java <literal>Long.MIN_VALUE</literal> and <literal>Long.
    MAX_VALUE</literal> divided by 1000 (the number of milliseconds in a second).
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<anchor id="strict-date-time" xreflabel="[strict-date-time]"/><literal>date_optional_time</literal> or <literal>strict_date_optional_time</literal>
</term>
<listitem>
<simpara>
    A generic ISO datetime parser where the date is mandatory and the time is
    optional.
    <ulink url="http://www.joda.org/joda-time/apidocs/org/joda/time/format/ISODateTimeFormat.html#dateOptionalTimeParser--">Full details here</ulink>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>basic_date</literal>
</term>
<listitem>
<simpara>
    A basic formatter for a full date as four digit year, two digit month of
    year, and two digit day of month: <literal>yyyyMMdd</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>basic_date_time</literal>
</term>
<listitem>
<simpara>
    A basic formatter that combines a basic date and time, separated by a <emphasis>T</emphasis>:
    <literal>yyyyMMdd'T'HHmmss.SSSZ</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>basic_date_time_no_millis</literal>
</term>
<listitem>
<simpara>
    A basic formatter that combines a basic date and time without millis,
    separated by a <emphasis>T</emphasis>: <literal>yyyyMMdd'T'HHmmssZ</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>basic_ordinal_date</literal>
</term>
<listitem>
<simpara>
    A formatter for a full ordinal date, using a four digit year and three
    digit dayOfYear: <literal>yyyyDDD</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>basic_ordinal_date_time</literal>
</term>
<listitem>
<simpara>
    A formatter for a full ordinal date and time, using a four digit year and
    three digit dayOfYear: <literal>yyyyDDD'T'HHmmss.SSSZ</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>basic_ordinal_date_time_no_millis</literal>
</term>
<listitem>
<simpara>
    A formatter for a full ordinal date and time without millis, using a four
    digit year and three digit dayOfYear: <literal>yyyyDDD'T'HHmmssZ</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>basic_time</literal>
</term>
<listitem>
<simpara>
    A basic formatter for a two digit hour of day, two digit minute of hour,
    two digit second of minute, three digit millis, and time zone offset:
    <literal>HHmmss.SSSZ</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>basic_time_no_millis</literal>
</term>
<listitem>
<simpara>
    A basic formatter for a two digit hour of day, two digit minute of hour,
    two digit second of minute, and time zone offset: <literal>HHmmssZ</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>basic_t_time</literal>
</term>
<listitem>
<simpara>
    A basic formatter for a two digit hour of day, two digit minute of hour,
    two digit second of minute, three digit millis, and time zone off set
    prefixed by <emphasis>T</emphasis>: <literal>'T'HHmmss.SSSZ</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>basic_t_time_no_millis</literal>
</term>
<listitem>
<simpara>
    A basic formatter for a two digit hour of day, two digit minute of hour,
    two digit second of minute, and time zone offset prefixed by <emphasis>T</emphasis>:
    <literal>'T'HHmmssZ</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>basic_week_date</literal> or <literal>strict_basic_week_date</literal>
</term>
<listitem>
<simpara>
    A basic formatter for a full date as four digit weekyear, two digit week
    of weekyear, and one digit day of week: <literal>xxxx'W'wwe</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>basic_week_date_time</literal> or <literal>strict_basic_week_date_time</literal>
</term>
<listitem>
<simpara>
    A basic formatter that combines a basic weekyear date and time, separated
    by a <emphasis>T</emphasis>: <literal>xxxx'W'wwe'T'HHmmss.SSSZ</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>basic_week_date_time_no_millis</literal> or <literal>strict_basic_week_date_time_no_millis</literal>
</term>
<listitem>
<simpara>
    A basic formatter that combines a basic weekyear date and time without
    millis, separated by a <emphasis>T</emphasis>: <literal>xxxx'W'wwe'T'HHmmssZ</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>date</literal> or <literal>strict_date</literal>
</term>
<listitem>
<simpara>
    A formatter for a full date as four digit year, two digit month of year,
    and two digit day of month: <literal>yyyy-MM-dd</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>date_hour</literal> or <literal>strict_date_hour</literal>
</term>
<listitem>
<simpara>
    A formatter that combines a full date and two digit hour of day:
    <literal>yyyy-MM-dd'T'HH</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>date_hour_minute</literal> or <literal>strict_date_hour_minute</literal>
</term>
<listitem>
<simpara>
    A formatter that combines a full date, two digit hour of day, and two
    digit minute of hour: <literal>yyyy-MM-dd'T'HH:mm</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>date_hour_minute_second</literal> or <literal>strict_date_hour_minute_second</literal>
</term>
<listitem>
<simpara>
    A formatter that combines a full date, two digit hour of day, two digit
    minute of hour, and two digit second of minute: <literal>yyyy-MM-dd'T'HH:mm:ss</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>date_hour_minute_second_fraction</literal> or <literal>strict_date_hour_minute_second_fraction</literal>
</term>
<listitem>
<simpara>
    A formatter that combines a full date, two digit hour of day, two digit
    minute of hour, two digit second of minute, and three digit fraction of
    second: <literal>yyyy-MM-dd'T'HH:mm:ss.SSS</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>date_hour_minute_second_millis</literal> or <literal>strict_date_hour_minute_second_millis</literal>
</term>
<listitem>
<simpara>
    A formatter that combines a full date, two digit hour of day, two digit
    minute of hour, two digit second of minute, and three digit fraction of
    second: <literal>yyyy-MM-dd'T'HH:mm:ss.SSS</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>date_time</literal> or <literal>strict_date_time</literal>
</term>
<listitem>
<simpara>
    A formatter that combines a full date and time, separated by a <emphasis>T</emphasis>:
    <literal>yyyy-MM-dd'T'HH:mm:ss.SSSZZ</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>date_time_no_millis</literal> or <literal>strict_date_time_no_millis</literal>
</term>
<listitem>
<simpara>
    A formatter that combines a full date and time without millis, separated
    by a <emphasis>T</emphasis>: <literal>yyyy-MM-dd'T'HH:mm:ssZZ</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>hour</literal> or <literal>strict_hour</literal>
</term>
<listitem>
<simpara>
    A formatter for a two digit hour of day: <literal>HH</literal>
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>hour_minute</literal> or <literal>strict_hour_minute</literal>
</term>
<listitem>
<simpara>
    A formatter for a two digit hour of day and two digit minute of hour:
    <literal>HH:mm</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>hour_minute_second</literal> or <literal>strict_hour_minute_second</literal>
</term>
<listitem>
<simpara>
    A formatter for a two digit hour of day, two digit minute of hour, and two
    digit second of minute: <literal>HH:mm:ss</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>hour_minute_second_fraction</literal> or <literal>strict_hour_minute_second_fraction</literal>
</term>
<listitem>
<simpara>
    A formatter for a two digit hour of day, two digit minute of hour, two
    digit second of minute, and three digit fraction of second: <literal>HH:mm:ss.SSS</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>hour_minute_second_millis</literal> or <literal>strict_hour_minute_second_millis</literal>
</term>
<listitem>
<simpara>
    A formatter for a two digit hour of day, two digit minute of hour, two
    digit second of minute, and three digit fraction of second: <literal>HH:mm:ss.SSS</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>ordinal_date</literal> or <literal>strict_ordinal_date</literal>
</term>
<listitem>
<simpara>
    A formatter for a full ordinal date, using a four digit year and three
    digit dayOfYear: <literal>yyyy-DDD</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>ordinal_date_time</literal> or <literal>strict_ordinal_date_time</literal>
</term>
<listitem>
<simpara>
    A formatter for a full ordinal date and time, using a four digit year and
    three digit dayOfYear: <literal>yyyy-DDD'T'HH:mm:ss.SSSZZ</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>ordinal_date_time_no_millis</literal> or <literal>strict_ordinal_date_time_no_millis</literal>
</term>
<listitem>
<simpara>
    A formatter for a full ordinal date and time without millis, using a four
    digit year and three digit dayOfYear: <literal>yyyy-DDD'T'HH:mm:ssZZ</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>time</literal> or <literal>strict_time</literal>
</term>
<listitem>
<simpara>
    A formatter for a two digit hour of day, two digit minute of hour, two
    digit second of minute, three digit fraction of second, and time zone
    offset: <literal>HH:mm:ss.SSSZZ</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>time_no_millis</literal> or <literal>strict_time_no_millis</literal>
</term>
<listitem>
<simpara>
    A formatter for a two digit hour of day, two digit minute of hour, two
    digit second of minute, and time zone offset: <literal>HH:mm:ssZZ</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>t_time</literal> or <literal>strict_t_time</literal>
</term>
<listitem>
<simpara>
    A formatter for a two digit hour of day, two digit minute of hour, two
    digit second of minute, three digit fraction of second, and time zone
    offset prefixed by <emphasis>T</emphasis>: <literal>'T'HH:mm:ss.SSSZZ</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>t_time_no_millis</literal> or <literal>strict_t_time_no_millis</literal>
</term>
<listitem>
<simpara>
    A formatter for a two digit hour of day, two digit minute of hour, two
    digit second of minute, and time zone offset prefixed by <emphasis>T</emphasis>: <literal>'T'HH:mm:ssZZ</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>week_date</literal> or <literal>strict_week_date</literal>
</term>
<listitem>
<simpara>
    A formatter for a full date as four digit weekyear, two digit week of
    weekyear, and one digit day of week: <literal>xxxx-'W'ww-e</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>week_date_time</literal> or <literal>strict_week_date_time</literal>
</term>
<listitem>
<simpara>
    A formatter that combines a full weekyear date and time, separated by a
    <emphasis>T</emphasis>: <literal>xxxx-'W'ww-e'T'HH:mm:ss.SSSZZ</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>week_date_time_no_millis</literal> or <literal>strict_week_date_time_no_millis</literal>
</term>
<listitem>
<simpara>
    A formatter that combines a full weekyear date and time without millis,
    separated by a <emphasis>T</emphasis>: <literal>xxxx-'W'ww-e'T'HH:mm:ssZZ</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>weekyear</literal> or <literal>strict_weekyear</literal>
</term>
<listitem>
<simpara>
    A formatter for a four digit weekyear: <literal>xxxx</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>weekyear_week</literal> or <literal>strict_weekyear_week</literal>
</term>
<listitem>
<simpara>
    A formatter for a four digit weekyear and two digit week of weekyear:
    <literal>xxxx-'W'ww</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>weekyear_week_day</literal> or <literal>strict_weekyear_week_day</literal>
</term>
<listitem>
<simpara>
    A formatter for a four digit weekyear, two digit week of weekyear, and one
    digit day of week: <literal>xxxx-'W'ww-e</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>year</literal> or <literal>strict_year</literal>
</term>
<listitem>
<simpara>
    A formatter for a four digit year: <literal>yyyy</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>year_month</literal> or <literal>strict_year_month</literal>
</term>
<listitem>
<simpara>
    A formatter for a four digit year and two digit month of year: <literal>yyyy-MM</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>year_month_day</literal> or <literal>strict_year_month_day</literal>
</term>
<listitem>
<simpara>
    A formatter for a four digit year, two digit month of year, and two digit
    day of month: <literal>yyyy-MM-dd</literal>.
</simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
</section>
<section id="ignore-above">
<title><literal>ignore_above</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/ignore-above.asciidoc">Edit me</ulink></title>
<simpara>Strings longer than the <literal>ignore_above</literal> setting will not be indexed or stored.</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "message": {
          "type": "keyword",
          "ignore_above": 20 <co id="CO205-1"/>
        }
      }
    }
  }
}

PUT my_index/my_type/1 <co id="CO205-2"/>
{
  "message": "Syntax error"
}

PUT my_index/my_type/2 <co id="CO205-3"/>
{
  "message": "Syntax error with some long stacktrace"
}

GET _search <co id="CO205-4"/>
{
  "aggs": {
    "messages": {
      "terms": {
        "field": "message"
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO205-1">
<para>
This field will ignore any string longer than 20 characters.
</para>
</callout>
<callout arearefs="CO205-2">
<para>
This document is indexed successfully.
</para>
</callout>
<callout arearefs="CO205-3">
<para>
This document will be indexed, but without indexing the <literal>message</literal> field.
</para>
</callout>
<callout arearefs="CO205-4">
<para>
Search returns both documents, but only the first is present in the terms aggregation.
</para>
</callout>
</calloutlist>
<tip><simpara>The <literal>ignore_above</literal> setting is allowed to have different settings for
fields of the same name in the same index.  Its value can be updated on
existing fields using the <link linkend="indices-put-mapping">PUT mapping API</link>.</simpara></tip>
<simpara>This option is also useful for protecting against Lucene&#8217;s term byte-length
limit of <literal>32766</literal>.</simpara>
<note><simpara>The value for <literal>ignore_above</literal> is the <emphasis>character count</emphasis>, but Lucene counts
bytes. If you use UTF-8 text with many non-ASCII characters, you may want to
set the limit to <literal>32766 / 3 = 10922</literal> since UTF-8 characters may occupy at most
3 bytes.</simpara></note>
</section>
<section id="ignore-malformed">
<title><literal>ignore_malformed</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/ignore-malformed.asciidoc">Edit me</ulink></title>
<simpara>Sometimes you don&#8217;t have much control over the data that you receive.  One
user may send a <literal>login</literal> field that is a <link linkend="date"><literal>date</literal></link>, and another sends a
<literal>login</literal> field that is an email address.</simpara>
<simpara>Trying to index the wrong datatype into a field throws an exception by
default, and rejects the whole document.  The <literal>ignore_malformed</literal> parameter, if
set to <literal>true</literal>, allows the exception to be ignored.  The malformed field is not
indexed, but other fields in the document are processed normally.</simpara>
<simpara>For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "number_one": {
          "type": "integer",
          "ignore_malformed": true
        },
        "number_two": {
          "type": "integer"
        }
      }
    }
  }
}

PUT my_index/my_type/1
{
  "text":       "Some text value",
  "number_one": "foo" <co id="CO206-1"/>
}

PUT my_index/my_type/2
{
  "text":       "Some text value",
  "number_two": "foo" <co id="CO206-2"/>
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[catch:request]</remark>
<calloutlist>
<callout arearefs="CO206-1">
<para>
This document will have the <literal>text</literal> field indexed, but not the <literal>number_one</literal> field.
</para>
</callout>
<callout arearefs="CO206-2">
<para>
This document will be rejected because <literal>number_two</literal> does not allow malformed values.
</para>
</callout>
</calloutlist>
<tip><simpara>The <literal>ignore_malformed</literal> setting is allowed to have different settings for
fields of the same name in the same index.  Its value can be updated on
existing fields using the <link linkend="indices-put-mapping">PUT mapping API</link>.</simpara></tip>
<section id="ignore-malformed-setting">
<title>Index-level default<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/ignore-malformed.asciidoc">Edit me</ulink></title>
<simpara>The <literal>index.mapping.ignore_malformed</literal> setting can be set on the index level to
allow to ignore malformed content globally across all mapping types.</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "index.mapping.ignore_malformed": true <co id="CO207-1"/>
  },
  "mappings": {
    "my_type": {
      "properties": {
        "number_one": { <co id="CO207-2"/>
          "type": "byte"
        },
        "number_two": {
          "type": "integer",
          "ignore_malformed": false <co id="CO207-3"/>
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO207-1 CO207-2">
<para>
The <literal>number_one</literal> field inherits the index-level setting.
</para>
</callout>
<callout arearefs="CO207-3">
<para>
The <literal>number_two</literal> field overrides the index-level setting to turn off <literal>ignore_malformed</literal>.
</para>
</callout>
</calloutlist>
</section>
</section>
<section id="include-in-all">
<title><literal>include_in_all</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/include-in-all.asciidoc">Edit me</ulink></title>
<simpara>The <literal>include_in_all</literal> parameter provides per-field control over which fields
are included in the <link linkend="mapping-all-field"><literal>_all</literal></link> field.  It defaults to <literal>true</literal>, unless <link linkend="mapping-index"><literal>index</literal></link> is set to <literal>no</literal>.</simpara>
<simpara>This example demonstrates how to exclude the <literal>date</literal> field from the <literal>_all</literal> field:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "title": { <co id="CO208-1"/>
          "type": "text"
        },
        "content": { <co id="CO208-2"/>
          "type": "text"
        },
        "date": { <co id="CO208-3"/>
          "type": "date",
          "include_in_all": false
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO208-1 CO208-2">
<para>
The <literal>title</literal> and <literal>content</literal> fields will be included in the <literal>_all</literal> field.
</para>
</callout>
<callout arearefs="CO208-3">
<para>
The <literal>date</literal> field will not be included in the <literal>_all</literal> field.
</para>
</callout>
</calloutlist>
<tip><simpara>The <literal>include_in_all</literal> setting is allowed to have different settings for
fields of the same name in the same index.  Its value can be updated on
existing fields using the <link linkend="indices-put-mapping">PUT mapping API</link>.</simpara></tip>
<simpara>The <literal>include_in_all</literal> parameter can also be set at the type level and on
<link linkend="object"><literal>object</literal></link> or <link linkend="nested"><literal>nested</literal></link> fields, in which case all sub-
fields inherit that setting.  For instance:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "include_in_all": false, <co id="CO209-1"/>
      "properties": {
        "title":          { "type": "text" },
        "author": {
          "include_in_all": true, <co id="CO209-2"/>
          "properties": {
            "first_name": { "type": "text" },
            "last_name":  { "type": "text" }
          }
        },
        "editor": {
          "properties": {
            "first_name": { "type": "text" }, <co id="CO209-3"/>
            "last_name":  { "type": "text", "include_in_all": true } <co id="CO209-4"/>
          }
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO209-1">
<para>
All fields in <literal>my_type</literal> are excluded from <literal>_all</literal>.
</para>
</callout>
<callout arearefs="CO209-2">
<para>
The <literal>author.first_name</literal> and <literal>author.last_name</literal> fields are included in <literal>_all</literal>.
</para>
</callout>
<callout arearefs="CO209-3 CO209-4">
<para>
Only the <literal>editor.last_name</literal> field is included in <literal>_all</literal>.
    The <literal>editor.first_name</literal> inherits the type-level setting and is excluded.
</para>
</callout>
</calloutlist>
<note>
<title>Multi-fields and <literal>include_in_all</literal></title>
<simpara>The original field value is added to the <literal>_all</literal> field, not the terms produced
by a field&#8217;s analyzer.  For this reason, it makes no sense to set
<literal>include_in_all</literal> to <literal>true</literal> on <link linkend="multi-fields">multi-fields</link>, as each
multi-field has exactly the same value as its parent.</simpara>
</note>
</section>
<section id="mapping-index">
<title><literal>index</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/index.asciidoc">Edit me</ulink></title>
<simpara>The <literal>index</literal> option controls whether field values are indexed. It accepts <literal>true</literal>
or <literal>false</literal>. Fields that are not indexed are not queryable.</simpara>
</section>
<section id="index-options">
<title><literal>index_options</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/index-options.asciidoc">Edit me</ulink></title>
<simpara>The <literal>index_options</literal> parameter controls what information is added to the
inverted index, for search and highlighting purposes.  It accepts the
following settings:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>docs</literal>
</simpara>
</entry>
<entry>
<simpara>
    Only the doc number is indexed.  Can answer the question <emphasis>Does this term
    exist in this field?</emphasis>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>freqs</literal>
</simpara>
</entry>
<entry>
<simpara>
    Doc number and term frequencies are indexed.  Term frequencies are used to
    score repeated terms higher than single terms.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>positions</literal>
</simpara>
</entry>
<entry>
<simpara>
    Doc number, term frequencies, and term positions (or order) are indexed.
    Positions can be used for
    <link linkend="query-dsl-match-query-phrase">proximity or phrase queries</link>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>offsets</literal>
</simpara>
</entry>
<entry>
<simpara>
    Doc number, term frequencies, positions, and start and end character
    offsets (which map the term back to the original string) are indexed.
    Offsets are used by the <link linkend="postings-highlighter">postings highlighter</link>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara><link linkend="mapping-index">Analyzed</link> string fields use <literal>positions</literal> as the default, and
all other fields use <literal>docs</literal> as the default.</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "text": {
          "type": "text",
          "index_options": "offsets"
        }
      }
    }
  }
}

PUT my_index/my_type/1
{
  "text": "Quick brown fox"
}

GET my_index/_search
{
  "query": {
    "match": {
      "text": "brown fox"
    }
  },
  "highlight": {
    "fields": {
      "text": {} <co id="CO210-1"/>
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO210-1">
<para>
The <literal>text</literal> field will use the postings highlighter by default because <literal>offsets</literal> are indexed.
</para>
</callout>
</calloutlist>
</section>
<section id="multi-fields">
<title><literal>fields</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/multi-fields.asciidoc">Edit me</ulink></title>
<simpara>It is often useful to index the same field in different ways for different
purposes.  This is the purpose of <emphasis>multi-fields</emphasis>. For instance, a <literal>string</literal>
field could be mapped as a <literal>text</literal> field for full-text
search, and as a <literal>keyword</literal> field for sorting or aggregations:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "city": {
          "type": "text",
          "fields": {
            "raw": { <co id="CO211-1"/>
              "type":  "keyword"
            }
          }
        }
      }
    }
  }
}

PUT my_index/my_type/1
{
  "city": "New York"
}

PUT my_index/my_type/2
{
  "city": "York"
}

GET my_index/_search
{
  "query": {
    "match": {
      "city": "york" <co id="CO211-2"/>
    }
  },
  "sort": {
    "city.raw": "asc" <co id="CO211-3"/>
  },
  "aggs": {
    "Cities": {
      "terms": {
        "field": "city.raw" <co id="CO211-4"/>
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO211-1">
<para>
The <literal>city.raw</literal> field is a <literal>keyword</literal> version of the <literal>city</literal> field.
</para>
</callout>
<callout arearefs="CO211-2">
<para>
The <literal>city</literal> field can be used for full text search.
</para>
</callout>
<callout arearefs="CO211-3 CO211-4">
<para>
The <literal>city.raw</literal> field can be used for sorting and aggregations
</para>
</callout>
</calloutlist>
<note><simpara>Multi-fields do not change the original <literal>_source</literal> field.</simpara></note>
<tip><simpara>The <literal>fields</literal> setting is allowed to have different settings for fields of
the same name in the same index.  New multi-fields can be added to existing
fields using the <link linkend="indices-put-mapping">PUT mapping API</link>.</simpara></tip>
<section id="_multi_fields_with_multiple_analyzers">
<title>Multi-fields with multiple analyzers<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/multi-fields.asciidoc">Edit me</ulink></title>
<simpara>Another use case of multi-fields is to analyze the same field in different
ways for better relevance. For instance we could index a field with the
<link linkend="analysis-standard-analyzer"><literal>standard</literal> analyzer</link> which breaks text up into
words, and again with the <link linkend="english-analyzer"><literal>english</literal> analyzer</link>
which stems words into their root form:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "text": { <co id="CO212-1"/>
          "type": "text",
          "fields": {
            "english": { <co id="CO212-2"/>
              "type":     "text",
              "analyzer": "english"
            }
          }
        }
      }
    }
  }
}

PUT my_index/my_type/1
{ "text": "quick brown fox" } <co id="CO212-3"/>

PUT my_index/my_type/2
{ "text": "quick brown foxes" } <co id="CO212-4"/>

GET my_index/_search
{
  "query": {
    "multi_match": {
      "query": "quick brown foxes",
      "fields": [ <co id="CO212-5"/>
        "text",
        "text.english"
      ],
      "type": "most_fields" <co id="CO212-6"/>
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO212-1">
<para>
The <literal>text</literal> field uses the <literal>standard</literal> analyzer.
</para>
</callout>
<callout arearefs="CO212-2">
<para>
The <literal>text.english</literal> field uses the <literal>english</literal> analyzer.
</para>
</callout>
<callout arearefs="CO212-3 CO212-4">
<para>
Index two documents, one with <literal>fox</literal> and the other with <literal>foxes</literal>.
</para>
</callout>
<callout arearefs="CO212-5 CO212-6">
<para>
Query both the <literal>text</literal> and <literal>text.english</literal> fields and combine the scores.
</para>
</callout>
</calloutlist>
<simpara>The <literal>text</literal> field contains the term <literal>fox</literal> in the first document and <literal>foxes</literal> in
the second document.  The <literal>text.english</literal> field contains <literal>fox</literal> for both
documents, because <literal>foxes</literal> is stemmed to <literal>fox</literal>.</simpara>
<simpara>The query string is also analyzed by the <literal>standard</literal> analyzer for the <literal>text</literal>
field, and by the <literal>english</literal> analyzer` for the <literal>text.english</literal> field.  The
stemmed field allows a query for <literal>foxes</literal> to also match the document containing
just <literal>fox</literal>.  This allows us to match as many documents as possible.  By also
querying the unstemmed <literal>text</literal> field, we improve the relevance score of the
document which matches <literal>foxes</literal> exactly.</simpara>
</section>
</section>
<section id="norms">
<title><literal>norms</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/norms.asciidoc">Edit me</ulink></title>
<simpara>Norms store various normalization factors that are later used at query time
in order to compute the score of a document relatively to a query.</simpara>
<simpara>Although useful for scoring, norms also require quite a lot of disk
(typically in the order of one byte per document per field in your index, even
for documents that don&#8217;t have this specific field). As a consequence, if you
don&#8217;t need scoring on a specific field, you should disable norms on that
field. In  particular, this is the case for fields that are used solely for
filtering or aggregations.</simpara>
<tip><simpara>The <literal>norms</literal> setting must have the same setting for fields of the
same name in the same index.  Norms can be disabled on existing fields using
the <link linkend="indices-put-mapping">PUT mapping API</link>.</simpara></tip>
<simpara>Norms can be disabled (but not reenabled) after the fact, using the
<link linkend="indices-put-mapping">PUT mapping API</link> like so:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index/_mapping/my_type
{
  "properties": {
    "title": {
      "type": "text",
      "norms": false
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT my_index\n/]</remark>
<note><simpara>Norms will not be removed instantly, but will be removed as old segments
are merged into new segments as you continue indexing new documents. Any score
computation on a field that has had norms removed might return inconsistent
results since some documents won&#8217;t have norms anymore while other documents
might still have norms.</simpara></note>
</section>
<section id="null-value">
<title><literal>null_value</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/null-value.asciidoc">Edit me</ulink></title>
<simpara>A <literal>null</literal> value cannot be indexed or searched.  When a field is set to <literal>null</literal>,
(or an empty array or an array of <literal>null</literal> values)  it is treated as though that
field has no values.</simpara>
<simpara>The <literal>null_value</literal> parameter allows you to replace explicit <literal>null</literal> values with
the specified value so that it can be indexed and searched.  For instance:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "status_code": {
          "type":       "keyword",
          "null_value": "NULL" <co id="CO213-1"/>
        }
      }
    }
  }
}

PUT my_index/my_type/1
{
  "status_code": null
}

PUT my_index/my_type/2
{
  "status_code": [] <co id="CO213-2"/>
}

GET my_index/_search
{
  "query": {
    "term": {
      "status_code": "NULL" <co id="CO213-3"/>
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO213-1">
<para>
Replace explicit <literal>null</literal> values with the term <literal>NULL</literal>.
</para>
</callout>
<callout arearefs="CO213-2">
<para>
An empty array does not contain an explicit <literal>null</literal>, and so won&#8217;t be replaced with the <literal>null_value</literal>.
</para>
</callout>
<callout arearefs="CO213-3">
<para>
A query for <literal>NULL</literal> returns document 1, but not document 2.
</para>
</callout>
</calloutlist>
<important><simpara>The <literal>null_value</literal> needs to be the same datatype as the field.  For
instance, a <literal>long</literal> field cannot have a string <literal>null_value</literal>.</simpara></important>
</section>
<section id="position-increment-gap">
<title><literal>position_increment_gap</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/position-increment-gap.asciidoc">Edit me</ulink></title>
<simpara><link linkend="mapping-index">Analyzed</link> text fields take term <link linkend="index-options">positions</link>
into account, in order to be able to support
<link linkend="query-dsl-match-query-phrase">proximity or phrase queries</link>.
When indexing text fields with multiple values a "fake" gap is added between
the values to prevent most phrase queries from matching across the values. The
size of this gap is configured using <literal>position_increment_gap</literal> and defaults to
<literal>100</literal>.</simpara>
<simpara>For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index/groups/1
{
    "names": [ "John Abraham", "Lincoln Smith"]
}

GET my_index/groups/_search
{
    "query": {
        "match_phrase": {
            "names": {
                "query": "Abraham Lincoln" <co id="CO214-1"/>
            }
        }
    }
}

GET my_index/groups/_search
{
    "query": {
        "match_phrase": {
            "names": {
                "query": "Abraham Lincoln",
                "slop": 101 <co id="CO214-2"/>
            }
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO214-1">
<para>
This phrase query doesn&#8217;t match our document which is totally expected.
</para>
</callout>
<callout arearefs="CO214-2">
<para>
This phrase query matches our document, even though <literal>Abraham</literal> and <literal>Lincoln</literal>
    are in separate strings, because <literal>slop</literal> &gt; <literal>position_increment_gap</literal>.
</para>
</callout>
</calloutlist>
<simpara>The <literal>position_increment_gap</literal> can be specified in the mapping.  For instance:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "groups": {
      "properties": {
        "names": {
          "type": "text",
          "position_increment_gap": 0 <co id="CO215-1"/>
        }
      }
    }
  }
}

PUT my_index/groups/1
{
    "names": [ "John Abraham", "Lincoln Smith"]
}

GET my_index/groups/_search
{
    "query": {
        "match_phrase": {
            "names": "Abraham Lincoln" <co id="CO215-2"/>
        }
    }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO215-1">
<para>
The first term in the next array element will be 0 terms apart from the
    last term in the previous array element.
</para>
</callout>
<callout arearefs="CO215-2">
<para>
The phrase query matches our document which is weird, but its what we asked
    for in the mapping.
</para>
</callout>
</calloutlist>
<tip><simpara>The <literal>position_increment_gap</literal> setting is allowed to have different settings
for fields of the same name in the same index.  Its value can be updated on
existing fields using the <link linkend="indices-put-mapping">PUT mapping API</link>.</simpara></tip>
</section>
<section id="properties">
<title><literal>properties</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/properties.asciidoc">Edit me</ulink></title>
<simpara>Type mappings, <link linkend="object"><literal>object</literal> fields</link> and <link linkend="nested"><literal>nested</literal> fields</link>
contain sub-fields, called <literal>properties</literal>. These properties may be of any
<link linkend="mapping-types">datatype</link>, including <literal>object</literal> and <literal>nested</literal>.  Properties can
be added:</simpara>
<itemizedlist>
<listitem>
<simpara>
explicitly by defining them when <link linkend="indices-create-index">creating an index</link>.
</simpara>
</listitem>
<listitem>
<simpara>
explicitly by defining them when adding or updating a mapping type with the <link linkend="indices-put-mapping">PUT mapping</link> API.
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="dynamic-mapping">dynamically</link> just by indexing documents containing new fields.
</simpara>
</listitem>
</itemizedlist>
<simpara>Below is an example of adding <literal>properties</literal> to a mapping type, an <literal>object</literal>
field, and a <literal>nested</literal> field:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": { <co id="CO216-1"/>
      "properties": {
        "manager": { <co id="CO216-2"/>
          "properties": {
            "age":  { "type": "integer" },
            "name": { "type": "text"  }
          }
        },
        "employees": { <co id="CO216-3"/>
          "type": "nested",
          "properties": {
            "age":  { "type": "integer" },
            "name": { "type": "text"  }
          }
        }
      }
    }
  }
}

PUT my_index/my_type/1 <co id="CO216-4"/>
{
  "region": "US",
  "manager": {
    "name": "Alice White",
    "age": 30
  },
  "employees": [
    {
      "name": "John Smith",
      "age": 34
    },
    {
      "name": "Peter Brown",
      "age": 26
    }
  ]
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO216-1">
<para>
Properties under the <literal>my_type</literal> mapping type.
</para>
</callout>
<callout arearefs="CO216-2">
<para>
Properties under the <literal>manager</literal> object field.
</para>
</callout>
<callout arearefs="CO216-3">
<para>
Properties under the <literal>employees</literal> nested field.
</para>
</callout>
<callout arearefs="CO216-4">
<para>
An example document which corresponds to the above mapping.
</para>
</callout>
</calloutlist>
<tip><simpara>The <literal>properties</literal> setting is allowed to have different settings for fields
of the same name in the same index.  New properties can be added to existing
fields using the <link linkend="indices-put-mapping">PUT mapping API</link>.</simpara></tip>
<section id="_dot_notation">
<title>Dot notation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/properties.asciidoc">Edit me</ulink></title>
<simpara>Inner fields can be referred to in queries, aggregations, etc., using <emphasis>dot
notation</emphasis>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET my_index/_search
{
  "query": {
    "match": {
      "manager.name": "Alice White" <co id="CO217-1"/>
    }
  },
  "aggs": {
    "Employees": {
      "nested": {
        "path": "employees"
      },
      "aggs": {
        "Employee Ages": {
          "histogram": {
            "field": "employees.age", <co id="CO217-2"/>
            "interval": 5
          }
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<important><simpara>The full path to the inner field must be specified.</simpara></important>
</section>
</section>
<section id="search-analyzer">
<title><literal>search_analyzer</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/search-analyzer.asciidoc">Edit me</ulink></title>
<simpara>Usually, the same <link linkend="analyzer">analyzer</link> should be applied at index time and at
search time, to ensure that the terms in the query are in the same format as
the terms in the inverted index.</simpara>
<simpara>Sometimes, though, it can make sense to use a different analyzer at search
time, such as when using the  <link linkend="analysis-edgengram-tokenizer"><literal>edge_ngram</literal></link>
tokenizer for autocomplete.</simpara>
<simpara>By default, queries will use the <literal>analyzer</literal> defined in the field mapping, but
this can be overridden with the <literal>search_analyzer</literal> setting:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "analysis": {
      "filter": {
        "autocomplete_filter": {
          "type": "edge_ngram",
          "min_gram": 1,
          "max_gram": 20
        }
      },
      "analyzer": {
        "autocomplete": { <co id="CO217-3"/>
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "autocomplete_filter"
          ]
        }
      }
    }
  },
  "mappings": {
    "my_type": {
      "properties": {
        "text": {
          "type": "text",
          "analyzer": "autocomplete", <co id="CO217-4"/>
          "search_analyzer": "standard" <co id="CO217-5"/>
        }
      }
    }
  }
}

PUT my_index/my_type/1
{
  "text": "Quick Brown Fox" <co id="CO217-6"/>
}

GET my_index/_search
{
  "query": {
    "match": {
      "text": {
        "query": "Quick Br", <co id="CO217-7"/>
        "operator": "and"
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO217-1 CO217-3">
<para>
Analysis settings to define the custom <literal>autocomplete</literal> analyzer.
</para>
</callout>
<callout arearefs="CO217-2 CO217-4 CO217-5">
<para>
The <literal>text</literal> field uses the <literal>autocomplete</literal> analyzer at index time, but the <literal>standard</literal> analyzer at search time.
</para>
</callout>
<callout arearefs="CO217-6">
<para>
This field is indexed as the terms: [ <literal>q</literal>, <literal>qu</literal>, <literal>qui</literal>, <literal>quic</literal>, <literal>quick</literal>, <literal>b</literal>, <literal>br</literal>, <literal>bro</literal>, <literal>brow</literal>, <literal>brown</literal>, <literal>f</literal>, <literal>fo</literal>, <literal>fox</literal> ]
</para>
</callout>
<callout arearefs="CO217-7">
<para>
The query searches for both of these terms: [ <literal>quick</literal>, <literal>br</literal> ]
</para>
</callout>
</calloutlist>
<simpara>See <ulink url="https://www.elastic.co/guide/en/elasticsearch/guide/master/_index_time_search_as_you_type.html">Index time search-as-you-
type</ulink> for a full explanation of this example.</simpara>
<tip><simpara>The <literal>search_analyzer</literal> setting must have the same setting for fields of
the same name in the same index.  Its value can be updated on existing fields
using the <link linkend="indices-put-mapping">PUT mapping API</link>.</simpara></tip>
</section>
<section id="similarity">
<title><literal>similarity</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/similarity.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch allows you to configure a scoring algorithm or <emphasis>similarity</emphasis> per
field. The <literal>similarity</literal> setting provides a simple way of choosing a similarity
algorithm other than the default TF/IDF, such as <literal>BM25</literal>.</simpara>
<simpara>Similarities are mostly useful for <link linkend="text"><literal>text</literal></link> fields, but can also apply
to other field types.</simpara>
<simpara>Custom similarities can be configured by tuning the parameters of the built-in
similarities. For more details about this expert options, see the
<link linkend="index-modules-similarity">similarity module</link>.</simpara>
<simpara>The only similarities which can be used out of the box, without any further
configuration are:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>BM25</literal>
</term>
<listitem>
<simpara>
        The Okapi BM25 algorithm. The algorithm used by default in Elasticsearch and Lucene.
        See <ulink url="https://www.elastic.co/guide/en/elasticsearch/guide/master/pluggable-similarites.html">Pluggable Similarity Algorithms</ulink>
        for more information.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>classic</literal>
</term>
<listitem>
<simpara>
        The TF/IDF algorithm which used to be the default in Elasticsearch and
        Lucene. See <ulink url="https://www.elastic.co/guide/en/elasticsearch/guide/master/practical-scoring-function.html">Lucene’s Practical Scoring Function</ulink>
        for more information.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>The <literal>similarity</literal> can be set on the field level when a field is first created,
as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "default_field": { <co id="CO218-1"/>
          "type": "text"
        },
        "classic_field": {
          "type": "text",
          "similarity": "classic" <co id="CO218-2"/>
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO218-1">
<para>
The <literal>default_field</literal> uses the <literal>BM25</literal> similarity.
</para>
</callout>
<callout arearefs="CO218-2">
<para>
The <literal>classic_field</literal> uses the <literal>classic</literal> similarity (ie TF/IDF).
</para>
</callout>
</calloutlist>
</section>
<section id="mapping-store">
<title><literal>store</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/store.asciidoc">Edit me</ulink></title>
<simpara>By default, field values are <link linkend="mapping-index">indexed</link> to make them searchable,
but they are not <emphasis>stored</emphasis>.  This means that the field can be queried, but the
original field value cannot be retrieved.</simpara>
<simpara>Usually this doesn&#8217;t matter.  The field value is already part of the
<link linkend="mapping-source-field"><literal>_source</literal> field</link>, which is stored by default. If you
only want to retrieve the value of a single field or of a few fields, instead
of the whole <literal>_source</literal>, then this can be achieved with
<link linkend="search-request-source-filtering">source filtering</link>.</simpara>
<simpara>In certain situations it can make sense to <literal>store</literal> a field.  For instance, if
you have a document with a <literal>title</literal>, a <literal>date</literal>, and a very large <literal>content</literal>
field, you may want to retrieve just the <literal>title</literal> and the <literal>date</literal> without having
to extract those fields from a large <literal>_source</literal> field:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "title": {
          "type": "text",
          "store": true <co id="CO219-1"/>
        },
        "date": {
          "type": "date",
          "store": true <co id="CO219-2"/>
        },
        "content": {
          "type": "text"
        }
      }
    }
  }
}

PUT my_index/my_type/1
{
  "title":   "Some short title",
  "date":    "2015-01-01",
  "content": "A very long content field..."
}

GET my_index/_search
{
  "stored_fields": [ "title", "date" ] <co id="CO219-3"/>
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO219-1 CO219-2">
<para>
The <literal>title</literal> and <literal>date</literal> fields are stored.
</para>
</callout>
<callout arearefs="CO219-3">
<para>
This request will retrieve the values of the <literal>title</literal> and <literal>date</literal> fields.
</para>
</callout>
</calloutlist>
<note>
<title>Stored fields returned as arrays</title>
<simpara>For consistency, stored fields are always returned as an <emphasis>array</emphasis> because there
is no way of knowing if the original field value was a single value, multiple
values, or an empty array.</simpara>
<simpara>If you need the original value, you should retrieve it from the <literal>_source</literal>
field instead.</simpara>
</note>
<simpara>Another situation where it can make sense to make a field stored is for those
that don&#8217;t appear in the <literal>_source</literal> field (such as <link linkend="copy-to"><literal>copy_to</literal> fields</link>).</simpara>
</section>
<section id="term-vector">
<title><literal>term_vector</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/params/term-vector.asciidoc">Edit me</ulink></title>
<simpara>Term vectors contain information about the terms produced by the
<link linkend="analysis">analysis</link> process, including:</simpara>
<itemizedlist>
<listitem>
<simpara>
a list of terms.
</simpara>
</listitem>
<listitem>
<simpara>
the position (or order) of each term.
</simpara>
</listitem>
<listitem>
<simpara>
the start and end character offsets mapping the term to its
  origin in the original string.
</simpara>
</listitem>
</itemizedlist>
<simpara>These term vectors can be stored so that they can be retrieved for a
particular document.</simpara>
<simpara>The <literal>term_vector</literal> setting accepts:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>no</literal>
</simpara>
</entry>
<entry>
<simpara>
No term vectors are stored. (default)
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>yes</literal>
</simpara>
</entry>
<entry>
<simpara>
Just the terms in the field are stored.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>with_positions</literal>
</simpara>
</entry>
<entry>
<simpara>
Terms and positions are stored.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>with_offsets</literal>
</simpara>
</entry>
<entry>
<simpara>
Terms and character offsets are stored.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>with_positions_offsets</literal>
</simpara>
</entry>
<entry>
<simpara>
Terms, positions, and character offsets are stored.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>The fast vector highlighter requires <literal>with_positions_offsets</literal>.  The term
vectors API can retrieve whatever is stored.</simpara>
<warning><simpara>Setting <literal>with_positions_offsets</literal> will double the size of a field&#8217;s
index.</simpara></warning>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "text": {
          "type":        "text",
          "term_vector": "with_positions_offsets"
        }
      }
    }
  }
}

PUT my_index/my_type/1
{
  "text": "Quick brown fox"
}

GET my_index/_search
{
  "query": {
    "match": {
      "text": "brown fox"
    }
  },
  "highlight": {
    "fields": {
      "text": {} <co id="CO220-1"/>
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO220-1">
<para>
The fast vector highlighter will be used by default for the <literal>text</literal> field
    because term vectors are enabled.
</para>
</callout>
</calloutlist>
</section>
</chapter>
<chapter id="dynamic-mapping">
<title>Dynamic Mapping<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/dynamic-mapping.asciidoc">Edit me</ulink></title>
<simpara>One of the most important features of Elasticsearch is that it tries to get
out of your way and let you start exploring your data as quickly as possible.
To index a document, you don&#8217;t have to first create an index, define a mapping
type, and define your fields&#8201;&#8212;&#8201;you can just index a document and the index,
type, and fields will spring to life automatically:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT data/counters/1 <co id="CO221-1"/>
{ "count": 5 }</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO221-1">
<para>
Creates the <literal>data</literal> index, the <literal>counters</literal> mapping type, and a field
    called <literal>count</literal> with datatype <literal>long</literal>.
</para>
</callout>
</calloutlist>
<simpara>The automatic detection and addition of new types and fields is called
<emphasis>dynamic mapping</emphasis>. The dynamic mapping rules can be customised to suit your
purposes with:</simpara>
<variablelist>
<varlistentry>
<term>
<link linkend="default-mapping"><literal>_default_</literal> mapping</link>
</term>
<listitem>
<simpara>
    Configure the base mapping to be used for new mapping types.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="dynamic-field-mapping">Dynamic field mappings</link>
</term>
<listitem>
<simpara>
    The rules governing dynamic field detection.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="dynamic-templates">Dynamic templates</link>
</term>
<listitem>
<simpara>
    Custom rules to configure the mapping for dynamically added fields.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<tip><simpara><link linkend="indices-templates">Index templates</link> allow you to configure the default
mappings, settings and aliases for new indices, whether created
automatically or explicitly.</simpara></tip>
<bridgehead id="_disabling_automatic_type_creation" renderas="sect2">Disabling automatic type creation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/dynamic-mapping.asciidoc">Edit me</ulink></bridgehead>
<simpara>Automatic type creation can be disabled per-index by setting the <literal>index.mapper.dynamic</literal>
setting to <literal>false</literal> in the index settings:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT data/_settings
{
  "index.mapper.dynamic":false <co id="CO222-1"/>
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<calloutlist>
<callout arearefs="CO222-1">
<para>
Disable automatic type creation for the index named "data".
</para>
</callout>
</calloutlist>
<simpara>Automatic type creation can also be disabled for all indices by setting an index template:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT _template/template_all
{
  "template": "*",
  "order":0,
  "settings": {
    "index.mapper.dynamic": false <co id="CO223-1"/>
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<calloutlist>
<callout arearefs="CO223-1">
<para>
Disable automatic type creation for all indices.
</para>
</callout>
</calloutlist>
<simpara>Regardless of the value of this setting, types can still be added explicitly
when <link linkend="indices-create-index">creating an index</link> or with the
<link linkend="indices-put-mapping">PUT mapping</link> API.</simpara>
<section id="default-mapping">
<title><literal>_default_</literal> mapping<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/dynamic/default-mapping.asciidoc">Edit me</ulink></title>
<simpara>The default mapping, which will be used as the base mapping for any new
mapping types, can be customised by adding a mapping type with the name
<literal>_default_</literal> to an index, either when
<link linkend="indices-create-index">creating the index</link> or later on with the
<link linkend="indices-put-mapping">PUT mapping</link> API.</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "_default_": { <co id="CO224-1"/>
      "_all": {
        "enabled": false
      }
    },
    "user": {}, <co id="CO224-2"/>
    "blogpost": { <co id="CO224-3"/>
      "_all": {
        "enabled": true
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO224-1">
<para>
The <literal>_default_</literal> mapping defaults the <link linkend="mapping-all-field"><literal>_all</literal></link> field to disabled.
</para>
</callout>
<callout arearefs="CO224-2">
<para>
The <literal>user</literal> type inherits the settings from <literal>_default_</literal>.
</para>
</callout>
<callout arearefs="CO224-3">
<para>
The <literal>blogpost</literal> type overrides the defaults and enables the <link linkend="mapping-all-field"><literal>_all</literal></link> field.
</para>
</callout>
</calloutlist>
<note><simpara>When updating the <literal>_default_</literal> mapping with the
<link linkend="indices-put-mapping">PUT mapping</link> API, the new mapping is not merged with
the existing mapping.  Instead, the new <literal>_default_</literal> mapping replaces the
existing one.</simpara></note>
<simpara>While the <literal>_default_</literal> mapping can be updated after an index has been created,
the new defaults will only affect mapping types that are created afterwards.</simpara>
<simpara>The <literal>_default_</literal> mapping can be used in conjunction with
<link linkend="indices-templates">Index templates</link> to control dynamically created types
within automatically created indices:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT _template/logging
{
  "template":   "logs-*", <co id="CO225-1"/>
  "settings": { "number_of_shards": 1 }, <co id="CO225-2"/>
  "mappings": {
    "_default_": {
      "_all": { <co id="CO225-3"/>
        "enabled": false
      },
      "dynamic_templates": [
        {
          "strings": { <co id="CO225-4"/>
            "match_mapping_type": "string",
            "mapping": {
              "type": "text",
              "fields": {
                "raw": {
                  "type":  "keyword",
                  "ignore_above": 256
                }
              }
            }
          }
        }
      ]
    }
  }
}

PUT logs-2015.10.01/event/1
{ "message": "error:16" }</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO225-1">
<para>
The <literal>logging</literal> template will match any indices beginning with <literal>logs-</literal>.
</para>
</callout>
<callout arearefs="CO225-2">
<para>
Matching indices will be created with a single primary shard.
</para>
</callout>
<callout arearefs="CO225-3">
<para>
The <literal>_all</literal> field will be disabled by default for new type mappings.
</para>
</callout>
<callout arearefs="CO225-4">
<para>
String fields will be created with a <literal>text</literal> main field, and a <literal>keyword</literal> <literal>.raw</literal> field.
</para>
</callout>
</calloutlist>
</section>
<section id="dynamic-field-mapping">
<title>Dynamic field mapping<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/dynamic/field-mapping.asciidoc">Edit me</ulink></title>
<simpara>By default, when a previously unseen field is found in a document,
Elasticsearch will add the new field to the type mapping.   This behaviour can
be disabled, both at the document and at the <link linkend="object"><literal>object</literal></link>  level, by
setting the <link linkend="dynamic"><literal>dynamic</literal></link> parameter to <literal>false</literal> or to <literal>strict</literal>.</simpara>
<simpara>Assuming <literal>dynamic</literal> field mapping is enabled, some simple rules are used to
determine which datatype the field should have:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<emphasis role="strong">JSON datatype</emphasis>
</simpara>
</entry>
<entry>
<simpara>
<emphasis role="strong">Elasticsearch datatype</emphasis>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>null</literal>
</simpara>
</entry>
<entry>
<simpara>
No field is added.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>true</literal> or <literal>false</literal>
</simpara>
</entry>
<entry>
<simpara>
<link linkend="boolean"><literal>boolean</literal></link> field
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
floating&#160;point&#160;number
</simpara>
</entry>
<entry>
<simpara>
<link linkend="number"><literal>float</literal></link> field
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
integer
</simpara>
</entry>
<entry>
<simpara>
<link linkend="number"><literal>long</literal></link> field
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
object
</simpara>
</entry>
<entry>
<simpara>
<link linkend="object"><literal>object</literal></link> field
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
array
</simpara>
</entry>
<entry>
<simpara>
Depends on the first non-<literal>null</literal> value in the array.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
string
</simpara>
</entry>
<entry>
<simpara>
Either a <link linkend="date"><literal>date</literal></link> field
                                        (if the value passes <link linkend="date-detection">date detection</link>),
                                    a <link linkend="number"><literal>double</literal></link> or <link linkend="number"><literal>long</literal></link> field
                                        (if the value passes <link linkend="numeric-detection">numeric detection</link>)
                                    or a <link linkend="text"><literal>text</literal></link> field, with a <link linkend="keyword"><literal>keyword</literal></link> sub-field.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>These are the only <link linkend="mapping-types">field datatypes</link> that are dynamically
detected.  All other datatypes must be mapped explicitly.</simpara>
<simpara>Besides the options listed below, dynamic field mapping rules can be further
customised with <link linkend="dynamic-templates"><literal>dynamic_templates</literal></link>.</simpara>
<section id="date-detection">
<title>Date detection<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/dynamic/field-mapping.asciidoc">Edit me</ulink></title>
<simpara>If <literal>date_detection</literal> is enabled (default), then new string fields are checked
to see whether their contents match any of the date patterns specified in
<literal>dynamic_date_formats</literal>.  If a match is found, a new <link linkend="date"><literal>date</literal></link> field is
added with the corresponding format.</simpara>
<simpara>The default value for <literal>dynamic_date_formats</literal> is:</simpara>
<simpara>&#91; <link linkend="strict-date-time"><literal>"strict_date_optional_time"</literal></link>,<literal>"yyyy/MM/dd HH:mm:ss Z||yyyy/MM/dd Z"</literal>]</simpara>
<simpara>For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index/my_type/1
{
  "create_date": "2015/09/02"
}

GET my_index/_mapping <co id="CO226-1"/></programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO226-1">
<para>
The <literal>create_date</literal> field has been added as a <link linkend="date"><literal>date</literal></link>
    field with the <link linkend="mapping-date-format"><literal>format</literal></link>:<?asciidoc-br?>
    <literal>"yyyy/MM/dd HH:mm:ss Z||yyyy/MM/dd Z"</literal>.
</para>
</callout>
</calloutlist>
<section id="_disabling_date_detection">
<title>Disabling date detection<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/dynamic/field-mapping.asciidoc">Edit me</ulink></title>
<simpara>Dynamic date detection can be disabled by setting <literal>date_detection</literal> to <literal>false</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "date_detection": false
    }
  }
}

PUT my_index/my_type/1 <co id="CO227-1"/>
{
  "create": "2015/09/02"
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO227-1">
<para>
The <literal>create_date</literal> field has been added as a <link linkend="text"><literal>text</literal></link> field.
</para>
</callout>
</calloutlist>
</section>
<section id="_customising_detected_date_formats">
<title>Customising detected date formats<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/dynamic/field-mapping.asciidoc">Edit me</ulink></title>
<simpara>Alternatively, the <literal>dynamic_date_formats</literal> can be customised to support your
own <link linkend="mapping-date-format">date formats</link>:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "dynamic_date_formats": ["MM/dd/yyyy"]
    }
  }
}

PUT my_index/my_type/1
{
  "create_date": "09/25/2015"
}</programlisting>
<remark> CONSOLE</remark>
</section>
</section>
<section id="numeric-detection">
<title>Numeric detection<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/dynamic/field-mapping.asciidoc">Edit me</ulink></title>
<simpara>While JSON has support for native floating point and integer datatypes, some
applications or languages may sometimes render numbers as strings. Usually the
correct solution is to map these fields explicitly, but numeric detection
(which is disabled by default) can be enabled to do this automatically:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "numeric_detection": true
    }
  }
}

PUT my_index/my_type/1
{
  "my_float":   "1.0", <co id="CO228-1"/>
  "my_integer": "1" <co id="CO228-2"/>
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO228-1">
<para>
The <literal>my_float</literal> field is added as a <link linkend="number"><literal>double</literal></link> field.
</para>
</callout>
<callout arearefs="CO228-2">
<para>
The <literal>my_integer</literal> field is added as a <link linkend="number"><literal>long</literal></link> field.
</para>
</callout>
</calloutlist>
</section>
</section>
<section id="dynamic-templates">
<title>Dynamic templates<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/dynamic/templates.asciidoc">Edit me</ulink></title>
<simpara>Dynamic templates allow you to define custom mappings that can be applied to
dynamically added fields based on:</simpara>
<itemizedlist>
<listitem>
<simpara>
the <link linkend="dynamic-mapping">datatype</link> detected by Elasticsearch, with <link linkend="match-mapping-type"><literal>match_mapping_type</literal></link>.
</simpara>
</listitem>
<listitem>
<simpara>
the name of the field, with <link linkend="match-unmatch"><literal>match</literal> and <literal>unmatch</literal></link> or <link linkend="match-pattern"><literal>match_pattern</literal></link>.
</simpara>
</listitem>
<listitem>
<simpara>
the full dotted path to the field, with <link linkend="path-match-unmatch"><literal>path_match</literal> and <literal>path_unmatch</literal></link>.
</simpara>
</listitem>
</itemizedlist>
<simpara>The original field name <literal>{name}</literal> and the detected datatype
<literal>{dynamic_type</literal>} <link linkend="template-variables">template variables</link> can be used in
the mapping specification as placeholders.</simpara>
<important><simpara>Dynamic field mappings are only added when a field contains a
concrete value&#8201;&#8212;&#8201;not <literal>null</literal> or an empty array. This means that if the
<literal>null_value</literal> option  is used in a <literal>dynamic_template</literal>, it will only be applied
after the first document  with a concrete value for the field has been
indexed.</simpara></important>
<simpara>Dynamic templates are specified as an array of named objects:</simpara>
<programlisting language="js" linenumbering="unnumbered">  "dynamic_templates": [
    {
      "my_template_name": { <co id="CO229-1"/>
        ...  match conditions ... <co id="CO229-2"/>
        "mapping": { ... } <co id="CO229-3"/>
      }
    },
    ...
  ]</programlisting>
<calloutlist>
<callout arearefs="CO229-1">
<para>
The template name can be any string value.
</para>
</callout>
<callout arearefs="CO229-2">
<para>
The match conditions can include any of : <literal>match_mapping_type</literal>, <literal>match</literal>, <literal>match_pattern</literal>, <literal>unmatch</literal>, <literal>path_match</literal>, <literal>path_unmatch</literal>.
</para>
</callout>
<callout arearefs="CO229-3">
<para>
The mapping that the matched field should use.
</para>
</callout>
</calloutlist>
<simpara>Templates are processed in order&#8201;&#8212;&#8201;the first matching template wins. New
templates can be appended to the end of the list with the
<link linkend="indices-put-mapping">PUT mapping</link> API.  If a new template has the same
name as an existing template, it will replace the old version.</simpara>
<section id="match-mapping-type">
<title><literal>match_mapping_type</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/dynamic/templates.asciidoc">Edit me</ulink></title>
<simpara>The <literal>match_mapping_type</literal> matches on the datatype detected by
<link linkend="dynamic-field-mapping">dynamic field mapping</link>, in other words, the datatype
that Elasticsearch thinks the field should have.  Only the following datatypes
can be automatically detected: <literal>boolean</literal>, <literal>date</literal>, <literal>double</literal>, <literal>long</literal>, <literal>object</literal>,
<literal>string</literal>.  It also accepts <literal>*</literal> to match all datatypes.</simpara>
<simpara>For example, if we wanted to map all integer fields as <literal>integer</literal> instead of
<literal>long</literal>, and all <literal>string</literal> fields as both <literal>text</literal> and <literal>keyword</literal>, we
could use the following template:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "dynamic_templates": [
        {
          "integers": {
            "match_mapping_type": "long",
            "mapping": {
              "type": "integer"
            }
          }
        },
        {
          "strings": {
            "match_mapping_type": "string",
            "mapping": {
              "type": "text",
              "fields": {
                "raw": {
                  "type":  "keyword",
                  "ignore_above": 256
                }
              }
            }
          }
        }
      ]
    }
  }
}

PUT my_index/my_type/1
{
  "my_integer": 5, <co id="CO230-1"/>
  "my_string": "Some string" <co id="CO230-2"/>
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO230-1">
<para>
The <literal>my_integer</literal> field is mapped as an <literal>integer</literal>.
</para>
</callout>
<callout arearefs="CO230-2">
<para>
The <literal>my_string</literal> field is mapped as a <literal>text</literal>, with a <literal>keyword</literal> <link linkend="multi-fields">multi field</link>.
</para>
</callout>
</calloutlist>
</section>
<section id="match-unmatch">
<title><literal>match</literal> and <literal>unmatch</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/dynamic/templates.asciidoc">Edit me</ulink></title>
<simpara>The <literal>match</literal> parameter uses a pattern to match on the fieldname, while
<literal>unmatch</literal> uses a pattern to exclude fields matched by <literal>match</literal>.</simpara>
<simpara>The following example matches all <literal>string</literal> fields whose name starts with
<literal>long_</literal> (except for those which end with <literal>_text</literal>) and maps them as <literal>long</literal>
fields:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "dynamic_templates": [
        {
          "longs_as_strings": {
            "match_mapping_type": "string",
            "match":   "long_*",
            "unmatch": "*_text",
            "mapping": {
              "type": "long"
            }
          }
        }
      ]
    }
  }
}

PUT my_index/my_type/1
{
  "long_num": "5", <co id="CO231-1"/>
  "long_text": "foo" <co id="CO231-2"/>
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO231-1">
<para>
The <literal>long_num</literal> field is mapped as a <literal>long</literal>.
</para>
</callout>
<callout arearefs="CO231-2">
<para>
The <literal>long_text</literal> field uses the default <literal>string</literal> mapping.
</para>
</callout>
</calloutlist>
</section>
<section id="match-pattern">
<title><literal>match_pattern</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/dynamic/templates.asciidoc">Edit me</ulink></title>
<simpara>The <literal>match_pattern</literal> parameter adjusts the behavior of the <literal>match</literal> parameter
such that it supports full Java regular expression matching on the field name
instead of simple wildcards, for instance:</simpara>
<programlisting language="js" linenumbering="unnumbered">  "match_pattern": "regex",
  "match": "^profit_\d+$"</programlisting>
</section>
<section id="path-match-unmatch">
<title><literal>path_match</literal> and <literal>path_unmatch</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/dynamic/templates.asciidoc">Edit me</ulink></title>
<simpara>The <literal>path_match</literal> and <literal>path_unmatch</literal> parameters work in the same way as <literal>match</literal>
and <literal>unmatch</literal>, but operate on the full dotted path to the field, not just the
final name, e.g. <literal>some_object.*.some_field</literal>.</simpara>
<simpara>This example copies the values of any fields in the <literal>name</literal> object to the
top-level <literal>full_name</literal> field, except for the <literal>middle</literal> field:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "dynamic_templates": [
        {
          "full_name": {
            "path_match":   "name.*",
            "path_unmatch": "*.middle",
            "mapping": {
              "type":       "text",
              "copy_to":    "full_name"
            }
          }
        }
      ]
    }
  }
}

PUT my_index/my_type/1
{
  "name": {
    "first":  "Alice",
    "middle": "Mary",
    "last":   "White"
  }
}</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="template-variables">
<title><literal>{name}</literal> and <literal>{dynamic_type}</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/dynamic/templates.asciidoc">Edit me</ulink></title>
<simpara>The <literal>{name}</literal> and <literal>{dynamic_type}</literal> placeholders are replaced in the <literal>mapping</literal>
with the field name and detected dynamic type.  The following example sets all
string fields to use an <link linkend="analyzer"><literal>analyzer</literal></link> with the same name as the
field, and disables <link linkend="doc-values"><literal>doc_values</literal></link> for all non-string fields:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "dynamic_templates": [
        {
          "named_analyzers": {
            "match_mapping_type": "string",
            "match": "*",
            "mapping": {
              "type": "text",
              "analyzer": "{name}"
            }
          }
        },
        {
          "no_doc_values": {
            "match_mapping_type":"*",
            "mapping": {
              "type": "{dynamic_type}",
              "doc_values": false
            }
          }
        }
      ]
    }
  }
}

PUT my_index/my_type/1
{
  "english": "Some English text", <co id="CO232-1"/>
  "count":   5 <co id="CO232-2"/>
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO232-1">
<para>
The <literal>english</literal> field is mapped as a <literal>string</literal> field with the <literal>english</literal> analyzer.
</para>
</callout>
<callout arearefs="CO232-2">
<para>
The <literal>count</literal> field is mapped as a <literal>long</literal> field with <literal>doc_values</literal> disabled
</para>
</callout>
</calloutlist>
</section>
<section id="template-examples">
<title>Template examples<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/dynamic/templates.asciidoc">Edit me</ulink></title>
<simpara>Here are some examples of potentially useful dynamic templates:</simpara>
<section id="_structured_search">
<title>Structured search<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/dynamic/templates.asciidoc">Edit me</ulink></title>
<simpara>By default elasticsearch will map string fields as a <literal>text</literal> field with a sub
<literal>keyword</literal> field. However if you are only indexing structured content and not
interested in full text search, you can make elasticsearch map your fields
only as `keyword`s. Note that this means that in order to search those fields,
you will have to search on the exact same value that was indexed.</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "dynamic_templates": [
        {
          "strings_as_keywords": {
            "match_mapping_type": "string",
            "mapping": {
              "type": "keyword"
            }
          }
        }
      ]
    }
  }
}</programlisting>
</section>
<section id="_literal_text_literal_only_mappings_for_strings">
<title><literal>text</literal>-only mappings for strings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/dynamic/templates.asciidoc">Edit me</ulink></title>
<simpara>On the contrary to the previous example, if the only thing that you care about
on your string fields is full-text search, and if you don&#8217;t plan on running
aggregations, sorting or exact search on your string fields, you could tell
elasticsearch to map it only as a text field (which was the default behaviour
before 5.0):</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "dynamic_templates": [
        {
          "strings_as_text": {
            "match_mapping_type": "string",
            "mapping": {
              "type": "text"
            }
          }
        }
      ]
    }
  }
}</programlisting>
</section>
<section id="_disabled_norms">
<title>Disabled norms<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/dynamic/templates.asciidoc">Edit me</ulink></title>
<simpara>Norms are index-time scoring factors. If you do not care about scoring, which
would be the case for instance if you never sort documents by score, you could
disable the storage of these scoring factors in the index and save some space.</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "dynamic_templates": [
        {
          "strings_as_keywords": {
            "match_mapping_type": "string",
            "mapping": {
              "type": "text",
              "norms": false,
              "fields": {
                "keyword": {
                  "type": "keyword",
                  "ignore_above": 256
                }
              }
            }
          }
        }
      ]
    }
  }
}</programlisting>
<simpara>The sub <literal>keyword</literal> field appears in this template to be consistent with the
default rules of dynamic mappings. Of course if you do not need them because
you don&#8217;t need to perform exact search or aggregate on this field, you could
remove it as described in the previous section.</simpara>
</section>
<section id="_time_series">
<title>Time-series<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/dynamic/templates.asciidoc">Edit me</ulink></title>
<simpara>When doing time series analysis with elasticsearch, it is common to have many
numeric fields that you will often aggregate on but never filter on. In such a
case, you could disable indexing on those fields to save disk space and also
maybe gain some indexing speed:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "dynamic_templates": [
        {
          "unindexed_longs": {
            "match_mapping_type": "long",
            "mapping": {
              "type": "long",
              "index": false
            }
          }
        },
        {
          "unindexed_doubles": {
            "match_mapping_type": "double",
            "mapping": {
              "type": "float", <co id="CO233-1"/>
              "index": false
            }
          }
        }
      ]
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO233-1">
<para>
Like the default dynamic mapping rules, doubles are mapped as floats, which
    are usually accurate enough, yet require half the disk space.
</para>
</callout>
</calloutlist>
</section>
</section>
</section>
<section id="override-default-template">
<title>Override default template<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/mapping/dynamic/templates.asciidoc">Edit me</ulink></title>
<simpara>You can override the default mappings for all indices and all types
by specifying a <literal>_default_</literal> type mapping in an index template
which matches all indices.</simpara>
<simpara>For example, to disable the <literal>_all</literal> field by default for all types in all
new indices, you could create the following index template:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT _template/disable_all_field
{
  "order": 0,
  "template": "*", <co id="CO234-1"/>
  "mappings": {
    "_default_": { <co id="CO234-2"/>
      "_all": { <co id="CO234-3"/>
        "enabled": false
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO234-1">
<para>
Applies the mappings to an <literal>index</literal> which matches the pattern <literal>*</literal>, in other
    words, all new indices.
</para>
</callout>
<callout arearefs="CO234-2">
<para>
Defines the <literal>_default_</literal> type mapping types within the index.
</para>
</callout>
<callout arearefs="CO234-3">
<para>
Disables the <literal>_all</literal> field by default.
</para>
</callout>
</calloutlist>
</section>
</chapter>
</part>
<part id="analysis">
<title>Analysis <ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis.asciidoc">Edit me</ulink></title>
<partintro>
<simpara><emphasis>Analysis</emphasis> is the process of converting text, like the body of any email, into
<emphasis>tokens</emphasis> or <emphasis>terms</emphasis> which are added to the inverted index for searching.
Analysis is performed by an <link linkend="analysis-analyzers"><emphasis>analyzer</emphasis></link> which can be
either a built-in analyzer or a <link linkend="analysis-custom-analyzer"><literal>custom</literal></link> analyzer
defined per index.</simpara>
<bridgehead id="_index_time_analysis" renderas="sect1">Index time analysis<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis.asciidoc">Edit me</ulink></bridgehead>
<simpara>For instance at index time, the built-in <link linkend="english-analyzer"><literal>english</literal></link> <emphasis>analyzer</emphasis> would
convert this sentence:</simpara>
<programlisting language="text" linenumbering="unnumbered">"The QUICK brown foxes jumped over the lazy dog!"</programlisting>
<simpara>into these terms, which would be added to the inverted index.</simpara>
<programlisting language="text" linenumbering="unnumbered">[ quick, brown, fox, jump, over, lazi, dog ]</programlisting>
<bridgehead id="_specifying_an_index_time_analyzer" renderas="sect2">Specifying an index time analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis.asciidoc">Edit me</ulink></bridgehead>
<simpara>Each <link linkend="text"><literal>text</literal></link> field in a mapping can specify its own
<link linkend="analyzer"><literal>analyzer</literal></link>:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "title": {
          "type":     "text",
          "analyzer": "standard"
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>At index time, if no <literal>analyzer</literal> has been specified, it looks for an analyzer
in the index settings called <literal>default</literal>.  Failing that, it defaults to using
the <link linkend="analysis-standard-analyzer"><literal>standard</literal> analyzer</link>.</simpara>
<bridgehead id="_search_time_analysis" renderas="sect1">Search time analysis<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis.asciidoc">Edit me</ulink></bridgehead>
<simpara>This same analysis process is applied to the query string at search time in
<link linkend="full-text-queries">full text queries</link> like the
<link linkend="query-dsl-match-query"><literal>match</literal> query</link>
to convert the text in the query string into terms of the same form as those
that are stored in the inverted index.</simpara>
<simpara>For instance, a user might search for:</simpara>
<programlisting language="text" linenumbering="unnumbered">"a quick fox"</programlisting>
<simpara>which would be analysed by the same <literal>english</literal> analyzer into the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ quick, fox ]</programlisting>
<simpara>Even though the exact words used in the query string don&#8217;t appear in the
original text (<literal>quick</literal> vs <literal>QUICK</literal>, <literal>fox</literal> vs <literal>foxes</literal>), because we have applied
the same analyzer to both the text and the query string, the terms from the
query string exactly match the terms from the text in the inverted index,
which means that this query would match our example document.</simpara>
<bridgehead id="_specifying_a_search_time_analyzer" renderas="sect2">Specifying a search time analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis.asciidoc">Edit me</ulink></bridgehead>
<simpara>Usually the same analyzer should be used both at
index time and at search time, and <link linkend="full-text-queries">full text queries</link>
like the  <link linkend="query-dsl-match-query"><literal>match</literal> query</link> will use the mapping to look
up the analyzer to use for each field.</simpara>
<simpara>The analyzer to use to search a particular field is determined by
looking for:</simpara>
<itemizedlist>
<listitem>
<simpara>
An <literal>analyzer</literal> specified in the query itself.
</simpara>
</listitem>
<listitem>
<simpara>
The <link linkend="search-analyzer"><literal>search_analyzer</literal></link> mapping parameter.
</simpara>
</listitem>
<listitem>
<simpara>
The <link linkend="analyzer"><literal>analyzer</literal></link> mapping parameter.
</simpara>
</listitem>
<listitem>
<simpara>
An analyzer in the index settings called <literal>default_search</literal>.
</simpara>
</listitem>
<listitem>
<simpara>
An analyzer in the index settings called <literal>default</literal>.
</simpara>
</listitem>
<listitem>
<simpara>
The <literal>standard</literal> analyzer.
</simpara>
</listitem>
</itemizedlist>
</partintro>
<chapter id="analyzer-anatomy">
<title>Anatomy of an analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/anatomy.asciidoc">Edit me</ulink></title>
<simpara>An <emphasis>analyzer</emphasis> &#8201;&#8212;&#8201;whether built-in or custom&#8201;&#8212;&#8201;is just a package which
contains three lower-level building blocks: <emphasis>character filters</emphasis>,
<emphasis>tokenizers</emphasis>, and <emphasis>token filters</emphasis>.</simpara>
<simpara>The built-in <link linkend="analysis-analyzers">analyzers</link> pre-package these building
blocks into analyzers suitable for different languages and types of text.
Elasticsearch also exposes the individual building blocks so that they can be
combined to define new <link linkend="analysis-custom-analyzer"><literal>custom</literal></link> analyzers.</simpara>
<bridgehead id="_character_filters" renderas="sect2">Character filters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/anatomy.asciidoc">Edit me</ulink></bridgehead>
<simpara>A <emphasis>character filter</emphasis> receives the original text as a stream of characters and
can transform the stream by adding, removing, or changing characters.  For
instance, a character filter could be used to convert Hindu-Arabic numerals
(٠‎١٢٣٤٥٦٧٨‎٩‎) into their Arabic-Latin equivalents (0123456789), or to strip HTML
elements like <literal>&lt;b&gt;</literal> from the stream.</simpara>
<simpara>An analyzer may have <emphasis role="strong">zero or more</emphasis> <link linkend="analysis-charfilters">character filters</link>,
which are applied in order.</simpara>
<bridgehead id="_tokenizer" renderas="sect2">Tokenizer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/anatomy.asciidoc">Edit me</ulink></bridgehead>
<simpara>A <emphasis>tokenizer</emphasis>  receives a stream of characters, breaks it up into individual
<emphasis>tokens</emphasis> (usually individual words), and outputs a stream of <emphasis>tokens</emphasis>. For
instance, a <link linkend="analysis-whitespace-tokenizer"><literal>whitespace</literal></link> tokenizer breaks
text into tokens whenever it sees any whitespace.  It would convert the text
<literal>"Quick brown fox!"</literal> into the terms <literal>[Quick, brown, fox!]</literal>.</simpara>
<simpara>The tokenizer is also responsible for recording the order or <emphasis>position</emphasis> of
each term and the start and end <emphasis>character offsets</emphasis> of the original word which
the term represents.</simpara>
<simpara>An analyzer must have <emphasis role="strong">exactly one</emphasis> <link linkend="analysis-tokenizers">tokenizer</link>.</simpara>
<bridgehead id="_token_filters" renderas="sect2">Token filters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/anatomy.asciidoc">Edit me</ulink></bridgehead>
<simpara>A <emphasis>token filter</emphasis> receives the token stream and may add, remove, or change
tokens.  For example, a <link linkend="analysis-lowercase-tokenfilter"><literal>lowercase</literal></link> token
filter converts all tokens to lowercase, a
<link linkend="analysis-stop-tokenfilter"><literal>stop</literal></link> token filter removes common words
(<emphasis>stop words</emphasis>) like <literal>the</literal> from the token stream, and a
<link linkend="analysis-synonym-tokenfilter"><literal>synonym</literal></link> token filter introduces synonyms
into the token stream.</simpara>
<simpara>Token filters are not allowed to change the position or character offsets of
each token.</simpara>
<simpara>An analyzer may have <emphasis role="strong">zero or more</emphasis> <link linkend="analysis-tokenfilters">token filters</link>,
which are applied in order.</simpara>
</chapter>
<chapter id="_testing_analyzers">
<title>Testing analyzers<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/testing.asciidoc">Edit me</ulink></title>
<simpara>The <link linkend="indices-analyze"><literal>analyze</literal> API</link> is an invaluable tool for viewing the
terms produced by an analyzer. A built-in analyzer (or combination of built-in
tokenizer, token filters, and character filters) can be specified inline in
the request:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _analyze
{
  "analyzer": "whitespace",
  "text":     "The quick brown fox."
}

POST _analyze
{
  "tokenizer": "standard",
  "filter":  [ "lowercase", "asciifolding" ],
  "text":      "Is this déja vu?"
}</programlisting>
<remark> CONSOLE</remark>
<sidebar>
<title>Positions and character offsets</title>
<simpara>As can be seen from the output of the <literal>analyze</literal> API, analyzers not only
convert words into terms, they also record the order or relative <emphasis>positions</emphasis>
of each term (used for phrase queries or word proximity queries), and the
start and end <emphasis>character offsets</emphasis> of each term in the original text (used for
highlighting search snippets).</simpara>
</sidebar>
<simpara>Alternatively, a <link linkend="analysis-custom-analyzer"><literal>custom</literal> analyzer</link> can be
referred to when running the <literal>analyze</literal> API on a specific index:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "std_folded": { <co id="CO235-1"/>
          "type": "custom",
          "tokenizer": "standard",
          "filter": [
            "lowercase",
            "asciifolding"
          ]
        }
      }
    }
  },
  "mappings": {
    "my_type": {
      "properties": {
        "my_text": {
          "type": "text",
          "analyzer": "std_folded" <co id="CO235-2"/>
        }
      }
    }
  }
}

GET my_index/_analyze <co id="CO235-3"/>
{
  "analyzer": "std_folded", <co id="CO235-4"/>
  "text":     "Is this déjà vu?"
}

GET my_index/_analyze <co id="CO235-5"/>
{
  "field": "my_text", <co id="CO235-6"/>
  "text":  "Is this déjà vu?"
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO235-1">
<para>
Define a <literal>custom</literal> analyzer called <literal>std_folded</literal>.
</para>
</callout>
<callout arearefs="CO235-2">
<para>
The field <literal>my_text</literal> uses the <literal>std_folded</literal> analyzer.
</para>
</callout>
<callout arearefs="CO235-3 CO235-5">
<para>
To refer to this analyzer, the <literal>analyze</literal> API must specify the index name.
</para>
</callout>
<callout arearefs="CO235-4">
<para>
Refer to the analyzer by name.
</para>
</callout>
<callout arearefs="CO235-6">
<para>
Refer to the analyzer used by field <literal>my_text</literal>.
</para>
</callout>
</calloutlist>
</chapter>
<chapter id="analysis-analyzers">
<title>Analyzers<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch ships with a wide range of built-in analyzers, which can be used
in any index without further configuration:</simpara>
<variablelist>
<varlistentry>
<term>
<link linkend="analysis-standard-analyzer">Standard Analyzer</link>
</term>
<listitem>
<simpara>
The <literal>standard</literal> analyzer divides text into terms on word boundaries, as defined
by the Unicode Text Segmentation algorithm. It removes most punctuation,
lowercases terms, and supports removing stop words.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="analysis-simple-analyzer">Simple Analyzer</link>
</term>
<listitem>
<simpara>
The <literal>simple</literal> analyzer divides text into terms whenever it encounters a
character which is not a letter.  It lowercases all terms.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="analysis-whitespace-analyzer">Whitespace Analyzer</link>
</term>
<listitem>
<simpara>
The <literal>whitespace</literal> analyzer divides text into terms whenever it encounters any
whitespace character.  It does not lowercase terms.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="analysis-stop-analyzer">Stop Analyzer</link>
</term>
<listitem>
<simpara>
The <literal>stop</literal> analyzer is like the <literal>simple</literal> analyzer, but also supports removal
of stop words.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="analysis-keyword-analyzer">Keyword Analyzer</link>
</term>
<listitem>
<simpara>
The <literal>keyword</literal> analyzer is a &#8220;noop&#8221; analyzer that accepts whatever text it is
given and outputs the exact same text as a single term.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="analysis-pattern-analyzer">Pattern Analyzer</link>
</term>
<listitem>
<simpara>
The <literal>pattern</literal> analyzer uses a regular expression to split the text into terms.
It supports lower-casing and stop words.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="analysis-lang-analyzer">Language Analyzers</link>
</term>
<listitem>
<simpara>
Elasticsearch provides many language-specific analyzers like <literal>english</literal> or
<literal>french</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="analysis-fingerprint-analyzer">Fingerprint Analyzer</link>
</term>
<listitem>
<simpara>
The <literal>fingerprint</literal> analyzer is a specialist analyzer which creates a
fingerprint which can be used for duplicate detection.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_custom_analyzers" renderas="sect2">Custom analyzers<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers.asciidoc">Edit me</ulink></bridgehead>
<simpara>If you do not find an analyzer suitable for your needs, you can create a
<link linkend="analysis-custom-analyzer"><literal>custom</literal></link> analyzer which combines the appropriate
<link linkend="analysis-charfilters">character filters</link>,
<link linkend="analysis-tokenizers">tokenizer</link>, and <link linkend="analysis-tokenfilters">token filters</link>.</simpara>
<section id="configuring-analyzers">
<title>Configuring built-in analyzers<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/configuring.asciidoc">Edit me</ulink></title>
<simpara>The built-in analyzers can be used directly without any configuration.  Some
of them, however, support configuration options to alter their behaviour.  For
instance, the <link linkend="analysis-standard-analyzer"><literal>standard</literal> analyzer</link> can be configured
to support a list of stop words:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "std_english": { <co id="CO236-1"/>
          "type":      "standard",
          "stopwords": "_english_"
        }
      }
    }
  },
  "mappings": {
    "my_type": {
      "properties": {
        "my_text": {
          "type":     "text",
          "analyzer": "standard", <co id="CO236-2"/>
          "fields": {
            "english": {
              "type":     "text",
              "analyzer": "std_english" <co id="CO236-3"/>
            }
          }
        }
      }
    }
  }
}

POST my_index/_analyze
{
  "field": "my_text", <co id="CO236-4"/>
  "text": "The old brown cow"
}

POST my_index/_analyze
{
  "field": "my_text.english", <co id="CO236-5"/>
  "text": "The old brown cow"
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO236-1">
<para>
We define the <literal>std_english</literal> analyzer to be based on the <literal>standard</literal>
    analyzer, but configured to remove the pre-defined list of English stopwords.
</para>
</callout>
<callout arearefs="CO236-2 CO236-4">
<para>
The <literal>my_text</literal> field uses the <literal>standard</literal> analyzer directly, without
    any configuration.  No stop words will be removed from this field.
    The resulting terms are: <literal>[ the, old, brown, cow ]</literal>
</para>
</callout>
<callout arearefs="CO236-3 CO236-5">
<para>
The <literal>my_text.english</literal> field uses the <literal>std_english</literal> analyzer, so
    English stop words will be removed.  The resulting terms are:
    <literal>[ old, brown, cow ]</literal>
</para>
</callout>
</calloutlist>
</section>
<section id="analysis-standard-analyzer">
<title>Standard Analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/standard-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>standard</literal> analyzer is the default analyzer which is used if none is
specified. It provides grammar based tokenization (based on the Unicode Text
Segmentation algorithm, as specified in
<ulink url="http://unicode.org/reports/tr29/">Unicode Standard Annex #29</ulink>) and works well
for most languages.</simpara>
<bridgehead id="_definition" renderas="sect2">Definition<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/standard-analyzer.asciidoc">Edit me</ulink></bridgehead>
<simpara>It consists of:</simpara>
<variablelist>
<varlistentry>
<term>
Tokenizer
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
<link linkend="analysis-standard-tokenizer">Standard Tokenizer</link>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Token Filters
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
<link linkend="analysis-standard-tokenfilter">Standard Token Filter</link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="analysis-lowercase-tokenfilter">Lower Case Token Filter</link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="analysis-stop-tokenfilter">Stop Token Filter</link> (disabled by default)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_example_output" renderas="sect2">Example output<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/standard-analyzer.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">POST _analyze
{
  "analyzer": "standard",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above sentence would produce the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ the, 2, quick, brown, foxes, jumped, over, the, lazy, dog's, bone ]</programlisting>
<bridgehead id="_configuration" renderas="sect2">Configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/standard-analyzer.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>standard</literal> analyzer accepts the following parameters:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>max_token_length</literal>
</simpara>
</entry>
<entry>
<simpara>
    The maximum token length. If a token is seen that exceeds this length then
    it is split at <literal>max_token_length</literal> intervals. Defaults to <literal>255</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>stopwords</literal>
</simpara>
</entry>
<entry>
<simpara>
    A pre-defined stop words list like <literal>_english_</literal> or an array  containing a
    list of stop words.  Defaults to <literal>\_none_</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>stopwords_path</literal>
</simpara>
</entry>
<entry>
<simpara>
    The path to a file containing stop words.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>See the <link linkend="analysis-stop-tokenfilter">Stop Token Filter</link> for more information
about stop word configuration.</simpara>
<bridgehead id="_example_configuration" renderas="sect2">Example configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/standard-analyzer.asciidoc">Edit me</ulink></bridgehead>
<simpara>In this example, we configure the <literal>standard</literal> analyzer to have a
<literal>max_token_length</literal> of 5 (for demonstration purposes), and to use the
pre-defined list of English stop words:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_english_analyzer": {
          "type": "standard",
          "max_token_length": 5,
          "stopwords": "_english_"
        }
      }
    }
  }
}

POST my_index/_analyze
{
  "analyzer": "my_english_analyzer",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above example produces the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ 2, quick, brown, foxes, jumpe, d, over, lazy, dog's, bone ]</programlisting>
</section>
<section id="analysis-simple-analyzer">
<title>Simple Analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/simple-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>simple</literal> analyzer breaks text into terms whenever it encounters a
character which is not a letter. All terms are lower cased.</simpara>
<bridgehead id="_definition_2" renderas="sect2">Definition<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/simple-analyzer.asciidoc">Edit me</ulink></bridgehead>
<simpara>It consists of:</simpara>
<variablelist>
<varlistentry>
<term>
Tokenizer
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
<link linkend="analysis-lowercase-tokenizer">Lower Case Tokenizer</link>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_example_output_2" renderas="sect2">Example output<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/simple-analyzer.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">POST _analyze
{
  "analyzer": "simple",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above sentence would produce the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ the, quick, brown, foxes, jumped, over, the, lazy, dog, s, bone ]</programlisting>
<bridgehead id="_configuration_2" renderas="sect2">Configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/simple-analyzer.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>simple</literal> analyzer is not configurable.</simpara>
</section>
<section id="analysis-whitespace-analyzer">
<title>Whitespace Analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/whitespace-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>whitespace</literal> analyzer breaks text into terms whenever it encounters a
whitespace character.</simpara>
<bridgehead id="_definition_3" renderas="sect2">Definition<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/whitespace-analyzer.asciidoc">Edit me</ulink></bridgehead>
<simpara>It consists of:</simpara>
<variablelist>
<varlistentry>
<term>
Tokenizer
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
<link linkend="analysis-whitespace-tokenizer">Whitespace Tokenizer</link>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_example_output_3" renderas="sect2">Example output<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/whitespace-analyzer.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">POST _analyze
{
  "analyzer": "whitespace",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above sentence would produce the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ The, 2, QUICK, Brown-Foxes, jumped, over, the, lazy, dog's, bone. ]</programlisting>
<bridgehead id="_configuration_3" renderas="sect2">Configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/whitespace-analyzer.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>whitespace</literal> analyzer is not configurable.</simpara>
</section>
<section id="analysis-stop-analyzer">
<title>Stop Analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/stop-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>stop</literal> analyzer is the same as the <link linkend="analysis-simple-analyzer"><literal>simple</literal> analyzer</link>
but adds support for removing stop words.  It defaults to using the
<literal>_english_</literal> stop words.</simpara>
<bridgehead id="_definition_4" renderas="sect2">Definition<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/stop-analyzer.asciidoc">Edit me</ulink></bridgehead>
<simpara>It consists of:</simpara>
<variablelist>
<varlistentry>
<term>
Tokenizer
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
<link linkend="analysis-lowercase-tokenizer">Lower Case Tokenizer</link>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Token filters
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
<link linkend="analysis-stop-tokenfilter">Stop Token Filter</link>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_example_output_4" renderas="sect2">Example output<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/stop-analyzer.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">POST _analyze
{
  "analyzer": "stop",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above sentence would produce the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ quick, brown, foxes, jumped, over, lazy, dog, s, bone ]</programlisting>
<bridgehead id="_configuration_4" renderas="sect2">Configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/stop-analyzer.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>stop</literal> analyzer accepts the following parameters:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>stopwords</literal>
</simpara>
</entry>
<entry>
<simpara>
    A pre-defined stop words list like <literal>_english_</literal> or an array  containing a
    list of stop words.  Defaults to <literal>_english_</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>stopwords_path</literal>
</simpara>
</entry>
<entry>
<simpara>
    The path to a file containing stop words.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>See the <link linkend="analysis-stop-tokenfilter">Stop Token Filter</link> for more information
about stop word configuration.</simpara>
<bridgehead id="_example_configuration_2" renderas="sect2">Example configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/stop-analyzer.asciidoc">Edit me</ulink></bridgehead>
<simpara>In this example, we configure the <literal>stop</literal> analyzer to use a specified list of
words as stop words:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_stop_analyzer": {
          "type": "stop",
          "stopwords": ["the", "over"]
        }
      }
    }
  }
}

POST my_index/_analyze
{
  "analyzer": "my_stop_analyzer",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above example produces the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ quick, brown, foxes, jumped, lazy, dog, s, bone ]</programlisting>
</section>
<section id="analysis-keyword-analyzer">
<title>Keyword Analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/keyword-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>keyword</literal> analyzer is a &#8220;noop&#8221; analyzer which returns the entire input
string as a single token.</simpara>
<bridgehead id="_definition_5" renderas="sect2">Definition<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/keyword-analyzer.asciidoc">Edit me</ulink></bridgehead>
<simpara>It consists of:</simpara>
<variablelist>
<varlistentry>
<term>
Tokenizer
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
<link linkend="analysis-keyword-tokenizer">Keyword Tokenizer</link>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_example_output_5" renderas="sect2">Example output<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/keyword-analyzer.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">POST _analyze
{
  "analyzer": "keyword",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above sentence would produce the following single term:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ The 2 QUICK Brown-Foxes jumped over the lazy dog's bone. ]</programlisting>
<bridgehead id="_configuration_5" renderas="sect2">Configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/keyword-analyzer.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>keyword</literal> analyzer is not configurable.</simpara>
</section>
<section id="analysis-pattern-analyzer">
<title>Pattern Analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/pattern-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>pattern</literal> analyzer uses a regular expression to split the text into terms.
The regular expression should match the <emphasis role="strong">token separators</emphasis>  not the tokens
themselves. The regular expression defaults to <literal>\W+</literal> (or all non-word characters).</simpara>
<warning>
<title>Beware of Pathological Regular Expressions</title>
<simpara>The pattern analyzer uses
<ulink url="http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html">Java Regular Expressions</ulink>.</simpara>
<simpara>A badly written regular expression could run very slowly or even throw a
StackOverflowError and cause the node it is running on to exit suddenly.</simpara>
<simpara>Read more about <ulink url="http://www.regular-expressions.info/catastrophic.html">pathological regular expressions and how to avoid them</ulink>.</simpara>
</warning>
<bridgehead id="_definition_6" renderas="sect2">Definition<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/pattern-analyzer.asciidoc">Edit me</ulink></bridgehead>
<simpara>It consists of:</simpara>
<variablelist>
<varlistentry>
<term>
Tokenizer
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
<link linkend="analysis-pattern-tokenizer">Pattern Tokenizer</link>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Token Filters
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
<link linkend="analysis-lowercase-tokenfilter">Lower Case Token Filter</link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="analysis-stop-tokenfilter">Stop Token Filter</link> (disabled by default)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_example_output_6" renderas="sect2">Example output<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/pattern-analyzer.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">POST _analyze
{
  "analyzer": "pattern",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above sentence would produce the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ the, 2, quick, brown, foxes, jumped, over, the, lazy, dog, s, bone ]</programlisting>
<bridgehead id="_configuration_6" renderas="sect2">Configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/pattern-analyzer.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>pattern</literal> analyzer accepts the following parameters:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>pattern</literal>
</simpara>
</entry>
<entry>
<simpara>
    A <ulink url="http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html">Java regular expression</ulink>, defaults to <literal>\W+</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>flags</literal>
</simpara>
</entry>
<entry>
<simpara>
    Java regular expression <ulink url="http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html#field.summary">flags</ulink>.
    Flags should be pipe-separated, eg <literal>"CASE_INSENSITIVE|COMMENTS"</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>lowercase</literal>
</simpara>
</entry>
<entry>
<simpara>
    Should terms be lowercased or not. Defaults to <literal>true</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>stopwords</literal>
</simpara>
</entry>
<entry>
<simpara>
    A pre-defined stop words list like <literal>_english_</literal> or an array  containing a
    list of stop words.  Defaults to <literal>\_none_</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>stopwords_path</literal>
</simpara>
</entry>
<entry>
<simpara>
    The path to a file containing stop words.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>See the <link linkend="analysis-stop-tokenfilter">Stop Token Filter</link> for more information
about stop word configuration.</simpara>
<bridgehead id="_example_configuration_3" renderas="sect2">Example configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/pattern-analyzer.asciidoc">Edit me</ulink></bridgehead>
<simpara>In this example, we configure the <literal>pattern</literal> analyzer to split email addresses
on non-word characters or on underscores (<literal>\W|_</literal>), and to lower-case the result:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_email_analyzer": {
          "type":      "pattern",
          "pattern":   "\\W|_", <co id="CO237-1"/>
          "lowercase": true
        }
      }
    }
  }
}

POST my_index/_analyze
{
  "analyzer": "my_email_analyzer",
  "text": "John_Smith@foo-bar.com"
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO237-1">
<para>
The backslashes in the pattern need to be escaped when specifying the
    pattern as a JSON string.
</para>
</callout>
</calloutlist>
<simpara>The above example produces the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ john, smith, foo, bar, com ]</programlisting>
<bridgehead id="_camelcase_tokenizer" renderas="sect3">CamelCase tokenizer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/pattern-analyzer.asciidoc">Edit me</ulink></bridgehead>
<simpara>The following more complicated example splits CamelCase text into tokens:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "camel": {
          "type": "pattern",
          "pattern": "([^\\p{L}\\d]+)|(?&lt;=\\D)(?=\\d)|(?&lt;=\\d)(?=\\D)|(?&lt;=[\\p{L}&amp;&amp;[^\\p{Lu}]])(?=\\p{Lu})|(?&lt;=\\p{Lu})(?=\\p{Lu}[\\p{L}&amp;&amp;[^\\p{Lu}]])"
        }
      }
    }
  }
}

GET my_index/_analyze
{
  "analyzer": "camel",
  "text": "MooseX::FTPClass2_beta"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above example produces the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ moose, x, ftp, class, 2, beta ]</programlisting>
<simpara>The regex above is easier to understand as:</simpara>
<programlisting language="js" linenumbering="unnumbered">  ([^\p{L}\d]+)                 # swallow non letters and numbers,
| (?&lt;=\D)(?=\d)                 # or non-number followed by number,
| (?&lt;=\d)(?=\D)                 # or number followed by non-number,
| (?&lt;=[ \p{L} &amp;&amp; [^\p{Lu}]])    # or lower case
  (?=\p{Lu})                    #   followed by upper case,
| (?&lt;=\p{Lu})                   # or upper case
  (?=\p{Lu}                     #   followed by upper case
    [\p{L}&amp;&amp;[^\p{Lu}]]          #   then lower case
  )</programlisting>
</section>
<section id="analysis-lang-analyzer">
<title>Language Analyzers<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>A set of analyzers aimed at analyzing specific language text. The
following types are supported:
<link linkend="arabic-analyzer"><literal>arabic</literal></link>,
<link linkend="armenian-analyzer"><literal>armenian</literal></link>,
<link linkend="basque-analyzer"><literal>basque</literal></link>,
<link linkend="brazilian-analyzer"><literal>brazilian</literal></link>,
<link linkend="bulgarian-analyzer"><literal>bulgarian</literal></link>,
<link linkend="catalan-analyzer"><literal>catalan</literal></link>,
<link linkend="cjk-analyzer"><literal>cjk</literal></link>,
<link linkend="czech-analyzer"><literal>czech</literal></link>,
<link linkend="danish-analyzer"><literal>danish</literal></link>,
<link linkend="dutch-analyzer"><literal>dutch</literal></link>,
<link linkend="english-analyzer"><literal>english</literal></link>,
<link linkend="finnish-analyzer"><literal>finnish</literal></link>,
<link linkend="french-analyzer"><literal>french</literal></link>,
<link linkend="galician-analyzer"><literal>galician</literal></link>,
<link linkend="german-analyzer"><literal>german</literal></link>,
<link linkend="greek-analyzer"><literal>greek</literal></link>,
<link linkend="hindi-analyzer"><literal>hindi</literal></link>,
<link linkend="hungarian-analyzer"><literal>hungarian</literal></link>,
<link linkend="indonesian-analyzer"><literal>indonesian</literal></link>,
<link linkend="irish-analyzer"><literal>irish</literal></link>,
<link linkend="italian-analyzer"><literal>italian</literal></link>,
<link linkend="latvian-analyzer"><literal>latvian</literal></link>,
<link linkend="lithuanian-analyzer"><literal>lithuanian</literal></link>,
<link linkend="norwegian-analyzer"><literal>norwegian</literal></link>,
<link linkend="persian-analyzer"><literal>persian</literal></link>,
<link linkend="portuguese-analyzer"><literal>portuguese</literal></link>,
<link linkend="romanian-analyzer"><literal>romanian</literal></link>,
<link linkend="russian-analyzer"><literal>russian</literal></link>,
<link linkend="sorani-analyzer"><literal>sorani</literal></link>,
<link linkend="spanish-analyzer"><literal>spanish</literal></link>,
<link linkend="swedish-analyzer"><literal>swedish</literal></link>,
<link linkend="turkish-analyzer"><literal>turkish</literal></link>,
<link linkend="thai-analyzer"><literal>thai</literal></link>.</simpara>
<section id="_configuring_language_analyzers">
<title>Configuring language analyzers<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<section id="_stopwords">
<title>Stopwords<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>All analyzers support setting custom <literal>stopwords</literal> either internally in
the config, or by using an external stopwords file by setting
<literal>stopwords_path</literal>. Check <link linkend="analysis-stop-analyzer">Stop Analyzer</link> for
more details.</simpara>
</section>
<section id="_excluding_words_from_stemming">
<title>Excluding words from stemming<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>stem_exclusion</literal> parameter allows you to specify an array
of lowercase words that should not be stemmed.  Internally, this
functionality is implemented by adding the
<link linkend="analysis-keyword-marker-tokenfilter"><literal>keyword_marker</literal> token filter</link>
with the <literal>keywords</literal> set to the value of the <literal>stem_exclusion</literal> parameter.</simpara>
<simpara>The following analyzers support setting custom <literal>stem_exclusion</literal> list:
<literal>arabic</literal>, <literal>armenian</literal>, <literal>basque</literal>, <literal>catalan</literal>, <literal>bulgarian</literal>, <literal>catalan</literal>,
<literal>czech</literal>, <literal>finnish</literal>, <literal>dutch</literal>, <literal>english</literal>, <literal>finnish</literal>, <literal>french</literal>, <literal>galician</literal>,
<literal>german</literal>, <literal>irish</literal>, <literal>hindi</literal>, <literal>hungarian</literal>, <literal>indonesian</literal>, <literal>italian</literal>, <literal>latvian</literal>,
<literal>lithuanian</literal>, <literal>norwegian</literal>, <literal>portuguese</literal>, <literal>romanian</literal>, <literal>russian</literal>, <literal>sorani</literal>,
<literal>spanish</literal>, <literal>swedish</literal>, <literal>turkish</literal>.</simpara>
</section>
</section>
<section id="_reimplementing_language_analyzers">
<title>Reimplementing language analyzers<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The built-in language analyzers can be reimplemented as <literal>custom</literal> analyzers
(as described below) in order to customize their behaviour.</simpara>
<note><simpara>If you do not intend to exclude words from being stemmed (the
equivalent of the <literal>stem_exclusion</literal> parameter above), then you should remove
the <literal>keyword_marker</literal> token filter from the custom analyzer configuration.</simpara></note>
<section id="arabic-analyzer">
<title><literal>arabic</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>arabic</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "arabic_stop": {
          "type":       "stop",
          "stopwords":  "_arabic_" <co id="CO238-1"/>
        },
        "arabic_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO238-2"/>
        },
        "arabic_stemmer": {
          "type":       "stemmer",
          "language":   "arabic"
        }
      },
      "analyzer": {
        "arabic": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "arabic_stop",
            "arabic_normalization",
            "arabic_keywords",
            "arabic_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO238-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO238-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="armenian-analyzer">
<title><literal>armenian</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>armenian</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "armenian_stop": {
          "type":       "stop",
          "stopwords":  "_armenian_" <co id="CO239-1"/>
        },
        "armenian_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO239-2"/>
        },
        "armenian_stemmer": {
          "type":       "stemmer",
          "language":   "armenian"
        }
      },
      "analyzer": {
        "armenian": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "armenian_stop",
            "armenian_keywords",
            "armenian_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO239-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO239-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="basque-analyzer">
<title><literal>basque</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>basque</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "basque_stop": {
          "type":       "stop",
          "stopwords":  "_basque_" <co id="CO240-1"/>
        },
        "basque_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO240-2"/>
        },
        "basque_stemmer": {
          "type":       "stemmer",
          "language":   "basque"
        }
      },
      "analyzer": {
        "basque": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "basque_stop",
            "basque_keywords",
            "basque_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO240-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO240-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="brazilian-analyzer">
<title><literal>brazilian</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>brazilian</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "brazilian_stop": {
          "type":       "stop",
          "stopwords":  "_brazilian_" <co id="CO241-1"/>
        },
        "brazilian_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO241-2"/>
        },
        "brazilian_stemmer": {
          "type":       "stemmer",
          "language":   "brazilian"
        }
      },
      "analyzer": {
        "brazilian": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "brazilian_stop",
            "brazilian_keywords",
            "brazilian_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO241-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO241-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="bulgarian-analyzer">
<title><literal>bulgarian</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>bulgarian</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "bulgarian_stop": {
          "type":       "stop",
          "stopwords":  "_bulgarian_" <co id="CO242-1"/>
        },
        "bulgarian_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO242-2"/>
        },
        "bulgarian_stemmer": {
          "type":       "stemmer",
          "language":   "bulgarian"
        }
      },
      "analyzer": {
        "bulgarian": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "bulgarian_stop",
            "bulgarian_keywords",
            "bulgarian_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO242-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO242-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="catalan-analyzer">
<title><literal>catalan</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>catalan</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "catalan_elision": {
          "type":       "elision",
          "articles":   [ "d", "l", "m", "n", "s", "t"]
        },
        "catalan_stop": {
          "type":       "stop",
          "stopwords":  "_catalan_" <co id="CO243-1"/>
        },
        "catalan_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO243-2"/>
        },
        "catalan_stemmer": {
          "type":       "stemmer",
          "language":   "catalan"
        }
      },
      "analyzer": {
        "catalan": {
          "tokenizer":  "standard",
          "filter": [
            "catalan_elision",
            "lowercase",
            "catalan_stop",
            "catalan_keywords",
            "catalan_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO243-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO243-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="cjk-analyzer">
<title><literal>cjk</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>cjk</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "english_stop": {
          "type":       "stop",
          "stopwords":  "_english_" <co id="CO244-1"/>
        }
      },
      "analyzer": {
        "cjk": {
          "tokenizer":  "standard",
          "filter": [
            "cjk_width",
            "lowercase",
            "cjk_bigram",
            "english_stop"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO244-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
</calloutlist>
</section>
<section id="czech-analyzer">
<title><literal>czech</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>czech</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "czech_stop": {
          "type":       "stop",
          "stopwords":  "_czech_" <co id="CO245-1"/>
        },
        "czech_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO245-2"/>
        },
        "czech_stemmer": {
          "type":       "stemmer",
          "language":   "czech"
        }
      },
      "analyzer": {
        "czech": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "czech_stop",
            "czech_keywords",
            "czech_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO245-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO245-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="danish-analyzer">
<title><literal>danish</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>danish</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "danish_stop": {
          "type":       "stop",
          "stopwords":  "_danish_" <co id="CO246-1"/>
        },
        "danish_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO246-2"/>
        },
        "danish_stemmer": {
          "type":       "stemmer",
          "language":   "danish"
        }
      },
      "analyzer": {
        "danish": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "danish_stop",
            "danish_keywords",
            "danish_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO246-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO246-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="dutch-analyzer">
<title><literal>dutch</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>dutch</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "dutch_stop": {
          "type":       "stop",
          "stopwords":  "_dutch_" <co id="CO247-1"/>
        },
        "dutch_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO247-2"/>
        },
        "dutch_stemmer": {
          "type":       "stemmer",
          "language":   "dutch"
        },
        "dutch_override": {
          "type":       "stemmer_override",
          "rules": [
            "fiets=&gt;fiets",
            "bromfiets=&gt;bromfiets",
            "ei=&gt;eier",
            "kind=&gt;kinder"
          ]
        }
      },
      "analyzer": {
        "dutch": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "dutch_stop",
            "dutch_keywords",
            "dutch_override",
            "dutch_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO247-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO247-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="english-analyzer">
<title><literal>english</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>english</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "english_stop": {
          "type":       "stop",
          "stopwords":  "_english_" <co id="CO248-1"/>
        },
        "english_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO248-2"/>
        },
        "english_stemmer": {
          "type":       "stemmer",
          "language":   "english"
        },
        "english_possessive_stemmer": {
          "type":       "stemmer",
          "language":   "possessive_english"
        }
      },
      "analyzer": {
        "english": {
          "tokenizer":  "standard",
          "filter": [
            "english_possessive_stemmer",
            "lowercase",
            "english_stop",
            "english_keywords",
            "english_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO248-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO248-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="finnish-analyzer">
<title><literal>finnish</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>finnish</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "finnish_stop": {
          "type":       "stop",
          "stopwords":  "_finnish_" <co id="CO249-1"/>
        },
        "finnish_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO249-2"/>
        },
        "finnish_stemmer": {
          "type":       "stemmer",
          "language":   "finnish"
        }
      },
      "analyzer": {
        "finnish": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "finnish_stop",
            "finnish_keywords",
            "finnish_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO249-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO249-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="french-analyzer">
<title><literal>french</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>french</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "french_elision": {
          "type":         "elision",
          "articles_case": true,
          "articles": [
              "l", "m", "t", "qu", "n", "s",
              "j", "d", "c", "jusqu", "quoiqu",
              "lorsqu", "puisqu"
            ]
        },
        "french_stop": {
          "type":       "stop",
          "stopwords":  "_french_" <co id="CO250-1"/>
        },
        "french_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO250-2"/>
        },
        "french_stemmer": {
          "type":       "stemmer",
          "language":   "light_french"
        }
      },
      "analyzer": {
        "french": {
          "tokenizer":  "standard",
          "filter": [
            "french_elision",
            "lowercase",
            "french_stop",
            "french_keywords",
            "french_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO250-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO250-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="galician-analyzer">
<title><literal>galician</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>galician</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "galician_stop": {
          "type":       "stop",
          "stopwords":  "_galician_" <co id="CO251-1"/>
        },
        "galician_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO251-2"/>
        },
        "galician_stemmer": {
          "type":       "stemmer",
          "language":   "galician"
        }
      },
      "analyzer": {
        "galician": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "galician_stop",
            "galician_keywords",
            "galician_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO251-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO251-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="german-analyzer">
<title><literal>german</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>german</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "german_stop": {
          "type":       "stop",
          "stopwords":  "_german_" <co id="CO252-1"/>
        },
        "german_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO252-2"/>
        },
        "german_stemmer": {
          "type":       "stemmer",
          "language":   "light_german"
        }
      },
      "analyzer": {
        "german": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "german_stop",
            "german_keywords",
            "german_normalization",
            "german_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO252-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO252-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="greek-analyzer">
<title><literal>greek</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>greek</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "greek_stop": {
          "type":       "stop",
          "stopwords":  "_greek_" <co id="CO253-1"/>
        },
        "greek_lowercase": {
          "type":       "lowercase",
          "language":   "greek"
        },
        "greek_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO253-2"/>
        },
        "greek_stemmer": {
          "type":       "stemmer",
          "language":   "greek"
        }
      },
      "analyzer": {
        "greek": {
          "tokenizer":  "standard",
          "filter": [
            "greek_lowercase",
            "greek_stop",
            "greek_keywords",
            "greek_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO253-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO253-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="hindi-analyzer">
<title><literal>hindi</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>hindi</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "hindi_stop": {
          "type":       "stop",
          "stopwords":  "_hindi_" <co id="CO254-1"/>
        },
        "hindi_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO254-2"/>
        },
        "hindi_stemmer": {
          "type":       "stemmer",
          "language":   "hindi"
        }
      },
      "analyzer": {
        "hindi": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "indic_normalization",
            "hindi_normalization",
            "hindi_stop",
            "hindi_keywords",
            "hindi_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO254-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO254-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="hungarian-analyzer">
<title><literal>hungarian</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>hungarian</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "hungarian_stop": {
          "type":       "stop",
          "stopwords":  "_hungarian_" <co id="CO255-1"/>
        },
        "hungarian_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO255-2"/>
        },
        "hungarian_stemmer": {
          "type":       "stemmer",
          "language":   "hungarian"
        }
      },
      "analyzer": {
        "hungarian": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "hungarian_stop",
            "hungarian_keywords",
            "hungarian_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO255-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO255-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="indonesian-analyzer">
<title><literal>indonesian</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>indonesian</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "indonesian_stop": {
          "type":       "stop",
          "stopwords":  "_indonesian_" <co id="CO256-1"/>
        },
        "indonesian_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO256-2"/>
        },
        "indonesian_stemmer": {
          "type":       "stemmer",
          "language":   "indonesian"
        }
      },
      "analyzer": {
        "indonesian": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "indonesian_stop",
            "indonesian_keywords",
            "indonesian_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO256-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO256-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="irish-analyzer">
<title><literal>irish</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>irish</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "irish_elision": {
          "type":       "elision",
          "articles": [ "h", "n", "t" ]
        },
        "irish_stop": {
          "type":       "stop",
          "stopwords":  "_irish_" <co id="CO257-1"/>
        },
        "irish_lowercase": {
          "type":       "lowercase",
          "language":   "irish"
        },
        "irish_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO257-2"/>
        },
        "irish_stemmer": {
          "type":       "stemmer",
          "language":   "irish"
        }
      },
      "analyzer": {
        "irish": {
          "tokenizer":  "standard",
          "filter": [
            "irish_stop",
            "irish_elision",
            "irish_lowercase",
            "irish_keywords",
            "irish_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO257-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO257-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="italian-analyzer">
<title><literal>italian</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>italian</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "italian_elision": {
          "type": "elision",
          "articles": [
                "c", "l", "all", "dall", "dell",
                "nell", "sull", "coll", "pell",
                "gl", "agl", "dagl", "degl", "negl",
                "sugl", "un", "m", "t", "s", "v", "d"
          ]
        },
        "italian_stop": {
          "type":       "stop",
          "stopwords":  "_italian_" <co id="CO258-1"/>
        },
        "italian_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO258-2"/>
        },
        "italian_stemmer": {
          "type":       "stemmer",
          "language":   "light_italian"
        }
      },
      "analyzer": {
        "italian": {
          "tokenizer":  "standard",
          "filter": [
            "italian_elision",
            "lowercase",
            "italian_stop",
            "italian_keywords",
            "italian_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO258-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO258-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="latvian-analyzer">
<title><literal>latvian</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>latvian</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "latvian_stop": {
          "type":       "stop",
          "stopwords":  "_latvian_" <co id="CO259-1"/>
        },
        "latvian_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO259-2"/>
        },
        "latvian_stemmer": {
          "type":       "stemmer",
          "language":   "latvian"
        }
      },
      "analyzer": {
        "latvian": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "latvian_stop",
            "latvian_keywords",
            "latvian_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO259-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO259-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="lithuanian-analyzer">
<title><literal>lithuanian</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>lithuanian</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "lithuanian_stop": {
          "type":       "stop",
          "stopwords":  "_lithuanian_" <co id="CO260-1"/>
        },
        "lithuanian_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO260-2"/>
        },
        "lithuanian_stemmer": {
          "type":       "stemmer",
          "language":   "lithuanian"
        }
      },
      "analyzer": {
        "lithuanian": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "lithuanian_stop",
            "lithuanian_keywords",
            "lithuanian_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO260-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO260-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="norwegian-analyzer">
<title><literal>norwegian</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>norwegian</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "norwegian_stop": {
          "type":       "stop",
          "stopwords":  "_norwegian_" <co id="CO261-1"/>
        },
        "norwegian_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO261-2"/>
        },
        "norwegian_stemmer": {
          "type":       "stemmer",
          "language":   "norwegian"
        }
      },
      "analyzer": {
        "norwegian": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "norwegian_stop",
            "norwegian_keywords",
            "norwegian_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO261-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO261-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="persian-analyzer">
<title><literal>persian</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>persian</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "char_filter": {
        "zero_width_spaces": {
            "type":       "mapping",
            "mappings": [ "\\u200C=&gt; "] <co id="CO262-1"/>
        }
      },
      "filter": {
        "persian_stop": {
          "type":       "stop",
          "stopwords":  "_persian_" <co id="CO262-2"/>
        }
      },
      "analyzer": {
        "persian": {
          "tokenizer":     "standard",
          "char_filter": [ "zero_width_spaces" ],
          "filter": [
            "lowercase",
            "arabic_normalization",
            "persian_normalization",
            "persian_stop"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO262-1">
<para>
Replaces zero-width non-joiners with an ASCII space.
</para>
</callout>
<callout arearefs="CO262-2">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
</calloutlist>
</section>
<section id="portuguese-analyzer">
<title><literal>portuguese</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>portuguese</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "portuguese_stop": {
          "type":       "stop",
          "stopwords":  "_portuguese_" <co id="CO263-1"/>
        },
        "portuguese_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO263-2"/>
        },
        "portuguese_stemmer": {
          "type":       "stemmer",
          "language":   "light_portuguese"
        }
      },
      "analyzer": {
        "portuguese": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "portuguese_stop",
            "portuguese_keywords",
            "portuguese_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO263-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO263-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="romanian-analyzer">
<title><literal>romanian</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>romanian</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "romanian_stop": {
          "type":       "stop",
          "stopwords":  "_romanian_" <co id="CO264-1"/>
        },
        "romanian_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO264-2"/>
        },
        "romanian_stemmer": {
          "type":       "stemmer",
          "language":   "romanian"
        }
      },
      "analyzer": {
        "romanian": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "romanian_stop",
            "romanian_keywords",
            "romanian_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO264-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO264-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="russian-analyzer">
<title><literal>russian</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>russian</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "russian_stop": {
          "type":       "stop",
          "stopwords":  "_russian_" <co id="CO265-1"/>
        },
        "russian_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO265-2"/>
        },
        "russian_stemmer": {
          "type":       "stemmer",
          "language":   "russian"
        }
      },
      "analyzer": {
        "russian": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "russian_stop",
            "russian_keywords",
            "russian_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO265-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO265-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="sorani-analyzer">
<title><literal>sorani</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>sorani</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "sorani_stop": {
          "type":       "stop",
          "stopwords":  "_sorani_" <co id="CO266-1"/>
        },
        "sorani_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO266-2"/>
        },
        "sorani_stemmer": {
          "type":       "stemmer",
          "language":   "sorani"
        }
      },
      "analyzer": {
        "sorani": {
          "tokenizer":  "standard",
          "filter": [
            "sorani_normalization",
            "lowercase",
            "sorani_stop",
            "sorani_keywords",
            "sorani_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO266-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO266-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="spanish-analyzer">
<title><literal>spanish</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>spanish</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "spanish_stop": {
          "type":       "stop",
          "stopwords":  "_spanish_" <co id="CO267-1"/>
        },
        "spanish_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO267-2"/>
        },
        "spanish_stemmer": {
          "type":       "stemmer",
          "language":   "light_spanish"
        }
      },
      "analyzer": {
        "spanish": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "spanish_stop",
            "spanish_keywords",
            "spanish_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO267-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO267-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="swedish-analyzer">
<title><literal>swedish</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>swedish</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "swedish_stop": {
          "type":       "stop",
          "stopwords":  "_swedish_" <co id="CO268-1"/>
        },
        "swedish_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO268-2"/>
        },
        "swedish_stemmer": {
          "type":       "stemmer",
          "language":   "swedish"
        }
      },
      "analyzer": {
        "swedish": {
          "tokenizer":  "standard",
          "filter": [
            "lowercase",
            "swedish_stop",
            "swedish_keywords",
            "swedish_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO268-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO268-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="turkish-analyzer">
<title><literal>turkish</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>turkish</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "turkish_stop": {
          "type":       "stop",
          "stopwords":  "_turkish_" <co id="CO269-1"/>
        },
        "turkish_lowercase": {
          "type":       "lowercase",
          "language":   "turkish"
        },
        "turkish_keywords": {
          "type":       "keyword_marker",
          "keywords":   [] <co id="CO269-2"/>
        },
        "turkish_stemmer": {
          "type":       "stemmer",
          "language":   "turkish"
        }
      },
      "analyzer": {
        "turkish": {
          "tokenizer":  "standard",
          "filter": [
            "apostrophe",
            "turkish_lowercase",
            "turkish_stop",
            "turkish_keywords",
            "turkish_stemmer"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO269-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
<callout arearefs="CO269-2">
<para>
This filter should be removed unless there are words which should
    be excluded from stemming.
</para>
</callout>
</calloutlist>
</section>
<section id="thai-analyzer">
<title><literal>thai</literal> analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/lang-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>thai</literal> analyzer could be reimplemented as a <literal>custom</literal> analyzer as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "settings": {
    "analysis": {
      "filter": {
        "thai_stop": {
          "type":       "stop",
          "stopwords":  "_thai_" <co id="CO270-1"/>
        }
      },
      "analyzer": {
        "thai": {
          "tokenizer":  "thai",
          "filter": [
            "lowercase",
            "thai_stop"
          ]
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO270-1">
<para>
The default stopwords can be overridden with the <literal>stopwords</literal>
    or <literal>stopwords_path</literal> parameters.
</para>
</callout>
</calloutlist>
</section>
</section>
</section>
<section id="analysis-fingerprint-analyzer">
<title>Fingerprint Analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/fingerprint-analyzer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>fingerprint</literal> analyzer implements a
<ulink url="https://github.com/OpenRefine/OpenRefine/wiki/Clustering-In-Depth#fingerprint">fingerprinting algorithm</ulink>
which is used by the OpenRefine project to assist in clustering.</simpara>
<simpara>Input text is lowercased, normalized to remove extended characters, sorted,
deduplicated and concatenated into a single token.  If a stopword list is
configured, stop words will also be removed.</simpara>
<bridgehead id="_definition_7" renderas="sect2">Definition<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/fingerprint-analyzer.asciidoc">Edit me</ulink></bridgehead>
<simpara>It consists of:</simpara>
<variablelist>
<varlistentry>
<term>
Tokenizer
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
<link linkend="analysis-standard-tokenizer">Standard Tokenizer</link>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Token Filters (in order)
</term>
<listitem>
<orderedlist numeration="arabic">
<listitem>
<simpara>
<link linkend="analysis-lowercase-tokenfilter">Lower Case Token Filter</link>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="analysis-asciifolding-tokenfilter"/>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="analysis-stop-tokenfilter">Stop Token Filter</link> (disabled by default)
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="analysis-fingerprint-tokenfilter"/>
</simpara>
</listitem>
</orderedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_example_output_7" renderas="sect2">Example output<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/fingerprint-analyzer.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">POST _analyze
{
  "analyzer": "fingerprint",
  "text": "Yes yes, Gödel said this sentence is consistent and."
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above sentence would produce the following single term:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ and consistent godel is said sentence this yes ]</programlisting>
<bridgehead id="_configuration_7" renderas="sect2">Configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/fingerprint-analyzer.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>fingerprint</literal> analyzer accepts the following parameters:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>separator</literal>
</simpara>
</entry>
<entry>
<simpara>
    The character to use to concate the terms.  Defaults to a space.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max_output_size</literal>
</simpara>
</entry>
<entry>
<simpara>
    The maximum token size to emit.  Defaults to <literal>255</literal>. Tokens larger than
    this size will be discarded.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>stopwords</literal>
</simpara>
</entry>
<entry>
<simpara>
    A pre-defined stop words list like <literal>_english_</literal> or an array  containing a
    list of stop words.  Defaults to <literal>\_none_</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>stopwords_path</literal>
</simpara>
</entry>
<entry>
<simpara>
    The path to a file containing stop words.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>See the <link linkend="analysis-stop-tokenfilter">Stop Token Filter</link> for more information
about stop word configuration.</simpara>
<bridgehead id="_example_configuration_4" renderas="sect2">Example configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/fingerprint-analyzer.asciidoc">Edit me</ulink></bridgehead>
<simpara>In this example, we configure the <literal>fingerprint</literal> analyzer to use the
pre-defined list of English stop words:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_fingerprint_analyzer": {
          "type": "fingerprint",
          "stopwords": "_english_"
        }
      }
    }
  }
}

POST my_index/_analyze
{
  "analyzer": "my_fingerprint_analyzer",
  "text": "Yes yes, Gödel said this sentence is consistent and."
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above example produces the following term:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ consistent godel said sentence yes ]</programlisting>
</section>
<section id="analysis-custom-analyzer">
<title>Custom Analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/custom-analyzer.asciidoc">Edit me</ulink></title>
<simpara>When the built-in analyzers do not fulfill your needs, you can create a
<literal>custom</literal> analyzer which uses the appropriate combination of:</simpara>
<itemizedlist>
<listitem>
<simpara>
zero or more <link linkend="analysis-charfilters">character filters</link>
</simpara>
</listitem>
<listitem>
<simpara>
a <link linkend="analysis-tokenizers">tokenizer</link>
</simpara>
</listitem>
<listitem>
<simpara>
zero or more <link linkend="analysis-tokenfilters">token filters</link>.
</simpara>
</listitem>
</itemizedlist>
<bridgehead id="_configuration_8" renderas="sect2">Configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/custom-analyzer.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>custom</literal> analyzer accepts the following parameters:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>tokenizer</literal>
</simpara>
</entry>
<entry>
<simpara>
    A built-in or customised <link linkend="analysis-tokenizers">tokenizer</link>.
    (Required)
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>char_filter</literal>
</simpara>
</entry>
<entry>
<simpara>
    An optional array of built-in or customised
    <link linkend="analysis-charfilters">character filters</link>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>filter</literal>
</simpara>
</entry>
<entry>
<simpara>
    An optional array of built-in or customised
    <link linkend="analysis-tokenfilters">token filters</link>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>position_increment_gap</literal>
</simpara>
</entry>
<entry>
<simpara>
    When indexing an array of text values, Elasticsearch inserts a fake "gap"
    between the last term of one value and the first term of the next value to
    ensure that a phrase query doesn&#8217;t match two terms from different array
    elements.  Defaults to <literal>100</literal>. See <xref linkend="position-increment-gap"/> for more.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="_example_configuration_5" renderas="sect2">Example configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/analyzers/custom-analyzer.asciidoc">Edit me</ulink></bridgehead>
<simpara>Here is an example that combines the following:</simpara>
<variablelist>
<varlistentry>
<term>
Character Filter
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
<link linkend="analysis-htmlstrip-charfilter">HTML Strip Character Filter</link>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Tokenizer
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
<link linkend="analysis-standard-tokenizer">Standard Tokenizer</link>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Token Filters
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
<link linkend="analysis-lowercase-tokenfilter">Lowercase Token Filter</link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="analysis-asciifolding-tokenfilter">ASCII-Folding Token Filter</link>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_custom_analyzer": {
          "type":      "custom",
          "tokenizer": "standard",
          "char_filter": [
            "html_strip"
          ],
          "filter": [
            "lowercase",
            "asciifolding"
          ]
        }
      }
    }
  }
}

POST my_index/_analyze
{
  "analyzer": "my_custom_analyzer",
  "text": "Is this &lt;b&gt;déjà vu&lt;/b&gt;?"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above example produces the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ is, this, deja, vu ]</programlisting>
<simpara>The previous example used tokenizer, token filters, and character filters with
their default configurations, but it is possible to create configured versions
of each and to use them in a custom analyzer.</simpara>
<simpara>Here is a more complicated example that combines the following:</simpara>
<variablelist>
<varlistentry>
<term>
Character Filter
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
<link linkend="analysis-mapping-charfilter">Mapping Character Filter</link>, configured to replace <literal>:)</literal> with <literal>_happy_</literal> and <literal>:(</literal> with <literal>_sad_</literal>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Tokenizer
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
<link linkend="analysis-pattern-tokenizer">Pattern Tokenizer</link>, configured to split on punctuation characters
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Token Filters
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
<link linkend="analysis-lowercase-tokenfilter">Lowercase Token Filter</link>
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="analysis-stop-tokenfilter">Stop Token Filter</link>, configured to use the pre-defined list of English stop words
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<simpara>Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_custom_analyzer": {
          "type": "custom",
          "char_filter": [
            "emoticons" <co id="CO271-1"/>
          ],
          "tokenizer": "punctuation", <co id="CO271-2"/>
          "filter": [
            "lowercase",
            "english_stop" <co id="CO271-3"/>
          ]
        }
      },
      "tokenizer": {
        "punctuation": { <co id="CO271-4"/>
          "type": "pattern",
          "pattern": "[ .,!?]"
        }
      },
      "char_filter": {
        "emoticons": { <co id="CO271-5"/>
          "type": "mapping",
          "mappings": [
            ":) =&gt; _happy_",
            ":( =&gt; _sad_"
          ]
        }
      },
      "filter": {
        "english_stop": { <co id="CO271-6"/>
          "type": "stop",
          "stopwords": "_english_"
        }
      }
    }
  }
}

POST my_index/_analyze
{
  "analyzer": "my_custom_analyzer",
  "text":     "I'm a :) person, and you?"
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO271-1 CO271-2 CO271-3 CO271-4 CO271-5 CO271-6">
<para>
The <literal>emoticon</literal> character filter, <literal>punctuation</literal> tokenizer and
    <literal>english_stop</literal> token filter are custom implementations which are defined
    in the same index settings.
</para>
</callout>
</calloutlist>
<simpara>The above example produces the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ i'm, _happy_, person, you ]</programlisting>
</section>
</chapter>
<chapter id="analysis-tokenizers">
<title>Tokenizers<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers.asciidoc">Edit me</ulink></title>
<simpara>A <emphasis>tokenizer</emphasis>  receives a stream of characters, breaks it up into individual
<emphasis>tokens</emphasis> (usually individual words), and outputs a stream of <emphasis>tokens</emphasis>. For
instance, a <link linkend="analysis-whitespace-tokenizer"><literal>whitespace</literal></link> tokenizer breaks
text into tokens whenever it sees any whitespace.  It would convert the text
<literal>"Quick brown fox!"</literal> into the terms <literal>[Quick, brown, fox!]</literal>.</simpara>
<simpara>The tokenizer is also responsible for recording the order or <emphasis>position</emphasis> of
each term (used for phrase and word proximity queries) and the start and end
<emphasis>character offsets</emphasis> of the original word which the term represents (used for
highlighting search snippets).</simpara>
<simpara>Elasticsearch has a number of built in tokenizers which can be used to build
<link linkend="analysis-custom-analyzer">custom analyzers</link>.</simpara>
<bridgehead id="_word_oriented_tokenizers" renderas="sect2">Word Oriented Tokenizers<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers.asciidoc">Edit me</ulink></bridgehead>
<simpara>The following tokenizers are usually used for tokenizing full text into
individual words:</simpara>
<variablelist>
<varlistentry>
<term>
<link linkend="analysis-standard-tokenizer">Standard Tokenizer</link>
</term>
<listitem>
<simpara>
The <literal>standard</literal> tokenizer divides text into terms on word boundaries, as
defined by the Unicode Text Segmentation algorithm. It removes most
punctuation symbols. It is the best choice for most languages.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="analysis-letter-tokenizer">Letter Tokenizer</link>
</term>
<listitem>
<simpara>
The <literal>letter</literal> tokenizer divides text into terms whenever it encounters a
character which is not a letter.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="analysis-letter-tokenizer">Lowercase Tokenizer</link>
</term>
<listitem>
<simpara>
The <literal>lowercase</literal> tokenizer, like the <literal>letter</literal> tokenizer,  divides text into
terms whenever it encounters a character which is not a letter, but it also
lowercases all terms.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="analysis-whitespace-tokenizer">Whitespace Tokenizer</link>
</term>
<listitem>
<simpara>
The <literal>whitespace</literal> tokenizer divides text into terms whenever it encounters any
whitespace character.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="analysis-uaxurlemail-tokenizer">UAX URL Email Tokenizer</link>
</term>
<listitem>
<simpara>
The <literal>uax_url_email</literal> tokenizer is like the <literal>standard</literal> tokenizer except that it
recognises URLs and email addresses as single tokens.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="analysis-classic-tokenizer">Classic Tokenizer</link>
</term>
<listitem>
<simpara>
The <literal>classic</literal> tokenizer is a grammar based tokenizer for the English Language.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="analysis-thai-tokenizer">Thai Tokenizer</link>
</term>
<listitem>
<simpara>
The <literal>thai</literal> tokenizer segments Thai text into words.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_partial_word_tokenizers" renderas="sect2">Partial Word Tokenizers<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers.asciidoc">Edit me</ulink></bridgehead>
<simpara>These tokenizers break up text or words into small fragments, for partial word
matching:</simpara>
<variablelist>
<varlistentry>
<term>
<link linkend="analysis-ngram-tokenizer">N-Gram Tokenizer</link>
</term>
<listitem>
<simpara>
The <literal>ngram</literal> tokenizer can break up text into words when it encounters any of
a list of specified characters (e.g. whitespace or punctuation), then it returns
n-grams of each word: a sliding window of continuous letters, e.g. <literal>quick</literal> &#8594;
<literal>[qu, ui, ic, ck]</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="analysis-edgengram-tokenizer">Edge N-Gram Tokenizer</link>
</term>
<listitem>
<simpara>
The <literal>edge_ngram</literal> tokenizer can break up text into words when it encounters any of
a list of specified characters (e.g. whitespace or punctuation), then it returns
n-grams of each word which are anchored to the start of the word, e.g. <literal>quick</literal> &#8594;
<literal>[q, qu, qui, quic, quick]</literal>.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_structured_text_tokenizers" renderas="sect2">Structured Text Tokenizers<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers.asciidoc">Edit me</ulink></bridgehead>
<simpara>The following tokenizers are usually used with structured text like
identifiers, email addresses, zip codes, and paths, rather than with full
text:</simpara>
<variablelist>
<varlistentry>
<term>
<link linkend="analysis-keyword-tokenizer">Keyword Tokenizer</link>
</term>
<listitem>
<simpara>
The <literal>keyword</literal> tokenizer is a &#8220;noop&#8221; tokenizer that accepts whatever text it
is given and outputs the exact same text as a single term.  It can be combined
with token filters like <link linkend="analysis-lowercase-tokenfilter"><literal>lowercase</literal></link> to
normalise the analysed terms.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="analysis-pattern-tokenizer">Pattern Tokenizer</link>
</term>
<listitem>
<simpara>
The <literal>pattern</literal> tokenizer uses a regular expression to either split text into
terms whenever it matches a word separator, or to capture matching text as
terms.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="analysis-pathhierarchy-tokenizer">Path Tokenizer</link>
</term>
<listitem>
<simpara>
The <literal>path_hierarchy</literal> tokenizer takes a hierarchical value like a filesystem
path, splits on the path separator, and emits a term for each component in the
tree, e.g. <literal>/foo/bar/baz</literal> &#8594; <literal>[/foo, /foo/bar, /foo/bar/baz ]</literal>.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<section id="analysis-standard-tokenizer">
<title>Standard Tokenizer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/standard-tokenizer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>standard</literal> tokenizer provides grammar based tokenization (based on the
Unicode Text Segmentation algorithm, as specified in
<ulink url="http://unicode.org/reports/tr29/">Unicode Standard Annex #29</ulink>) and works well
for most languages.</simpara>
<bridgehead id="_example_output_8" renderas="sect2">Example output<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/standard-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">POST _analyze
{
  "tokenizer": "standard",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above sentence would produce the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ The, 2, QUICK, Brown, Foxes, jumped, over, the, lazy, dog's, bone ]</programlisting>
<bridgehead id="_configuration_9" renderas="sect2">Configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/standard-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>standard</literal> tokenizer accepts the following parameters:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>max_token_length</literal>
</simpara>
</entry>
<entry>
<simpara>
    The maximum token length. If a token is seen that exceeds this length then
    it is split at <literal>max_token_length</literal> intervals. Defaults to <literal>255</literal>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="_example_configuration_6" renderas="sect2">Example configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/standard-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<simpara>In this example, we configure the <literal>standard</literal> tokenizer to have a
<literal>max_token_length</literal> of 5 (for demonstration purposes):</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "standard",
          "max_token_length": 5
        }
      }
    }
  }
}

POST my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above example produces the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ The, 2, QUICK, Brown, Foxes, jumpe, d, over, the, lazy, dog's, bone ]</programlisting>
</section>
<section id="analysis-letter-tokenizer">
<title>Letter Tokenizer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/letter-tokenizer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>letter</literal> tokenizer breaks text into terms whenever it encounters a
character which is not a letter. It does a reasonable job for most European
languages, but does a terrible job for some Asian languages, where words are
not separated by spaces.</simpara>
<bridgehead id="_example_output_9" renderas="sect2">Example output<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/letter-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">POST _analyze
{
  "tokenizer": "letter",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above sentence would produce the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ The, QUICK, Brown, Foxes, jumped, over, the, lazy, dog, s, bone ]</programlisting>
<bridgehead id="_configuration_10" renderas="sect2">Configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/letter-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>letter</literal> tokenizer is not configurable.</simpara>
</section>
<section id="analysis-lowercase-tokenizer">
<title>Lowercase Tokenizer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/lowercase-tokenizer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>lowercase</literal> tokenizer, like the
<link linkend="analysis-letter-tokenizer"><literal>letter</literal> tokenizer</link> breaks text into terms
whenever it encounters a character which is not a letter, but it also
lowercases all terms.  It is functionally equivalent to the
<link linkend="analysis-letter-tokenizer"><literal>letter</literal> tokenizer</link> combined with the
<link linkend="analysis-lowercase-tokenfilter"><literal>lowercase</literal> token filter</link>, but is more
efficient as it performs both steps in a single pass.</simpara>
<bridgehead id="_example_output_10" renderas="sect2">Example output<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/lowercase-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">POST _analyze
{
  "tokenizer": "lowercase",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above sentence would produce the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ the, quick, brown, foxes, jumped, over, the, lazy, dog, s, bone ]</programlisting>
<bridgehead id="_configuration_11" renderas="sect2">Configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/lowercase-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>lowercase</literal> tokenizer is not configurable.</simpara>
</section>
<section id="analysis-whitespace-tokenizer">
<title>Whitespace Analyzer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/whitespace-tokenizer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>whitespace</literal> tokenizer breaks text into terms whenever it encounters a
whitespace character.</simpara>
<bridgehead id="_example_output_11" renderas="sect2">Example output<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/whitespace-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">POST _analyze
{
  "tokenizer": "whitespace",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above sentence would produce the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ The, 2, QUICK, Brown-Foxes, jumped, over, the, lazy, dog's, bone. ]</programlisting>
<bridgehead id="_configuration_12" renderas="sect2">Configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/whitespace-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>whitespace</literal> tokenizer is not configurable.</simpara>
</section>
<section id="analysis-uaxurlemail-tokenizer">
<title>UAX URL Email  Tokenizer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/uaxurlemail-tokenizer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>uax_url_email</literal> tokenizer is like the <link linkend="analysis-standard-tokenizer"><literal>standard</literal> tokenizer</link> except that it
recognises URLs and email addresses as single tokens.</simpara>
<bridgehead id="_example_output_12" renderas="sect2">Example output<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/uaxurlemail-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">POST _analyze
{
  "tokenizer": "uax_url_email",
  "text": "Email me at john.smith@global-international.com"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above sentence would produce the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ Email, me, at, john.smith@global-international.com ]</programlisting>
<simpara>while the <literal>standard</literal> tokenizer would produce:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ Email, me, at, john.smith, global, international.com ]</programlisting>
<bridgehead id="_configuration_13" renderas="sect2">Configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/uaxurlemail-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>uax_url_email</literal> tokenizer accepts the following parameters:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>max_token_length</literal>
</simpara>
</entry>
<entry>
<simpara>
    The maximum token length. If a token is seen that exceeds this length then
    it is split at <literal>max_token_length</literal> intervals. Defaults to <literal>255</literal>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="_example_configuration_7" renderas="sect2">Example configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/uaxurlemail-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<simpara>In this example, we configure the <literal>uax_url_email</literal> tokenizer to have a
<literal>max_token_length</literal> of 5 (for demonstration purposes):</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "uax_url_email",
          "max_token_length": 5
        }
      }
    }
  }
}

POST my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "john.smith@global-international.com"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above example produces the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ john, smith, globa, l, inter, natio, nal.c, om ]</programlisting>
</section>
<section id="analysis-classic-tokenizer">
<title>Classic Tokenizer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/classic-tokenizer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>classic</literal> tokenizer is a grammar based tokenizer that is good for English
language documents. This tokenizer has heuristics for special treatment of
acronyms, company names, email addresses, and internet host names. However,
these rules don&#8217;t always work, and the tokenizer doesn&#8217;t work well for most
languages other than English:</simpara>
<itemizedlist>
<listitem>
<simpara>
It splits words at most punctuation characters, removing punctuation. However, a
  dot that&#8217;s not followed by whitespace is considered part of a token.
</simpara>
</listitem>
<listitem>
<simpara>
It splits words at hyphens, unless there&#8217;s a number in the token, in which case
  the whole token is interpreted as a product number and is not split.
</simpara>
</listitem>
<listitem>
<simpara>
It recognizes email addresses and internet hostnames as one token.
</simpara>
</listitem>
</itemizedlist>
<bridgehead id="_example_output_13" renderas="sect2">Example output<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/classic-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">POST _analyze
{
  "tokenizer": "classic",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above sentence would produce the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ The, 2, QUICK, Brown, Foxes, jumped, over, the, lazy, dog's, bone ]</programlisting>
<bridgehead id="_configuration_14" renderas="sect2">Configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/classic-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>classic</literal> tokenizer accepts the following parameters:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>max_token_length</literal>
</simpara>
</entry>
<entry>
<simpara>
    The maximum token length. If a token is seen that exceeds this length then
    it is split at <literal>max_token_length</literal> intervals. Defaults to <literal>255</literal>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="_example_configuration_8" renderas="sect2">Example configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/classic-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<simpara>In this example, we configure the <literal>classic</literal> tokenizer to have a
<literal>max_token_length</literal> of 5 (for demonstration purposes):</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "classic",
          "max_token_length": 5
        }
      }
    }
  }
}

POST my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "The 2 QUICK Brown-Foxes jumped over the lazy dog's bone."
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above example produces the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ The, 2, QUICK, Brown, Foxes, jumpe, d, over, the, lazy, dog's, bone ]</programlisting>
</section>
<section id="analysis-thai-tokenizer">
<title>Thai Tokenizer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/thai-tokenizer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>thai</literal> tokenizer segments Thai text into words, using the Thai
segmentation algorithm included with Java. Text in other languages in general
will be treated the same as the
<link linkend="analysis-standard-tokenizer"><literal>standard</literal> tokenizer</link>.</simpara>
<warning><simpara>This tokenizer may not be supported by all JREs. It is known to work
with Sun/Oracle and OpenJDK. If your application needs to be fully portable,
consider using the <ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/analysis-icu-tokenizer.html">ICU Tokenizer</ulink> instead.</simpara></warning>
<bridgehead id="_example_output_14" renderas="sect2">Example output<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/thai-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">POST _analyze
{
  "tokenizer": "thai",
  "text": "การที่ได้ต้องแสดงว่างานดี"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above sentence would produce the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ การ, ที่, ได้, ต้อง, แสดง, ว่า, งาน, ดี ]</programlisting>
<bridgehead id="_configuration_15" renderas="sect2">Configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/thai-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>thai</literal> tokenizer is not configurable.</simpara>
</section>
<section id="analysis-ngram-tokenizer">
<title>NGram Tokenizer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/ngram-tokenizer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>ngram</literal> tokenizer first breaks text down into words whenever it encounters
one of a list of specified characters, then it emits
<ulink url="https://en.wikipedia.org/wiki/N-gram">N-grams</ulink> of each word of the specified
length.</simpara>
<simpara>N-grams are like a sliding window that moves across the word - a continuous
sequence of characters of the specified length. They are useful for querying
languages that don&#8217;t use spaces or that have long compound words, like German.</simpara>
<bridgehead id="_example_output_15" renderas="sect2">Example output<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/ngram-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<simpara>With the default settings, the <literal>ngram</literal> tokenizer treats the initial text as a
single token and produces N-grams with minimum length <literal>1</literal> and maximum length
<literal>2</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _analyze
{
  "tokenizer": "ngram",
  "text": "Quick Fox"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above sentence would produce the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ Q, Qu, u, ui, i, ic, c, ck, k, "k ", " ", " F", F, Fo, o, ox, x ]</programlisting>
<bridgehead id="_configuration_16" renderas="sect2">Configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/ngram-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>ngram</literal> tokenizer accepts the following parameters:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>min_gram</literal>
</simpara>
</entry>
<entry>
<simpara>
    Minimum length of characters in a gram.  Defaults to <literal>1</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max_gram</literal>
</simpara>
</entry>
<entry>
<simpara>
    Maximum length of characters in a gram.  Defaults to <literal>2</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>token_chars</literal>
</simpara>
</entry>
<entry>
<simpara>
    Character classes that should be included in a token.  Elasticsearch
    will split on characters that don&#8217;t belong to the classes specified.
    Defaults to <literal>[]</literal> (keep all characters).
</simpara>
<simpara>Character classes may be any of the following:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>letter</literal>&#8201;&#8212;&#8201;     for example <literal>a</literal>, <literal>b</literal>, <literal>ï</literal> or <literal>京</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>digit</literal>&#8201;&#8212;&#8201;      for example <literal>3</literal> or <literal>7</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>whitespace</literal>&#8201;&#8212;&#8201; for example <literal>" "</literal> or <literal>"\n"</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>punctuation</literal>&#8201;&#8212;&#8201;for example <literal>!</literal> or <literal>"</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>symbol</literal>&#8201;&#8212;&#8201;     for example <literal>$</literal> or <literal>√</literal>
</simpara>
</listitem>
</itemizedlist>
</entry>
</row>
</tbody></tgroup></informaltable>
<tip><simpara>It usually makes sense to set <literal>min_gram</literal> and <literal>max_gram</literal> to the same
value.  The smaller the length, the more documents will match but the lower
the quality of the matches.  The longer the length, the more specific the
matches.  A tri-gram (length <literal>3</literal>) is a good place to start.</simpara></tip>
<bridgehead id="_example_configuration_9" renderas="sect2">Example configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/ngram-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<simpara>In this example, we configure the <literal>ngram</literal> tokenizer to treat letters and
digits as tokens, and to produce tri-grams (grams of length <literal>3</literal>):</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "ngram",
          "min_gram": 3,
          "max_gram": 3,
          "token_chars": [
            "letter",
            "digit"
          ]
        }
      }
    }
  }
}

POST my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "2 Quick Foxes."
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above example produces the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ Qui, uic, ick, Fox, oxe, xes ]</programlisting>
</section>
<section id="analysis-edgengram-tokenizer">
<title>Edge NGram Tokenizer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/edgengram-tokenizer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>edge_ngram</literal> tokenizer first breaks text down into words whenever it
encounters one of a list of specified characters, then it emits
<ulink url="https://en.wikipedia.org/wiki/N-gram">N-grams</ulink> of each word where the start of
the N-gram is anchored to the beginning of the word.</simpara>
<simpara>Edge N-Grams are useful for <emphasis>search-as-you-type</emphasis> queries.</simpara>
<tip><simpara>When you need <emphasis>search-as-you-type</emphasis> for text which has a widely known
order, such as movie or song titles, the
<link linkend="search-suggesters-completion">completion suggester</link> is a much more efficient
choice than edge N-grams.  Edge N-grams have the advantage when trying to
autocomplete words that can appear in any order.</simpara></tip>
<bridgehead id="_example_output_16" renderas="sect2">Example output<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/edgengram-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<simpara>With the default settings, the <literal>edge_ngram</literal> tokenizer treats the initial text as a
single token and produces N-grams with minimum length <literal>1</literal> and maximum length
<literal>2</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _analyze
{
  "tokenizer": "edge_ngram",
  "text": "Quick Fox"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above sentence would produce the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ Q, Qu ]</programlisting>
<note><simpara>These default gram lengths are almost entirely useless.  You need to
configure the <literal>edge_ngram</literal> before using it.</simpara></note>
<bridgehead id="_configuration_17" renderas="sect2">Configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/edgengram-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>edge_ngram</literal> tokenizer accepts the following parameters:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>min_gram</literal>
</simpara>
</entry>
<entry>
<simpara>
    Minimum length of characters in a gram.  Defaults to <literal>1</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max_gram</literal>
</simpara>
</entry>
<entry>
<simpara>
    Maximum length of characters in a gram.  Defaults to <literal>2</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>token_chars</literal>
</simpara>
</entry>
<entry>
<simpara>
    Character classes that should be included in a token.  Elasticsearch
    will split on characters that don&#8217;t belong to the classes specified.
    Defaults to <literal>[]</literal> (keep all characters).
</simpara>
<simpara>Character classes may be any of the following:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>letter</literal>&#8201;&#8212;&#8201;     for example <literal>a</literal>, <literal>b</literal>, <literal>ï</literal> or <literal>京</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>digit</literal>&#8201;&#8212;&#8201;      for example <literal>3</literal> or <literal>7</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>whitespace</literal>&#8201;&#8212;&#8201; for example <literal>" "</literal> or <literal>"\n"</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>punctuation</literal>&#8201;&#8212;&#8201;for example <literal>!</literal> or <literal>"</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>symbol</literal>&#8201;&#8212;&#8201;     for example <literal>$</literal> or <literal>√</literal>
</simpara>
</listitem>
</itemizedlist>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="_example_configuration_10" renderas="sect2">Example configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/edgengram-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<simpara>In this example, we configure the <literal>edge_ngram</literal> tokenizer to treat letters and
digits as tokens, and to produce grams with minimum length <literal>2</literal> and maximum
length <literal>10</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "edge_ngram",
          "min_gram": 2,
          "max_gram": 10,
          "token_chars": [
            "letter",
            "digit"
          ]
        }
      }
    }
  }
}

POST my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "2 Quick Foxes."
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above example produces the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ Qu, Qui, Quic, Quick, Fo, Fox, Foxe, Foxes ]</programlisting>
<simpara>Usually we recommend using the same <literal>analyzer</literal> at index time and at search
time. In the case of the <literal>edge_ngram</literal> tokenizer, the advice is different.  It
only makes sense to use the <literal>edge_ngram</literal> tokenizer at index time, to ensure
that partial words are available for matching in the index.  At search time,
just search for the terms the user has typed in, for instance: <literal>Quick Fo</literal>.</simpara>
<simpara>Below is an example of how to set up a field for <emphasis>search-as-you-type</emphasis>:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "autocomplete": {
          "tokenizer": "autocomplete",
          "filter": [
            "lowercase"
          ]
        },
        "autocomplete_search": {
          "tokenizer": "lowercase"
        }
      },
      "tokenizer": {
        "autocomplete": {
          "type": "edge_ngram",
          "min_gram": 2,
          "max_gram": 10,
          "token_chars": [
            "letter"
          ]
        }
      }
    }
  },
  "mappings": {
    "doc": {
      "properties": {
        "title": {
          "type": "text",
          "analyzer": "autocomplete",
          "search_analyzer": "autocomplete_search"
        }
      }
    }
  }
}

PUT my_index/doc/1
{
  "title": "Quick Foxes" <co id="CO272-1"/>
}

POST my_index/_refresh

GET my_index/_search
{
  "query": {
    "match": {
      "title": {
        "query": "Quick Fo", <co id="CO272-2"/>
        "operator": "and"
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO272-1">
<para>
The <literal>autocomplete</literal> analyzer indexes the terms <literal>[qu, qui, quic, quick, fo, fox, foxe, foxes]</literal>.
</para>
</callout>
<callout arearefs="CO272-2">
<para>
The <literal>autocomplete_search</literal> analyzer searches for the terms <literal>[quick, fo]</literal>, both of which appear in the index.
</para>
</callout>
</calloutlist>
</section>
<section id="analysis-keyword-tokenizer">
<title>Keyword Tokenizer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/keyword-tokenizer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>keyword</literal> tokenizer  is a &#8220;noop&#8221; tokenizer that accepts whatever text it
is given and outputs the exact same text as a single term.  It can be combined
with token filters to normalise output, e.g. lower-casing email addresses.</simpara>
<bridgehead id="_example_output_17" renderas="sect2">Example output<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/keyword-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">POST _analyze
{
  "tokenizer": "keyword",
  "text": "New York"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above sentence would produce the following term:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ New York ]</programlisting>
<bridgehead id="_configuration_18" renderas="sect2">Configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/keyword-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>keyword</literal> tokenizer accepts the following parameters:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>buffer_size</literal>
</simpara>
</entry>
<entry>
<simpara>
    The number of characters read into the term buffer in a single pass.
    Defaults to <literal>256</literal>.  The term buffer will grow by this size until all the
    text has been consumed.  It is advisable not to change this setting.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
<section id="analysis-pattern-tokenizer">
<title>Pattern Tokenizer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/pattern-tokenizer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>pattern</literal> tokenizer uses a regular expression to either split text into
terms whenever it matches a word separator, or to capture matching text as
terms.</simpara>
<simpara>The default pattern is <literal>\W+</literal>, which splits text whenever it encounters
non-word characters.</simpara>
<warning>
<title>Beware of Pathological Regular Expressions</title>
<simpara>The pattern tokenizer uses
<ulink url="http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html">Java Regular Expressions</ulink>.</simpara>
<simpara>A badly written regular expression could run very slowly or even throw a
StackOverflowError and cause the node it is running on to exit suddenly.</simpara>
<simpara>Read more about <ulink url="http://www.regular-expressions.info/catastrophic.html">pathological regular expressions and how to avoid them</ulink>.</simpara>
</warning>
<bridgehead id="_example_output_18" renderas="sect2">Example output<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/pattern-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">POST _analyze
{
  "tokenizer": "pattern",
  "text": "The foo_bar_size's default is 5."
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above sentence would produce the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ The, foo_bar_size, s, default, is, 5 ]</programlisting>
<bridgehead id="_configuration_19" renderas="sect2">Configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/pattern-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>pattern</literal> tokenizer accepts the following parameters:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>pattern</literal>
</simpara>
</entry>
<entry>
<simpara>
    A <ulink url="http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html">Java regular expression</ulink>, defaults to <literal>\W+</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>flags</literal>
</simpara>
</entry>
<entry>
<simpara>
    Java regular expression <ulink url="http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html#field.summary">flags</ulink>.
    lags should be pipe-separated, eg <literal>"CASE_INSENSITIVE|COMMENTS"</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>group</literal>
</simpara>
</entry>
<entry>
<simpara>
    Which capture group to extract as tokens.  Defaults to <literal>-1</literal> (split).
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="_example_configuration_11" renderas="sect2">Example configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/pattern-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<simpara>In this example, we configure the <literal>pattern</literal> tokenizer to break text into
tokens when it encounters commas:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "pattern",
          "pattern": ","
        }
      }
    }
  }
}

POST my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "comma,separated,values"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above example produces the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ comma, separated, values ]</programlisting>
<simpara>In the next example, we configure the <literal>pattern</literal> tokenizer to capture values
enclosed in double quotes (ignoring embedded escaped quotes <literal>\"</literal>).  The regex
itself looks like this:</simpara>
<literallayout class="monospaced">"((?:\\"|[^"]|\\")*)"</literallayout>
<simpara>And reads as follows:</simpara>
<itemizedlist>
<listitem>
<simpara>
A literal <literal>"</literal>
</simpara>
</listitem>
<listitem>
<simpara>
Start capturing:
</simpara>
<itemizedlist>
<listitem>
<simpara>
A literal <literal>\"</literal> OR any character except <literal>"</literal>
</simpara>
</listitem>
<listitem>
<simpara>
Repeat until no more characters match
</simpara>
</listitem>
</itemizedlist>
</listitem>
<listitem>
<simpara>
A literal closing <literal>"</literal>
</simpara>
</listitem>
</itemizedlist>
<simpara>When the pattern is specified in JSON, the <literal>"</literal> and <literal>\</literal> characters need to be
escaped, so the pattern ends up looking like:</simpara>
<literallayout class="monospaced">\"((?:\\\\\"|[^\"]|\\\\\")+)\"</literallayout>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "pattern",
          "pattern": "\"((?:\\\\\"|[^\"]|\\\\\")+)\"",
          "group": 1
        }
      }
    }
  }
}

POST my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "\"value\", \"value with embedded \\\" quote\""
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above example produces the following two terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ value, value with embedded \" quote ]</programlisting>
</section>
<section id="analysis-pathhierarchy-tokenizer">
<title>Path Hierarchy Tokenizer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/pathhierarchy-tokenizer.asciidoc">Edit me</ulink></title>
<simpara>The <literal>path_hierarchy</literal> tokenizer takes a hierarchical value like a filesystem
path, splits on the path separator, and emits a term for each component in the
tree.</simpara>
<bridgehead id="_example_output_19" renderas="sect2">Example output<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/pathhierarchy-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">POST _analyze
{
  "tokenizer": "path_hierarchy",
  "text": "/one/two/three"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above text would produce the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ /one, /one/two, /one/two/three ]</programlisting>
<bridgehead id="_configuration_20" renderas="sect2">Configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/pathhierarchy-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>path_hierarchy</literal> tokenizer accepts the following parameters:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>delimiter</literal>
</simpara>
</entry>
<entry>
<simpara>
    The character to use as the path separator.  Defaults to <literal>/</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>replacement</literal>
</simpara>
</entry>
<entry>
<simpara>
    An optional replacement character to use for the delimiter.
    Defaults to the <literal>delimiter</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>buffer_size</literal>
</simpara>
</entry>
<entry>
<simpara>
    The number of characters read into the term buffer in a single pass.
    Defaults to <literal>1024</literal>.  The term buffer will grow by this size until all the
    text has been consumed.  It is advisable not to change this setting.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>reverse</literal>
</simpara>
</entry>
<entry>
<simpara>
    If set to <literal>true</literal>, emits the tokens in reverse order.  Defaults to <literal>false</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>skip</literal>
</simpara>
</entry>
<entry>
<simpara>
    The number of initial tokens to skip.  Defaults to <literal>0</literal>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="_example_configuration_12" renderas="sect2">Example configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenizers/pathhierarchy-tokenizer.asciidoc">Edit me</ulink></bridgehead>
<simpara>In this example, we configure the <literal>path_hierarchy</literal> tokenizer to split on <literal>-</literal>
characters, and to replace them with <literal>/</literal>.  The first two tokens are skipped:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "path_hierarchy",
          "delimiter": "-",
          "replacement": "/",
          "skip": 2
        }
      }
    }
  }
}

POST my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "one-two-three-four-five"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above example produces the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ /three, /three/four, /three/four/five ]</programlisting>
<simpara>If we were to set <literal>reverse</literal> to <literal>true</literal>, it would produce the following:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ one/two/three/, two/three/, three/ ]</programlisting>
</section>
</chapter>
<chapter id="analysis-tokenfilters">
<title>Token Filters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters.asciidoc">Edit me</ulink></title>
<simpara>Token filters accept a stream of tokens from a
<link linkend="analysis-tokenizers">tokenizer</link> and can modify tokens
(eg lowercasing), delete tokens (eg remove stopwords)
or add tokens (eg synonyms).</simpara>
<simpara>Elasticsearch has a number of built in token filters which can be
used to build <link linkend="analysis-custom-analyzer">custom analyzers</link>.</simpara>
<section id="analysis-standard-tokenfilter">
<title>Standard Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/standard-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>A token filter of type <literal>standard</literal> that normalizes tokens extracted with
the
<link linkend="analysis-standard-tokenizer">Standard Tokenizer</link>.</simpara>
<tip>
<simpara>The <literal>standard</literal> token filter currently does nothing.  It remains as a placeholder
in case some filtering function needs to be added in a future version.</simpara>
</tip>
</section>
<section id="analysis-asciifolding-tokenfilter">
<title>ASCII Folding Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/asciifolding-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>A token filter of type <literal>asciifolding</literal> that converts alphabetic, numeric,
and symbolic Unicode characters which are not in the first 127 ASCII
characters (the "Basic Latin" Unicode block) into their ASCII
equivalents, if one exists.  Example:</simpara>
<programlisting language="js" linenumbering="unnumbered">"index" : {
    "analysis" : {
        "analyzer" : {
            "default" : {
                "tokenizer" : "standard",
                "filter" : ["standard", "asciifolding"]
            }
        }
    }
}</programlisting>
<simpara>Accepts <literal>preserve_original</literal> setting which defaults to false but if true
will keep the original token as well as emit the folded token.  For
example:</simpara>
<programlisting language="js" linenumbering="unnumbered">"index" : {
    "analysis" : {
        "analyzer" : {
            "default" : {
                "tokenizer" : "standard",
                "filter" : ["standard", "my_ascii_folding"]
            }
        },
        "filter" : {
            "my_ascii_folding" : {
                "type" : "asciifolding",
                "preserve_original" : true
            }
        }
    }
}</programlisting>
</section>
<section id="analysis-length-tokenfilter">
<title>Length Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/length-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>A token filter of type <literal>length</literal> that removes words that are too long or
too short for the stream.</simpara>
<simpara>The following are settings that can be set for a <literal>length</literal> token filter
type:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Setting </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>min</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The minimum number. Defaults to <literal>0</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>max</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The maximum number. Defaults to <literal>Integer.MAX_VALUE</literal>.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section id="analysis-lowercase-tokenfilter">
<title>Lowercase Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/lowercase-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>A token filter of type <literal>lowercase</literal> that normalizes token text to lower
case.</simpara>
<simpara>Lowercase token filter supports Greek, Irish, and Turkish lowercase token
filters through the <literal>language</literal> parameter. Below is a usage example in a
custom analyzer</simpara>
<programlisting language="js" linenumbering="unnumbered">index :
    analysis :
        analyzer :
            myAnalyzer2 :
                type : custom
                tokenizer : myTokenizer1
                filter : [myTokenFilter1, myGreekLowerCaseFilter]
                char_filter : [my_html]
        tokenizer :
            myTokenizer1 :
                type : standard
                max_token_length : 900
        filter :
            myTokenFilter1 :
                type : stop
                stopwords : [stop1, stop2, stop3, stop4]
            myGreekLowerCaseFilter :
                type : lowercase
                language : greek
        char_filter :
              my_html :
                type : html_strip
                escaped_tags : [xxx, yyy]
                read_ahead : 1024</programlisting>
</section>
<section id="analysis-uppercase-tokenfilter">
<title>Uppercase Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/uppercase-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>A token filter of type <literal>uppercase</literal> that normalizes token text to upper
case.</simpara>
</section>
<section id="analysis-ngram-tokenfilter">
<title>NGram Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/ngram-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>A token filter of type <literal>nGram</literal>.</simpara>
<simpara>The following are settings that can be set for a <literal>nGram</literal> token filter
type:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Setting </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>min_gram</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Defaults to <literal>1</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>max_gram</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Defaults to <literal>2</literal>.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section id="analysis-edgengram-tokenfilter">
<title>Edge NGram Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/edgengram-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>A token filter of type <literal>edgeNGram</literal>.</simpara>
<simpara>The following are settings that can be set for a <literal>edgeNGram</literal> token
filter type:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Setting </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>min_gram</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Defaults to <literal>1</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>max_gram</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Defaults to <literal>2</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>side</literal></simpara></entry>
<entry align="left" valign="top"><simpara>deprecated. Either <literal>front</literal> or <literal>back</literal>. Defaults to <literal>front</literal>.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section id="analysis-porterstem-tokenfilter">
<title>Porter Stem Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/porterstem-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>A token filter of type <literal>porter_stem</literal> that transforms the token stream as
per the Porter stemming algorithm.</simpara>
<simpara>Note, the input to the stemming filter must already be in lower case, so
you will need to use
<link linkend="analysis-lowercase-tokenfilter">Lower Case Token Filter</link> or
<link linkend="analysis-lowercase-tokenizer">Lower Case Tokenizer</link> farther down the Tokenizer chain in order for this to
work properly!. For example, when using custom analyzer, make sure the
<literal>lowercase</literal> filter comes before the <literal>porter_stem</literal> filter in the list of
filters.</simpara>
</section>
<section id="analysis-shingle-tokenfilter">
<title>Shingle Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/shingle-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>A token filter of type <literal>shingle</literal> that constructs shingles (token
n-grams) from a token stream. In other words, it creates combinations of
tokens as a single token. For example, the sentence "please divide this
sentence into shingles" might be tokenized into shingles "please
divide", "divide this", "this sentence", "sentence into", and "into
shingles".</simpara>
<simpara>This filter handles position increments &gt; 1 by inserting filler tokens
(tokens with termtext "_"). It does not handle a position increment of
0.</simpara>
<simpara>The following are settings that can be set for a <literal>shingle</literal> token filter
type:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Setting </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>max_shingle_size</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The maximum shingle size. Defaults to <literal>2</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>min_shingle_size</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The minimum shingle size. Defaults to <literal>2</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>output_unigrams</literal></simpara></entry>
<entry align="left" valign="top"><simpara>If <literal>true</literal> the output will contain the input tokens
(unigrams) as well as the shingles. Defaults to <literal>true</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>output_unigrams_if_no_shingles</literal></simpara></entry>
<entry align="left" valign="top"><simpara>If <literal>output_unigrams</literal> is <literal>false</literal> the
output will contain the input tokens (unigrams) if no shingles are
available. Note if <literal>output_unigrams</literal> is set to <literal>true</literal> this setting has
no effect. Defaults to <literal>false</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>token_separator</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The string to use when joining adjacent tokens to
form a shingle. Defaults to <literal>" "</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>filler_token</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The string to use as a replacement for each position
at which there is no actual token in the stream. For instance this string is
used if the position increment is greater than one when a <literal>stop</literal> filter is used
together with the <literal>shingle</literal> filter. Defaults to <literal>"_"</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section id="analysis-stop-tokenfilter">
<title>Stop Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/stop-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>A token filter of type <literal>stop</literal> that removes stop words from token
streams.</simpara>
<simpara>The following are settings that can be set for a <literal>stop</literal> token filter
type:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>stopwords</literal>
</simpara>
</entry>
<entry>
<simpara>
    A list of stop words to use. Defaults to <literal>_english_</literal> stop words.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>stopwords_path</literal>
</simpara>
</entry>
<entry>
<simpara>
    A path (either relative to <literal>config</literal> location, or absolute) to a stopwords
    file configuration. Each stop word should be in its own "line" (separated
    by a line break). The file must be UTF-8 encoded.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>ignore_case</literal>
</simpara>
</entry>
<entry>
<simpara>
    Set to <literal>true</literal> to lower case all words first. Defaults to <literal>false</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>remove_trailing</literal>
</simpara>
</entry>
<entry>
<simpara>
    Set to <literal>false</literal> in order to not ignore the last term of a search if it is a
    stop word. This is very useful for the completion suggester as a query
    like <literal>green a</literal> can be extended to <literal>green apple</literal> even though you remove
    stop words in general. Defaults to <literal>true</literal>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>The <literal>stopwords</literal> parameter accepts either an array of stopwords:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /my_index
{
    "settings": {
        "analysis": {
            "filter": {
                "my_stop": {
                    "type":       "stop",
                    "stopwords": ["and", "is", "the"]
                }
            }
        }
    }
}</programlisting>
<simpara>or a predefined language-specific list:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /my_index
{
    "settings": {
        "analysis": {
            "filter": {
                "my_stop": {
                    "type":       "stop",
                    "stopwords":  "_english_"
                }
            }
        }
    }
}</programlisting>
<simpara>Elasticsearch provides the following predefined list of languages:</simpara>
<simpara><literal>_arabic_</literal>, <literal>_armenian_</literal>, <literal>_basque_</literal>, <literal>_brazilian_</literal>, <literal>_bulgarian_</literal>,
<literal>_catalan_</literal>, <literal>_czech_</literal>, <literal>_danish_</literal>, <literal>_dutch_</literal>, <literal>_english_</literal>, <literal>_finnish_</literal>,
<literal>_french_</literal>, <literal>_galician_</literal>, <literal>_german_</literal>, <literal>_greek_</literal>, <literal>_hindi_</literal>, <literal>_hungarian_</literal>,
<literal>_indonesian_</literal>, <literal>_irish_</literal>, <literal>_italian_</literal>, <literal>_latvian_</literal>, <literal>_norwegian_</literal>, <literal>_persian_</literal>,
<literal>_portuguese_</literal>, <literal>_romanian_</literal>, <literal>_russian_</literal>, <literal>_sorani_</literal>, <literal>_spanish_</literal>,
<literal>_swedish_</literal>, <literal>_thai_</literal>, <literal>_turkish_</literal>.</simpara>
<simpara>For the empty stopwords list (to disable stopwords) use: <literal>\_none_</literal>.</simpara>
</section>
<section id="analysis-word-delimiter-tokenfilter">
<title>Word Delimiter Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/word-delimiter-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>Named <literal>word_delimiter</literal>, it Splits words into subwords and performs
optional transformations on subword groups. Words are split into
subwords with the following rules:</simpara>
<itemizedlist>
<listitem>
<simpara>
split on intra-word delimiters (by default, all non alpha-numeric
characters).
</simpara>
</listitem>
<listitem>
<simpara>
"Wi-Fi" &#8594; "Wi", "Fi"
</simpara>
</listitem>
<listitem>
<simpara>
split on case transitions: "PowerShot" &#8594; "Power", "Shot"
</simpara>
</listitem>
<listitem>
<simpara>
split on letter-number transitions: "SD500" &#8594; "SD", "500"
</simpara>
</listitem>
<listitem>
<simpara>
leading and trailing intra-word delimiters on each subword are
ignored: "//hello---there, <emphasis>dude</emphasis>" &#8594; "hello", "there", "dude"
</simpara>
</listitem>
<listitem>
<simpara>
trailing "'s" are removed for each subword: "O&#8217;Neil&#8217;s" &#8594; "O", "Neil"
</simpara>
</listitem>
</itemizedlist>
<simpara>Parameters include:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>generate_word_parts</literal>
</term>
<listitem>
<simpara>
    If <literal>true</literal> causes parts of words to be
    generated: "PowerShot" &#8658; "Power" "Shot". Defaults to <literal>true</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>generate_number_parts</literal>
</term>
<listitem>
<simpara>
    If <literal>true</literal> causes number subwords to be
    generated: "500-42" &#8658; "500" "42". Defaults to <literal>true</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>catenate_words</literal>
</term>
<listitem>
<simpara>
    If <literal>true</literal> causes maximum runs of word parts to be
    catenated: "wi-fi" &#8658; "wifi". Defaults to <literal>false</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>catenate_numbers</literal>
</term>
<listitem>
<simpara>
    If <literal>true</literal> causes maximum runs of number parts to
    be catenated: "500-42" &#8658; "50042". Defaults to <literal>false</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>catenate_all</literal>
</term>
<listitem>
<simpara>
    If <literal>true</literal> causes all subword parts to be catenated:
    "wi-fi-4000" &#8658; "wifi4000". Defaults to <literal>false</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>split_on_case_change</literal>
</term>
<listitem>
<simpara>
    If <literal>true</literal> causes "PowerShot" to be two tokens;
    ("Power-Shot" remains two parts regards). Defaults to <literal>true</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>preserve_original</literal>
</term>
<listitem>
<simpara>
    If <literal>true</literal> includes original words in subwords:
    "500-42" &#8658; "500-42" "500" "42". Defaults to <literal>false</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>split_on_numerics</literal>
</term>
<listitem>
<simpara>
    If <literal>true</literal> causes "j2se" to be three tokens; "j"
    "2" "se". Defaults to <literal>true</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>stem_english_possessive</literal>
</term>
<listitem>
<simpara>
    If <literal>true</literal> causes trailing "'s" to be
    removed for each subword: "O&#8217;Neil&#8217;s" &#8658; "O", "Neil". Defaults to <literal>true</literal>.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>Advance settings include:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>protected_words</literal>
</term>
<listitem>
<simpara>
    A list of protected words from being delimiter.
    Either an array, or also can set <literal>protected_words_path</literal> which resolved
    to a file configured with protected words (one on each line).
    Automatically resolves to <literal>config/</literal> based location if exists.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>type_table</literal>
</term>
<listitem>
<simpara>
    A custom type mapping table, for example (when configured
    using <literal>type_table_path</literal>):
</simpara>
</listitem>
</varlistentry>
</variablelist>
<programlisting language="js" linenumbering="unnumbered">    # Map the $, %, '.', and ',' characters to DIGIT
    # This might be useful for financial data.
    $ =&gt; DIGIT
    % =&gt; DIGIT
    . =&gt; DIGIT
    \\u002C =&gt; DIGIT

    # in some cases you might not want to split on ZWJ
    # this also tests the case where we need a bigger byte[]
    # see http://en.wikipedia.org/wiki/Zero-width_joiner
    \\u200D =&gt; ALPHANUM</programlisting>
<note><simpara>Using a tokenizer like the <literal>standard</literal> tokenizer may interfere with
the <literal>catenate_*</literal> and <literal>preserve_original</literal> parameters, as the original
string may already have lost punctuation during tokenization.  Instead,
you may want to use the <literal>whitespace</literal> tokenizer.</simpara></note>
</section>
<section id="analysis-stemmer-tokenfilter">
<title>Stemmer Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/stemmer-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>A filter that provides access to (almost) all of the available stemming token
filters through a single unified interface. For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "index" : {
        "analysis" : {
            "analyzer" : {
                "my_analyzer" : {
                    "tokenizer" : "standard",
                    "filter" : ["standard", "lowercase", "my_stemmer"]
                }
            },
            "filter" : {
                "my_stemmer" : {
                    "type" : "stemmer",
                    "name" : "light_german"
                }
            }
        }
    }
}</programlisting>
<simpara>The <literal>language</literal>/<literal>name</literal> parameter controls the stemmer with the following
available values (the preferred filters are marked in <emphasis role="strong">bold</emphasis>):</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
Arabic
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://lucene.apache.org/core/4_9_0/analyzers-common/org/apache/lucene/analysis/ar/ArabicStemmer.html"><emphasis role="strong"><literal>arabic</literal></emphasis></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Armenian
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://snowball.tartarus.org/algorithms/armenian/stemmer.html"><emphasis role="strong"><literal>armenian</literal></emphasis></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Basque
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://snowball.tartarus.org/algorithms/basque/stemmer.html"><emphasis role="strong"><literal>basque</literal></emphasis></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Brazilian Portuguese
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://lucene.apache.org/core/4_9_0/analyzers-common/org/apache/lucene/analysis/br/BrazilianStemmer.html"><emphasis role="strong"><literal>brazilian</literal></emphasis></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Bulgarian
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://members.unine.ch/jacques.savoy/Papers/BUIR.pdf"><emphasis role="strong"><literal>bulgarian</literal></emphasis></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Catalan
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://snowball.tartarus.org/algorithms/catalan/stemmer.html"><emphasis role="strong"><literal>catalan</literal></emphasis></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Czech
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://portal.acm.org/citation.cfm?id=1598600"><emphasis role="strong"><literal>czech</literal></emphasis></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Danish
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://snowball.tartarus.org/algorithms/danish/stemmer.html"><emphasis role="strong"><literal>danish</literal></emphasis></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Dutch
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://snowball.tartarus.org/algorithms/dutch/stemmer.html"><emphasis role="strong"><literal>dutch</literal></emphasis></ulink>,
<ulink url="http://snowball.tartarus.org/algorithms/kraaij_pohlmann/stemmer.html"><literal>dutch_kp</literal></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
English
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://snowball.tartarus.org/algorithms/porter/stemmer.html"><emphasis role="strong"><literal>english</literal></emphasis></ulink>,
<ulink url="http://ciir.cs.umass.edu/pubfiles/ir-35.pdf"><literal>light_english</literal></ulink>,
<ulink url="http://www.researchgate.net/publication/220433848_How_effective_is_suffixing"><literal>minimal_english</literal></ulink>,
<ulink url="http://lucene.apache.org/core/4_9_0/analyzers-common/org/apache/lucene/analysis/en/EnglishPossessiveFilter.html"><literal>possessive_english</literal></ulink>,
<ulink url="http://snowball.tartarus.org/algorithms/english/stemmer.html"><literal>porter2</literal></ulink>,
<ulink url="http://snowball.tartarus.org/algorithms/lovins/stemmer.html"><literal>lovins</literal></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Finnish
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://snowball.tartarus.org/algorithms/finnish/stemmer.html"><emphasis role="strong"><literal>finnish</literal></emphasis></ulink>,
<ulink url="http://clef.isti.cnr.it/2003/WN_web/22.pdf"><literal>light_finnish</literal></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
French
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://snowball.tartarus.org/algorithms/french/stemmer.html"><literal>french</literal></ulink>,
<ulink url="http://dl.acm.org/citation.cfm?id=1141523"><emphasis role="strong"><literal>light_french</literal></emphasis></ulink>,
<ulink url="http://dl.acm.org/citation.cfm?id=318984"><literal>minimal_french</literal></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Galician
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://bvg.udc.es/recursos_lingua/stemming.jsp"><emphasis role="strong"><literal>galician</literal></emphasis></ulink>,
<ulink url="http://bvg.udc.es/recursos_lingua/stemming.jsp"><literal>minimal_galician</literal></ulink> (Plural step only)
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
German
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://snowball.tartarus.org/algorithms/german/stemmer.html"><literal>german</literal></ulink>,
<ulink url="http://snowball.tartarus.org/algorithms/german2/stemmer.html"><literal>german2</literal></ulink>,
<ulink url="http://dl.acm.org/citation.cfm?id=1141523"><emphasis role="strong"><literal>light_german</literal></emphasis></ulink>,
<ulink url="http://members.unine.ch/jacques.savoy/clef/morpho.pdf"><literal>minimal_german</literal></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Greek
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://sais.se/mthprize/2007/ntais2007.pdf"><emphasis role="strong"><literal>greek</literal></emphasis></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Hindi
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://computing.open.ac.uk/Sites/EACLSouthAsia/Papers/p6-Ramanathan.pdf"><emphasis role="strong"><literal>hindi</literal></emphasis></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Hungarian
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://snowball.tartarus.org/algorithms/hungarian/stemmer.html"><emphasis role="strong"><literal>hungarian</literal></emphasis></ulink>,
<ulink url="http://dl.acm.org/citation.cfm?id=1141523&amp;dl=ACM&amp;coll=DL&amp;CFID=179095584&amp;CFTOKEN=80067181"><literal>light_hungarian</literal></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Indonesian
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://www.illc.uva.nl/Publications/ResearchReports/MoL-2003-02.text.pdf"><emphasis role="strong"><literal>indonesian</literal></emphasis></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Irish
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://snowball.tartarus.org/otherapps/oregan/intro.html"><emphasis role="strong"><literal>irish</literal></emphasis></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Italian
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://snowball.tartarus.org/algorithms/italian/stemmer.html"><literal>italian</literal></ulink>,
<ulink url="http://www.ercim.eu/publication/ws-proceedings/CLEF2/savoy.pdf"><emphasis role="strong"><literal>light_italian</literal></emphasis></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Kurdish (Sorani)
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://lucene.apache.org/core/4_9_0/analyzers-common/org/apache/lucene/analysis/ckb/SoraniStemmer.html"><emphasis role="strong"><literal>sorani</literal></emphasis></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Latvian
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://lucene.apache.org/core/4_9_0/analyzers-common/org/apache/lucene/analysis/lv/LatvianStemmer.html"><emphasis role="strong"><literal>latvian</literal></emphasis></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Lithuanian
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://svn.apache.org/viewvc/lucene/dev/branches/lucene_solr_5_3/lucene/analysis/common/src/java/org/apache/lucene/analysis/lt/stem_ISO_8859_1.sbl?view=markup"><emphasis role="strong"><literal>lithuanian</literal></emphasis></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Norwegian (Bokmål)
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://snowball.tartarus.org/algorithms/norwegian/stemmer.html"><emphasis role="strong"><literal>norwegian</literal></emphasis></ulink>,
<ulink url="http://lucene.apache.org/core/4_9_0/analyzers-common/org/apache/lucene/analysis/no/NorwegianLightStemmer.html"><emphasis role="strong"><literal>light_norwegian</literal></emphasis></ulink>,
<ulink url="http://lucene.apache.org/core/4_9_0/analyzers-common/org/apache/lucene/analysis/no/NorwegianMinimalStemmer.html"><literal>minimal_norwegian</literal></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Norwegian (Nynorsk)
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://lucene.apache.org/core/4_9_0/analyzers-common/org/apache/lucene/analysis/no/NorwegianLightStemmer.html"><emphasis role="strong"><literal>light_nynorsk</literal></emphasis></ulink>,
<ulink url="http://lucene.apache.org/core/4_9_0/analyzers-common/org/apache/lucene/analysis/no/NorwegianMinimalStemmer.html"><literal>minimal_nynorsk</literal></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Portuguese
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://snowball.tartarus.org/algorithms/portuguese/stemmer.html"><literal>portuguese</literal></ulink>,
<ulink url="http://dl.acm.org/citation.cfm?id=1141523&amp;dl=ACM&amp;coll=DL&amp;CFID=179095584&amp;CFTOKEN=80067181"><emphasis role="strong"><literal>light_portuguese</literal></emphasis></ulink>,
<ulink url="http://www.inf.ufrgs.br/~buriol/papers/Orengo_CLEF07.pdf"><literal>minimal_portuguese</literal></ulink>,
<ulink url="http://www.inf.ufrgs.br/\~viviane/rslp/index.htm"><literal>portuguese_rslp</literal></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Romanian
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://snowball.tartarus.org/algorithms/romanian/stemmer.html"><emphasis role="strong"><literal>romanian</literal></emphasis></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Russian
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://snowball.tartarus.org/algorithms/russian/stemmer.html"><emphasis role="strong"><literal>russian</literal></emphasis></ulink>,
<ulink url="http://doc.rero.ch/lm.php?url=1000%2C43%2C4%2C20091209094227-CA%2FDolamic_Ljiljana_-_Indexing_and_Searching_Strategies_for_the_Russian_20091209.pdf"><literal>light_russian</literal></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Spanish
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://snowball.tartarus.org/algorithms/spanish/stemmer.html"><literal>spanish</literal></ulink>,
<ulink url="http://www.ercim.eu/publication/ws-proceedings/CLEF2/savoy.pdf"><emphasis role="strong"><literal>light_spanish</literal></emphasis></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Swedish
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://snowball.tartarus.org/algorithms/swedish/stemmer.html"><emphasis role="strong"><literal>swedish</literal></emphasis></ulink>,
<ulink url="http://clef.isti.cnr.it/2003/WN_web/22.pdf"><literal>light_swedish</literal></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Turkish
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://snowball.tartarus.org/algorithms/turkish/stemmer.html"><emphasis role="strong"><literal>turkish</literal></emphasis></ulink>
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
<section id="analysis-stemmer-override-tokenfilter">
<title>Stemmer Override Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/stemmer-override-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>Overrides stemming algorithms, by applying a custom mapping, then
protecting these terms from being modified by stemmers. Must be placed
before any stemming filters.</simpara>
<simpara>Rules are separated by <literal>=&gt;</literal></simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Setting </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>rules</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A list of mapping rules to use.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>rules_path</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A path (either relative to <literal>config</literal> location, or
absolute) to a list of mappings.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">index :
    analysis :
        analyzer :
            myAnalyzer :
                type : custom
                tokenizer : standard
                filter : [lowercase, custom_stems, porter_stem]
        filter:
            custom_stems:
                type: stemmer_override
                rules_path : analysis/custom_stems.txt</programlisting>
</section>
<section id="analysis-keyword-marker-tokenfilter">
<title>Keyword Marker Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/keyword-marker-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>Protects words from being modified by stemmers. Must be placed before
any stemming filters.</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Setting </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>keywords</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A list of words to use.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>keywords_path</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A path (either relative to <literal>config</literal> location, or
absolute) to a list of words.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ignore_case</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Set to <literal>true</literal> to lower case all words first. Defaults to
<literal>false</literal>.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">index :
    analysis :
        analyzer :
            myAnalyzer :
                type : custom
                tokenizer : standard
                filter : [lowercase, protwords, porter_stem]
        filter :
            protwords :
                type : keyword_marker
                keywords_path : analysis/protwords.txt</programlisting>
</section>
<section id="analysis-keyword-repeat-tokenfilter">
<title>Keyword Repeat Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/keyword-repeat-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>The <literal>keyword_repeat</literal> token filter Emits each incoming token twice once
as keyword and once as a non-keyword to allow an unstemmed version of a
term to be indexed side by side with the stemmed version of the term.
Given the nature of this filter each token that isn&#8217;t transformed by a
subsequent stemmer will be indexed twice. Therefore, consider adding a
<literal>unique</literal> filter with <literal>only_on_same_position</literal> set to <literal>true</literal> to drop
unnecessary duplicates.</simpara>
<simpara>Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">index :
    analysis :
        analyzer :
            myAnalyzer :
                type : custom
                tokenizer : standard
                filter : [lowercase, keyword_repeat, porter_stem, unique_stem]
            unique_stem:
                type: unique
                only_on_same_position : true</programlisting>
</section>
<section id="analysis-kstem-tokenfilter">
<title>KStem Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/kstem-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>The <literal>kstem</literal> token filter is a high performance filter for english. All
terms must already be lowercased (use <literal>lowercase</literal> filter) for this
filter to work correctly.</simpara>
</section>
<section id="analysis-snowball-tokenfilter">
<title>Snowball Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/snowball-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>A filter that stems words using a Snowball-generated stemmer. The
<literal>language</literal> parameter controls the stemmer with the following available
values: <literal>Armenian</literal>, <literal>Basque</literal>, <literal>Catalan</literal>, <literal>Danish</literal>, <literal>Dutch</literal>, <literal>English</literal>,
<literal>Finnish</literal>, <literal>French</literal>, <literal>German</literal>, <literal>German2</literal>, <literal>Hungarian</literal>, <literal>Italian</literal>, <literal>Kp</literal>,
<literal>Lithuanian</literal>, <literal>Lovins</literal>, <literal>Norwegian</literal>, <literal>Porter</literal>, <literal>Portuguese</literal>, <literal>Romanian</literal>,
<literal>Russian</literal>, <literal>Spanish</literal>, <literal>Swedish</literal>, <literal>Turkish</literal>.</simpara>
<simpara>For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "index" : {
        "analysis" : {
            "analyzer" : {
                "my_analyzer" : {
                    "tokenizer" : "standard",
                    "filter" : ["standard", "lowercase", "my_snow"]
                }
            },
            "filter" : {
                "my_snow" : {
                    "type" : "snowball",
                    "language" : "Lovins"
                }
            }
        }
    }
}</programlisting>
</section>
<section id="analysis-phonetic-tokenfilter">
<title>Phonetic Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/phonetic-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>The <literal>phonetic</literal> token filter is provided as the <ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/analysis-phonetic.html"><literal>analysis-phonetic</literal></ulink> plugin.</simpara>
</section>
<section id="analysis-synonym-tokenfilter">
<title>Synonym Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/synonym-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>The <literal>synonym</literal> token filter allows to easily handle synonyms during the
analysis process. Synonyms are configured using a configuration file.
Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "index" : {
        "analysis" : {
            "analyzer" : {
                "synonym" : {
                    "tokenizer" : "whitespace",
                    "filter" : ["synonym"]
                }
            },
            "filter" : {
                "synonym" : {
                    "type" : "synonym",
                    "synonyms_path" : "analysis/synonym.txt"
                }
            }
        }
    }
}</programlisting>
<simpara>The above configures a <literal>synonym</literal> filter, with a path of
<literal>analysis/synonym.txt</literal> (relative to the <literal>config</literal> location). The
<literal>synonym</literal> analyzer is then configured with the filter. Additional
settings are: <literal>ignore_case</literal> (defaults to <literal>false</literal>), and <literal>expand</literal>
(defaults to <literal>true</literal>).</simpara>
<simpara>The <literal>tokenizer</literal> parameter controls the tokenizers that will be used to
tokenize the synonym, and defaults to the <literal>whitespace</literal> tokenizer.</simpara>
<simpara>Two synonym formats are supported: Solr, WordNet.</simpara>
<bridgehead id="_solr_synonyms" renderas="sect3">Solr synonyms<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/synonym-tokenfilter.asciidoc">Edit me</ulink></bridgehead>
<simpara>The following is a sample format of the file:</simpara>
<programlisting language="js" linenumbering="unnumbered"># Blank lines and lines starting with pound are comments.

# Explicit mappings match any token sequence on the LHS of "=&gt;"
# and replace with all alternatives on the RHS.  These types of mappings
# ignore the expand parameter in the schema.
# Examples:
i-pod, i pod =&gt; ipod,
sea biscuit, sea biscit =&gt; seabiscuit

# Equivalent synonyms may be separated with commas and give
# no explicit mapping.  In this case the mapping behavior will
# be taken from the expand parameter in the schema.  This allows
# the same synonym file to be used in different synonym handling strategies.
# Examples:
ipod, i-pod, i pod
foozball , foosball
universe , cosmos

# If expand==true, "ipod, i-pod, i pod" is equivalent
# to the explicit mapping:
ipod, i-pod, i pod =&gt; ipod, i-pod, i pod
# If expand==false, "ipod, i-pod, i pod" is equivalent
# to the explicit mapping:
ipod, i-pod, i pod =&gt; ipod

# Multiple synonym mapping entries are merged.
foo =&gt; foo bar
foo =&gt; baz
# is equivalent to
foo =&gt; foo bar, baz</programlisting>
<simpara>You can also define synonyms for the filter directly in the
configuration file (note use of <literal>synonyms</literal> instead of <literal>synonyms_path</literal>):</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "filter" : {
        "synonym" : {
            "type" : "synonym",
            "synonyms" : [
                "i-pod, i pod =&gt; ipod",
                "universe, cosmos"
            ]
        }
    }
}</programlisting>
<simpara>However, it is recommended to define large synonyms set in a file using
<literal>synonyms_path</literal>, because specifying them inline increases cluster size unnecessarily.</simpara>
<bridgehead id="_wordnet_synonyms" renderas="sect3">WordNet synonyms<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/synonym-tokenfilter.asciidoc">Edit me</ulink></bridgehead>
<simpara>Synonyms based on <ulink url="http://wordnet.princeton.edu/">WordNet</ulink> format can be
declared using <literal>format</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "filter" : {
        "synonym" : {
            "type" : "synonym",
            "format" : "wordnet",
            "synonyms" : [
                "s(100000001,1,'abstain',v,1,0).",
                "s(100000001,2,'refrain',v,1,0).",
                "s(100000001,3,'desist',v,1,0)."
            ]
        }
    }
}</programlisting>
<simpara>Using <literal>synonyms_path</literal> to define WordNet synonyms in a file is supported
as well.</simpara>
</section>
<section id="analysis-compound-word-tokenfilter">
<title>Compound Word Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/compound-word-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>The <literal>hyphenation_decompounder</literal> and <literal>dictionary_decompounder</literal> token filters can
decompose compound words found in many German languages into word parts.</simpara>
<simpara>Both token filters require a dictionary of word parts, which can be provided
as:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>word_list</literal>
</simpara>
</entry>
<entry>
<simpara>
An array of words, specified inline in the token filter configuration, or
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>word_list_path</literal>
</simpara>
</entry>
<entry>
<simpara>
The path (either absolute or relative to the <literal>config</literal> directory) to a UTF-8
encoded file containing one word per line.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="_hyphenation_decompounder" renderas="sect2">Hyphenation decompounder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/compound-word-tokenfilter.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>hyphenation_decompounder</literal> uses hyphenation grammars to find potential
subwords that are then checked against the word dictionary. The quality of the
output tokens is directly connected to the quality of the grammar file you
use. For languages like German they are quite good.</simpara>
<simpara>XML based hyphenation grammar files can be found in the
<ulink url="http://offo.sourceforge.net/hyphenation/#FOP+XML+Hyphenation+Patterns">Objects For Formatting Objects</ulink>
(OFFO) Sourceforge project. Currently only FOP v1.2 compatible hyphenation files
are supported. You can download <ulink url="https://sourceforge.net/projects/offo/files/offo-hyphenation/1.2/offo-hyphenation_v1.2.zip/download">offo-hyphenation_v1.2.zip</ulink>
directly and look in the <literal>offo-hyphenation/hyph/</literal> directory.
Credits for the hyphenation code go to the Apache FOP project .</simpara>
<bridgehead id="_dictionary_decompounder" renderas="sect2">Dictionary decompounder<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/compound-word-tokenfilter.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>dictionary_decompounder</literal> uses a brute force approach in conjunction with
only the word dictionary to find subwords in a compound word. It is much
slower than the hyphenation decompounder but can be used as a first start to
check the quality of your dictionary.</simpara>
<bridgehead id="_compound_token_filter_parameters" renderas="sect2">Compound token filter parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/compound-word-tokenfilter.asciidoc">Edit me</ulink></bridgehead>
<simpara>The following parameters can be used to configure a compound word token
filter:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>type</literal>
</simpara>
</entry>
<entry>
<simpara>
Either <literal>dictionary_decompounder</literal> or <literal>hyphenation_decompounder</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>word_list</literal>
</simpara>
</entry>
<entry>
<simpara>
A array containing a list of words to use for the word dictionary.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>word_list_path</literal>
</simpara>
</entry>
<entry>
<simpara>
The path (either absolute or relative to the <literal>config</literal> directory) to the word dictionary.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>hyphenation_patterns_path</literal>
</simpara>
</entry>
<entry>
<simpara>
The path (either absolute or relative to the <literal>config</literal> directory) to a FOP XML hyphenation pattern file. (required for hyphenation)
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>min_word_size</literal>
</simpara>
</entry>
<entry>
<simpara>
Minimum word size. Defaults to 5.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>min_subword_size</literal>
</simpara>
</entry>
<entry>
<simpara>
Minimum subword size. Defaults to 2.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max_subword_size</literal>
</simpara>
</entry>
<entry>
<simpara>
Maximum subword size. Defaults to 15.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>only_longest_match</literal>
</simpara>
</entry>
<entry>
<simpara>
Whether to include only the longest matching subword or not.  Defaults to <literal>false</literal>
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">index :
    analysis :
        analyzer :
            myAnalyzer2 :
                type : custom
                tokenizer : standard
                filter : [myTokenFilter1, myTokenFilter2]
        filter :
            myTokenFilter1 :
                type : dictionary_decompounder
                word_list: [one, two, three]
            myTokenFilter2 :
                type : hyphenation_decompounder
                word_list_path: path/to/words.txt
                hyphenation_patterns_path: path/to/fop.xml
                max_subword_size : 22</programlisting>
</section>
<section id="analysis-reverse-tokenfilter">
<title>Reverse Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/reverse-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>A token filter of type <literal>reverse</literal> that simply reverses each token.</simpara>
</section>
<section id="analysis-elision-tokenfilter">
<title>Elision Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/elision-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>A token filter which removes elisions. For example, "l&#8217;avion" (the
plane) will tokenized as "avion" (plane).</simpara>
<simpara>Accepts <literal>articles</literal> setting which is a set of stop words articles. For
example:</simpara>
<programlisting language="js" linenumbering="unnumbered">"index" : {
    "analysis" : {
        "analyzer" : {
            "default" : {
                "tokenizer" : "standard",
                "filter" : ["standard", "elision"]
            }
        },
        "filter" : {
            "elision" : {
                "type" : "elision",
                "articles" : ["l", "m", "t", "qu", "n", "s", "j"]
            }
        }
    }
}</programlisting>
</section>
<section id="analysis-truncate-tokenfilter">
<title>Truncate Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/truncate-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>The <literal>truncate</literal> token filter can be used to truncate tokens into a
specific length. This can come in handy with keyword (single token)
based mapped fields that are used for sorting in order to reduce memory
usage.</simpara>
<simpara>It accepts a <literal>length</literal> parameter which control the number of characters
to truncate to, defaults to <literal>10</literal>.</simpara>
</section>
<section id="analysis-unique-tokenfilter">
<title>Unique Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/unique-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>The <literal>unique</literal> token filter can be used to only index unique tokens during
analysis. By default it is applied on all the token stream. If
<literal>only_on_same_position</literal> is set to <literal>true</literal>, it will only remove duplicate
tokens on the same position.</simpara>
</section>
<section id="analysis-pattern-capture-tokenfilter">
<title>Pattern Capture Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/pattern-capture-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>The <literal>pattern_capture</literal> token filter, unlike the <literal>pattern</literal> tokenizer,
emits a token for every capture group in the regular expression.
Patterns are not anchored to the beginning and end of the string, so
each pattern can match multiple times, and matches are allowed to
overlap.</simpara>
<warning>
<title>Beware of Pathological Regular Expressions</title>
<simpara>The pattern capture token filter uses
<ulink url="http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html">Java Regular Expressions</ulink>.</simpara>
<simpara>A badly written regular expression could run very slowly or even throw a
StackOverflowError and cause the node it is running on to exit suddenly.</simpara>
<simpara>Read more about <ulink url="http://www.regular-expressions.info/catastrophic.html">pathological regular expressions and how to avoid them</ulink>.</simpara>
</warning>
<simpara>For instance a pattern like :</simpara>
<programlisting language="js" linenumbering="unnumbered">"(([a-z]+)(\d*))"</programlisting>
<simpara>when matched against:</simpara>
<programlisting language="js" linenumbering="unnumbered">"abc123def456"</programlisting>
<simpara>would produce the tokens: [ <literal>abc123</literal>, <literal>abc</literal>, <literal>123</literal>, <literal>def456</literal>, <literal>def</literal>,
<literal>456</literal> ]</simpara>
<simpara>If <literal>preserve_original</literal> is set to <literal>true</literal> (the default) then it would also
emit the original token: <literal>abc123def456</literal>.</simpara>
<simpara>This is particularly useful for indexing text like camel-case code, eg
<literal>stripHTML</literal> where a user may search for <literal>"strip html"</literal> or <literal>"striphtml"</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XPUT localhost:9200/test/  -d '
{
   "settings" : {
      "analysis" : {
         "filter" : {
            "code" : {
               "type" : "pattern_capture",
               "preserve_original" : 1,
               "patterns" : [
                  "(\\p{Ll}+|\\p{Lu}\\p{Ll}+|\\p{Lu}+)",
                  "(\\d+)"
               ]
            }
         },
         "analyzer" : {
            "code" : {
               "tokenizer" : "pattern",
               "filter" : [ "code", "lowercase" ]
            }
         }
      }
   }
}
'</programlisting>
<simpara>When used to analyze the text</simpara>
<programlisting language="js" linenumbering="unnumbered">import static org.apache.commons.lang.StringEscapeUtils.escapeHtml</programlisting>
<simpara>this emits the tokens: [ <literal>import</literal>, <literal>static</literal>, <literal>org</literal>, <literal>apache</literal>, <literal>commons</literal>,
<literal>lang</literal>, <literal>stringescapeutils</literal>, <literal>string</literal>, <literal>escape</literal>, <literal>utils</literal>, <literal>escapehtml</literal>,
<literal>escape</literal>, <literal>html</literal> ]</simpara>
<simpara>Another example is analyzing email addresses:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XPUT localhost:9200/test/  -d '
{
   "settings" : {
      "analysis" : {
         "filter" : {
            "email" : {
               "type" : "pattern_capture",
               "preserve_original" : 1,
               "patterns" : [
                  "([^@]+)",
                  "(\\p{L}+)",
                  "(\\d+)",
                  "@(.+)"
               ]
            }
         },
         "analyzer" : {
            "email" : {
               "tokenizer" : "uax_url_email",
               "filter" : [ "email", "lowercase",  "unique" ]
            }
         }
      }
   }
}
'</programlisting>
<simpara>When the above analyzer is used on an email address like:</simpara>
<programlisting language="js" linenumbering="unnumbered">john-smith_123@foo-bar.com</programlisting>
<simpara>it would produce the following tokens:</simpara>
<literallayout class="monospaced">john-smith_123@foo-bar.com, john-smith_123,
john, smith, 123, foo-bar.com, foo, bar, com</literallayout>
<simpara>Multiple patterns are required to allow overlapping captures, but also
means that patterns are less dense and easier to understand.</simpara>
<simpara><emphasis role="strong">Note:</emphasis> All tokens are emitted in the same position, and with the same
character offsets, so when combined with highlighting, the whole
original token will be highlighted, not just the matching subset. For
instance, querying the above email address for <literal>"smith"</literal> would
highlight:</simpara>
<programlisting language="js" linenumbering="unnumbered">  &lt;em&gt;john-smith_123@foo-bar.com&lt;/em&gt;</programlisting>
<simpara>not:</simpara>
<programlisting language="js" linenumbering="unnumbered">  john-&lt;em&gt;smith&lt;/em&gt;_123@foo-bar.com</programlisting>
</section>
<section id="analysis-pattern_replace-tokenfilter">
<title>Pattern Replace Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/pattern_replace-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>The <literal>pattern_replace</literal> token filter allows to easily handle string
replacements based on a regular expression. The regular expression is
defined using the <literal>pattern</literal> parameter, and the replacement string can be
provided using the <literal>replacement</literal> parameter (supporting referencing the
original text, as explained
<ulink url="http://docs.oracle.com/javase/6/docs/api/java/util/regex/Matcher.html#appendReplacement(java.lang.StringBuffer,%20java.lang.String)">here</ulink>).</simpara>
<warning>
<title>Beware of Pathological Regular Expressions</title>
<simpara>The pattern replace token filter uses
<ulink url="http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html">Java Regular Expressions</ulink>.</simpara>
<simpara>A badly written regular expression could run very slowly or even throw a
StackOverflowError and cause the node it is running on to exit suddenly.</simpara>
<simpara>Read more about <ulink url="http://www.regular-expressions.info/catastrophic.html">pathological regular expressions and how to avoid them</ulink>.</simpara>
</warning>
</section>
<section id="analysis-trim-tokenfilter">
<title>Trim Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/trim-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>The <literal>trim</literal> token filter trims the whitespace surrounding a token.</simpara>
</section>
<section id="analysis-limit-token-count-tokenfilter">
<title>Limit Token Count Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/limit-token-count-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>Limits the number of tokens that are indexed per document and field.</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Setting </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>max_token_count</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The maximum number of tokens that should be indexed
per document and field. The default is <literal>1</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>consume_all_tokens</literal></simpara></entry>
<entry align="left" valign="top"><simpara>If set to <literal>true</literal> the filter exhaust the stream
even if <literal>max_token_count</literal> tokens have been consumed already. The default
is <literal>false</literal>.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">index :
    analysis :
        analyzer :
            myAnalyzer :
                type : custom
                tokenizer : standard
                filter : [lowercase, five_token_limit]
        filter :
            five_token_limit :
                type : limit
                max_token_count : 5</programlisting>
</section>
<section id="analysis-hunspell-tokenfilter">
<title>Hunspell Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/hunspell-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>Basic support for hunspell stemming. Hunspell dictionaries will be
picked up from a dedicated hunspell directory on the filesystem
(<literal>&lt;path.conf&gt;/hunspell</literal>). Each dictionary is expected to
have its own directory named after its associated locale (language).
This dictionary directory is expected to hold a single <literal>*.aff</literal> and
one or more <literal>*.dic</literal> files (all of which will automatically be picked up).
For example, assuming the default hunspell location is used, the
following directory layout will define the <literal>en_US</literal> dictionary:</simpara>
<programlisting language="js" linenumbering="unnumbered">- conf
    |-- hunspell
    |    |-- en_US
    |    |    |-- en_US.dic
    |    |    |-- en_US.aff</programlisting>
<simpara>Each dictionary can be configured with one setting:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>ignore_case</literal>
</term>
<listitem>
<simpara>
    If true, dictionary matching will be case insensitive
    (defaults to <literal>false</literal>)
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>This setting can be configured globally in <literal>elasticsearch.yml</literal> using</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>indices.analysis.hunspell.dictionary.ignore_case</literal>
</simpara>
</listitem>
</itemizedlist>
<simpara>or for specific dictionaries:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>indices.analysis.hunspell.dictionary.en_US.ignore_case</literal>.
</simpara>
</listitem>
</itemizedlist>
<simpara>It is also possible to add <literal>settings.yml</literal> file under the dictionary
directory which holds these settings (this will override any other
settings defined in the <literal>elasticsearch.yml</literal>).</simpara>
<simpara>One can use the hunspell stem filter by configuring it the analysis
settings:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "analysis" : {
        "analyzer" : {
            "en" : {
                "tokenizer" : "standard",
                "filter" : [ "lowercase", "en_US" ]
            }
        },
        "filter" : {
            "en_US" : {
                "type" : "hunspell",
                "locale" : "en_US",
                "dedup" : true
            }
        }
    }
}</programlisting>
<simpara>The hunspell token filter accepts four options:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>locale</literal>
</term>
<listitem>
<simpara>
    A locale for this filter. If this is unset, the <literal>lang</literal> or
    <literal>language</literal> are used instead - so one of these has to be set.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>dictionary</literal>
</term>
<listitem>
<simpara>
    The name of a dictionary. The path to your hunspell
    dictionaries should be configured via
    <literal>indices.analysis.hunspell.dictionary.location</literal> before.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>dedup</literal>
</term>
<listitem>
<simpara>
    If only unique terms should be returned, this needs to be
    set to <literal>true</literal>. Defaults to <literal>true</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>longest_only</literal>
</term>
<listitem>
<simpara>
    If only the longest term should be returned, set this to <literal>true</literal>.
    Defaults to <literal>false</literal>: all possible stems are returned.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<note><simpara>As opposed to the snowball stemmers (which are algorithm based)
this is a dictionary lookup based stemmer and therefore the quality of
the stemming is determined by the quality of the dictionary.</simpara></note>
<bridgehead id="_dictionary_loading" renderas="sect3">Dictionary loading<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/hunspell-tokenfilter.asciidoc">Edit me</ulink></bridgehead>
<simpara>By default, the default Hunspell directory (<literal>config/hunspell/</literal>) is checked
for dictionaries when the node starts up, and any dictionaries are
automatically loaded.</simpara>
<simpara>Dictionary loading can be deferred until they are actually used by setting
<literal>indices.analysis.hunspell.dictionary.lazy</literal> to <literal>true</literal> in the config file.</simpara>
<bridgehead id="_references" renderas="sect3">References<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/hunspell-tokenfilter.asciidoc">Edit me</ulink></bridgehead>
<simpara>Hunspell is a spell checker and morphological analyzer designed for
languages with rich morphology and complex word compounding and
character encoding.</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>
Wikipedia, <ulink url="http://en.wikipedia.org/wiki/Hunspell">http://en.wikipedia.org/wiki/Hunspell</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Source code, <ulink url="http://hunspell.sourceforge.net/">http://hunspell.sourceforge.net/</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Open Office Hunspell dictionaries, <ulink url="http://wiki.openoffice.org/wiki/Dictionaries">http://wiki.openoffice.org/wiki/Dictionaries</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Mozilla Hunspell dictionaries, <ulink url="https://addons.mozilla.org/en-US/firefox/language-tools/">https://addons.mozilla.org/en-US/firefox/language-tools/</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Chromium Hunspell dictionaries,
   <ulink url="http://src.chromium.org/viewvc/chrome/trunk/deps/third_party/hunspell_dictionaries/">http://src.chromium.org/viewvc/chrome/trunk/deps/third_party/hunspell_dictionaries/</ulink>
</simpara>
</listitem>
</orderedlist>
</section>
<section id="analysis-common-grams-tokenfilter">
<title>Common Grams Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/common-grams-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>Token filter that generates bigrams for frequently occurring terms.
Single terms are still indexed. It can be used as an alternative to the
<link linkend="analysis-stop-tokenfilter">Stop Token Filter</link> when we don&#8217;t want to completely ignore common terms.</simpara>
<simpara>For example, the text "the quick brown is a fox" will be tokenized as
"the", "the_quick", "quick", "brown", "brown_is", "is_a", "a_fox",
"fox". Assuming "the", "is" and "a" are common words.</simpara>
<simpara>When <literal>query_mode</literal> is enabled, the token filter removes common words and
single terms followed by a common word. This parameter should be enabled
in the search analyzer.</simpara>
<simpara>For example, the query "the quick brown is a fox" will be tokenized as
"the_quick", "quick", "brown_is", "is_a", "a_fox", "fox".</simpara>
<simpara>The following are settings that can be set:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Setting </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>common_words</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A list of common words to use.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>common_words_path</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A path (either relative to <literal>config</literal> location, or
absolute) to a list of common words. Each word should be in its own
"line" (separated by a line break). The file must be UTF-8 encoded.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ignore_case</literal></simpara></entry>
<entry align="left" valign="top"><simpara>If true, common words matching will be case insensitive
(defaults to <literal>false</literal>).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>query_mode</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Generates bigrams then removes common words and single
terms followed by a common word (defaults to <literal>false</literal>).</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>Note, <literal>common_words</literal> or <literal>common_words_path</literal> field is required.</simpara>
<simpara>Here is an example:</simpara>
<programlisting language="js" linenumbering="unnumbered">index :
    analysis :
        analyzer :
            index_grams :
                tokenizer : whitespace
                filter : [common_grams]
            search_grams :
                tokenizer : whitespace
                filter : [common_grams_query]
        filter :
            common_grams :
                type : common_grams
                common_words: [a, an, the]
            common_grams_query :
                type : common_grams
                query_mode: true
                common_words: [a, an, the]</programlisting>
</section>
<section id="analysis-normalization-tokenfilter">
<title>Normalization Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/normalization-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>There are several token filters available which try to normalize special
characters of a certain language.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
Arabic
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://lucene.apache.org/core/4_9_0/analyzers-common/org/apache/lucene/analysis/ar/ArabicNormalizer.html"><literal>arabic_normalization</literal></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
German
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://lucene.apache.org/core/4_9_0/analyzers-common/org/apache/lucene/analysis/de/GermanNormalizationFilter.html"><literal>german_normalization</literal></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Hindi
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://lucene.apache.org/core/4_9_0/analyzers-common/org/apache/lucene/analysis/hi/HindiNormalizer.html"><literal>hindi_normalization</literal></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Indic
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://lucene.apache.org/core/4_9_0/analyzers-common/org/apache/lucene/analysis/in/IndicNormalizer.html"><literal>indic_normalization</literal></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Kurdish (Sorani)
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://lucene.apache.org/core/4_9_0/analyzers-common/org/apache/lucene/analysis/ckb/SoraniNormalizer.html"><literal>sorani_normalization</literal></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Persian
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://lucene.apache.org/core/4_9_0/analyzers-common/org/apache/lucene/analysis/fa/PersianNormalizer.html"><literal>persian_normalization</literal></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Scandinavian
</simpara>
</entry>
<entry>
<simpara>
<ulink url="http://lucene.apache.org/core/4_9_0/analyzers-common/org/apache/lucene/analysis/miscellaneous/ScandinavianNormalizationFilter.html"><literal>scandinavian_normalization</literal></ulink>,
<ulink url="http://lucene.apache.org/core/4_9_0/analyzers-common/org/apache/lucene/analysis/miscellaneous/ScandinavianFoldingFilter.html"><literal>scandinavian_folding</literal></ulink>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
Serbian
</simpara>
</entry>
<entry>
<simpara>
not-released-yet[<literal>serbian_normalization</literal>],
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
<section id="analysis-cjk-width-tokenfilter">
<title>CJK Width Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/cjk-width-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>The <literal>cjk_width</literal> token filter normalizes CJK width differences:</simpara>
<itemizedlist>
<listitem>
<simpara>
Folds fullwidth ASCII variants into the equivalent basic Latin
</simpara>
</listitem>
<listitem>
<simpara>
Folds halfwidth Katakana variants into the equivalent Kana
</simpara>
</listitem>
</itemizedlist>
<note><simpara>This token filter can be viewed as a subset of NFKC/NFKD
Unicode normalization.  See the <ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/analysis-icu-normalization-charfilter.html"><literal>analysis-icu</literal> plugin</ulink>
for full normalization support.</simpara></note>
</section>
<section id="analysis-cjk-bigram-tokenfilter">
<title>CJK Bigram Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/cjk-bigram-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>The <literal>cjk_bigram</literal> token filter forms bigrams out of the CJK
terms that are generated by the <link linkend="analysis-standard-tokenizer"><literal>standard</literal> tokenizer</link>
or the <literal>icu_tokenizer</literal> (see <ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/analysis-icu-tokenizer.html"><literal>analysis-icu</literal> plugin</ulink>).</simpara>
<simpara>By default, when a CJK character has no adjacent characters to form a bigram,
it is output in unigram form. If you always want to output both unigrams and
bigrams, set the <literal>output_unigrams</literal> flag to <literal>true</literal>. This can be used for a
combined unigram+bigram approach.</simpara>
<simpara>Bigrams are generated for characters in <literal>han</literal>, <literal>hiragana</literal>, <literal>katakana</literal> and
<literal>hangul</literal>, but bigrams can be disabled for particular scripts with the
<literal>ignored_scripts</literal> parameter.  All non-CJK input is passed through unmodified.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
    "index" : {
        "analysis" : {
            "analyzer" : {
                "han_bigrams" : {
                    "tokenizer" : "standard",
                    "filter" : ["han_bigrams_filter"]
                }
            },
            "filter" : {
                "han_bigrams_filter" : {
                    "type" : "cjk_bigram",
                    "ignored_scripts": [
                        "hiragana",
                        "katakana",
                        "hangul"
                    ],
                    "output_unigrams" : true
                }
            }
        }
    }
}</programlisting>
</section>
<section id="analysis-delimited-payload-tokenfilter">
<title>Delimited Payload Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/delimited-payload-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>Named <literal>delimited_payload_filter</literal>. Splits tokens into tokens and payload whenever a delimiter character is found.</simpara>
<simpara>Example: "the|1 quick|2 fox|3" is split by default into tokens <literal>the</literal>, <literal>quick</literal>, and <literal>fox</literal> with payloads <literal>1</literal>, <literal>2</literal>, and <literal>3</literal> respectively.</simpara>
<simpara>Parameters:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>delimiter</literal>
</term>
<listitem>
<simpara>
    Character used for splitting the tokens. Default is <literal>|</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>encoding</literal>
</term>
<listitem>
<simpara>
    The type of the payload. <literal>int</literal> for integer, <literal>float</literal> for float and <literal>identity</literal> for characters. Default is <literal>float</literal>.
</simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
<section id="analysis-keep-words-tokenfilter">
<title>Keep Words Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/keep-words-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>A token filter of type <literal>keep</literal> that only keeps tokens with text contained in a
predefined set of words. The set of words can be defined in the settings or
loaded from a text file containing one word per line.</simpara>
<bridgehead id="_options_5" renderas="sect2">Options<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/keep-words-tokenfilter.asciidoc">Edit me</ulink></bridgehead>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
keep_words
</simpara>
</entry>
<entry>
<simpara>
a list of words to keep
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
keep_words_path
</simpara>
</entry>
<entry>
<simpara>
a path to a words file
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
keep_words_case
</simpara>
</entry>
<entry>
<simpara>
a boolean indicating whether to lower case the words (defaults to <literal>false</literal>)
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="_settings_example" renderas="sect2">Settings example<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/keep-words-tokenfilter.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">{
    "index" : {
        "analysis" : {
            "analyzer" : {
                "my_analyzer" : {
                    "tokenizer" : "standard",
                    "filter" : ["standard", "lowercase", "words_till_three"]
                },
                "my_analyzer1" : {
                    "tokenizer" : "standard",
                    "filter" : ["standard", "lowercase", "words_on_file"]
                }
            },
            "filter" : {
                "words_till_three" : {
                    "type" : "keep",
                    "keep_words" : [ "one", "two", "three"]
                },
                "words_on_file" : {
                    "type" : "keep",
                    "keep_words_path" : "/path/to/word/file"
                }
            }
        }
    }
}</programlisting>
</section>
<section id="analysis-keep-types-tokenfilter">
<title>Keep Types Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/keep-types-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>A token filter of type <literal>keep_types</literal> that only keeps tokens with a token type
contained in a predefined set.</simpara>
<bridgehead id="_options_6" renderas="sect2">Options<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/keep-types-tokenfilter.asciidoc">Edit me</ulink></bridgehead>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
types
</simpara>
</entry>
<entry>
<simpara>
a list of types to keep
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="_settings_example_2" renderas="sect2">Settings example<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/keep-types-tokenfilter.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">{
    "index" : {
        "analysis" : {
            "analyzer" : {
                "my_analyzer" : {
                    "tokenizer" : "standard",
                    "filter" : ["standard", "lowercase", "extract_numbers"]
                },
            },
            "filter" : {
                "extract_numbers" : {
                    "type" : "keep_types",
                    "types" : [ "&lt;NUM&gt;" ]
                },
            }
        }
    }
}</programlisting>
</section>
<section id="analysis-classic-tokenfilter">
<title>Classic Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/classic-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>The <literal>classic</literal> token filter does optional post-processing of
terms that are generated by the <link linkend="analysis-classic-tokenizer"><literal>classic</literal> tokenizer</link>.</simpara>
<simpara>This filter removes the english possessive from the end of words, and
it removes dots from acronyms.</simpara>
</section>
<section id="analysis-apostrophe-tokenfilter">
<title>Apostrophe Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/apostrophe-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>The <literal>apostrophe</literal> token filter strips all characters after an apostrophe,
including the apostrophe itself.</simpara>
</section>
<section id="analysis-decimal-digit-tokenfilter">
<title>Decimal Digit Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/decimal-digit-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>The <literal>decimal_digit</literal> token filter folds unicode digits to <literal>0-9</literal></simpara>
</section>
<section id="analysis-fingerprint-tokenfilter">
<title>Fingerprint Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/fingerprint-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>The <literal>fingerprint</literal> token filter emits a single token which is useful for fingerprinting
a body of text, and/or providing a token that can be clustered on.  It does this by
sorting the tokens, deduplicating and then concatenating them back into a single token.</simpara>
<simpara>For example, the tokens <literal>["the", "quick", "quick", "brown", "fox", "was", "very", "brown"]</literal> will be
transformed into a single token: <literal>"brown fox quick the very was"</literal>.  Notice how the tokens were sorted
alphabetically, and there is only one <literal>"quick"</literal>.</simpara>
<simpara>The following are settings that can be set for a <literal>fingerprint</literal> token
filter type:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Setting </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>separator</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Defaults to a space.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>max_output_size</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Defaults to <literal>255</literal>.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<section id="analysis-fingerprint-tokenfilter-max-size">
<title>Maximum token size<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/fingerprint-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>Because a field may have many unique tokens, it is important to set a cutoff so that fields do not grow
too large.  The <literal>max_output_size</literal> setting controls this behavior.  If the concatenated fingerprint
grows larger than <literal>max_output_size</literal>, the token filter will exit and will not emit a token (e.g. the
field will be empty).</simpara>
</section>
</section>
<section id="analysis-minhash-tokenfilter">
<title>Minhash Token Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/tokenfilters/minhash-tokenfilter.asciidoc">Edit me</ulink></title>
<simpara>A token filter of type <literal>min_hash</literal> hashes each token of the token stream and divides
the resulting hashes into buckets, keeping the lowest-valued hashes per
bucket. It then returns these hashes as tokens.</simpara>
<simpara>The following are settings that can be set for a <literal>min_hash</literal> token filter.</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Setting </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>hash_count</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The number of hashes to hash the token stream with. Defaults to <literal>1</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>bucket_count</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The number of buckets to divide the minhashes into. Defaults to <literal>512</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>hash_set_size</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The number of minhashes to keep per bucket. Defaults to <literal>1</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>with_rotation</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Whether or not to fill empty buckets with the value of the first non-empty
bucket to its circular right. Only takes effect if hash_set_size is equal to one.
Defaults to <literal>true</literal> if bucket_count is greater than one, else <literal>false</literal>.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
</chapter>
<chapter id="analysis-charfilters">
<title>Character Filters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/charfilters.asciidoc">Edit me</ulink></title>
<simpara><emphasis>Character filters</emphasis> are used to preprocess the stream of characters before it
is passed to the <link linkend="analysis-tokenizers">tokenizer</link>.</simpara>
<simpara>A character filter receives the original text as a stream of characters and
can transform the stream by adding, removing, or changing characters.  For
instance, a character filter could be used to convert Arabic numerals
(٠‎١٢٣٤٥٦٧٨‎٩‎) into their Latin equivalents (0123456789), or to strip HTML
elements like <literal>&lt;b&gt;</literal> from the stream.</simpara>
<simpara>Elasticsearch has a number of built in character filters which can be used to build
<link linkend="analysis-custom-analyzer">custom analyzers</link>.</simpara>
<variablelist>
<varlistentry>
<term>
<link linkend="analysis-htmlstrip-charfilter">HTML Strip Character Filter</link>
</term>
<listitem>
<simpara>
The <literal>html_strip</literal> character filter strips out HTML elements like <literal>&lt;b&gt;</literal> and
decodes HTML entities like <literal>&amp;amp;</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="analysis-mapping-charfilter">Mapping Character Filter</link>
</term>
<listitem>
<simpara>
The <literal>mapping</literal> character filter replaces any occurrences of the specified
strings with the specified replacements.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="analysis-pattern-replace-charfilter">Pattern Replace Character Filter</link>
</term>
<listitem>
<simpara>
The <literal>pattern_replace</literal> character filter replaces any characters matching a
regular expression with the specified replacement.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<section id="analysis-htmlstrip-charfilter">
<title>HTML Strip Char Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/charfilters/htmlstrip-charfilter.asciidoc">Edit me</ulink></title>
<simpara>The <literal>html_strip</literal> character filter strips HTML elements from the text and
replaces HTML entities with their decoded value (e.g. replacing <literal>&amp;amp;</literal> with
<literal>&amp;</literal>).</simpara>
<bridgehead id="_example_output_20" renderas="sect2">Example output<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/charfilters/htmlstrip-charfilter.asciidoc">Edit me</ulink></bridgehead>
<programlisting language="js" linenumbering="unnumbered">POST _analyze
{
  "tokenizer":      "keyword", <co id="CO273-1"/>
  "char_filter":  [ "html_strip" ],
  "text": "&lt;p&gt;I&amp;apos;m so &lt;b&gt;happy&lt;/b&gt;!&lt;/p&gt;"
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO273-1">
<para>
The <link linkend="analysis-keyword-tokenizer"><literal>keyword</literal> tokenizer</link> returns a single term.
</para>
</callout>
</calloutlist>
<simpara>The above example returns the term:</simpara>
<programlisting language="js" linenumbering="unnumbered">[ \nI'm so happy!\n ]</programlisting>
<simpara>The same example with the <literal>standard</literal> tokenizer would return the following terms:</simpara>
<programlisting language="js" linenumbering="unnumbered">[ I'm, so, happy ]</programlisting>
<bridgehead id="_configuration_21" renderas="sect2">Configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/charfilters/htmlstrip-charfilter.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>html_strip</literal> character filter accepts the following parameter:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>escaped_tags</literal>
</simpara>
</entry>
<entry>
<simpara>
    An array of HTML tags which should not be stripped from the original text.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="_example_configuration_13" renderas="sect2">Example configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/charfilters/htmlstrip-charfilter.asciidoc">Edit me</ulink></bridgehead>
<simpara>In this example, we configure the <literal>html_strip</literal> character filter to leave <literal>&lt;b&gt;</literal>
tags in place:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "keyword",
          "char_filter": ["my_char_filter"]
        }
      },
      "char_filter": {
        "my_char_filter": {
          "type": "html_strip",
          "escaped_tags": ["b"]
        }
      }
    }
  }
}

POST my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "&lt;p&gt;I&amp;apos;m so &lt;b&gt;happy&lt;/b&gt;!&lt;/p&gt;"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above example produces the following term:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ \nI'm so &lt;b&gt;happy&lt;/b&gt;!\n ]</programlisting>
</section>
<section id="analysis-mapping-charfilter">
<title>Mapping Char Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/charfilters/mapping-charfilter.asciidoc">Edit me</ulink></title>
<simpara>The <literal>mapping</literal> character filter accepts a map of keys and values.  Whenever it
encounters a string of characters that is the same as a key, it replaces them
with the value associated with that key.</simpara>
<simpara>Matching is greedy; the longest pattern matching at a given point wins.
Replacements are allowed to be the empty string.</simpara>
<bridgehead id="_configuration_22" renderas="sect2">Configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/charfilters/mapping-charfilter.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>mapping</literal> character filter accepts the following parameters:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>mappings</literal>
</simpara>
</entry>
<entry>
<simpara>
    A array of mappings, with each element having the form <literal>key =&gt; value</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>mappings_path</literal>
</simpara>
</entry>
<entry>
<simpara>
    A path, either absolute or relative to the <literal>config</literal> directory, to a UTF-8
    encoded text mappings file containing a <literal>key =&gt; value</literal> mapping per line.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>Either the <literal>mappings</literal> or <literal>mappings_path</literal> parameter must be provided.</simpara>
<bridgehead id="_example_configuration_14" renderas="sect2">Example configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/charfilters/mapping-charfilter.asciidoc">Edit me</ulink></bridgehead>
<simpara>In this example, we configure the <literal>mapping</literal> character filter to replace Arabic
numerals with their Latin equivalents:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "keyword",
          "char_filter": [
            "my_char_filter"
          ]
        }
      },
      "char_filter": {
        "my_char_filter": {
          "type": "mapping",
          "mappings": [
            "٠ =&gt; 0",
            "١ =&gt; 1",
            "٢ =&gt; 2",
            "٣ =&gt; 3",
            "٤ =&gt; 4",
            "٥ =&gt; 5",
            "٦ =&gt; 6",
            "٧ =&gt; 7",
            "٨ =&gt; 8",
            "٩ =&gt; 9"
          ]
        }
      }
    }
  }
}

POST my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "My license plate is ٢٥٠١٥"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above example produces the following term:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ My license plate is 25015 ]</programlisting>
<simpara>Keys and values can be strings with multiple characters.  The following
example replaces the <literal>:)</literal> and <literal>:(</literal> emoticons with a text equivalent:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "standard",
          "char_filter": [
            "my_char_filter"
          ]
        }
      },
      "char_filter": {
        "my_char_filter": {
          "type": "mapping",
          "mappings": [
            ":) =&gt; _happy_",
            ":( =&gt; _sad_"
          ]
        }
      }
    }
  }
}

POST my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "I'm delighted about it :("
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above example produces the following terms:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ I'm, delighted, about, it, _sad_ ]</programlisting>
</section>
<section id="analysis-pattern-replace-charfilter">
<title>Pattern Replace Char Filter<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/charfilters/pattern-replace-charfilter.asciidoc">Edit me</ulink></title>
<simpara>The <literal>pattern_replace</literal> character filter uses a regular expression to match
characters which should be replaced with the specified replacement string.
The replacement string can refer to capture groups in the regular expression.</simpara>
<warning>
<title>Beware of Pathological Regular Expressions</title>
<simpara>The pattern replace character filter uses
<ulink url="http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html">Java Regular Expressions</ulink>.</simpara>
<simpara>A badly written regular expression could run very slowly or even throw a
StackOverflowError and cause the node it is running on to exit suddenly.</simpara>
<simpara>Read more about <ulink url="http://www.regular-expressions.info/catastrophic.html">pathological regular expressions and how to avoid them</ulink>.</simpara>
</warning>
<bridgehead id="_configuration_23" renderas="sect2">Configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/charfilters/pattern-replace-charfilter.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>pattern_replace</literal> character filter accepts the following parameters:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>pattern</literal>
</simpara>
</entry>
<entry>
<simpara>
    A <ulink url="http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html">Java regular expression</ulink>. Required.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>replacement</literal>
</simpara>
</entry>
<entry>
<simpara>
    The replacement string, which can reference capture groups using the
    <literal>$1</literal>..<literal>$9</literal> syntax, as explained
    <ulink url="http://docs.oracle.com/javase/8/docs/api/java/util/regex/Matcher.html#appendReplacement-java.lang.StringBuffer-java.lang.String-">here</ulink>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>flags</literal>
</simpara>
</entry>
<entry>
<simpara>
    Java regular expression <ulink url="http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html#field.summary">flags</ulink>.
    Flags should be pipe-separated, eg <literal>"CASE_INSENSITIVE|COMMENTS"</literal>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="_example_configuration_15" renderas="sect2">Example configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/analysis/charfilters/pattern-replace-charfilter.asciidoc">Edit me</ulink></bridgehead>
<simpara>In this example, we configure the <literal>pattern_replace</literal> character filter to
replace any embedded dashes in numbers with underscores, i.e <literal>123-456-789</literal> &#8594;
<literal>123_456_789</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "standard",
          "char_filter": [
            "my_char_filter"
          ]
        }
      },
      "char_filter": {
        "my_char_filter": {
          "type": "pattern_replace",
          "pattern": "(\\d+)-(?=\\d)",
          "replacement": "$1_"
        }
      }
    }
  }
}

POST my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "My credit card is 123-456-789"
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[skip:Test interprets $1 as a stashed variable]</remark>
<simpara>The above example produces the following term:</simpara>
<programlisting language="text" linenumbering="unnumbered">[ My, credit, card, is 123_456_789 ]</programlisting>
<warning><simpara>Using a replacement string that changes the length of the original
text will work for search purposes, but will result in incorrect highlighting,
as can be seen in the following example.</simpara></warning>
<simpara>This example inserts a space whenever it encounters a lower-case letter
followed by an upper-case letter (i.e. <literal>fooBarBaz</literal> &#8594; <literal>foo Bar Baz</literal>), allowing
camelCase words to be queried individually:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "standard",
          "char_filter": [
            "my_char_filter"
          ],
          "filter": [
            "lowercase"
          ]
        }
      },
      "char_filter": {
        "my_char_filter": {
          "type": "pattern_replace",
          "pattern": "(?&lt;=\\p{Lower})(?=\\p{Upper})",
          "replacement": " "
        }
      }
    }
  },
  "mappings": {
    "my_type": {
      "properties": {
        "text": {
          "type": "text",
          "analyzer": "my_analyzer"
        }
      }
    }
  }
}

POST my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "The fooBarBaz method"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The above returns the following terms:</simpara>
<programlisting language="js" linenumbering="unnumbered">[ the, foo, bar, baz, method ]</programlisting>
<simpara>Querying for <literal>bar</literal> will find the document correctly, but highlighting on the
result will produce incorrect highlights, because our character filter changed
the length of the original text:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index/my_doc/1?refresh
{
  "text": "The fooBarBaz method"
}

GET my_index/_search
{
  "query": {
    "match": {
      "text": "bar"
    }
  },
  "highlight": {
    "fields": {
      "text": {}
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>The output from the above is:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "timed_out": false,
  "took": $body.took,
  "_shards": {
    "total": 5,
    "successful": 5,
    "failed": 0
  },
  "hits": {
    "total": 1,
    "max_score": 0.2824934,
    "hits": [
      {
        "_index": "my_index",
        "_type": "my_doc",
        "_id": "1",
        "_score": 0.2824934,
        "_source": {
          "text": "The fooBarBaz method"
        },
        "highlight": {
          "text": [
            "The foo&lt;em&gt;Ba&lt;/em&gt;rBaz method" <co id="CO274-1"/>
          ]
        }
      }
    ]
  }
}</programlisting>
<remark> TESTRESPONSE[s/"took".*/"took": "$body.took",/]</remark>
<calloutlist>
<callout arearefs="CO274-1">
<para>
Note the incorrect highlight.
</para>
</callout>
</calloutlist>
</section>
</chapter>
</part>
<part id="modules">
<title>Modules <ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules.asciidoc">Edit me</ulink></title>
<partintro>
<simpara>This section contains modules responsible for various aspects of the functionality in Elasticsearch.  Each module has settings which may be:</simpara>
<variablelist>
<varlistentry>
<term>
<emphasis>static</emphasis>
</term>
<listitem>
<simpara>
These settings must be set at the node level, either in the
<literal>elasticsearch.yml</literal> file, or as an environment variable or on the command line
when starting a node.  They must be set on every relevant node in the cluster.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<emphasis>dynamic</emphasis>
</term>
<listitem>
<simpara>
These settings can be dynamically updated on a live cluster with the
<link linkend="cluster-update-settings">cluster-update-settings</link> API.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>The modules in this section are:</simpara>
<variablelist>
<varlistentry>
<term>
<link linkend="modules-cluster">Cluster-level routing and shard allocation</link>
</term>
<listitem>
<simpara>
    Settings to control where, when, and how shards are allocated to nodes.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="modules-discovery">Discovery</link>
</term>
<listitem>
<simpara>
    How nodes discover each other to form a cluster.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="modules-gateway">Gateway</link>
</term>
<listitem>
<simpara>
    How many nodes need to join the cluster before recovery can start.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="modules-http">HTTP</link>
</term>
<listitem>
<simpara>
    Settings to control the HTTP REST interface.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="modules-indices">Indices</link>
</term>
<listitem>
<simpara>
    Global index-related settings.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="modules-network">Network</link>
</term>
<listitem>
<simpara>
    Controls default network settings.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="modules-node">Node client</link>
</term>
<listitem>
<simpara>
    A Java node client joins the cluster, but doesn&#8217;t hold data or act as a master node.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="modules-scripting-painless">Painless</link>
</term>
<listitem>
<simpara>
    A built-in scripting language for Elasticsearch that&#8217;s designed to be as secure as possible.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="modules-plugins">Plugins</link>
</term>
<listitem>
<simpara>
    Using plugins to extend Elasticsearch.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="modules-scripting">Scripting</link>
</term>
<listitem>
<simpara>
    Custom scripting available in Lucene Expressions, Groovy, Python, and
    Javascript. You can also write scripts in the built-in scripting language,
    <link linkend="modules-scripting-painless">Painless</link>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="modules-snapshots">Snapshot/Restore</link>
</term>
<listitem>
<simpara>
    Backup your data with snapshot/restore.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="modules-threadpool">Thread pools</link>
</term>
<listitem>
<simpara>
    Information about the dedicated thread pools used in Elasticsearch.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="modules-transport">Transport</link>
</term>
<listitem>
<simpara>
    Configure the transport networking layer, used internally by Elasticsearch
    to communicate between nodes.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="modules-tribe">Tribe nodes</link>
</term>
<listitem>
<simpara>
    A tribe node joins one or more clusters and acts as a federated
    client across them.
</simpara>
</listitem>
</varlistentry>
</variablelist>
</partintro>
<chapter id="modules-cluster">
<title>Cluster<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/cluster.asciidoc">Edit me</ulink></title>
<simpara>One of the main roles of the master is to decide which shards to allocate to
which nodes, and when to move shards between nodes in order to rebalance the
cluster.</simpara>
<simpara>There are a number of settings available to control the shard allocation process:</simpara>
<itemizedlist>
<listitem>
<simpara>
<xref linkend="shards-allocation"/> lists the settings to control the allocation and
    rebalancing operations.
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="disk-allocator"/> explains how Elasticsearch takes available disk space
    into account, and the related settings.
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="allocation-awareness"/> and <xref linkend="forced-awareness"/> control how shards can
    be distributed across different racks or availability zones.
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="allocation-filtering"/> allows certain nodes or groups of nodes excluded
    from allocation so that they can be decommissioned.
</simpara>
</listitem>
</itemizedlist>
<simpara>Besides these, there are a few other <link linkend="misc-cluster">miscellaneous cluster-level settings</link>.</simpara>
<simpara>All of the settings in this section are <emphasis>dynamic</emphasis> settings which can be
updated on a live cluster with the
<link linkend="cluster-update-settings">cluster-update-settings</link> API.</simpara>
<section id="shards-allocation">
<title>Cluster Level Shard Allocation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/cluster/shards_allocation.asciidoc">Edit me</ulink></title>
<simpara>Shard allocation is the process of allocating shards to nodes. This can
happen during initial recovery, replica allocation, rebalancing, or
when nodes are added or removed.</simpara>
<bridgehead id="_shard_allocation_settings" renderas="sect2">Shard Allocation Settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/cluster/shards_allocation.asciidoc">Edit me</ulink></bridgehead>
<simpara>The following <emphasis>dynamic</emphasis> settings may be used to control shard allocation and recovery:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>cluster.routing.allocation.enable</literal>
</term>
<listitem>
<simpara>Enable or disable allocation for specific kinds of shards:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>all</literal> -             (default) Allows shard allocation for all kinds of shards.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>primaries</literal> -       Allows shard allocation only for primary shards.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>new_primaries</literal> -   Allows shard allocation only for primary shards for new indices.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>none</literal> -            No shard allocations of any kind are allowed for any indices.
</simpara>
</listitem>
</itemizedlist>
<simpara>This setting does not affect the recovery of local primary shards when
restarting a node.  A restarted node that has a copy of an unassigned primary
shard will recover that primary immediately, assuming that its allocation id matches
one of the active allocation ids in the cluster state.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>cluster.routing.allocation.node_concurrent_incoming_recoveries</literal>
</term>
<listitem>
<simpara>
     How many concurrent incoming shard recoveries are allowed to happen on a node. Incoming recoveries are the recoveries
     where the target shard (most likely the replica unless a shard is relocating) is allocated on the node. Defaults to <literal>2</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>cluster.routing.allocation.node_concurrent_outgoing_recoveries</literal>
</term>
<listitem>
<simpara>
     How many concurrent outgoing shard recoveries are allowed to happen on a node. Outgoing recoveries are the recoveries
     where the source shard (most likely the primary unless a shard is relocating) is allocated on the node. Defaults to <literal>2</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>cluster.routing.allocation.node_initial_primaries_recoveries</literal>
</term>
<listitem>
<simpara>
    While the recovery of replicas happens over the network, the recovery of
    an unassigned primary after node restart uses data from the local disk.
    These should be fast so more initial primary recoveries can happen in
    parallel on the same node.  Defaults to <literal>4</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>cluster.routing.allocation.same_shard.host</literal>
</term>
<listitem>
<simpara>
      Allows to perform a check to prevent allocation of multiple instances of
      the same shard on a single host, based on host name and host address.
      Defaults to <literal>false</literal>, meaning that no check is performed by default. This
      setting only applies if multiple nodes are started on the same machine.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_shard_rebalancing_settings" renderas="sect2">Shard Rebalancing Settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/cluster/shards_allocation.asciidoc">Edit me</ulink></bridgehead>
<simpara>The following <emphasis>dynamic</emphasis> settings may be used to control the rebalancing of
shards across the cluster:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>cluster.routing.rebalance.enable</literal>
</term>
<listitem>
<simpara>Enable or disable rebalancing for specific kinds of shards:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>all</literal> -         (default) Allows shard balancing for all kinds of shards.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>primaries</literal> -   Allows shard balancing only for primary shards.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>replicas</literal> -    Allows shard balancing only for replica shards.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>none</literal> -        No shard balancing of any kind are allowed for any indices.
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>cluster.routing.allocation.allow_rebalance</literal>
</term>
<listitem>
<simpara>Specify when shard rebalancing is allowed:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>always</literal> -                    Always allow rebalancing.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>indices_primaries_active</literal> -  Only when all primaries in the cluster are allocated.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>indices_all_active</literal> -        (default) Only when all shards (primaries and replicas) in the cluster are allocated.
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>cluster.routing.allocation.cluster_concurrent_rebalance</literal>
</term>
<listitem>
<simpara>
      Allow to control how many concurrent shard rebalances are
      allowed cluster wide. Defaults to <literal>2</literal>. Note that this setting
      only controls the number of concurrent shard relocations due
      to imbalances in the cluster. This setting does not limit shard
      relocations due to <link linkend="allocation-filtering">allocation filtering</link>
      or <link linkend="forced-awareness">forced awareness</link>.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_shard_balancing_heuristics" renderas="sect2">Shard Balancing Heuristics<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/cluster/shards_allocation.asciidoc">Edit me</ulink></bridgehead>
<simpara>The following settings are used together to determine where to place each
shard.  The cluster is balanced when no allowed action can bring the weights
of each node closer together by more then the <literal>balance.threshold</literal>.</simpara>
<variablelist>
<varlistentry>
<term>
<literal>cluster.routing.allocation.balance.shard</literal>
</term>
<listitem>
<simpara>
     Defines the weight factor for shards allocated on a node
     (float). Defaults to <literal>0.45f</literal>.  Raising this raises the tendency to
     equalize the number of shards across all nodes in the cluster.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>cluster.routing.allocation.balance.index</literal>
</term>
<listitem>
<simpara>
     Defines a factor to the number of shards per index allocated
      on a specific node (float). Defaults to <literal>0.55f</literal>.  Raising this raises the
      tendency to equalize the number of shards per index across all nodes in
      the cluster.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>cluster.routing.allocation.balance.threshold</literal>
</term>
<listitem>
<simpara>
     Minimal optimization value of operations that should be performed (non
      negative float). Defaults to <literal>1.0f</literal>.  Raising this will cause the cluster
      to be less aggressive about optimizing the shard balance.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<note><simpara>Regardless of the result of the balancing algorithm, rebalancing might
not be allowed due to forced awareness or allocation filtering.</simpara></note>
</section>
<section id="disk-allocator">
<title>Disk-based Shard Allocation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/cluster/disk_allocator.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch factors in the available disk space on a node before deciding
whether to allocate new shards to that node or to actively relocate shards
away from that node.</simpara>
<simpara>Below are the settings that can be configured in the <literal>elasticsearch.yml</literal> config
file or updated dynamically on a live cluster with the
<link linkend="cluster-update-settings">cluster-update-settings</link> API:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>cluster.routing.allocation.disk.threshold_enabled</literal>
</term>
<listitem>
<simpara>
    Defaults to <literal>true</literal>.  Set to <literal>false</literal> to disable the disk allocation decider.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>cluster.routing.allocation.disk.watermark.low</literal>
</term>
<listitem>
<simpara>
    Controls the low watermark for disk usage. It defaults to 85%, meaning ES will
    not allocate new shards to nodes once they have more than 85% disk used. It
    can also be set to an absolute byte value (like 500mb) to prevent ES from
    allocating shards if less than the configured amount of space is available.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>cluster.routing.allocation.disk.watermark.high</literal>
</term>
<listitem>
<simpara>
    Controls the high watermark. It defaults to 90%, meaning ES will attempt to
    relocate shards to another node if the node disk usage rises above 90%. It can
    also be set to an absolute byte value (similar to the low watermark) to
    relocate shards once less than the configured amount of space is available on
    the node.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<note><simpara>Percentage values refer to used disk space, while byte values refer to
free disk space. This can be confusing, since it flips the meaning of high and
low. For example, it makes sense to set the low watermark to 10gb and the high
watermark to 5gb, but not the other way around.</simpara></note>
<variablelist>
<varlistentry>
<term>
<literal>cluster.info.update.interval</literal>
</term>
<listitem>
<simpara>
    How often Elasticsearch should check on disk usage for each node in the
    cluster. Defaults to <literal>30s</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>cluster.routing.allocation.disk.include_relocations</literal>
</term>
<listitem>
<simpara>
    Defaults to <literal>true</literal>, which means that Elasticsearch will take into account
    shards that are currently being relocated to the target node when computing a
    node&#8217;s disk usage. Taking relocating shards' sizes into account may, however,
    mean that the disk usage for a node is incorrectly estimated on the high side,
    since the relocation could be 90% complete and a recently retrieved disk usage
    would include the total size of the relocating shard as well as the space
    already used by the running relocation.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>An example of updating the low watermark to no more than 80% of the disk size, a
high watermark of at least 50 gigabytes free, and updating the information about
the cluster every minute:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT _cluster/settings
{
  "transient": {
    "cluster.routing.allocation.disk.watermark.low": "80%",
    "cluster.routing.allocation.disk.watermark.high": "50gb",
    "cluster.info.update.interval": "1m"
  }
}</programlisting>
<remark> CONSOLE</remark>
<note><simpara>Prior to 2.0.0, when using multiple data paths, the disk threshold
decider only factored in the usage across all data paths (if you had two
data paths, one with 50b out of 100b free (50% used) and another with
40b out of 50b free (80% used) it would see the node&#8217;s disk usage as 90b
out of 150b). In 2.0.0, the minimum and maximum disk usages are tracked
separately.</simpara></note>
</section>
<section id="allocation-awareness">
<title>Shard Allocation Awareness<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/cluster/allocation_awareness.asciidoc">Edit me</ulink></title>
<simpara>When running nodes on multiple VMs on the same physical server, on multiple
racks, or across multiple awareness zones, it is more likely that two nodes on
the same physical server, in the same rack, or in the same awareness zone will
crash at the same time, rather than two unrelated nodes crashing
simultaneously.</simpara>
<simpara>If Elasticsearch is <emphasis>aware</emphasis> of the physical configuration of your hardware, it
can ensure that the primary shard and its replica shards are spread across
different physical servers, racks, or zones, to minimise the risk of losing
all shard copies at the same time.</simpara>
<simpara>The shard allocation awareness settings allow you to tell Elasticsearch about
your hardware configuration.</simpara>
<simpara>As an example, let&#8217;s assume we have several racks.  When we start a node, we
can tell it which rack it is in by assigning it an arbitrary metadata
attribute called <literal>rack_id</literal>&#8201;&#8212;&#8201;we could use any attribute name.  For example:</simpara>
<programlisting language="sh" linenumbering="unnumbered">./bin/elasticsearch -Enode.attr.rack_id=rack_one <co id="CO275-1"/></programlisting>
<calloutlist>
<callout arearefs="CO275-1">
<para>
This setting could also be specified in the <literal>elasticsearch.yml</literal> config file.
</para>
</callout>
</calloutlist>
<simpara>Now, we need to setup <emphasis>shard allocation awareness</emphasis>  by telling Elasticsearch
which attributes to use.  This can be configured in the <literal>elasticsearch.yml</literal>
file on <emphasis role="strong">all</emphasis> master-eligible nodes, or it can be set (and changed) with the
<link linkend="cluster-update-settings">cluster-update-settings</link> API.</simpara>
<simpara>For our example, we&#8217;ll set the value in the config file:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">cluster.routing.allocation.awareness.attributes: rack_id</programlisting>
<simpara>With this config in place, let&#8217;s say we start two nodes with <literal>node.attr.rack_id</literal>
set to <literal>rack_one</literal>, and we create an index with 5 primary shards and 1 replica
of each primary.  All primaries and replicas are allocated across the two
nodes.</simpara>
<simpara>Now, if we start two more nodes with <literal>node.attr.rack_id</literal> set to <literal>rack_two</literal>,
Elasticsearch will move shards across to the new nodes, ensuring (if possible)
that no two copies of the same shard will be in the same rack. However if <literal>rack_two</literal>
were to fail, taking down both of its nodes, Elasticsearch will still allocate the lost
shard copies to nodes in <literal>rack_one</literal>.</simpara>
<sidebar>
<title>Prefer local shards</title>
<simpara>When executing search or GET requests, with shard awareness enabled,
Elasticsearch will prefer using local shards&#8201;&#8212;&#8201;shards in the same awareness
group&#8201;&#8212;&#8201;to execute the request. This is usually faster than crossing racks or
awareness zones.</simpara>
</sidebar>
<simpara>Multiple awareness attributes can be specified, in which case the combination
of values from each attribute is considered to be a separate value.</simpara>
<programlisting language="yaml" linenumbering="unnumbered">cluster.routing.allocation.awareness.attributes: rack_id,zone</programlisting>
<note><simpara>When using awareness attributes, shards will not be allocated to
nodes that don&#8217;t have values set for those attributes.</simpara></note>
<note><simpara>Number of primary/replica of a shard allocated on a specific group
of nodes with the same awareness attribute value is determined by the number
of attribute values. When the number of nodes in groups is unbalanced and
there are many replicas, replica shards may be left unassigned.</simpara></note>
<bridgehead id="forced-awareness" renderas="sect2">Forced Awareness<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/cluster/allocation_awareness.asciidoc">Edit me</ulink></bridgehead>
<simpara>Imagine that you have two awareness zones and enough hardware across the two
zones to host all of your primary and replica shards.  But perhaps the
hardware in a single zone, while sufficient to host half the shards, would be
unable to host <emphasis role="strong">ALL</emphasis> the shards.</simpara>
<simpara>With ordinary awareness, if one zone lost contact with the other zone,
Elasticsearch would assign all of the missing replica shards to a single zone.
But in this example, this sudden extra load would cause the hardware in the
remaining zone to be overloaded.</simpara>
<simpara>Forced awareness solves this problem by <emphasis role="strong">NEVER</emphasis> allowing copies of the same
shard to be allocated to the same zone.</simpara>
<simpara>For example, lets say we have an awareness attribute called <literal>zone</literal>, and
we know we are going to have two zones, <literal>zone1</literal> and <literal>zone2</literal>. Here is how
we can force awareness on a node:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">cluster.routing.allocation.awareness.force.zone.values: zone1,zone2 <co id="CO276-1"/>
cluster.routing.allocation.awareness.attributes: zone</programlisting>
<calloutlist>
<callout arearefs="CO276-1">
<para>
We must list all possible values that the <literal>zone</literal> attribute can have.
</para>
</callout>
</calloutlist>
<simpara>Now, if we start 2 nodes with <literal>node.attr.zone</literal> set to <literal>zone1</literal> and create an index
with 5 shards and 1 replica. The index will be created, but only the 5 primary
shards will be allocated (with no replicas). Only when we start more nodes
with <literal>node.attr.zone</literal> set to <literal>zone2</literal> will the replicas be allocated.</simpara>
<simpara>The <literal>cluster.routing.allocation.awareness.*</literal> settings can all be updated
dynamically on a live cluster with the
<link linkend="cluster-update-settings">cluster-update-settings</link> API.</simpara>
</section>
<section id="allocation-filtering">
<title>Shard Allocation Filtering<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/cluster/allocation_filtering.asciidoc">Edit me</ulink></title>
<simpara>While <xref linkend="index-modules-allocation"/> provides <emphasis role="strong">per-index</emphasis> settings to control the
allocation of shards to nodes, cluster-level shard allocation filtering allows
you to allow or disallow the allocation of shards from <emphasis role="strong">any</emphasis> index to
particular nodes.</simpara>
<simpara>The typical use case for cluster-wide shard allocation filtering is when you
want to decommission a node, and you would like to move the shards from that
node to other nodes in the cluster before shutting it down.</simpara>
<simpara>For instance, we could decommission a node using its IP address as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT _cluster/settings
{
  "transient" : {
    "cluster.routing.allocation.exclude._ip" : "10.0.0.1"
  }
}</programlisting>
<remark> CONSOLE</remark>
<note><simpara>Shards will only be relocated if it is possible to do so without
breaking another routing constraint, such as never allocating a primary and
replica shard to the same node.</simpara></note>
<simpara>Cluster-wide shard allocation filtering works in the same way as index-level
shard allocation filtering (see <xref linkend="index-modules-allocation"/> for details).</simpara>
<simpara>The available <emphasis>dynamic</emphasis> cluster settings are as follows, where <literal>{attribute}</literal>
refers to an arbitrary node attribute.:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>cluster.routing.allocation.include.{attribute}</literal>
</term>
<listitem>
<simpara>
    Assign the index to a node whose <literal>{attribute}</literal> has at least one of the
    comma-separated values.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>cluster.routing.allocation.require.{attribute}</literal>
</term>
<listitem>
<simpara>
    Assign the index to a node whose <literal>{attribute}</literal> has <emphasis>all</emphasis> of the
    comma-separated values.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>cluster.routing.allocation.exclude.{attribute}</literal>
</term>
<listitem>
<simpara>
    Assign the index to a node whose <literal>{attribute}</literal> has <emphasis>none</emphasis> of the
    comma-separated values.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>These special attributes are also supported:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>_name</literal>
</simpara>
</entry>
<entry>
<simpara>
Match nodes by node name
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>_ip</literal>
</simpara>
</entry>
<entry>
<simpara>
Match nodes by IP address (the IP address associated with the hostname)
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>_host</literal>
</simpara>
</entry>
<entry>
<simpara>
Match nodes by hostname
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>All attribute values can be specified with wildcards, eg:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT _cluster/settings
{
  "transient": {
    "cluster.routing.allocation.exclude._ip": "192.168.2.*"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[skip:indexes don't assign]</remark>
</section>
<section id="misc-cluster">
<title>Miscellaneous cluster settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/cluster/misc.asciidoc">Edit me</ulink></title>
<section id="cluster-read-only">
<title>Metadata<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/cluster/misc.asciidoc">Edit me</ulink></title>
<simpara>An entire cluster may be set to read-only with the following <emphasis>dynamic</emphasis> setting:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>cluster.blocks.read_only</literal>
</term>
<listitem>
<simpara>
      Make the whole cluster read only (indices do not accept write
      operations), metadata is not allowed to be modified (create or delete
      indices).
</simpara>
</listitem>
</varlistentry>
</variablelist>
<warning><simpara>Don&#8217;t rely on this setting to prevent changes to your cluster. Any
user with access to the <link linkend="cluster-update-settings">cluster-update-settings</link>
API can make the cluster read-write again.</simpara></warning>
</section>
<section id="cluster-max-tombstones">
<title>Index Tombstones<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/cluster/misc.asciidoc">Edit me</ulink></title>
<simpara>The cluster state maintains index tombstones to explicitly denote indices that
have been deleted.  The number of tombstones maintained in the cluster state is
controlled by the following property, which cannot be updated dynamically:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>cluster.indices.tombstones.size</literal>
</term>
<listitem>
<simpara>
Index tombstones prevent nodes that are not part of the cluster when a delete
occurs from joining the cluster and reimporting the index as though the delete
was never issued. To keep the cluster state from growing huge we only keep the
last <literal>cluster.indices.tombstones.size</literal> deletes, which defaults to 500. You can
increase it if you expect nodes to be absent from the cluster and miss more
than 500 deletes. We think that is rare, thus the default. Tombstones don&#8217;t take
up much space, but we also think that a number like 50,000 is probably too big.
</simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
<section id="cluster-logger">
<title>Logger<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/cluster/misc.asciidoc">Edit me</ulink></title>
<simpara>The settings which control logging can be updated dynamically with the
<literal>logger.</literal> prefix.  For instance, to increase the logging level of the
<literal>indices.recovery</literal> module to <literal>DEBUG</literal>, issue this request:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /_cluster/settings
{
  "transient": {
    "logger.org.elasticsearch.indices.recovery": "DEBUG"
  }
}</programlisting>
<remark> CONSOLE</remark>
</section>
</section>
</chapter>
<chapter id="modules-discovery">
<title>Discovery<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/discovery.asciidoc">Edit me</ulink></title>
<simpara>The discovery module is responsible for discovering nodes within a
cluster, as well as electing a master node.</simpara>
<simpara>Note, Elasticsearch is a peer to peer based system, nodes communicate
with one another directly if operations are delegated / broadcast. All
the main APIs (index, delete, search) do not communicate with the master
node. The responsibility of the master node is to maintain the global
cluster state, and act if nodes join or leave the cluster by reassigning
shards. Each time a cluster state is changed, the state is made known to
the other nodes in the cluster (the manner depends on the actual
discovery implementation).</simpara>
<bridgehead id="_settings" renderas="sect2">Settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/discovery.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>cluster.name</literal> allows to create separated clusters from one another.
The default value for the cluster name is <literal>elasticsearch</literal>, though it is
recommended to change this to reflect the logical group name of the
cluster running.</simpara>
<section id="modules-discovery-azure-classic">
<title>Azure Classic Discovery<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/discovery/azure.asciidoc">Edit me</ulink></title>
<simpara>Azure classic discovery allows to use the Azure Classic APIs to perform automatic discovery (similar to multicast).
It is available as a plugin. See <ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/discovery-azure-classic.html">discovery-azure-classic</ulink> for more information.</simpara>
</section>
<section id="modules-discovery-ec2">
<title>EC2 Discovery<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/discovery/ec2.asciidoc">Edit me</ulink></title>
<simpara>EC2 discovery is available as a plugin. See <ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/discovery-ec2.html">discovery-ec2</ulink> for more information.</simpara>
</section>
<section id="modules-discovery-gce">
<title>Google Compute Engine Discovery<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/discovery/gce.asciidoc">Edit me</ulink></title>
<simpara>Google Compute Engine (GCE) discovery allows to use the GCE APIs to perform automatic discovery (similar to multicast).
It is available as a plugin. See <ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/discovery-gce.html">discovery-gce</ulink> for more information.</simpara>
</section>
<section id="modules-discovery-zen">
<title>Zen Discovery<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/discovery/zen.asciidoc">Edit me</ulink></title>
<simpara>The zen discovery is the built in discovery module for elasticsearch and
the default. It provides unicast discovery, but can be extended to
support cloud environments and other forms of discovery.</simpara>
<simpara>The zen discovery is integrated with other modules, for example, all
communication between nodes is done using the
<link linkend="modules-transport">transport</link> module.</simpara>
<simpara>It is separated into several sub modules, which are explained below:</simpara>
<bridgehead id="ping" renderas="sect3">Ping<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/discovery/zen.asciidoc">Edit me</ulink></bridgehead>
<simpara>This is the process where a node uses the discovery mechanisms to find
other nodes.</simpara>
<bridgehead id="unicast" renderas="sect4">Unicast<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/discovery/zen.asciidoc">Edit me</ulink></bridgehead>
<simpara>Unicast discovery requires a list of hosts to use that will act as gossip routers. These hosts can be specified as
hostnames or IP addresses; hosts specified as hostnames are resolved to IP addresses during each round of pinging. Note
that with the Java security manager in place, the JVM defaults to caching positive hostname resolutions indefinitely.
This can be modified by adding
<ulink url="http://docs.oracle.com/javase/8/docs/technotes/guides/net/properties.html"><literal>networkaddress.cache.ttl=&lt;timeout&gt;</literal></ulink> to your
<ulink url="http://docs.oracle.com/javase/8/docs/technotes/guides/security/PolicyFiles.html">Java security policy</ulink>. Any hosts that
fail to resolve will be logged. Note also that with the Java security manager in place, the JVM defaults to caching
negative hostname resolutions for ten seconds. This can be modified by adding
<ulink url="http://docs.oracle.com/javase/8/docs/technotes/guides/net/properties.html"><literal>networkaddress.cache.negative.ttl=&lt;timeout&gt;</literal></ulink>
to your <ulink url="http://docs.oracle.com/javase/8/docs/technotes/guides/security/PolicyFiles.html">Java security policy</ulink>.</simpara>
<simpara>Unicast discovery provides the following settings with the <literal>discovery.zen.ping.unicast</literal> prefix:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Setting </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>hosts</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Either an array setting or a comma delimited setting. Each
value should be in the form of <literal>host:port</literal> or <literal>host</literal> (where <literal>port</literal> defaults to <literal>9300</literal>). Note that IPv6 hosts must be
bracketed. Defaults to <literal>127.0.0.1, [::1]</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>hosts.resolve_timeout</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The amount of time to wait for DNS lookups on each round of pinging. Specified as
<link linkend="time-units">time units</link>. Defaults to 5s.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>The unicast discovery uses the <link linkend="modules-transport">transport</link> module to perform the discovery.</simpara>
<bridgehead id="master-election" renderas="sect3">Master Election<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/discovery/zen.asciidoc">Edit me</ulink></bridgehead>
<simpara>As part of the ping process a master of the cluster is either
elected or joined to. This is done automatically. The
<literal>discovery.zen.ping_timeout</literal> (which defaults to <literal>3s</literal>) allows for the
tweaking of election time to handle cases of slow or congested networks
(higher values assure less chance of failure). Once a node joins, it
will send a join request to the master (<literal>discovery.zen.join_timeout</literal>)
with a timeout defaulting at 20 times the ping timeout.</simpara>
<simpara>When the master node stops or has encountered a problem, the cluster nodes
start pinging again and will elect a new master. This pinging round also
serves as a protection against (partial) network failures where a node may unjustly
think that the master has failed. In this case the node will simply hear from
other nodes about the currently active master.</simpara>
<simpara>If <literal>discovery.zen.master_election.ignore_non_master_pings</literal> is <literal>true</literal>, pings from nodes that are not master
eligible (nodes where <literal>node.master</literal> is <literal>false</literal>) are ignored during master election; the default value is
<literal>false</literal>.</simpara>
<simpara>Nodes can be excluded from becoming a master by setting <literal>node.master</literal> to <literal>false</literal>.</simpara>
<simpara>The <literal>discovery.zen.minimum_master_nodes</literal> sets the minimum
number of master eligible nodes that need to join a newly elected master in order for an election to
complete and for the elected node to accept its mastership. The same setting controls the minimum number of
active master eligible nodes that should be a part of any active cluster. If this requirement is not met the
active master node will step down and a new master election will be begin.</simpara>
<simpara>This setting must be set to a quorum of your master eligible nodes. It is recommended to avoid
having only two master eligible nodes, since a quorum of two is two. Therefore, a loss
of either master eligible node will result in an inoperable cluster.</simpara>
<bridgehead id="fault-detection" renderas="sect3">Fault Detection<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/discovery/zen.asciidoc">Edit me</ulink></bridgehead>
<simpara>There are two fault detection processes running. The first is by the
master, to ping all the other nodes in the cluster and verify that they
are alive. And on the other end, each node pings to master to verify if
its still alive or an election process needs to be initiated.</simpara>
<simpara>The following settings control the fault detection process using the
<literal>discovery.zen.fd</literal> prefix:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Setting </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>ping_interval</literal></simpara></entry>
<entry align="left" valign="top"><simpara>How often a node gets pinged. Defaults to <literal>1s</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ping_timeout</literal></simpara></entry>
<entry align="left" valign="top"><simpara>How long to wait for a ping response, defaults to
<literal>30s</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ping_retries</literal></simpara></entry>
<entry align="left" valign="top"><simpara>How many ping failures / timeouts cause a node to be
considered failed. Defaults to <literal>3</literal>.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<bridgehead id="_cluster_state_updates" renderas="sect3">Cluster state updates<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/discovery/zen.asciidoc">Edit me</ulink></bridgehead>
<simpara>The master node is the only node in a cluster that can make changes to the
cluster state. The master node processes one cluster state update at a time,
applies the required changes and publishes the updated cluster state to all
the other nodes in the cluster. Each node receives the publish message, acknowledges
it, but does <emphasis role="strong">not</emphasis> yet apply it. If the master does not receive acknowledgement from
at least <literal>discovery.zen.minimum_master_nodes</literal> nodes within a certain time (controlled by
the <literal>discovery.zen.commit_timeout</literal> setting and defaults to 30 seconds) the cluster state
change is rejected.</simpara>
<simpara>Once enough nodes have responded, the cluster state is committed and a message will
be sent to all the nodes. The nodes then proceed to apply the new cluster state to their
internal state. The master node waits for all nodes to respond, up to a timeout, before
going ahead processing the next updates in the queue. The <literal>discovery.zen.publish_timeout</literal> is
set by default to 30 seconds and is measured from the moment the publishing started. Both
timeout settings can be changed dynamically through the <link linkend="cluster-update-settings">cluster update settings api</link></simpara>
<bridgehead id="no-master-block" renderas="sect3">No master block<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/discovery/zen.asciidoc">Edit me</ulink></bridgehead>
<simpara>For the cluster to be fully operational, it must have an active master and the
number of running master eligible nodes must satisfy the
<literal>discovery.zen.minimum_master_nodes</literal> setting if set. The
<literal>discovery.zen.no_master_block</literal> settings controls what operations should be
rejected when there is no active master.</simpara>
<simpara>The <literal>discovery.zen.no_master_block</literal> setting has two valid options:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>all</literal>
</simpara>
</entry>
<entry>
<simpara>
All operations on the node&#8212;i.e. both read &amp; writes&#8212;will be rejected. This also applies for api cluster state
read or write operations, like the get index settings, put mapping and cluster state api.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>write</literal>
</simpara>
</entry>
<entry>
<simpara>
(default) Write operations will be rejected. Read operations will succeed, based on the last known cluster configuration.
This may result in partial reads of stale data as this node may be isolated from the rest of the cluster.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>The <literal>discovery.zen.no_master_block</literal> setting doesn&#8217;t apply to nodes-based apis (for example cluster stats, node info and
node stats apis).  Requests to these apis will not be blocked and can run on any available node.</simpara>
</section>
</chapter>
<chapter id="modules-gateway">
<title>Local Gateway<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/gateway.asciidoc">Edit me</ulink></title>
<simpara>The local gateway module stores the cluster state and shard data across full
cluster restarts.</simpara>
<literallayout class="monospaced">The following _static_ settings, which must be set on every master node,
 control how long a freshly elected master should wait before it tries to
 recover the cluster state and the cluster's data:</literallayout>
<variablelist>
<varlistentry>
<term>
<literal>gateway.expected_nodes</literal>
</term>
<listitem>
<simpara>
    The number of (data or master) nodes that are expected to be in the cluster.
    Recovery of local shards will start as soon as the expected number of
    nodes have joined the cluster. Defaults to <literal>0</literal>
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>gateway.expected_master_nodes</literal>
</term>
<listitem>
<simpara>
    The number of master nodes that are expected to be in the cluster.
    Recovery of local shards will start as soon as the expected number of
    master nodes have joined the cluster. Defaults to <literal>0</literal>
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>gateway.expected_data_nodes</literal>
</term>
<listitem>
<simpara>
    The number of data nodes that are expected to be in the cluster.
    Recovery of local shards will start as soon as the expected number of
    data nodes have joined the cluster. Defaults to <literal>0</literal>
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>gateway.recover_after_time</literal>
</term>
<listitem>
<simpara>
    If the expected number of nodes is not achieved, the recovery process waits
    for the configured amount of time before trying to recover regardless.
    Defaults to <literal>5m</literal> if one of the <literal>expected_nodes</literal> settings is configured.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>Once the <literal>recover_after_time</literal> duration has timed out, recovery will start
as long as the following conditions are met:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>gateway.recover_after_nodes</literal>
</term>
<listitem>
<simpara>
    Recover as long as this many data or master nodes have joined the cluster.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>gateway.recover_after_master_nodes</literal>
</term>
<listitem>
<simpara>
    Recover as long as this many master nodes have joined the cluster.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>gateway.recover_after_data_nodes</literal>
</term>
<listitem>
<simpara>
    Recover as long as this many data nodes have joined the cluster.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<note><simpara>These settings only take effect on a full cluster restart.</simpara></note>
</chapter>
<chapter id="modules-http">
<title>HTTP<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/http.asciidoc">Edit me</ulink></title>
<simpara>The http module allows to expose <emphasis role="strong">elasticsearch</emphasis> APIs
over HTTP.</simpara>
<simpara>The http mechanism is completely asynchronous in nature, meaning that
there is no blocking thread waiting for a response. The benefit of using
asynchronous communication for HTTP is solving the
<ulink url="http://en.wikipedia.org/wiki/C10k_problem">C10k problem</ulink>.</simpara>
<simpara>When possible, consider using
<ulink url="http://en.wikipedia.org/wiki/Keepalive#HTTP_Keepalive">HTTP keep alive</ulink>
when connecting for better performance and try to get your favorite
client not to do
<ulink url="http://en.wikipedia.org/wiki/Chunked_transfer_encoding">HTTP chunking</ulink>.</simpara>
<bridgehead id="_settings_2" renderas="sect2">Settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/http.asciidoc">Edit me</ulink></bridgehead>
<simpara>The settings in the table below can be configured for HTTP. Note that none of
them are dynamically updatable so for them to take effect they should be set in
<literal>elasticsearch.yml</literal>.</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Setting </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>http.port</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A bind port range. Defaults to <literal>9200-9300</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>http.publish_port</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The port that HTTP clients should use when
communicating with this node. Useful when a cluster node is behind a
proxy or firewall and the <literal>http.port</literal> is not directly addressable
from the outside. Defaults to the actual port assigned via <literal>http.port</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>http.bind_host</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The host address to bind the HTTP service to. Defaults to <literal>http.host</literal> (if set) or <literal>network.bind_host</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>http.publish_host</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The host address to publish for HTTP clients to connect to. Defaults to <literal>http.host</literal> (if set) or <literal>network.publish_host</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>http.host</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Used to set the <literal>http.bind_host</literal> and the <literal>http.publish_host</literal> Defaults to <literal>http.host</literal> or <literal>network.host</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>http.max_content_length</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The max content of an HTTP request. Defaults to
<literal>100mb</literal>. If set to greater than <literal>Integer.MAX_VALUE</literal>, it will be reset to 100mb.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>http.max_initial_line_length</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The max length of an HTTP URL. Defaults
to <literal>4kb</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>http.max_header_size</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The max size of allowed headers.  Defaults to <literal>8kB</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>http.compression</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Support for compression when possible (with
Accept-Encoding). Defaults to <literal>true</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>http.compression_level</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Defines the compression level to use for HTTP responses. Valid values are in the range of 1 (minimum compression)
and 9 (maximum compression). Defaults to <literal>3</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>http.cors.enabled</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Enable or disable cross-origin resource sharing,
i.e. whether a browser on another origin can execute requests against
Elasticsearch. Set to <literal>true</literal> to enable Elasticsearch to process pre-flight
<ulink url="https://en.wikipedia.org/wiki/Cross-origin_resource_sharing">CORS</ulink> requests.
Elasticsearch will respond to those requests with the <literal>Access-Control-Allow-Origin</literal> header
if the <literal>Origin</literal> sent in the request is permitted by the <literal>http.cors.allow-origin</literal>
list. Set to <literal>false</literal> (the default) to make Elasticsearch ignore the <literal>Origin</literal>
request header, effectively disabling CORS requests because Elasticsearch will
never respond with the <literal>Access-Control-Allow-Origin</literal> response header. Note that
if the client does not send a pre-flight request with an <literal>Origin</literal> header or it
does not check the response headers from the server to validate the
<literal>Access-Control-Allow-Origin</literal> response header, then cross-origin security is
compromised. If CORS is not enabled on Elasticsearch, the only way for the client
to know is to send a pre-flight request and realize the required response headers
are missing.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>http.cors.allow-origin</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Which origins to allow. Defaults to no origins
allowed. If you prepend and append a <literal>/</literal> to the value, this will
be treated as a regular expression, allowing you to support HTTP and HTTPs.
for example using <literal>/https?:\/\/localhost(:[0-9]+)?/</literal> would return the
request header appropriately in both cases. <literal>*</literal> is a valid value but is
considered a <emphasis role="strong">security risk</emphasis> as your elasticsearch instance is open to cross origin
requests from <emphasis role="strong">anywhere</emphasis>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>http.cors.max-age</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Browsers send a "preflight" OPTIONS-request to
determine CORS settings. <literal>max-age</literal> defines how long the result should
be cached for. Defaults to <literal>1728000</literal> (20 days)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>http.cors.allow-methods</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Which methods to allow. Defaults to
<literal>OPTIONS, HEAD, GET, POST, PUT, DELETE</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>http.cors.allow-headers</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Which headers to allow. Defaults to
<literal>X-Requested-With, Content-Type, Content-Length</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>http.cors.allow-credentials</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Whether the <literal>Access-Control-Allow-Credentials</literal>
header should be returned. Note: This header is only returned, when the setting is
set to <literal>true</literal>. Defaults to <literal>false</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>http.detailed_errors.enabled</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Enables or disables the output of detailed error messages
and stack traces in response output. Note: When set to <literal>false</literal> and the <literal>error_trace</literal> request
parameter is specified, an error will be returned; when <literal>error_trace</literal> is not specified, a
simple message will be returned. Defaults to <literal>true</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>http.pipelining</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Enable or disable HTTP pipelining, defaults to <literal>true</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>http.pipelining.max_events</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The maximum number of events to be queued up in memory before a HTTP connection is closed, defaults to <literal>10000</literal>.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>It also uses the common
<link linkend="modules-network">network settings</link>.</simpara>
<bridgehead id="_disable_http" renderas="sect2">Disable HTTP<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/http.asciidoc">Edit me</ulink></bridgehead>
<simpara>The http module can be completely disabled and not started by setting
<literal>http.enabled</literal> to <literal>false</literal>. Elasticsearch nodes (and Java clients) communicate
internally using the <link linkend="modules-transport">transport interface</link>, not HTTP. It
might make  sense to disable the <literal>http</literal> layer entirely on nodes which are not
meant to serve REST requests directly. For instance, you could disable HTTP on
<link linkend="modules-node">data-only nodes</link> if you also have
<link linkend="modules-node">client nodes</link> which are intended to serve all REST requests.
Be aware, however, that you will not be able to send any REST requests (eg to
retrieve node stats) directly to nodes which have HTTP disabled.</simpara>
</chapter>
<chapter id="modules-indices">
<title>Indices<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/indices.asciidoc">Edit me</ulink></title>
<simpara>The indices module controls index-related settings that are globally managed
for all indices, rather than being configurable at a per-index level.</simpara>
<simpara>Available settings include:</simpara>
<variablelist>
<varlistentry>
<term>
<link linkend="circuit-breaker">Circuit breaker</link>
</term>
<listitem>
<simpara>
    Circuit breakers set limits on memory usage to avoid out of memory exceptions.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="modules-fielddata">Fielddata cache</link>
</term>
<listitem>
<simpara>
    Set limits on the amount of heap used by the in-memory fielddata cache.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="query-cache">Node query cache</link>
</term>
<listitem>
<simpara>
    Configure the amount heap used to cache queries results.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="indexing-buffer">Indexing buffer</link>
</term>
<listitem>
<simpara>
    Control the size of the buffer allocated to the indexing process.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="shard-request-cache">Shard request cache</link>
</term>
<listitem>
<simpara>
    Control the behaviour of the shard-level request cache.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="recovery">Recovery</link>
</term>
<listitem>
<simpara>
    Control the resource limits on the shard recovery process.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<section id="circuit-breaker">
<title>Circuit Breaker<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/indices/circuit_breaker.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch contains multiple circuit breakers used to prevent operations from
causing an OutOfMemoryError. Each breaker specifies a limit for how much memory
it can use. Additionally, there is a parent-level breaker that specifies the
total amount of memory that can be used across all breakers.</simpara>
<simpara>These settings can be dynamically updated on a live cluster with the
<link linkend="cluster-update-settings">cluster-update-settings</link> API.</simpara>
<bridgehead id="parent-circuit-breaker" renderas="sect3">Parent circuit breaker<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/indices/circuit_breaker.asciidoc">Edit me</ulink></bridgehead>
<simpara>The parent-level breaker can be configured with the following setting:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>indices.breaker.total.limit</literal>
</term>
<listitem>
<simpara>
    Starting limit for overall parent breaker, defaults to 70% of JVM heap.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="fielddata-circuit-breaker" renderas="sect3">Field data circuit breaker<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/indices/circuit_breaker.asciidoc">Edit me</ulink></bridgehead>
<simpara>The field data circuit breaker allows Elasticsearch to estimate the amount of
memory a field will require to be loaded into memory. It can then prevent the
field data loading by raising an exception. By default the limit is configured
to 60% of the maximum JVM heap. It can be configured with the following
parameters:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>indices.breaker.fielddata.limit</literal>
</term>
<listitem>
<simpara>
    Limit for fielddata breaker, defaults to 60% of JVM heap
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>indices.breaker.fielddata.overhead</literal>
</term>
<listitem>
<simpara>
    A constant that all field data estimations are multiplied with to determine a
    final estimation. Defaults to 1.03
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="request-circuit-breaker" renderas="sect3">Request circuit breaker<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/indices/circuit_breaker.asciidoc">Edit me</ulink></bridgehead>
<simpara>The request circuit breaker allows Elasticsearch to prevent per-request data
structures (for example, memory used for calculating aggregations during a
request) from exceeding a certain amount of memory.</simpara>
<variablelist>
<varlistentry>
<term>
<literal>indices.breaker.request.limit</literal>
</term>
<listitem>
<simpara>
    Limit for request breaker, defaults to 60% of JVM heap
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>indices.breaker.request.overhead</literal>
</term>
<listitem>
<simpara>
    A constant that all request estimations are multiplied with to determine a
    final estimation. Defaults to 1
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="in-flight-circuit-breaker" renderas="sect3">In flight requests circuit breaker<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/indices/circuit_breaker.asciidoc">Edit me</ulink></bridgehead>
<simpara>The in flight requests circuit breaker allows Elasticsearch to limit the memory usage of all
currently active incoming requests on transport or HTTP level from exceeding a certain amount of
memory on a node. The memory usage is based on the content length of the request itself.</simpara>
<variablelist>
<varlistentry>
<term>
<literal>network.breaker.inflight_requests.limit</literal>
</term>
<listitem>
<simpara>
    Limit for in flight requests breaker, defaults to 100% of JVM heap. This means that it is bound
    by the limit configured for the parent circuit breaker.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>network.breaker.inflight_requests.overhead</literal>
</term>
<listitem>
<simpara>
    A constant that all in flight requests estimations are multiplied with to determine a
    final estimation. Defaults to 1
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="script-compilation-circuit-breaker" renderas="sect3">Script compilation circuit breaker<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/indices/circuit_breaker.asciidoc">Edit me</ulink></bridgehead>
<simpara>Slightly different than the previous memory-based circuit breaker, the script
compilation circuit breaker limits the number of inline script compilations
within a period of time.</simpara>
<simpara>See the "prefer-parameters" section of the <link linkend="modules-scripting-using">scripting</link>
documentation for more information.</simpara>
<variablelist>
<varlistentry>
<term>
<literal>script.max_compilations_per_minute</literal>
</term>
<listitem>
<simpara>
    Limit for the number of unique dynamic scripts within a minute that are
    allowed to be compiled. Defaults to 15.
</simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
<section id="modules-fielddata">
<title>Fielddata<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/indices/fielddata.asciidoc">Edit me</ulink></title>
<simpara>The field data cache is used mainly when sorting on or computing aggregations
on a field. It loads all the field values to memory in order to provide fast
document based access to those values. The field data cache can be
expensive to build for a field, so its recommended to have enough memory
to allocate it, and to keep it loaded.</simpara>
<simpara>The amount of memory used for the field
data cache can be controlled using <literal>indices.fielddata.cache.size</literal>. Note:
reloading  the field data which does not fit into your cache will be expensive
and  perform poorly.</simpara>
<variablelist>
<varlistentry>
<term>
<literal>indices.fielddata.cache.size</literal>
</term>
<listitem>
<simpara>
    The max size of the field data cache, eg <literal>30%</literal> of node heap space, or an
    absolute value, eg <literal>12GB</literal>. Defaults to unbounded.  Also see
    <xref linkend="fielddata-circuit-breaker"/>.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<note><simpara>These are static settings which must be configured on every data node in
the cluster.</simpara></note>
<bridgehead id="fielddata-monitoring" renderas="sect3">Monitoring field data<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/indices/fielddata.asciidoc">Edit me</ulink></bridgehead>
<simpara>You can monitor memory usage for field data as well as the field data circuit
breaker using
<link linkend="cluster-nodes-stats">Nodes Stats API</link></simpara>
</section>
<section id="query-cache">
<title>Node Query Cache<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/indices/query_cache.asciidoc">Edit me</ulink></title>
<simpara>The query cache is responsible for caching the results of queries.
There is one queries cache per node that is shared by all shards.
The cache implements an LRU eviction policy: when a cache becomes full, the
least recently used data is evicted to make way for new data.</simpara>
<simpara>The query cache only caches queries which are being used in a filter context.</simpara>
<simpara>The following setting is <emphasis>static</emphasis> and must be configured on every data node in
the cluster:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>indices.queries.cache.size</literal>
</term>
<listitem>
<simpara>
    Controls the memory size for the filter cache , defaults to <literal>10%</literal>. Accepts
    either a percentage value, like <literal>5%</literal>, or an exact value, like <literal>512mb</literal>.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>The following setting is an <emphasis>index</emphasis> setting that can be configured on a
per-index basis:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>index.queries.cache.enabled</literal>
</term>
<listitem>
<simpara>
    Controls whether to enable query caching. Accepts <literal>true</literal> (default) or
    <literal>false</literal>.
</simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
<section id="indexing-buffer">
<title>Indexing Buffer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/indices/indexing_buffer.asciidoc">Edit me</ulink></title>
<simpara>The indexing buffer is used to store newly indexed documents.  When it fills
up, the documents in the buffer are written to a segment on disk. It is divided
between all shards on the node.</simpara>
<simpara>The following settings are <emphasis>static</emphasis> and must be configured on every data node
in the cluster:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>indices.memory.index_buffer_size</literal>
</term>
<listitem>
<simpara>
    Accepts either a percentage or a byte size value. It defaults to <literal>10%</literal>,
    meaning that <literal>10%</literal> of the total heap allocated to a node will be used as the
    indexing buffer size shared across all shards.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>indices.memory.min_index_buffer_size</literal>
</term>
<listitem>
<simpara>
    If the <literal>index_buffer_size</literal> is specified as a percentage, then this
    setting can be used to specify an absolute minimum.  Defaults to <literal>48mb</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>indices.memory.max_index_buffer_size</literal>
</term>
<listitem>
<simpara>
    If the <literal>index_buffer_size</literal> is specified as a percentage, then this
    setting can be used to specify an absolute maximum.  Defaults to unbounded.
</simpara>
</listitem>
</varlistentry>
</variablelist>
</section>
<section id="shard-request-cache">
<title>Shard request cache<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/indices/request_cache.asciidoc">Edit me</ulink></title>
<simpara>When a search request is run against an index or against many indices, each
involved shard executes the search locally and returns its local results to
the <emphasis>coordinating node</emphasis>, which combines these shard-level results into a
&#8220;global&#8221; result set.</simpara>
<simpara>The shard-level request cache module caches the local results on each shard.
This allows frequently used (and potentially heavy) search requests to return
results almost instantly. The requests cache is a very good fit for the logging
use case, where only the most recent index is being actively updated&#8201;&#8212;&#8201;results from older indices will be served directly from the cache.</simpara>
<important>
<simpara>By default, the requests cache will only cache the results of search requests
where <literal>size=0</literal>, so it will not cache <literal>hits</literal>,
but it will cache <literal>hits.total</literal>,  <link linkend="search-aggregations">aggregations</link>, and
<link linkend="search-suggesters">suggestions</link>.</simpara>
<simpara>Most queries that use <literal>now</literal> (see <xref linkend="date-math"/>) cannot be cached.</simpara>
</important>
<bridgehead id="_cache_invalidation" renderas="sect3">Cache invalidation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/indices/request_cache.asciidoc">Edit me</ulink></bridgehead>
<simpara>The cache is smart&#8201;&#8212;&#8201;it keeps the same <emphasis>near real-time</emphasis> promise as uncached
search.</simpara>
<simpara>Cached results are invalidated automatically whenever the shard refreshes, but
only if the data in the shard has actually changed.  In other words, you will
always get the same results from the cache as you would for an uncached search
request.</simpara>
<simpara>The longer the refresh interval, the longer that cached entries will remain
valid. If the cache is full, the least recently used cache keys will be
evicted.</simpara>
<simpara>The cache can be expired manually with the <link linkend="indices-clearcache"><literal>clear-cache</literal> API</link>:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /kimchy,elasticsearch/_cache/clear?request_cache=true</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT kimchy\nPUT elasticsearch\n/]</remark>
<bridgehead id="_enabling_and_disabling_caching" renderas="sect3">Enabling and disabling caching<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/indices/request_cache.asciidoc">Edit me</ulink></bridgehead>
<simpara>The cache is enabled by default, but can be disabled when creating a new
index as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /my_index
{
  "settings": {
    "index.requests.cache.enable": false
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>It can also be enabled or disabled dynamically on an existing index with the
<link linkend="indices-update-settings"><literal>update-settings</literal></link> API:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /my_index/_settings
{ "index.requests.cache.enable": true }</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<bridgehead id="_enabling_and_disabling_caching_per_request" renderas="sect3">Enabling and disabling caching per request<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/indices/request_cache.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>request_cache</literal> query-string parameter can be used to enable or disable
caching on a <emphasis role="strong">per-request</emphasis> basis.  If set, it overrides the index-level setting:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /my_index/_search?request_cache=true
{
  "size": 0,
  "aggs": {
    "popular_colors": {
      "terms": {
        "field": "colors"
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<important><simpara>If your query uses a script whose result is not deterministic (e.g.
it uses a random function or references the current time) you should set the
<literal>request_cache</literal> flag to <literal>false</literal> to disable caching for that request.</simpara></important>
<simpara>Requests <literal>size</literal> is greater than 0 will not be cached even if the request cache is
enabled in the index settings. To cache these requests you will need to use the
query-string parameter detailed here.</simpara>
<bridgehead id="_cache_key" renderas="sect3">Cache key<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/indices/request_cache.asciidoc">Edit me</ulink></bridgehead>
<simpara>The whole JSON body is used as the cache key.  This means that if the JSON
changes&#8201;&#8212;&#8201;for instance if keys are output in a different order&#8201;&#8212;&#8201;then the
cache key will not be recognised.</simpara>
<tip><simpara>Most JSON libraries support a <emphasis>canonical</emphasis> mode which ensures that JSON
keys are always emitted in the same order. This canonical mode can be used in
the application to ensure that a request is always serialized in the same way.</simpara></tip>
<bridgehead id="_cache_settings" renderas="sect3">Cache settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/indices/request_cache.asciidoc">Edit me</ulink></bridgehead>
<simpara>The cache is managed at the node level, and has a default maximum size of <literal>1%</literal>
of the heap.  This can be changed in the <literal>config/elasticsearch.yml</literal> file with:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">indices.requests.cache.size: 2%</programlisting>
<simpara>Also, you can use the <literal>indices.requests.cache.expire</literal> setting to specify a TTL
for cached results, but there should be no reason to do so.  Remember that
stale results are automatically invalidated when the index is refreshed. This
setting is provided for completeness' sake only.</simpara>
<bridgehead id="_monitoring_cache_usage" renderas="sect3">Monitoring cache usage<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/indices/request_cache.asciidoc">Edit me</ulink></bridgehead>
<simpara>The size of the cache (in bytes) and the number of evictions can be viewed
by index, with the <link linkend="indices-stats"><literal>indices-stats</literal></link> API:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_stats/request_cache?human</programlisting>
<remark> CONSOLE</remark>
<simpara>or by node with the <link linkend="cluster-nodes-stats"><literal>nodes-stats</literal></link> API:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_nodes/stats/indices/request_cache?human</programlisting>
<remark> CONSOLE</remark>
</section>
<section id="recovery">
<title>Indices Recovery<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/indices/recovery.asciidoc">Edit me</ulink></title>
<simpara>The following <emphasis>expert</emphasis> settings can be set to manage the recovery policy.</simpara>
<variablelist>
<varlistentry>
<term>
<literal>indices.recovery.file_chunk_size</literal>
</term>
<listitem>
<simpara>
    Defaults to <literal>512kb</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>indices.recovery.translog_ops</literal>
</term>
<listitem>
<simpara>
    Defaults to <literal>1000</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>indices.recovery.translog_size</literal>
</term>
<listitem>
<simpara>
    Defaults to <literal>512kb</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>indices.recovery.compress</literal>
</term>
<listitem>
<simpara>
    Defaults to <literal>true</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>indices.recovery.max_bytes_per_sec</literal>
</term>
<listitem>
<simpara>
    Defaults to <literal>40mb</literal>.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>These settings can be dynamically updated on a live cluster with the
<link linkend="cluster-update-settings">cluster-update-settings</link> API:</simpara>
</section>
</chapter>
<chapter id="modules-network">
<title>Network Settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/network.asciidoc">Edit me</ulink></title>
<simpara>Elasticsearch binds to localhost only by default.  This is sufficient for you
to run a local development server (or even a development cluster, if you start
multiple nodes on the same machine), but you will need to configure some
<link linkend="common-network-settings">basic network settings</link> in order to run a real
production cluster across multiple servers.</simpara>
<warning>
<title>Be careful with the network configuration!</title>
<simpara>Never expose an unprotected node to the public internet.</simpara>
</warning>
<bridgehead id="common-network-settings" renderas="sect2">Commonly Used Network Settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/network.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
<literal>network.host</literal>
</term>
<listitem>
<simpara>
The node will bind to this hostname or IP address and <emphasis>publish</emphasis> (advertise)
this host to other nodes in the cluster. Accepts an IP address, hostname, a
<link linkend="network-interface-values">special value</link>, or an array of any combination
of these.
</simpara>
<simpara>Defaults to <literal>_local_</literal>.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>discovery.zen.ping.unicast.hosts</literal>
</term>
<listitem>
<simpara>
In order to join a cluster, a node needs to know the hostname or IP address of
at least some of the other nodes in the cluster.  This setting provides the
initial list of other nodes that this node will try to contact. Accepts IP
addresses or hostnames.
</simpara>
<simpara>Defaults to <literal>["127.0.0.1", "[::1]"]</literal>.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>http.port</literal>
</term>
<listitem>
<simpara>
Port to bind to for incoming HTTP requests. Accepts a single value or a range.
If a range is specified, the node will bind to the first available port in the
range.
</simpara>
<simpara>Defaults to <literal>9200-9300</literal>.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>transport.tcp.port</literal>
</term>
<listitem>
<simpara>
Port to bind for communication between nodes. Accepts a single value or a
range. If a range is specified, the node will bind to the first available port
in the range.
</simpara>
<simpara>Defaults to <literal>9300-9400</literal>.</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="network-interface-values" renderas="sect2">Special values for <literal>network.host</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/network.asciidoc">Edit me</ulink></bridgehead>
<simpara>The following special values may be passed to <literal>network.host</literal>:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>_[networkInterface]_</literal>
</simpara>
</entry>
<entry>
<simpara>
  Addresses of a network interface, for example <literal>_en0_</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>_local_</literal>
</simpara>
</entry>
<entry>
<simpara>
  Any loopback addresses on the system, for example <literal>127.0.0.1</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>_site_</literal>
</simpara>
</entry>
<entry>
<simpara>
  Any site-local addresses on the system, for example <literal>192.168.0.1</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>_global_</literal>
</simpara>
</entry>
<entry>
<simpara>
  Any globally-scoped addresses on the system, for example <literal>8.8.8.8</literal>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="_ipv4_vs_ipv6" renderas="sect3">IPv4 vs IPv6<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/network.asciidoc">Edit me</ulink></bridgehead>
<simpara>These special values will work over both IPv4 and IPv6 by default, but you can
also limit this with the use of <literal>:ipv4</literal> of <literal>:ipv6</literal> specifiers. For example,
<literal>_en0:ipv4_</literal> would only bind to the IPv4 addresses of interface <literal>en0</literal>.</simpara>
<tip>
<title>Discovery in the cloud</title>
<simpara>More special settings are available when running in the cloud with either the
<ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/discovery-ec2-discovery.html#discovery-ec2-network-host">EC2 discovery plugin</ulink> or the
<ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/discovery-gce-network-host.html#discovery-gce-network-host">Google Compute Engine discovery plugin</ulink>
installed.</simpara>
</tip>
<bridgehead id="advanced-network-settings" renderas="sect2">Advanced network settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/network.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>network.host</literal> setting explained in <link linkend="common-network-settings">Commonly used network settings</link>
is a shortcut which sets the <emphasis>bind host</emphasis> and the <emphasis>publish host</emphasis> at the same
time. In advanced used cases, such as when running behind a proxy server, you
may need to set these settings to different values:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>network.bind_host</literal>
</term>
<listitem>
<simpara>
This specifies which network interface(s) a node should bind to in order to
listen for incoming requests.  A node can bind to multiple interfaces, e.g.
two network cards, or a site-local address and a local address. Defaults to
<literal>network.host</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>network.publish_host</literal>
</term>
<listitem>
<simpara>
The publish host is the single interface that the node advertises to other
nodes in the cluster, so that those nodes can connect to it.   Currently an
elasticsearch node may be bound to multiple addresses, but only publishes one.
If not specified, this defaults to the &#8220;best&#8221; address from
<literal>network.host</literal>, sorted by IPv4/IPv6 stack preference, then by
reachability.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>Both of the above settings can be configured just like <literal>network.host</literal>&#8201;&#8212;&#8201;they
accept IP addresses, host names, and
<link linkend="network-interface-values">special values</link>.</simpara>
<bridgehead id="tcp-settings" renderas="sect2">Advanced TCP Settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/network.asciidoc">Edit me</ulink></bridgehead>
<simpara>Any component that uses TCP (like the <link linkend="modules-http">HTTP</link> and
<link linkend="modules-transport">Transport</link> modules) share the following settings:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>network.tcp.no_delay</literal>
</simpara>
</entry>
<entry>
<simpara>
Enable or disable the <ulink url="https://en.wikipedia.org/wiki/Nagle%27s_algorithm">TCP no delay</ulink>
setting. Defaults to <literal>true</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>network.tcp.keep_alive</literal>
</simpara>
</entry>
<entry>
<simpara>
Enable or disable <ulink url="https://en.wikipedia.org/wiki/Keepalive">TCP keep alive</ulink>.
Defaults to <literal>true</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>network.tcp.reuse_address</literal>
</simpara>
</entry>
<entry>
<simpara>
Should an address be reused or not. Defaults to <literal>true</literal> on non-windows
machines.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>network.tcp.send_buffer_size</literal>
</simpara>
</entry>
<entry>
<simpara>
The size of the TCP send buffer (specified with <link linkend="size-units">size units</link>).
By default not explicitly set.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>network.tcp.receive_buffer_size</literal>
</simpara>
</entry>
<entry>
<simpara>
The size of the TCP receive buffer (specified with <link linkend="size-units">size units</link>).
By default not explicitly set.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="_transport_and_http_protocols" renderas="sect2">Transport and HTTP protocols<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/network.asciidoc">Edit me</ulink></bridgehead>
<simpara>An Elasticsearch node exposes two network protocols which inherit the above
settings, but may be further configured independently:</simpara>
<variablelist>
<varlistentry>
<term>
TCP Transport
</term>
<listitem>
<simpara>
Used for communication between nodes in the cluster, by the Java
<ulink url="https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.x//transport-client.html">Transport client</ulink> and by the
<link linkend="modules-tribe">Tribe node</link>.  See the <link linkend="modules-transport">Transport module</link>
for more information.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
HTTP
</term>
<listitem>
<simpara>
Exposes the JSON-over-HTTP interface used by all clients other than the Java
clients. See the <link linkend="modules-http">HTTP module</link> for more information.
</simpara>
</listitem>
</varlistentry>
</variablelist>
</chapter>
<chapter id="modules-node">
<title>Node<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/node.asciidoc">Edit me</ulink></title>
<simpara>Any time that you start an instance of Elasticsearch, you are starting a
<emphasis>node</emphasis>. A collection of connected nodes is  called a
<link linkend="modules-cluster">cluster</link>. If you are running a single node of Elasticsearch,
then you have a cluster of one node.</simpara>
<simpara>Every node in the cluster can handle <link linkend="modules-http">HTTP</link> and
<link linkend="modules-transport">Transport</link> traffic by default. The transport layer
is used exclusively for communication between nodes and the
<ulink url="https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.x//transport-client.html">Java <literal>TransportClient</literal></ulink>; the HTTP layer is
used only by external REST clients.</simpara>
<simpara>All nodes know about all the other nodes in the cluster and can forward client
requests to the appropriate node. Besides that, each node serves one or more
purpose:</simpara>
<variablelist>
<varlistentry>
<term>
<link linkend="master-node">Master-eligible node</link>
</term>
<listitem>
<simpara>
A node that has <literal>node.master</literal> set to <literal>true</literal> (default), which makes it eligible
to be <link linkend="modules-discovery-zen">elected as the <emphasis>master</emphasis> node</link>, which controls
the cluster.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="data-node">Data node</link>
</term>
<listitem>
<simpara>
A node that has <literal>node.data</literal> set to <literal>true</literal> (default). Data nodes hold data and
perform data related operations such as CRUD, search, and aggregations.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="ingest">Ingest node</link>
</term>
<listitem>
<simpara>
A node that has <literal>node.ingest</literal> set to <literal>true</literal> (default). Ingest nodes are able
to apply an <link linkend="pipeline">ingest pipeline</link> to a document in order to transform
and enrich the document before indexing. With a heavy ingest load, it makes
sense to use dedicated ingest nodes and to mark the master and data nodes as
<literal>node.ingest: false</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="modules-tribe">Tribe node</link>
</term>
<listitem>
<simpara>
A tribe node, configured via the <literal>tribe.*</literal> settings, is a special type  of
coordinating only node that can connect to multiple clusters and perform
search and other operations across all connected clusters.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>By default a node is a master-eligible node and a data node, plus it can
pre-process documents through ingest pipelines. This is very convenient for
small clusters but, as the cluster grows, it becomes important to consider
separating dedicated master-eligible nodes from dedicated data nodes.</simpara>
<note id="coordinating-node">
<title>Coordinating node</title>
<simpara>Requests like search requests or bulk-indexing requests may involve data held
on different data nodes. A search request, for example, is executed in two
phases which are coordinated by the node which receives the client request&#8201;&#8212;&#8201;the <emphasis>coordinating node</emphasis>.</simpara>
<simpara>In the <emphasis>scatter</emphasis> phase, the coordinating node forwards the request to the data
nodes which hold the data.  Each data node executes the request locally and
returns its results to the coordinating node. In the <emphasis>gather</emphasis>  phase, the
coordinating node reduces each data node&#8217;s results into a single global
resultset.</simpara>
<simpara>Every node is implicitly a coordinating node. This means that a node that has
all three <literal>node.master</literal>, <literal>node.data</literal> and <literal>node.ingest</literal> set to <literal>false</literal> will
only act as a coordinating node, which cannot be disabled. As a result, such
a node needs to have enough memory and CPU in order to deal with the gather
phase.</simpara>
</note>
<bridgehead id="master-node" renderas="sect2">Master Eligible Node<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/node.asciidoc">Edit me</ulink></bridgehead>
<simpara>The master node is responsible for lightweight cluster-wide actions such as
creating or deleting an index, tracking which nodes are part of the cluster,
and deciding which shards to allocate to which nodes. It is important for
cluster health to have a stable master node.</simpara>
<simpara>Any master-eligible node (all nodes by default) may be elected to become the
master node by the <link linkend="modules-discovery-zen">master election process</link>.</simpara>
<important><simpara>Master nodes must have access to the <literal>data/</literal> directory (just like
<literal>data</literal> nodes) as this is where the cluster state is persisted between node restarts.</simpara></important>
<simpara>Indexing and searching your data is CPU-, memory-, and I/O-intensive work
which can put pressure on a node&#8217;s resources. To ensure that your master
node is stable and not under pressure, it is a good idea in a bigger
cluster to split the roles between dedicated master-eligible nodes and
dedicated data nodes.</simpara>
<simpara>While master nodes can also behave as <link linkend="coordinating-node">coordinating nodes</link>
and route search and indexing requests from clients to data nodes, it is
better <emphasis>not</emphasis> to use dedicated master nodes for this purpose. It is important
for the stability of the cluster that master-eligible nodes do as little work
as possible.</simpara>
<simpara>To create a standalone master-eligible node, set:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">node.master: true <co id="CO277-1"/>
node.data: false <co id="CO277-2"/>
node.ingest: false <co id="CO277-3"/></programlisting>
<calloutlist>
<callout arearefs="CO277-1">
<para>
The <literal>node.master</literal> role is enabled by default.
</para>
</callout>
<callout arearefs="CO277-2">
<para>
Disable the <literal>node.data</literal> role (enabled by default).
</para>
</callout>
<callout arearefs="CO277-3">
<para>
Disable the <literal>node.ingest</literal> role (enabled by default).
</para>
</callout>
</calloutlist>
<bridgehead id="split-brain" renderas="sect3">Avoiding split brain with <literal>minimum_master_nodes</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/node.asciidoc">Edit me</ulink></bridgehead>
<simpara>To prevent data loss, it is vital to configure the
<literal>discovery.zen.minimum_master_nodes</literal> setting (which defaults to <literal>1</literal>) so that
each master-eligible node knows the <emphasis>minimum number of master-eligible nodes</emphasis>
that must be visible in order to form a cluster.</simpara>
<simpara>To explain, imagine that you have a cluster consisting of two master-eligible
nodes. A network failure breaks communication between these two nodes.  Each
node sees one master-eligible node&#8230; itself. With <literal>minimum_master_nodes</literal> set
to the default of <literal>1</literal>,  this is sufficient to form a cluster. Each node elects
itself as the new master (thinking that the other master-eligible node has
died) and the result is two clusters, or a <emphasis>split brain</emphasis>.  These two nodes
will never rejoin until one node is restarted.  Any data that has been written
to the restarted node will be lost.</simpara>
<simpara>Now imagine that you have a cluster with three master-eligible nodes, and
<literal>minimum_master_nodes</literal> set to <literal>2</literal>.  If a network split separates one node from
the other two nodes, the side with one node cannot see enough master-eligible
nodes and will realise that it cannot elect itself as master.  The side with
two nodes will elect a new master (if needed) and continue functioning
correctly.  As soon as the network split is resolved, the single node will
rejoin the cluster and start serving requests again.</simpara>
<simpara>This setting should be set to a <emphasis>quorum</emphasis> of master-eligible nodes:</simpara>
<literallayout class="monospaced">(master_eligible_nodes / 2) + 1</literallayout>
<simpara>In other words, if there are three master-eligible nodes, then minimum master
nodes should be set to <literal>(3 / 2) + 1</literal> or <literal>2</literal>:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">discovery.zen.minimum_master_nodes: 2 <co id="CO278-1"/></programlisting>
<calloutlist>
<callout arearefs="CO278-1">
<para>
Defaults to <literal>1</literal>.
</para>
</callout>
</calloutlist>
<simpara>This setting can also be changed dynamically on a live cluster with the
<link linkend="cluster-update-settings">cluster update settings API</link>:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT _cluster/settings
{
  "transient": {
    "discovery.zen.minimum_master_nodes": 2
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[catch:/cannot set discovery.zen.minimum_master_nodes to more than the current master nodes/]</remark>
<tip><simpara>An advantage of splitting the master and data roles between dedicated
nodes is that you can have just three master-eligible nodes and set
<literal>minimum_master_nodes</literal> to <literal>2</literal>. You never have to change this setting, no
matter how many dedicated data nodes you add to the cluster.</simpara></tip>
<bridgehead id="data-node" renderas="sect2">Data Node<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/node.asciidoc">Edit me</ulink></bridgehead>
<simpara>Data nodes hold the shards that contain the documents you have indexed. Data
nodes handle data related operations like CRUD, search, and aggregations.
These operations are I/O-, memory-, and CPU-intensive. It is important to
monitor these resources and to add more data nodes if they are overloaded.</simpara>
<simpara>The main benefit of having dedicated data nodes is the separation of the
master and data roles.</simpara>
<simpara>To create a dedicated data node, set:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">node.master: false <co id="CO279-1"/>
node.data: true <co id="CO279-2"/>
node.ingest: false <co id="CO279-3"/></programlisting>
<calloutlist>
<callout arearefs="CO279-1">
<para>
Disable the <literal>node.master</literal> role (enabled by default).
</para>
</callout>
<callout arearefs="CO279-2">
<para>
The <literal>node.data</literal> role is enabled by default.
</para>
</callout>
<callout arearefs="CO279-3">
<para>
Disable the <literal>node.ingest</literal> role (enabled by default).
</para>
</callout>
</calloutlist>
<bridgehead id="node-ingest-node" renderas="sect2">Ingest Node<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/node.asciidoc">Edit me</ulink></bridgehead>
<simpara>Ingest nodes can execute pre-processing pipelines, composed of one or more
ingest processors. Depending on the type of operations performed by the ingest
processors and the required resources, it may make sense to have dedicated
ingest nodes, that will only perform this specific task.</simpara>
<simpara>To create a dedicated ingest node, set:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">node.master: false <co id="CO280-1"/>
node.data: false <co id="CO280-2"/>
node.ingest: true <co id="CO280-3"/></programlisting>
<calloutlist>
<callout arearefs="CO280-1">
<para>
Disable the <literal>node.master</literal> role (enabled by default).
</para>
</callout>
<callout arearefs="CO280-2">
<para>
Disable the <literal>node.data</literal> role (enabled by default).
</para>
</callout>
<callout arearefs="CO280-3">
<para>
The <literal>node.ingest</literal> role is enabled by default.
</para>
</callout>
</calloutlist>
<bridgehead id="coordinating-only-node" renderas="sect2">Coordinating only node<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/node.asciidoc">Edit me</ulink></bridgehead>
<simpara>If you take away the ability to be able to handle master duties, to hold data,
and pre-process documents, then you are left with a <emphasis>coordinating</emphasis> node that
can only route requests, handle the search reduce phase, and distribute bulk
indexing. Essentially, coordinating only nodes behave as smart load balancers.</simpara>
<simpara>Coordinating only nodes can benefit large clusters by offloading the
coordinating node role from data and master-eligible nodes.  They join the
cluster and receive the full <link linkend="cluster-state">cluster state</link>, like every other
node, and they use the cluster state to route requests directly to the
appropriate place(s).</simpara>
<warning><simpara>Adding too many coordinating only nodes to a cluster can increase the
burden on the entire cluster because the elected master node must await
acknowledgement of cluster state updates from every node! The benefit of
coordinating only nodes should not be overstated&#8201;&#8212;&#8201;data nodes can happily
serve the same purpose.</simpara></warning>
<simpara>To create a coordinating only node, set:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">node.master: false <co id="CO281-1"/>
node.data: false <co id="CO281-2"/>
node.ingest: false <co id="CO281-3"/></programlisting>
<calloutlist>
<callout arearefs="CO281-1">
<para>
Disable the <literal>node.master</literal> role (enabled by default).
</para>
</callout>
<callout arearefs="CO281-2">
<para>
Disable the <literal>node.data</literal> role (enabled by default).
</para>
</callout>
<callout arearefs="CO281-3">
<para>
Disable the <literal>node.ingest</literal> role (enabled by default).
</para>
</callout>
</calloutlist>
<bridgehead id="_node_data_path_settings" renderas="sect1">Node data path settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/node.asciidoc">Edit me</ulink></bridgehead>
<bridgehead id="data-path" renderas="sect2"><literal>path.data</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/node.asciidoc">Edit me</ulink></bridgehead>
<simpara>Every data and master-eligible node requires access to a data directory where
shards and index and cluster metadata will be stored. The <literal>path.data</literal> defaults
to <literal>$ES_HOME/data</literal> but can be configured in the <literal>elasticsearch.yml</literal> config
file an absolute path or a path relative to <literal>$ES_HOME</literal> as follows:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">path.data:  /var/elasticsearch/data</programlisting>
<simpara>Like all node settings, it can also be specified on the command line as:</simpara>
<programlisting language="sh" linenumbering="unnumbered">./bin/elasticsearch -Epath.data=/var/elasticsearch/data</programlisting>
<tip><simpara>When using the <literal>.zip</literal> or <literal>.tar.gz</literal> distributions, the <literal>path.data</literal> setting
should be configured to locate the data directory outside the Elasticsearch
home directory, so that the home directory can be deleted without deleting
your data! The RPM and Debian distributions do this for you already.</simpara></tip>
<bridgehead id="max-local-storage-nodes" renderas="sect2"><literal>node.max_local_storage_nodes</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/node.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <link linkend="data-path">data path</link> can be shared by multiple nodes, even by nodes from different
clusters. This is very useful for testing failover and different configurations on your development
machine. In production, however, it is recommended to run only one node of Elasticsearch per server.</simpara>
<simpara>By default, Elasticsearch is configured to prevent more than one node from sharing the same data
path. To allow for more than one node (e.g., on your development machine), use the setting
<literal>node.max_local_storage_nodes</literal> and set this to a positive integer larger than one.</simpara>
<warning><simpara>Never run different node types (i.e. master, data) from the same data directory. This can
lead to unexpected data loss.</simpara></warning>
<bridgehead id="_other_node_settings" renderas="sect1">Other node settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/node.asciidoc">Edit me</ulink></bridgehead>
<simpara>More node settings can be found in <link linkend="modules">Modules</link>.  Of particular note are
the <link linkend="cluster.name"><literal>cluster.name</literal></link>, the <link linkend="node.name"><literal>node.name</literal></link> and the
<link linkend="modules-network">network settings</link>.</simpara>
</chapter>
<chapter id="modules-plugins">
<title>Plugins<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/plugins.asciidoc">Edit me</ulink></title>
<bridgehead id="_plugins" renderas="sect2">Plugins<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/plugins.asciidoc">Edit me</ulink></bridgehead>
<simpara>Plugins are a way to enhance the basic elasticsearch functionality in a
custom manner. They range from adding custom mapping types, custom
analyzers (in a more built in fashion), native scripts, custom discovery
and more.</simpara>
<simpara>See the <ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/index.html">Plugins documentation</ulink> for more.</simpara>
</chapter>
<chapter id="modules-scripting">
<title>Scripting<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting.asciidoc">Edit me</ulink></title>
<simpara>The scripting module enables you to use scripts to evaluate custom
expressions. For example, you could use a script to return "script fields"
as part of a search request or evaluate a custom score for a query.</simpara>
<simpara>The default scripting language is <link linkend="modules-scripting-painless"><literal>Painless</literal></link>.
Additional <literal>lang</literal> plugins enable you to run scripts written in other languages.
Everywhere a script can be used, you can include a <literal>lang</literal> parameter
to specify the language of the script.</simpara>
<bridgehead id="_general_purpose_languages" renderas="sect2">General-purpose languages:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting.asciidoc">Edit me</ulink></bridgehead>
<simpara>These languages can be used for any purpose in the scripting APIs,
and give the most flexibility.</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="3">
<colspec colname="col_1" colwidth="33*"/>
<colspec colname="col_2" colwidth="33*"/>
<colspec colname="col_3" colwidth="33*"/>
<thead>
<row>
<entry align="left" valign="top">Language
    </entry>
<entry align="left" valign="top">Sandboxed
    </entry>
<entry align="left" valign="top">Required plugin</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><link linkend="modules-scripting-painless"><literal>painless</literal></link></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>built-in</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><link linkend="modules-scripting-groovy"><literal>groovy</literal></link></simpara></entry>
<entry align="left" valign="top"><simpara><link linkend="modules-scripting-security">no</link></simpara></entry>
<entry align="left" valign="top"><simpara>built-in</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/lang-javascript.html"><literal>javascript</literal></ulink></simpara></entry>
<entry align="left" valign="top"><simpara><link linkend="modules-scripting-security">no</link></simpara></entry>
<entry align="left" valign="top"><simpara><ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/lang-javascript.html"><literal>lang-javascript</literal></ulink></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/lang-python.html"><literal>python</literal></ulink></simpara></entry>
<entry align="left" valign="top"><simpara><link linkend="modules-scripting-security">no</link></simpara></entry>
<entry align="left" valign="top"><simpara><ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/lang-python.html"><literal>lang-python</literal></ulink></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<bridgehead id="_special_purpose_languages" renderas="sect2">Special-purpose languages:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting.asciidoc">Edit me</ulink></bridgehead>
<simpara>These languages are less flexible, but typically have higher performance for
certain tasks.</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top">Language
    </entry>
<entry align="left" valign="top">Sandboxed
    </entry>
<entry align="left" valign="top">Required plugin
    </entry>
<entry align="left" valign="top">Purpose</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><link linkend="modules-scripting-expression"><literal>expression</literal></link></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>built-in</simpara></entry>
<entry align="left" valign="top"><simpara>fast custom ranking and sorting</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><link linkend="search-template"><literal>mustache</literal></link></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>built-in</simpara></entry>
<entry align="left" valign="top"><simpara>templates</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><link linkend="modules-scripting-native"><literal>java</literal></link></simpara></entry>
<entry align="left" valign="top"><simpara>n/a</simpara></entry>
<entry align="left" valign="top"><simpara>you write it!</simpara></entry>
<entry align="left" valign="top"><simpara>expert API</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<warning>
<title>Scripts and security</title>
<simpara>Languages that are sandboxed are designed with security in mind. However, non-
sandboxed languages can be a security issue, please read
<link linkend="modules-scripting-security">Scripting and security</link> for more details.</simpara>
</warning>
<section id="modules-scripting-using">
<title>How to use scripts<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/using.asciidoc">Edit me</ulink></title>
<simpara>Wherever scripting is supported in the Elasticsearch API, the syntax follows
the same pattern:</simpara>
<programlisting language="js" linenumbering="unnumbered">  "script": {
    "lang":   "...",  <co id="CO282-1"/>
    "inline" | "stored" | "file": "...", <co id="CO282-2"/>
    "params": { ... } <co id="CO282-3"/>
  }</programlisting>
<calloutlist>
<callout arearefs="CO282-1">
<para>
The language the script is written in, which defaults to <literal>painless</literal>.
</para>
</callout>
<callout arearefs="CO282-2">
<para>
The script itself which may be specified as <literal>inline</literal>, <literal>stored</literal>, or <literal>file</literal>.
</para>
</callout>
<callout arearefs="CO282-3">
<para>
Any named parameters that should be passed into the script.
</para>
</callout>
</calloutlist>
<simpara>For example, the following script is used in a search request to return a
<link linkend="search-request-script-fields">scripted field</link>:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index/my_type/1
{
  "my_field": 5
}

GET my_index/_search
{
  "script_fields": {
    "my_doubled_field": {
      "script": {
        "lang":   "expression",
        "inline": "doc['my_field'] * multiplier",
        "params": {
          "multiplier": 2
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_script_parameters" renderas="sect2">Script Parameters<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/using.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
<literal>lang</literal>
</term>
<listitem>
<simpara>
    Specifies the language the script is written in.  Defaults to <literal>groovy</literal> but
    may be set to any of languages listed in <xref linkend="modules-scripting"/>. The
    default language may be changed in the <literal>elasticsearch.yml</literal> config file by
    setting <literal>script.default_lang</literal> to the appropriate language.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>inline</literal>, <literal>id</literal>, <literal>file</literal>
</term>
<listitem>
<simpara>
    Specifies the source of the script.  An <literal>inline</literal> script is specified
    <literal>inline</literal> as in the example above, a stored script with the specified <literal>id</literal>
    is retrieved from the cluster state (see <link linkend="modules-scripting-stored-scripts">Stored Scripts</link>),
    and a <literal>file</literal> script is retrieved from a file in the <literal>config/scripts</literal>
    directory (see <link linkend="modules-scripting-file-scripts">File Scripts</link>).
</simpara>
<simpara>While languages like <literal>expression</literal> and <literal>painless</literal> can be used out of the box as
inline or stored scripts, other languages like <literal>groovy</literal> can only be
specified as <literal>file</literal> unless you first adjust the default
<link linkend="modules-scripting-security">scripting security settings</link>.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>params</literal>
</term>
<listitem>
<simpara>
    Specifies any named parameters that are passed into the script as
    variables.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<important id="prefer-params">
<title>Prefer parameters</title>
<simpara>The first time Elasticsearch sees a new script, it compiles it and stores the
compiled version in a cache. Compilation can be a heavy process.</simpara>
<simpara>If you need to pass variables into the script, you should pass them in as
named <literal>params</literal> instead of hard-coding values into the script itself.  For
example, if you want to be able to multiply a field value by different
multipliers, don&#8217;t hard-code the multiplier into the script:</simpara>
<programlisting language="js" linenumbering="unnumbered">  "inline": "doc['my_field'] * 2"</programlisting>
<simpara>Instead, pass it in as a named parameter:</simpara>
<programlisting language="js" linenumbering="unnumbered">  "inline": "doc['my_field'] * multiplier",
  "params": {
    "multiplier": 2
  }</programlisting>
<simpara>The first version has to be recompiled every time the multiplier changes.  The
second version is only compiled once.</simpara>
<simpara>If you compile too many unique scripts within a small amount of time,
Elasticsearch will reject the new dynamic scripts with a
<literal>circuit_breaking_exception</literal> error. By default, up to 15 inline scripts per
minute will be compiled. You can change this setting dynamically by setting
<literal>script.max_compilations_per_minute</literal>.</simpara>
</important>
<bridgehead id="modules-scripting-file-scripts" renderas="sect2">File-based Scripts<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/using.asciidoc">Edit me</ulink></bridgehead>
<simpara>To increase security, non-sandboxed languages can only be specified in script
files stored on every node in the cluster.  File scripts must be saved in the
<literal>scripts</literal> directory whose default location depends on whether you use  the
<link linkend="zip-targz-layout"><literal>zip</literal>/<literal>tar.gz</literal></link> (<literal>$ES_HOME/config/scripts/</literal>),
<link linkend="rpm-layout">RPM</link>, or <link linkend="deb-layout">Debian</link> package.  The default may be
changed with the <literal>path.scripts</literal> setting.</simpara>
<simpara>The languages which are assumed to be safe by default are: <literal>painless</literal>,
<literal>expression</literal>, and <literal>mustache</literal> (used for search and query templates).</simpara>
<simpara>Any files placed in the <literal>scripts</literal> directory will be compiled automatically
when the node starts up and then <link linkend="reload-scripts">every 60 seconds thereafter</link>.</simpara>
<simpara>The file should be named as follows: <literal>{script-name}.{lang}</literal>.  For instance,
the following example creates a Groovy script called <literal>calculate-score</literal>:</simpara>
<programlisting language="sh" linenumbering="unnumbered">cat "log(_score * 2) + my_modifier" &gt; config/scripts/calculate-score.groovy</programlisting>
<simpara>This script can be used as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET my_index/_search
{
  "query": {
    "script": {
      "script": {
        "lang":   "groovy", <co id="CO283-1"/>
        "file":   "calculate-score", <co id="CO283-2"/>
        "params": {
          "my_modifier": 2
        }
      }
    }
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO283-1">
<para>
The language of the script, which should correspond with the script file suffix.
</para>
</callout>
<callout arearefs="CO283-2">
<para>
The name of the script, which should be the name of the file.
</para>
</callout>
</calloutlist>
<simpara>The <literal>script</literal> directory may contain sub-directories, in which case the
hierarchy of directories is flattened and concatenated with underscores.  A
script in <literal>group1/group2/my_script.groovy</literal> should use <literal>group1_group2_myscript</literal>
as the <literal>file</literal> name.</simpara>
<bridgehead id="reload-scripts" renderas="sect3">Automatic script reloading<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/using.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>scripts</literal> directory will be rescanned every <literal>60s</literal> (configurable with the
<literal>resource.reload.interval</literal> setting) and new, changed, or removed scripts will
be compiled, updated, or deleted from the script cache.</simpara>
<simpara>Script reloading can be completely disabled by setting
<literal>script.auto_reload_enabled</literal> to <literal>false</literal>.</simpara>
<bridgehead id="modules-scripting-stored-scripts" renderas="sect2">Stored Scripts<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/using.asciidoc">Edit me</ulink></bridgehead>
<simpara>Scripts may be stored in and retrieved from the cluster state using the
<literal>_scripts</literal> end-point:</simpara>
<programlisting language="js" linenumbering="unnumbered">/_scripts/{lang}/{id} <co id="CO284-1"/> <co id="CO284-2"/></programlisting>
<calloutlist>
<callout arearefs="CO284-1">
<para>
The <literal>lang</literal> represents the script language.
</para>
</callout>
<callout arearefs="CO284-2">
<para>
The <literal>id</literal> is a unique identifier or script name.
</para>
</callout>
</calloutlist>
<simpara>This example stores a Groovy script called <literal>calculate-score</literal> in the cluster
state:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _scripts/groovy/calculate-score
{
  "script": "log(_score * 2) + my_modifier"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>This same script can be retrieved with:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _scripts/groovy/calculate-score</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Stored scripts can be used by specifying the <literal>lang</literal> and <literal>stored</literal> parameters as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _search
{
  "query": {
    "script": {
      "script": {
        "lang": "groovy",
        "stored":   "calculate-score",
        "params": {
          "my_modifier": 2
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>And deleted with:</simpara>
<programlisting language="js" linenumbering="unnumbered">DELETE _scripts/groovy/calculate-score</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<bridgehead id="modules-scripting-using-caching" renderas="sect2">Script Caching<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/using.asciidoc">Edit me</ulink></bridgehead>
<simpara>All scripts are cached by default so that they only need to be recompiled
when updates occur. File scripts keep a static cache and will always reside
in memory. Both inline and stored scripts are stored in a cache that can evict
residing scripts. By default, scripts do not have a time-based expiration, but
you can change this behavior by using the <literal>script.cache.expire</literal> setting.
You can configure the size of this cache by using the <literal>script.cache.max_size</literal> setting.
By default, the cache size is <literal>100</literal>.</simpara>
<note><simpara>The size of stored scripts is limited to 65,535 bytes. This can be
changed by setting <literal>script.max_size_in_bytes</literal> setting to increase that soft
limit, but if scripts are really large then alternatives like
<link linkend="modules-scripting-native">native</link> scripts should be considered instead.</simpara></note>
</section>
<section id="modules-scripting-fields">
<title>Accessing document fields and special variables<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/fields.asciidoc">Edit me</ulink></title>
<simpara>Depending on where a script is used, it will have access to certain special
variables and document fields.</simpara>
<bridgehead id="_update_scripts" renderas="sect1">Update scripts<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/fields.asciidoc">Edit me</ulink></bridgehead>
<simpara>A script used in the <link linkend="docs-update">update</link>,
<link linkend="docs-update-by-query">update-by-query</link>, or <link linkend="docs-reindex">reindex</link>
API will have access to the <literal>ctx</literal> variable which exposes:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>ctx._source</literal>
</simpara>
</entry>
<entry>
<simpara>
Access to the document <link linkend="mapping-source-field"><literal>_source</literal> field</link>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>ctx.op</literal>
</simpara>
</entry>
<entry>
<simpara>
The operation that should be applied to the document: <literal>index</literal> or <literal>delete</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>ctx._index</literal> etc
</simpara>
</entry>
<entry>
<simpara>
Access to <link linkend="mapping-fields">document meta-fields</link>, some of which may be read-only.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="_search_and_aggregation_scripts" renderas="sect1">Search and Aggregation scripts<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/fields.asciidoc">Edit me</ulink></bridgehead>
<simpara>With the exception of <link linkend="search-request-script-fields">script fields</link> which are
executed once per search hit, scripts used in search and aggregations will be
executed once for every document which might match a query or an aggregation.
Depending on how many documents you have, this could mean millions or billions
of executions: these scripts need to be fast!</simpara>
<simpara>Field values can be accessed from a script using
<link linkend="modules-scripting-doc-vals">doc-values</link>, or
<link linkend="modules-scripting-stored">stored fields or <literal>_source</literal> field</link>, which are explained below.</simpara>
<simpara>Scripts may also have access to the document&#8217;s relevance
<link linkend="scripting-score"><literal>_score</literal></link> and, via the experimental <literal>_index</literal> variable,
to term statistics for <link linkend="modules-advanced-scripting">advanced text scoring</link>.</simpara>
<bridgehead id="scripting-score" renderas="sect2">Accessing the score of a document within a script<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/fields.asciidoc">Edit me</ulink></bridgehead>
<simpara>Scripts used in the <link linkend="query-dsl-function-score-query"><literal>function_score</literal> query</link>,
in <link linkend="search-request-sort">script-based sorting</link>, or in
<link linkend="search-aggregations">aggregations</link> have access to the <literal>_score</literal> variable which
represents the current relevance score of a document.</simpara>
<simpara>Here&#8217;s an example of using a script in a
<link linkend="query-dsl-function-score-query"><literal>function_score</literal> query</link> to alter the
relevance <literal>_score</literal> of each document:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index/my_type/1
{
  "text": "quick brown fox",
  "popularity": 1
}

PUT my_index/my_type/2
{
  "text": "quick fox",
  "popularity": 5
}

GET my_index/_search
{
  "query": {
    "function_score": {
      "query": {
        "match": {
          "text": "quick brown fox"
        }
      },
      "script_score": {
        "script": {
          "lang": "expression",
          "inline": "_score * doc['popularity']"
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="modules-scripting-doc-vals" renderas="sect2">Doc Values<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/fields.asciidoc">Edit me</ulink></bridgehead>
<simpara>By far the fastest most efficient way to access a field value from a
script is to use the <literal>doc['field_name']</literal> syntax, which retrieves the field
value from <link linkend="doc-values">doc values</link>. Doc values are a columnar field value
store, enabled by default on all fields except for <link linkend="text">analyzed <literal>text</literal> fields</link>.</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index/my_type/1
{
  "cost_price": 100
}

GET my_index/_search
{
  "script_fields": {
    "sales_price": {
      "script": {
        "lang":   "expression",
        "inline": "doc['cost_price'] * markup",
        "params": {
          "markup": 0.2
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Doc-values can only return "simple" field values like numbers, dates, geo-
points, terms, etc, or arrays of these values if the field is multi-valued.
It cannot return JSON objects.</simpara>
<note>
<title>Doc values and <literal>text</literal> fields</title>
<simpara>The <literal>doc['field']</literal> syntax can also be used for <link linkend="text">analyzed <literal>text</literal> fields</link>
if <link linkend="fielddata"><literal>fielddata</literal></link> is enabled, but <emphasis role="strong">BEWARE</emphasis>: enabling fielddata on a
<literal>text</literal> field requires loading all of the terms into the JVM heap, which can be
very expensive both in terms of memory and CPU.  It seldom makes sense to
access <literal>text</literal> fields from scripts.</simpara>
</note>
<bridgehead id="modules-scripting-stored" renderas="sect2">Stored Fields and <literal>_source</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/fields.asciidoc">Edit me</ulink></bridgehead>
<simpara><emphasis>Stored fields</emphasis>&#8201;&#8212;&#8201;fields explicitly marked as
<link linkend="mapping-store"><literal>"store": true</literal></link>&#8201;&#8212;&#8201;can be accessed using the
<literal>_fields['field_name'].value</literal> or <literal>_fields['field_name'].values</literal> syntax.</simpara>
<simpara>The document <link linkend="mapping-source-field"><literal>_source</literal></link>, which is really just a
special stored field,  can be accessed using the <literal>_source.field_name</literal> syntax.
The <literal>_source</literal> is loaded as a map-of-maps, so properties within object fields
can be accessed as, for example, <literal>_source.name.first</literal>.</simpara>
<important>
<title>Prefer doc-values to stored fields</title>
<simpara>Stored fields (which includes the stored <literal>_source</literal> field) are much slower than
doc-values.  They are  optimised for returning several fields per result,
while doc values are optimised for accessing the value of a specific field in
many documents.</simpara>
<simpara>It makes sense to use <literal>_source</literal> or stored fields when generating a
<link linkend="search-request-script-fields">script field</link> for the top ten hits from a search
result but, for other search and aggregation use cases, always prefer using
doc values.</simpara>
</important>
<simpara>For instance:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my_index
{
  "mappings": {
    "my_type": {
      "properties": {
        "title": { <co id="CO285-1"/>
          "type": "text"
        },
        "first_name": {
          "type": "text",
          "store": true
        },
        "last_name": {
          "type": "text",
          "store": true
        }
      }
    }
  }
}

PUT my_index/my_type/1
{
  "title": "Mr",
  "first_name": "Barry",
  "last_name": "White"
}

GET my_index/_search
{
  "script_fields": {
    "source": {
      "script": {
        "lang": "groovy",
        "inline": "_source.title + ' ' + _source.first_name + ' ' + _source.last_name" <co id="CO285-2"/>
      }
    },
    "stored_fields": {
      "script": {
        "lang": "groovy",
        "inline": "_fields['first_name'].value + ' ' + _fields['last_name'].value"
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO285-1">
<para>
The <literal>title</literal> field is not stored and so cannot be used with the <literal>_fields[]</literal> syntax.
</para>
</callout>
<callout arearefs="CO285-2">
<para>
The <literal>title</literal> field can still be accessed from the <literal>_source</literal>.
</para>
</callout>
</calloutlist>
<tip>
<title>Stored vs <literal>_source</literal></title>
<simpara>The <literal>_source</literal> field is just a special stored field, so the performance is
similar to that of other stored fields.  The <literal>_source</literal> provides access to the
original document body that was indexed (including the ability to distinguish
<literal>null</literal> values from empty fields, single-value arrays from plain scalars, etc).</simpara>
<simpara>The only time it really makes sense to use stored fields instead of the
<literal>_source</literal> field is when the <literal>_source</literal> is very large and it is less costly to
access a few small stored fields instead of the entire <literal>_source</literal>.</simpara>
</tip>
</section>
<section id="modules-scripting-security">
<title>Scripting and security<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/security.asciidoc">Edit me</ulink></title>
<simpara>You should never run Elasticsearch as the <literal>root</literal> user, as this would allow a
script to access or do <emphasis role="strong">anything</emphasis> on your server, without limitations.</simpara>
<simpara>You should not expose Elasticsearch directly to users, but instead have a
proxy application inbetween. If you <emphasis role="strong">do</emphasis> intend to expose Elasticsearch
directly to your users, then you have to decide whether you trust them enough
to run scripts on your box or not, and apply the appropriate safety measures.</simpara>
<bridgehead id="enable-dynamic-scripting" renderas="sect2">Enabling dynamic scripting<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/security.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>script.*</literal> settings allow for <link linkend="security-script-fine">fine-grained</link>
control of which script languages (e.g <literal>groovy</literal>, <literal>painless</literal>) are allowed to
run in which context ( e.g. <literal>search</literal>, <literal>aggs</literal>, <literal>update</literal>), and where the script
source is allowed to come from (i.e. <literal>inline</literal>, <literal>stored</literal>, <literal>file</literal>).</simpara>
<simpara>For instance, the following setting enables <literal>stored</literal> <literal>update</literal> scripts for
<literal>groovy</literal>:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">script.engine.groovy.inline.update: true</programlisting>
<simpara>Less fine-grained settings exist which allow you to enable or disable scripts
for all sources, all languages, or all contexts.  The following settings
enable <literal>inline</literal> and <literal>stored</literal> scripts for all languages in all contexts:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">script.inline: true
script.stored: true</programlisting>
<warning><simpara>The above settings mean that anybody who can send requests to your
Elasticsearch instance can run whatever scripts they choose! This is a
security risk and may well lead to your Elasticsearch cluster being
compromised.</simpara></warning>
<bridgehead id="security-script-source" renderas="sect2">Script source settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/security.asciidoc">Edit me</ulink></bridgehead>
<simpara>Scripts may be enabled or disabled depending on their source: <literal>inline</literal>,
<literal>stored</literal> in the cluster state, or from a <literal>file</literal> on each node in the cluster.
Each of these settings takes one of these values:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>false</literal>
</simpara>
</entry>
<entry>
<simpara>
Scripting is enabled.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>true</literal>
</simpara>
</entry>
<entry>
<simpara>
Scripting is disabled.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>The default values are the following:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">script.inline: false
script.stored: false
script.file:   true</programlisting>
<note><simpara>Global scripting settings affect the <literal>mustache</literal> scripting language.
<link linkend="search-template">Search templates</link> internally use the <literal>mustache</literal> language,
and will still be enabled by default as the <literal>mustache</literal> engine is sandboxed,
but they will be enabled/disabled according to fine-grained settings
specified in <literal>elasticsearch.yml</literal>.</simpara></note>
<bridgehead id="security-script-context" renderas="sect2">Script context settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/security.asciidoc">Edit me</ulink></bridgehead>
<simpara>Scripting may also be enabled or disabled in different contexts in the
Elasticsearch API. The supported contexts are:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>aggs</literal>
</simpara>
</entry>
<entry>
<simpara>
Aggregations
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>search</literal>
</simpara>
</entry>
<entry>
<simpara>
Search api, Percolator API and Suggester API
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>update</literal>
</simpara>
</entry>
<entry>
<simpara>
Update api
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>plugin</literal>
</simpara>
</entry>
<entry>
<simpara>
Any plugin that makes use of scripts under the generic <literal>plugin</literal> category
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>Plugins can also define custom operations that they use scripts for instead
of using the generic <literal>plugin</literal> category. Those operations can be referred to
in the following form: <literal>${pluginName}_${operation}</literal>.</simpara>
<simpara>The following example disables scripting for <literal>update</literal> and <literal>plugin</literal> operations,
regardless of the script source or language. Scripts can still be executed
from sandboxed languages as part of <literal>aggregations</literal>, <literal>search</literal> and plugins
execution though, as the above defaults still get applied.</simpara>
<programlisting language="yaml" linenumbering="unnumbered">script.update: false
script.plugin: false</programlisting>
<bridgehead id="security-script-fine" renderas="sect2">Fine-grained script settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/security.asciidoc">Edit me</ulink></bridgehead>
<simpara>First, the high-level script settings described above are applied in order
(context settings have precedence over source settings).  Then,  fine-grained
settings which include the script language take precedence over any high-level
settings.</simpara>
<simpara>Fine-grained settings have the form:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">script.engine.{lang}.{source}.{context}: true|false</programlisting>
<simpara>And</simpara>
<programlisting language="yaml" linenumbering="unnumbered">script.engine.{lang}.{inline|file|stored}: true|false</programlisting>
<simpara>For example:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">script.inline: false <co id="CO286-1"/>
script.stored: false <co id="CO286-2"/>
script.file:   false <co id="CO286-3"/>

script.engine.groovy.inline:          true <co id="CO286-4"/>
script.engine.groovy.stored.search:   true <co id="CO286-5"/>
script.engine.groovy.stored.aggs:     true <co id="CO286-6"/>

script.engine.mustache.stored.search: true <co id="CO286-7"/></programlisting>
<calloutlist>
<callout arearefs="CO286-1 CO286-2 CO286-3">
<para>
Disable all scripting from any source.
</para>
</callout>
<callout arearefs="CO286-4">
<para>
Allow inline Groovy scripts for all operations
</para>
</callout>
<callout arearefs="CO286-5 CO286-6">
<para>
Allow stored Groovy scripts to be used for search and aggregations.
</para>
</callout>
<callout arearefs="CO286-7">
<para>
Allow stored Mustache templates to be used for search.
</para>
</callout>
</calloutlist>
<bridgehead id="java-security-manager" renderas="sect2">Java Security Manager<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/security.asciidoc">Edit me</ulink></bridgehead>
<simpara>Elasticsearch runs with the <ulink url="https://docs.oracle.com/javase/tutorial/essential/environment/security.html">Java Security Manager</ulink>
enabled by default.  The security policy in Elasticsearch locks down the
permissions granted to each class to the bare minimum required to operate.
The benefit of doing this is that it severely limits the attack vectors
available to a hacker.</simpara>
<simpara>Restricting permissions is particularly important with scripting languages
like Groovy and Javascript which are designed to do anything that can be done
in Java itself, including writing to the file system, opening sockets to
remote servers, etc.</simpara>
<bridgehead id="_script_classloader_whitelist" renderas="sect2">Script Classloader Whitelist<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/security.asciidoc">Edit me</ulink></bridgehead>
<simpara>Scripting languages are only allowed to load classes which appear in a
hardcoded whitelist that can be found in
<ulink url="https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/script/ClassPermission.java"><literal>org.elasticsearch.script.ClassPermission</literal></ulink>.</simpara>
<simpara>In a script, attempting to load a class that does not appear in the whitelist
<emphasis>may</emphasis> result in a <literal>ClassNotFoundException</literal>, for instance this script:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _search
{
  "script_fields": {
    "the_hour": {
      "script": "use(java.math.BigInteger); new BigInteger(1)"
    }
  }
}</programlisting>
<simpara>will return the following exception:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "reason": {
    "type": "script_exception",
    "reason": "failed to run inline script [use(java.math.BigInteger); new BigInteger(1)] using lang [groovy]",
    "caused_by": {
      "type": "no_class_def_found_error",
      "reason": "java/math/BigInteger",
      "caused_by": {
        "type": "class_not_found_exception",
        "reason": "java.math.BigInteger"
      }
    }
  }
}</programlisting>
<simpara>However, classloader issues may also result in more difficult to interpret
exceptions.  For instance, this script:</simpara>
<programlisting language="groovy" linenumbering="unnumbered">use(groovy.time.TimeCategory); new Date(123456789).format('HH')</programlisting>
<simpara>Returns the following exception:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "reason": {
    "type": "script_exception",
    "reason": "failed to run inline script [use(groovy.time.TimeCategory); new Date(123456789).format('HH')] using lang [groovy]",
    "caused_by": {
      "type": "missing_property_exception",
      "reason": "No such property: groovy for class: 8d45f5c1a07a1ab5dda953234863e283a7586240"
    }
  }
}</programlisting>
<bridgehead id="_dealing_with_java_security_manager_issues" renderas="sect1">Dealing with Java Security Manager issues<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/security.asciidoc">Edit me</ulink></bridgehead>
<simpara>If you encounter issues with the Java Security Manager, you have two options
for resolving these issues:</simpara>
<bridgehead id="_fix_the_security_problem" renderas="sect2">Fix the security problem<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/security.asciidoc">Edit me</ulink></bridgehead>
<simpara>The safest and most secure long term solution is to change the code causing
the security issue.  We recognise that this may take time to do correctly and
so we provide the following two alternatives.</simpara>
<bridgehead id="_customising_the_classloader_whitelist" renderas="sect2">Customising the classloader whitelist<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/security.asciidoc">Edit me</ulink></bridgehead>
<simpara>The classloader whitelist can be customised by tweaking the local Java
Security Policy either:</simpara>
<itemizedlist>
<listitem>
<simpara>
system wide: <literal>$JAVA_HOME/lib/security/java.policy</literal>,
</simpara>
</listitem>
<listitem>
<simpara>
for just the <literal>elasticsearch</literal> user: <literal>/home/elasticsearch/.java.policy</literal>
</simpara>
</listitem>
<listitem>
<simpara>
by adding a system property to the <link linkend="jvm-options">jvm.options</link> configuration: <literal>-Djava.security.policy=someURL</literal>, or
</simpara>
</listitem>
<listitem>
<simpara>
via the <literal>ES_JAVA_OPTS</literal> environment variable with <literal>-Djava.security.policy=someURL</literal>:
</simpara>
<programlisting language="js" linenumbering="unnumbered">export ES_JAVA_OPTS="${ES_JAVA_OPTS} -Djava.security.policy=file:///path/to/my.policy`
./bin/elasticsearch</programlisting>
</listitem>
</itemizedlist>
<simpara>Permissions may be granted at the class, package, or global level.  For instance:</simpara>
<programlisting language="js" linenumbering="unnumbered">grant {
    permission org.elasticsearch.script.ClassPermission "java.util.Base64"; // allow class
    permission org.elasticsearch.script.ClassPermission "java.util.*"; // allow package
    permission org.elasticsearch.script.ClassPermission "*"; // allow all (disables filtering basically)
};</programlisting>
<simpara>Here is an example of how to enable the <literal>groovy.time.TimeCategory</literal> class:</simpara>
<programlisting language="js" linenumbering="unnumbered">grant {
    permission org.elasticsearch.script.ClassPermission "java.lang.Class";
    permission org.elasticsearch.script.ClassPermission "groovy.time.TimeCategory";
};</programlisting>
<tip>
<simpara>Before adding classes to the whitelist, consider the security impact that it
will have on Elasticsearch. Do you really need an extra class or can your code
be rewritten in a more secure way?</simpara>
<simpara>It is quite possible that we have not whitelisted a generically useful and
safe class. If you have a class that you think should be whitelisted by
default, please open an issue on GitHub and we will consider the impact of
doing so.</simpara>
</tip>
<simpara>See <ulink url="http://docs.oracle.com/javase/7/docs/technotes/guides/security/PolicyFiles.html">http://docs.oracle.com/javase/7/docs/technotes/guides/security/PolicyFiles.html</ulink> for more information.</simpara>
</section>
<section id="modules-scripting-groovy">
<title>Groovy Scripting Language<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/groovy.asciidoc">Edit me</ulink></title>
<warning revisionflag="deleted" revision="5.0.0"><title>Deprecated in 5.0.0.</title><simpara>Groovy will be replaced by the new scripting language <link linkend="modules-scripting-painless"><literal>Painless</literal></link>.</simpara></warning>
<simpara>Groovy is available in Elasticsearch by default.  Although
limited by the <link linkend="java-security-manager">Java Security Manager</link>, it is not a
sandboxed language and only <literal>file</literal> scripts may be used by default.</simpara>
<simpara>Enabling <literal>inline</literal> or <literal>stored</literal> Groovy scripting is a security risk and should
only be considered if your Elasticsearch cluster is protected from the outside
world. Even a simple <literal>while (true) { }</literal> loop could behave as a denial-of-
service attack on your cluster.</simpara>
<simpara>See <link linkend="modules-scripting-security">Scripting and Security</link> for details
on security issues with scripts, including how to customize class
whitelisting.</simpara>
<bridgehead id="_doc_value_properties_and_methods" renderas="sect2">Doc value properties and methods<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/groovy.asciidoc">Edit me</ulink></bridgehead>
<simpara>Doc values in Groovy support the following properties and methods (depending
on the underlying field type):</simpara>
<variablelist>
<varlistentry>
<term>
<literal>doc['field_name'].value</literal>
</term>
<listitem>
<simpara>
    The native value of the field. For example, if its a short type, it will be short.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>doc['field_name'].values</literal>
</term>
<listitem>
<simpara>
    The native array values of the field. For example, if its a short type,
     it will be short[]. Remember, a field can have several values within a
     single doc. Returns an empty array if the field has no values.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>doc['field_name'].empty</literal>
</term>
<listitem>
<simpara>
    A boolean indicating if the field has no values within the doc.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>doc['field_name'].lat</literal>
</term>
<listitem>
<simpara>
    The latitude of a geo point type, or <literal>null</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>doc['field_name'].lon</literal>
</term>
<listitem>
<simpara>
    The longitude of a geo point type, or <literal>null</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>doc['field_name'].lats</literal>
</term>
<listitem>
<simpara>
    The latitudes of a geo point type, or an empty array.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>doc['field_name'].lons</literal>
</term>
<listitem>
<simpara>
    The longitudes of a geo point type, or an empty array.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>doc['field_name'].arcDistance(lat, lon)</literal>
</term>
<listitem>
<simpara>
    The <literal>arc</literal> distance (in meters) of this geo point field from the provided lat/lon.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>doc['field_name'].arcDistanceWithDefault(lat, lon, default)</literal>
</term>
<listitem>
<simpara>
    The <literal>arc</literal> distance (in meters) of this geo point field from the provided lat/lon with a default value
    for empty fields.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>doc['field_name'].planeDistance(lat, lon)</literal>
</term>
<listitem>
<simpara>
    The <literal>plane</literal> distance (in meters) of this geo point field from the provided lat/lon.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>doc['field_name'].planeDistanceWithDefault(lat, lon, default)</literal>
</term>
<listitem>
<simpara>
    The <literal>plane</literal> distance (in meters) of this geo point field from the provided lat/lon with a default value
    for empty fields.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>doc['field_name'].geohashDistance(geohash)</literal>
</term>
<listitem>
<simpara>
    The <literal>arc</literal> distance (in meters) of this geo point field from the provided geohash.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>doc['field_name'].geohashDistanceWithDefault(geohash, default)</literal>
</term>
<listitem>
<simpara>
    The <literal>arc</literal> distance (in meters) of this geo point field from the provided geohash with a default value
    for empty fields.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_groovy_built_in_functions" renderas="sect2">Groovy Built In Functions<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/groovy.asciidoc">Edit me</ulink></bridgehead>
<simpara>There are several built in functions that can be used within scripts.
They include:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Function </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>sin(a)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns the trigonometric sine of an angle.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>cos(a)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns the trigonometric cosine of an angle.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>tan(a)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns the trigonometric tangent of an angle.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>asin(a)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns the arc sine of a value.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>acos(a)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns the arc cosine of a value.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>atan(a)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns the arc tangent of a value.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>toRadians(angdeg)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Converts an angle measured in degrees to an
approximately equivalent angle measured in radians</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>toDegrees(angrad)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Converts an angle measured in radians to an
approximately equivalent angle measured in degrees.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>exp(a)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns Euler&#8217;s number <emphasis>e</emphasis> raised to the power of value.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>log(a)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns the natural logarithm (base <emphasis>e</emphasis>) of a value.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>log10(a)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns the base 10 logarithm of a value.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>sqrt(a)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns the correctly rounded positive square root of a
value.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>cbrt(a)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns the cube root of a double value.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>IEEEremainder(f1, f2)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Computes the remainder operation on two
arguments as prescribed by the IEEE 754 standard.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ceil(a)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns the smallest (closest to negative infinity) value
that is greater than or equal to the argument and is equal to a
mathematical integer.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>floor(a)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns the largest (closest to positive infinity) value
that is less than or equal to the argument and is equal to a
mathematical integer.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>rint(a)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns the value that is closest in value to the argument
and is equal to a mathematical integer.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>atan2(y, x)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns the angle <emphasis>theta</emphasis> from the conversion of
rectangular coordinates (<emphasis>x</emphasis>, <emphasis>y</emphasis>) to polar coordinates (r,<emphasis>theta</emphasis>).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>pow(a, b)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns the value of the first argument raised to the
power of the second argument.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>round(a)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns the closest <emphasis>int</emphasis> to the argument.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>random()</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns a random <emphasis>double</emphasis> value.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>abs(a)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns the absolute value of a value.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>max(a, b)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns the greater of two values.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>min(a, b)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns the smaller of two values.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ulp(d)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns the size of an ulp of the argument.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>signum(d)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns the signum function of the argument.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>sinh(x)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns the hyperbolic sine of a value.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>cosh(x)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns the hyperbolic cosine of a value.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>tanh(x)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns the hyperbolic tangent of a value.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>hypot(x, y)</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Returns sqrt(<emphasis>x2</emphasis> + <emphasis>y2</emphasis>) without intermediate overflow
or underflow.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
</section>
<section id="modules-scripting-painless">
<title>Painless Scripting Language<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/painless.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>The Painless scripting language is new and is still marked as experimental. The syntax or API may be changed in the future in non-backwards compatible ways if required..</simpara></warning>
<simpara><emphasis>Painless</emphasis> is a simple, secure scripting language available in Elasticsearch
by default. It is designed specifically for use with Elasticsearch and can
safely be used with <literal>inline</literal> and <literal>stored</literal> scripting, which is enabled by
default.</simpara>
<simpara>The Painless syntax is similar to <ulink url="http://groovy-lang.org/index.html">Groovy</ulink>.</simpara>
<simpara>You can use Painless anywhere a script can be used in Elasticsearch&#8212;simply set the <literal>lang</literal> parameter
to <literal>painless</literal>.</simpara>
<bridgehead id="painless-features" renderas="sect1">Painless Features<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/painless.asciidoc">Edit me</ulink></bridgehead>
<itemizedlist>
<listitem>
<simpara>
Fast performance: <ulink url="https://benchmarks.elastic.co/index.html#search_qps_scripts">several times faster</ulink> than the alternatives.
</simpara>
</listitem>
<listitem>
<simpara>
Safety: Fine-grained <link linkend="painless-api">whitelist</link> with method call/field granularity.
</simpara>
</listitem>
<listitem>
<simpara>
Optional typing: Variables and parameters can use explicit types or the dynamic <literal>def</literal> type.
</simpara>
</listitem>
<listitem>
<simpara>
Syntax: Extends Java&#8217;s syntax with a subset of Groovy for ease of use. See the <link linkend="modules-scripting-painless-syntax">Syntax Overview</link>.
</simpara>
</listitem>
<listitem>
<simpara>
Optimizations: Designed specifically for Elasticsearch scripting.
</simpara>
</listitem>
</itemizedlist>
<bridgehead id="painless-examples" renderas="sect1">Painless Examples<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/painless.asciidoc">Edit me</ulink></bridgehead>
<simpara>To illustrate how Painless works, let&#8217;s load some hockey stats into an Elasticsearch index:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT hockey/player/_bulk?refresh
{"index":{"_id":1}}
{"first":"johnny","last":"gaudreau","goals":[9,27,1],"assists":[17,46,0],"gp":[26,82,1]}
{"index":{"_id":2}}
{"first":"sean","last":"monohan","goals":[7,54,26],"assists":[11,26,13],"gp":[26,82,82]}
{"index":{"_id":3}}
{"first":"jiri","last":"hudler","goals":[5,34,36],"assists":[11,62,42],"gp":[24,80,79]}
{"index":{"_id":4}}
{"first":"micheal","last":"frolik","goals":[4,6,15],"assists":[8,23,15],"gp":[26,82,82]}
{"index":{"_id":5}}
{"first":"sam","last":"bennett","goals":[5,0,0],"assists":[8,1,0],"gp":[26,1,0]}
{"index":{"_id":6}}
{"first":"dennis","last":"wideman","goals":[0,26,15],"assists":[11,30,24],"gp":[26,81,82]}
{"index":{"_id":7}}
{"first":"david","last":"jones","goals":[7,19,5],"assists":[3,17,4],"gp":[26,45,34]}
{"index":{"_id":8}}
{"first":"tj","last":"brodie","goals":[2,14,7],"assists":[8,42,30],"gp":[26,82,82]}
{"index":{"_id":39}}
{"first":"mark","last":"giordano","goals":[6,30,15],"assists":[3,30,24],"gp":[26,60,63]}
{"index":{"_id":10}}
{"first":"mikael","last":"backlund","goals":[3,15,13],"assists":[6,24,18],"gp":[26,82,82]}
{"index":{"_id":11}}
{"first":"joe","last":"colborne","goals":[3,18,13],"assists":[6,20,24],"gp":[26,67,82]}</programlisting>
<remark> CONSOLE</remark>
<remark> TESTSETUP</remark>
<bridgehead id="_accessing_doc_values_from_painless" renderas="sect2">Accessing Doc Values from Painless<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/painless.asciidoc">Edit me</ulink></bridgehead>
<simpara>Document values can be accessed from a <literal>Map</literal> named <literal>doc</literal>.</simpara>
<simpara>For example, the following script calculates a player&#8217;s total goals. This example uses a strongly typed <literal>int</literal> and a <literal>for</literal> loop.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET hockey/_search
{
  "query": {
    "function_score": {
      "script_score": {
        "script": {
          "lang": "painless",
          "inline": "int total = 0; for (int i = 0; i &lt; doc['goals'].length; ++i) { total += doc['goals'][i]; } return total;"
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Alternatively, you could do the same thing using a script field instead of a function score:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET hockey/_search
{
  "query": {
    "match_all": {}
  },
  "script_fields": {
    "total_goals": {
      "script": {
        "lang": "painless",
        "inline": "int total = 0; for (int i = 0; i &lt; doc['goals'].length; ++i) { total += doc['goals'][i]; } return total;"
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The following example uses a Painless script to sort the players by their combined first and last names. The names are accessed using
<literal>doc['first'].value</literal> and <literal>doc['last'].value</literal>.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET hockey/_search
{
  "query": {
    "match_all": {}
  },
  "sort": {
    "_script": {
      "type": "string",
      "order": "asc",
      "script": {
        "lang": "painless",
        "inline": "doc['first.keyword'].value + ' ' + doc['last.keyword'].value"
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_updating_fields_with_painless" renderas="sect2">Updating Fields with Painless<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/painless.asciidoc">Edit me</ulink></bridgehead>
<simpara>You can also easily update fields. You access the original source for a field as <literal>ctx._source.&lt;field-name&gt;</literal>.</simpara>
<simpara>First, let&#8217;s look at the source data for a player by submitting the following request:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET hockey/_search
{
  "stored_fields": [
    "_id",
    "_source"
  ],
  "query": {
    "term": {
      "_id": 1
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>To change player 1&#8217;s last name to <literal>hockey</literal>, simply set <literal>ctx._source.last</literal> to the new value:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST hockey/player/1/_update
{
  "script": {
    "lang": "painless",
    "inline": "ctx._source.last = params.last",
    "params": {
      "last": "hockey"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>You can also add fields to a document. For example, this script adds a new field that contains
the player&#8217;s nickname,  <emphasis>hockey</emphasis>.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST hockey/player/1/_update
{
  "script": {
    "lang": "painless",
    "inline": "ctx._source.last = params.last; ctx._source.nick = params.nick",
    "params": {
      "last": "gaudreau",
      "nick": "hockey"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="modules-scripting-painless-regex" renderas="sect2">Regular expressions<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/painless.asciidoc">Edit me</ulink></bridgehead>
<note><simpara>Regexes are disabled by default because they circumvent Painless&#8217;s
protection against long running and memory hungry scripts. To make matters
worse even innocuous looking regexes can have staggering performance and stack
depth behavior. They remain an amazing powerful tool but are too scary to enable
by default. To enable them yourself set <literal>script.painless.regex.enabled: true</literal> in
<literal>elasticsearch.yml</literal>. We&#8217;d like very much to have a safe alternative
implementation that can be enabled by default so check this space for later
developments!</simpara></note>
<simpara>Painless&#8217;s native support for regular expressions has syntax constructs:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>/pattern/</literal>: Pattern literals create patterns. This is the only way to create
a pattern in painless. The pattern inside the `/`s are just
<ulink url="http://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html">Java regular expressions</ulink>.
See <xref linkend="modules-scripting-painless-regex-flags"/> for more.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>=~</literal>: The find operator return a <literal>boolean</literal>, <literal>true</literal> if a subsequence of the
text matches, <literal>false</literal> otherwise.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>==~</literal>: The match operator returns a <literal>boolean</literal>, <literal>true</literal> if the text matches,
<literal>false</literal> if it doesn&#8217;t.
</simpara>
</listitem>
</itemizedlist>
<simpara>Using the find operator (<literal>=~</literal>) you can update all hockey players with "b" in
their last name:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST hockey/player/_update_by_query
{
  "script": {
    "lang": "painless",
    "inline": "if (ctx._source.last =~ /b/) {ctx._source.last += \"matched\"} else {ctx.op = 'noop'}"
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Using the match operator (<literal>==~</literal>) you can update all the hockey players who&#8217;s
names start with a consonant and end with a vowel:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST hockey/player/_update_by_query
{
  "script": {
    "lang": "painless",
    "inline": "if (ctx._source.last ==~ /[^aeiou].*[aeiou]/) {ctx._source.last += \"matched\"} else {ctx.op = 'noop'}"
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>You can use the <literal>Pattern.matcher</literal> directly to get a <literal>Matcher</literal> instance and
remove all of the vowels in all of their last names:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST hockey/player/_update_by_query
{
  "script": {
    "lang": "painless",
    "inline": "ctx._source.last = /[aeiou]/.matcher(ctx._source.last).replaceAll('')"
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara><literal>Matcher.replaceAll</literal> is just a call to Java&#8217;s <literal>Matcher</literal>'s
<ulink url="http://docs.oracle.com/javase/8/docs/api/java/util/regex/Matcher.html#replaceAll-java.lang.String-">replaceAll</ulink>
method so it supports <literal>$1</literal> and <literal>\1</literal> for replacements:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST hockey/player/_update_by_query
{
  "script": {
    "lang": "painless",
    "inline": "ctx._source.last = /n([aeiou])/.matcher(ctx._source.last).replaceAll('$1')"
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>If you need more control over replacements you can call <literal>replaceAll</literal> on a
<literal>CharSequence</literal> with a <literal>Function&lt;Matcher, String&gt;</literal> that builds the replacement.
This does not support <literal>$1</literal> or <literal>\1</literal> to access replacements because you already
have a reference to the matcher and can get them with <literal>m.group(1)</literal>.</simpara>
<important><simpara>Calling <literal>Matcher.find</literal> inside of the function that builds the
replacement is rude and will likely break the replacement process.</simpara></important>
<simpara>This will make all of the vowels in the hockey player&#8217;s last names upper case:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST hockey/player/_update_by_query
{
  "script": {
    "lang": "painless",
    "inline": "ctx._source.last = ctx._source.last.replaceAll(/[aeiou]/, m -&gt; m.group().toUpperCase(Locale.ROOT))"
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Or you can use the <literal>CharSequence.replaceFirst</literal> to make the first vowel in their
last names upper case:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST hockey/player/_update_by_query
{
  "script": {
    "lang": "painless",
    "inline": "ctx._source.last = ctx._source.last.replaceFirst(/[aeiou]/, m -&gt; m.group().toUpperCase(Locale.ROOT))"
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Note: all of the <literal>_update_by_query</literal> examples above could really do with a
<literal>query</literal> to limit the data that they pull back. While you <emphasis role="strong">could</emphasis> use a
<xref linkend="query-dsl-script-query"/> it wouldn&#8217;t be as efficient as using any other query
because script queries aren&#8217;t able to use the inverted index to limit the
documents that they have to check.</simpara>
<bridgehead id="painless-api" renderas="sect1">Painless API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/painless.asciidoc">Edit me</ulink></bridgehead>
<simpara>The following Java packages are available for use in the Painless language:</simpara>
<itemizedlist>
<listitem>
<simpara>
<ulink url="https://docs.oracle.com/javase/8/docs/api/java/lang/package-summary.html">java.lang</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
<ulink url="https://docs.oracle.com/javase/8/docs/api/java/math/package-summary.html">java.math</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
<ulink url="https://docs.oracle.com/javase/8/docs/api/java/text/package-summary.html">java.text</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
<ulink url="https://docs.oracle.com/javase/8/docs/api/java/time/package-summary.html">java.time</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
<ulink url="https://docs.oracle.com/javase/8/docs/api/java/time/chrono/package-summary.html">java.time.chrono</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
<ulink url="https://docs.oracle.com/javase/8/docs/api/java/time/format/package-summary.html">java.time.format</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
<ulink url="https://docs.oracle.com/javase/8/docs/api/java/time/temporal/package-summary.html">java.time.temporal</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
<ulink url="https://docs.oracle.com/javase/8/docs/api/java/time/zone/package-summary.html">java.time.zone</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
<ulink url="https://docs.oracle.com/javase/8/docs/api/java/util/package-summary.html">java.util</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
<ulink url="https://docs.oracle.com/javase/8/docs/api/java/util/function/package-summary.html">java.util.function</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
<ulink url="https://docs.oracle.com/javase/8/docs/api/java/util/regex/package-summary.html">java.util.regex</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
<ulink url="https://docs.oracle.com/javase/8/docs/api/java/util/stream/package-summary.html">java.util.stream</ulink>
</simpara>
</listitem>
</itemizedlist>
<simpara>Note that unsafe classes and methods are not included, there is no support for:</simpara>
<itemizedlist>
<listitem>
<simpara>
Manipulation of processes and threads
</simpara>
</listitem>
<listitem>
<simpara>
Input/Output
</simpara>
</listitem>
<listitem>
<simpara>
Reflection
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="modules-scripting-painless-syntax">
<title>Painless Syntax<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/painless-syntax.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>The Painless scripting language is new and is still marked as experimental. The syntax or API may be changed in the future in non-backwards compatible ways if required..</simpara></warning>
<bridgehead id="painless-types" renderas="sect2">Variable types<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/painless-syntax.asciidoc">Edit me</ulink></bridgehead>
<simpara>Painless supports all of <ulink url="https://docs.oracle.com/javase/tutorial/java/nutsandbolts/variables.html">Java&#8217;s types</ulink>,
including array types, but adds some additional built-in types.</simpara>
<bridgehead id="painless-def" renderas="sect3">Def<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/painless-syntax.asciidoc">Edit me</ulink></bridgehead>
<simpara>The dynamic type <literal>def</literal> serves as a placeholder for any other type. It adopts the behavior
of whatever runtime type it represents.</simpara>
<bridgehead id="painless-strings" renderas="sect3">String<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/painless-syntax.asciidoc">Edit me</ulink></bridgehead>
<simpara>String constants can be declared with single quotes, to avoid escaping horrors with JSON:</simpara>
<programlisting language="painless" linenumbering="unnumbered">def mystring = 'foo';</programlisting>
<bridgehead id="painless-arrays" renderas="sect3">Arrays<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/painless-syntax.asciidoc">Edit me</ulink></bridgehead>
<simpara>Arrays can be subscripted starting from <literal>0</literal> for traditional array access or with
negative numbers to starting from the back of the array. So the following
returns <literal>2</literal>.</simpara>
<programlisting language="painless" linenumbering="unnumbered">int[] x = new int[5];
x[0]++;
x[-5]++;
return x[0];</programlisting>
<bridgehead id="painless-lists" renderas="sect3">List<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/painless-syntax.asciidoc">Edit me</ulink></bridgehead>
<simpara>Lists can be created explicitly (e.g. <literal>new ArrayList()</literal>) or initialized similar to Groovy:</simpara>
<programlisting language="painless" linenumbering="unnumbered">def list = [1,2,3];</programlisting>
<simpara>Lists can also be accessed similar to arrays. They support <literal>.length</literal> and
subscripts, including negative subscripts to read from the back of the list:</simpara>
<programlisting language="painless" linenumbering="unnumbered">def list = [1,2,3];
list[-1] = 5
return list[0]</programlisting>
<bridgehead id="painless-maps" renderas="sect3">Map<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/painless-syntax.asciidoc">Edit me</ulink></bridgehead>
<simpara>Maps can be created explicitly (e.g. <literal>new HashMap()</literal>) or initialized similar to Groovy:</simpara>
<programlisting language="painless" linenumbering="unnumbered">def person = ['name': 'Joe', 'age': 63];</programlisting>
<simpara>Map keys can also be accessed as properties.</simpara>
<programlisting language="painless" linenumbering="unnumbered">def person = ['name': 'Joe', 'age': 63];
person.retired = true;
return person.name</programlisting>
<simpara>Map keys can also be accessed via subscript (for keys containing special characters):</simpara>
<programlisting language="painless" linenumbering="unnumbered">return map['something-absurd!']</programlisting>
<bridgehead id="painless-pattern" renderas="sect3">Pattern<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/painless-syntax.asciidoc">Edit me</ulink></bridgehead>
<simpara>Regular expression constants are directly supported:</simpara>
<programlisting language="painless" linenumbering="unnumbered">Pattern p = /[aeiou]/</programlisting>
<simpara>Patterns can only be created via this mechanism. This ensures fast performance, regular expressions
are always constants and compiled efficiently a single time.</simpara>
<bridgehead id="modules-scripting-painless-regex-flags" renderas="sect3">Pattern flags<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/painless-syntax.asciidoc">Edit me</ulink></bridgehead>
<simpara>You can define flags on patterns in Painless by adding characters after the
trailing <literal>/</literal> like <literal>/foo/i</literal> or <literal>/foo \w #comment/iUx</literal>. Painless exposes all the
flags from
<ulink url="https://docs.oracle.com/javase/8/docs/api/java/util/regex/Pattern.html">Java&#8217;s Pattern class</ulink>
using these characters:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="3">
<colspec colname="col_1" colwidth="33*"/>
<colspec colname="col_2" colwidth="33*"/>
<colspec colname="col_3" colwidth="33*"/>
<thead>
<row>
<entry align="left" valign="top"> Character </entry>
<entry align="left" valign="top"> Java Constant </entry>
<entry align="left" valign="top"> Example</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>c</literal></simpara></entry>
<entry align="left" valign="top"><simpara>CANON_EQ</simpara></entry>
<entry align="left" valign="top"><simpara><literal>'å' ==~ /å/c</literal> (open in hex editor to see)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>i</literal></simpara></entry>
<entry align="left" valign="top"><simpara>CASE_INSENSITIVE</simpara></entry>
<entry align="left" valign="top"><simpara><literal>'A' ==~ /a/i</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>l</literal></simpara></entry>
<entry align="left" valign="top"><simpara>LITERAL</simpara></entry>
<entry align="left" valign="top"><simpara><literal>'[a]' ==~ /[a]/l</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>m</literal></simpara></entry>
<entry align="left" valign="top"><simpara>MULTILINE</simpara></entry>
<entry align="left" valign="top"><simpara><literal>'a\nb\nc' =~ /^b$/m</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>s</literal></simpara></entry>
<entry align="left" valign="top"><simpara>DOTALL (aka single line)</simpara></entry>
<entry align="left" valign="top"><simpara><literal>'a\nb\nc' =~ /.b./s</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>U</literal></simpara></entry>
<entry align="left" valign="top"><simpara>UNICODE_CHARACTER_CLASS</simpara></entry>
<entry align="left" valign="top"><simpara><literal>'Ɛ' ==~ /\\w/U</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>u</literal></simpara></entry>
<entry align="left" valign="top"><simpara>UNICODE_CASE</simpara></entry>
<entry align="left" valign="top"><simpara><literal>'Ɛ' ==~ /ɛ/iu</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>x</literal></simpara></entry>
<entry align="left" valign="top"><simpara>COMMENTS (aka extended)</simpara></entry>
<entry align="left" valign="top"><simpara><literal>'a' ==~ /a #comment/x</literal></simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<bridgehead id="painless-deref" renderas="sect2">Dereferences<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/painless-syntax.asciidoc">Edit me</ulink></bridgehead>
<simpara>Like lots of languages, Painless uses <literal>.</literal> to reference fields and call methods:</simpara>
<programlisting language="painless" linenumbering="unnumbered">String foo = 'foo';
TypeWithGetterOrPublicField bar = new TypeWithGetterOrPublicField()
return foo.length() + bar.x</programlisting>
<simpara>Like Groovy, Painless uses <literal>?.</literal> to perform null-safe references, with the
result being <literal>null</literal> if the left hand side is null:</simpara>
<programlisting language="painless" linenumbering="unnumbered">String foo = null;
return foo?.length()  // Returns null</programlisting>
<simpara>Unlike Groovy, Painless doesn&#8217;t support writing to null values with this
operator:</simpara>
<programlisting language="painless" linenumbering="unnumbered">TypeWithSetterOrPublicField foo = null;
foo?.x = 'bar'  // Compile error</programlisting>
<bridgehead id="painless-operators" renderas="sect2">Operators<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/painless-syntax.asciidoc">Edit me</ulink></bridgehead>
<simpara>All of Java&#8217;s <ulink url="https://docs.oracle.com/javase/tutorial/java/nutsandbolts/operators.html">operators</ulink> are
supported with the same precedence, promotion, and semantics.</simpara>
<simpara>There are only a few minor differences and add-ons:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>==</literal> behaves as Java&#8217;s for numeric types, but for non-numeric types acts as <ulink url="https://docs.oracle.com/javase/8/docs/api/java/lang/Object.html#equals-java.lang.Object-"><literal>Object.equals()</literal></ulink>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>===</literal> and <literal>!==</literal> support exact reference comparison (e.g. <literal>x === y</literal>)
</simpara>
</listitem>
<listitem>
<simpara>
<literal>=~</literal> true if a portion of the text matches a pattern (e.g. <literal>x =~ /b/</literal>)
</simpara>
</listitem>
<listitem>
<simpara>
<literal>==~</literal> true if the entire text matches a pattern (e.g. <literal>x ==~ /[Bb]ob/</literal>)
</simpara>
</listitem>
</itemizedlist>
<simpara>The <literal>?:</literal> (aka Elvis) operator coalesces null values. So <literal>x ?: 0</literal> is <literal>0</literal> if <literal>x</literal>
is <literal>null</literal> and whatever value <literal>x</literal> has otherwise. It is a convenient way to write
default values like <literal>doc['x'].value ?: 0</literal> which is 0 if <literal>x</literal> is not in the
document being processed. It can also work with null safe dereferences to
efficiently handle null in chains. For example,
<literal>doc['foo.keyword'].value?.length() ?: 0</literal> is 0 if the document being processed
doesn&#8217;t have a <literal>foo.keyword</literal> field but is the length of that field if it does.
Lastly, <literal>?:</literal> is lazy so the right hand side is not evaluated at all if the left
hand side isn&#8217;t null.</simpara>
<note><simpara>Unlike Groovy, Painless' &#8216;?:` operator only coalesces <literal>null</literal>, not <literal>false</literal>
or <ulink url="http://groovy-lang.org/semantics.html#Groovy-Truth">falsy</ulink> values. Strictly
speaking Painless&#8217; <literal>?:</literal> is more like Kotlin&#8217;s <literal>?:</literal> than Groovy&#8217;s <literal>?:</literal>.</simpara></note>
<note><simpara>The result of <literal>?.</literal> and <literal>?:</literal> can&#8217;t be assigned to primitives. So
<literal>int[] someArray = null; int l = someArray?.length</literal> and
<literal>int s = params.size ?: 100</literal> don&#8217;t work. Do
<literal>def someArray = null; def l = someArray?.length</literal> and
<literal>def s = params.size ?: 100</literal> instead.</simpara></note>
<bridgehead id="painless-control-flow" renderas="sect2">Control flow<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/painless-syntax.asciidoc">Edit me</ulink></bridgehead>
<simpara>Java&#8217;s <ulink url="https://docs.oracle.com/javase/tutorial/java/nutsandbolts/flow.html">control flow statements</ulink> are supported, with the exception
of the <literal>switch</literal> statement.</simpara>
<simpara>In addition to Java&#8217;s <literal>enhanced for</literal> loop, the <literal>for in</literal> syntax from groovy can also be used:</simpara>
<programlisting language="painless" linenumbering="unnumbered">for (item : list) {
  ...
}</programlisting>
<bridgehead id="painless-functions" renderas="sect2">Functions<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/painless-syntax.asciidoc">Edit me</ulink></bridgehead>
<simpara>Functions can be declared at the beginning of the script, for example:</simpara>
<programlisting language="painless" linenumbering="unnumbered">boolean isNegative(def x) { x &lt; 0 }
...
if (isNegative(someVar)) {
  ...
}</programlisting>
<bridgehead id="painless-lambda-expressions" renderas="sect2">Lambda expressions<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/painless-syntax.asciidoc">Edit me</ulink></bridgehead>
<simpara>Lambda expressions and method references work the same as <ulink url="https://docs.oracle.com/javase/tutorial/java/javaOO/lambdaexpressions.html">Java&#8217;s</ulink>.</simpara>
<programlisting language="painless" linenumbering="unnumbered">list.removeIf(item -&gt; item == 2);
list.removeIf((int item) -&gt; item == 2);
list.removeIf((int item) -&gt; { item == 2 });
list.sort((x, y) -&gt; x - y);
list.sort(Integer::compare);</programlisting>
<simpara>Method references to functions within the script can be accomplished using <literal>this</literal>, e.g. <literal>list.sort(this::mycompare)</literal>.</simpara>
</section>
<section id="modules-scripting-painless-debugging">
<title>Painless Debugging<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/painless-debugging.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>The Painless scripting language is new and is still marked as experimental. The syntax or API may be changed in the future in non-backwards compatible ways if required..</simpara></warning>
<section id="_debug_explain">
<title>Debug.Explain<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/painless-debugging.asciidoc">Edit me</ulink></title>
<simpara>Painless doesn&#8217;t have a
<ulink url="https://en.wikipedia.org/wiki/Read%E2%80%93eval%E2%80%93print_loop">REPL</ulink>
and while it&#8217;d be nice for it to have one one day, it wouldn&#8217;t tell you the
whole story around debugging painless scripts embedded in Elasticsearch because
the data that the scripts have access to or "context" is so important. For now
the best way to debug embedded scripts is by throwing exceptions at choice
places. While you can throw your own exceptions
(<literal>throw new Exception('whatever')</literal>), Painless&#8217;s sandbox prevents you from
accessing useful information like the type of an object. So Painless has a
utility method, <literal>Debug.explain</literal> which throws the exception for you. For
example, you can use the <xref linkend="search-explain"/> to explore the context available to
a <xref linkend="query-dsl-script-query"/>.</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /hockey/player/1?refresh
{"first":"johnny","last":"gaudreau","goals":[9,27,1],"assists":[17,46,0],"gp":[26,82,1]}

POST /hockey/player/1/_explain
{
  "query": {
    "script": {
      "script": "Debug.explain(doc.goals)"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[catch:/painless_explain_error/]</remark>
<simpara>Which shows that the class of <literal>doc.first</literal> is
<literal>org.elasticsearch.index.fielddata.ScriptDocValues$Longs</literal> by responding with:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "error": {
      "type": "script_exception",
      "class": "org.elasticsearch.index.fielddata.ScriptDocValues$Longs",
      "to_string": "[1, 9, 27]",
      ...
   },
   "status": 500
}</programlisting>
<remark> TESTRESPONSE[s/\.\.\./"script_stack": $body.error.script_stack, "script": $body.error.script, "lang": $body.error.lang, "caused_by": $body.error.caused_by, "root_cause": $body.error.root_cause, "reason": $body.error.reason/]</remark>
<simpara>You can use the same trick to see that <literal>_source</literal> is a <literal>java.util.LinkedHashMap</literal>
in the <literal>_update</literal> API:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /hockey/player/1/_update
{
  "script": "Debug.explain(ctx._source)"
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued catch:/painless_explain_error/]</remark>
<simpara>The response looks like:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "error" : {
    "root_cause": ...,
    "type": "illegal_argument_exception",
    "reason": "failed to execute script",
    "caused_by": {
      "type": "script_exception",
      "class": "java.util.LinkedHashMap",
      "to_string": "{gp=[26, 82, 1], last=gaudreau, assists=[17, 46, 0], first=johnny, goals=[9, 27, 1]}",
      ...
    }
  },
  "status": 400
}</programlisting>
<remark> TESTRESPONSE[s/"root_cause": \.\.\./"root_cause": $body.error.root_cause/]</remark>
<remark> TESTRESPONSE[s/\.\.\./"script_stack": $body.error.caused_by.script_stack, "script": $body.error.caused_by.script, "lang": $body.error.caused_by.lang, "caused_by": $body.error.caused_by.caused_by, "reason": $body.error.caused_by.reason/]</remark>
<remark> TESTRESPONSE[s/"to_string": ".+"/"to_string": $body.error.caused_by.to_string/]</remark>
<remark> TODO we should build some javadoc like mashup so people don't have to jump through these hoops.</remark>
<simpara>Once you have the class of an object you can go
<ulink url="https://github.com/elastic/elasticsearch/tree/master/modules/lang-painless/src/main/resources/org/elasticsearch/painless">here</ulink>
and check the available methods. Painless uses a strict whitelist to prevent
scripts that don&#8217;t work well with Elasticsearch and all whitelisted methods
are listed in a file named after the package of the object (everything before
the last <literal>.</literal>). So <literal>java.util.Map</literal> is listed in a file named <literal>java.util.txt</literal>
starting on the line that looks like <literal>class Map -&gt; java.util.Map {</literal>.</simpara>
<simpara>With the list of whitelisted methods in hand you can turn to either
<ulink url="https://docs.oracle.com/javase/8/docs/api/">Javadoc</ulink>,
<ulink url="https://github.com/elastic/elasticsearch/tree/master">Elasticsearch&#8217;s source tree</ulink>
or, for whitelisted methods ending in <literal>*</literal>, the
<ulink url="https://github.com/elastic/elasticsearch/blob/master/modules/lang-painless/src/main/java/org/elasticsearch/painless/Augmentation.java">Augmentation</ulink>
class.</simpara>
</section>
</section>
<section id="modules-scripting-expression">
<title>Lucene Expressions Language<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/expression.asciidoc">Edit me</ulink></title>
<simpara>Lucene&#8217;s expressions compile a <literal>javascript</literal> expression to bytecode. They are
designed for high-performance custom ranking and sorting functions and are
enabled for <literal>inline</literal> and <literal>stored</literal> scripting by default.</simpara>
<bridgehead id="_performance" renderas="sect2">Performance<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/expression.asciidoc">Edit me</ulink></bridgehead>
<simpara>Expressions were designed to have competitive performance with custom Lucene code.
This performance is due to having low per-document overhead as opposed to other
scripting engines: expressions do more "up-front".</simpara>
<simpara>This allows for very fast execution, even faster than if you had written a <literal>native</literal> script.</simpara>
<bridgehead id="_syntax_14" renderas="sect2">Syntax<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/expression.asciidoc">Edit me</ulink></bridgehead>
<simpara>Expressions support a subset of javascript syntax: a single expression.</simpara>
<simpara>See the <ulink url="http://lucene.apache.org/core/6_0_0/expressions/index.html?org/apache/lucene/expressions/js/package-summary.html">expressions module documentation</ulink>
for details on what operators and functions are available.</simpara>
<simpara>Variables in <literal>expression</literal> scripts are available to access:</simpara>
<itemizedlist>
<listitem>
<simpara>
document fields, e.g. <literal>doc['myfield'].value</literal>
</simpara>
</listitem>
<listitem>
<simpara>
variables and methods that the field supports, e.g. <literal>doc['myfield'].empty</literal>
</simpara>
</listitem>
<listitem>
<simpara>
Parameters passed into the script, e.g. <literal>mymodifier</literal>
</simpara>
</listitem>
<listitem>
<simpara>
The current document&#8217;s score, <literal>_score</literal> (only available when used in a <literal>script_score</literal>)
</simpara>
</listitem>
</itemizedlist>
<simpara>You can use Expressions scripts for <literal>script_score</literal>, <literal>script_fields</literal>, sort scripts, and numeric aggregation
scripts, simply set the <literal>lang</literal> parameter to <literal>expression</literal>.</simpara>
<bridgehead id="_numeric_field_api" renderas="sect2">Numeric field API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/expression.asciidoc">Edit me</ulink></bridgehead>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Expression </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].value</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The value of the field, as a <literal>double</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].empty</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A boolean indicating if the field has no
values within the doc.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].length</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The number of values in this document.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].min()</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The minimum value of the field in this document.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].max()</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The maximum value of the field in this document.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].median()</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The median value of the field in this document.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].avg()</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The average of the values in this document.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].sum()</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The sum of the values in this document.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>When a document is missing the field completely, by default the value will be treated as <literal>0</literal>.
You can treat it as another value instead, e.g. <literal>doc['myfield'].empty ? 100 : doc['myfield'].value</literal></simpara>
<simpara>When a document has multiple values for the field, by default the minimum value is returned.
You can choose a different value instead, e.g. <literal>doc['myfield'].sum()</literal>.</simpara>
<simpara>When a document is missing the field completely, by default the value will be treated as <literal>0</literal>.</simpara>
<simpara>Boolean fields are exposed as numerics, with <literal>true</literal> mapped to <literal>1</literal> and <literal>false</literal> mapped to <literal>0</literal>.
For example: <literal>doc['on_sale'].value ? doc['price'].value * 0.5 : doc['price'].value</literal></simpara>
<bridgehead id="_date_field_api" renderas="sect2">Date field API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/expression.asciidoc">Edit me</ulink></bridgehead>
<simpara>Date fields are treated as the number of milliseconds since January 1, 1970 and
support the Numeric Fields API above, plus access to some date-specific fields:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Expression </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].date.centuryOfEra</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Century (1-2920000)</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].date.dayOfMonth</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Day (1-31), e.g. <literal>1</literal> for the first of the month.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].date.dayOfWeek</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Day of the week (1-7), e.g. <literal>1</literal> for Monday.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].date.dayOfYear</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Day of the year, e.g. <literal>1</literal> for January 1.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].date.era</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Era: <literal>0</literal> for BC, <literal>1</literal> for AD.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].date.hourOfDay</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Hour (0-23).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].date.millisOfDay</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Milliseconds within the day (0-86399999).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].date.millisOfSecond</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Milliseconds within the second (0-999).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].date.minuteOfDay</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Minute within the day (0-1439).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].date.minuteOfHour</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Minute within the hour (0-59).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].date.monthOfYear</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Month within the year (1-12), e.g. <literal>1</literal> for January.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].date.secondOfDay</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Second within the day (0-86399).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].date.secondOfMinute</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Second within the minute (0-59).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].date.year</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Year (-292000000 - 292000000).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].date.yearOfCentury</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Year within the century (1-100).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].date.yearOfEra</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Year within the era (1-292000000).</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>The following example shows the difference in years between the <literal>date</literal> fields date0 and date1:</simpara>
<simpara><literal>doc['date1'].date.year - doc['date0'].date.year</literal></simpara>
<bridgehead id="_literal_geo_point_literal_field_api" renderas="sect2"><literal>geo_point</literal> field API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/expression.asciidoc">Edit me</ulink></bridgehead>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Expression </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].empty</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A boolean indicating if the field has no
values within the doc.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].lat</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The latitude of the geo point.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>doc['field_name'].lon</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The longitude of the geo point.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>The following example computes distance in kilometers from Washington, DC:</simpara>
<simpara><literal>haversin(38.9072, 77.0369, doc['field_name'].lat, doc['field_name'].lon)</literal></simpara>
<simpara>In this example the coordinates could have been passed as parameters to the script,
e.g. based on geolocation of the user.</simpara>
<bridgehead id="_limitations_6" renderas="sect2">Limitations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/expression.asciidoc">Edit me</ulink></bridgehead>
<simpara>There are a few limitations relative to other script languages:</simpara>
<itemizedlist>
<listitem>
<simpara>
Only numeric, boolean, date, and geo_point fields may be accessed
</simpara>
</listitem>
<listitem>
<simpara>
Stored fields are not available
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="modules-scripting-native">
<title>Native (Java) Scripts<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/native.asciidoc">Edit me</ulink></title>
<simpara>Sometimes <literal>groovy</literal> and <link linkend="modules-scripting-expression">expression</link> aren&#8217;t enough. For those times you can
implement a native script.</simpara>
<simpara>The best way to implement a native script is to write a plugin and install it.
The plugin <ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/plugin-authors.html">documentation</ulink> has more information on
how to write a plugin so that Elasticsearch will properly load it.</simpara>
<simpara>To register the actual script you&#8217;ll need to implement <literal>NativeScriptFactory</literal>
to construct the script. The actual script will extend either
<literal>AbstractExecutableScript</literal> or <literal>AbstractSearchScript</literal>. The second one is likely
the most useful and has several helpful subclasses you can extend like
<literal>AbstractLongSearchScript</literal> and <literal>AbstractDoubleSearchScript</literal>.
Finally, your plugin should register the native script by implementing the
<literal>ScriptPlugin</literal> interface.</simpara>
<simpara>If you squashed the whole thing into one class it&#8217;d look like:</simpara>
<programlisting language="java" linenumbering="unnumbered">public class MyNativeScriptPlugin extends Plugin implements ScriptPlugin {

    @Override
    public List&lt;NativeScriptFactory&gt; getNativeScripts() {
        return Collections.singletonList(new MyNativeScriptFactory());
    }

    public static class MyNativeScriptFactory implements NativeScriptFactory {
        @Override
        public ExecutableScript newScript(@Nullable Map&lt;String, Object&gt; params) {
            return new MyNativeScript();
        }
        @Override
        public boolean needsScores() {
            return false;
        }
    }

    public static class MyNativeScript extends AbstractDoubleSearchScript {
        @Override
        public double runAsDouble() {
            double a = (double) source().get("a");
            double b = (double) source().get("b");
            return a * b;
        }
    }
}</programlisting>
<simpara>You can execute the script by specifying its <literal>lang</literal> as <literal>native</literal>, and the name
of the script as the <literal>id</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XPOST localhost:9200/_search -d '{
  "query": {
    "function_score": {
      "query": {
        "match": {
          "body": "foo"
        }
      },
      "functions": [
        {
          "script_score": {
            "script": {
                "id": "my_script",
                "lang" : "native"
            }
          }
        }
      ]
    }
  }
}'</programlisting>
</section>
<section id="modules-advanced-scripting">
<title>Advanced text scoring in scripts<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/advanced-scripting.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>The functionality described on this page is considered experimental and may be changed or removed in a future release.</simpara></warning>
<simpara>Text features, such as term or document frequency for a specific term can be
accessed in scripts with the <literal>_index</literal> variable. This can be useful if, for
example, you want to implement your own scoring model using for example a
script inside a <link linkend="query-dsl-function-score-query">function score query</link>.
Statistics over the document collection are computed <emphasis role="strong">per shard</emphasis>, not per
index.</simpara>
<bridgehead id="_nomenclature" renderas="sect2">Nomenclature:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/advanced-scripting.asciidoc">Edit me</ulink></bridgehead>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>df</literal>
</simpara>
</entry>
<entry>
<simpara>
    document frequency. The number of documents a term appears in. Computed
    per field.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>tf</literal>
</simpara>
</entry>
<entry>
<simpara>
    term frequency. The number times a term appears in a field in one specific
    document.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>ttf</literal>
</simpara>
</entry>
<entry>
<simpara>
    total term frequency. The number of times this term appears in all
    documents, that is, the sum of <literal>tf</literal> over all documents.  Computed per
    field.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara><literal>df</literal> and <literal>ttf</literal> are computed per shard and therefore these numbers can vary
depending on the shard the current document resides in.</simpara>
<bridgehead id="_shard_statistics" renderas="sect2">Shard statistics:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/advanced-scripting.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
<literal>_index.numDocs()</literal>
</term>
<listitem>
<simpara>
    Number of documents in shard.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>_index.maxDoc()</literal>
</term>
<listitem>
<simpara>
    Maximal document number in shard.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>_index.numDeletedDocs()</literal>
</term>
<listitem>
<simpara>
    Number of deleted documents in shard.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_field_statistics_3" renderas="sect2">Field statistics:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/advanced-scripting.asciidoc">Edit me</ulink></bridgehead>
<simpara>Field statistics can be accessed with a subscript operator like this:
<literal>_index['FIELD']</literal>.</simpara>
<variablelist>
<varlistentry>
<term>
<literal>_index['FIELD'].docCount()</literal>
</term>
<listitem>
<simpara>
    Number of documents containing the field <literal>FIELD</literal>. Does not take deleted documents into account.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>_index['FIELD'].sumttf()</literal>
</term>
<listitem>
<simpara>
    Sum of <literal>ttf</literal> over all terms that appear in field <literal>FIELD</literal> in all documents.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>_index['FIELD'].sumdf()</literal>
</term>
<listitem>
<simpara>
    The sum of <literal>df</literal> s over all terms that appear in field <literal>FIELD</literal> in all
    documents.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>Field statistics are computed per shard and therefore these numbers can vary
depending on the shard the current document resides in.
The number of terms in a field cannot be accessed using the <literal>_index</literal> variable. See <xref linkend="token-count"/> for how to do that.</simpara>
<bridgehead id="_term_statistics_2" renderas="sect2">Term statistics:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/advanced-scripting.asciidoc">Edit me</ulink></bridgehead>
<simpara>Term statistics for a field can be accessed with a subscript operator like
this: <literal>_index['FIELD']['TERM']</literal>. This will never return null, even if term or field does not exist.
If you do not need the term frequency, call <literal>_index['FIELD'].get('TERM', 0)</literal>
to avoid unnecessary initialization of the frequencies. The flag will have only
affect is your set the <link linkend="index-options"><literal>index_options</literal></link> to <literal>docs</literal>.</simpara>
<variablelist>
<varlistentry>
<term>
<literal>_index['FIELD']['TERM'].df()</literal>
</term>
<listitem>
<simpara>
    <literal>df</literal> of term <literal>TERM</literal> in field <literal>FIELD</literal>. Will be returned, even if the term
    is not present in the current document.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>_index['FIELD']['TERM'].ttf()</literal>
</term>
<listitem>
<simpara>
    The sum of term frequencies of term <literal>TERM</literal> in field <literal>FIELD</literal> over all
    documents. Will be returned, even if the term is not present in the
    current document.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>_index['FIELD']['TERM'].tf()</literal>
</term>
<listitem>
<simpara>
    <literal>tf</literal> of term <literal>TERM</literal> in field <literal>FIELD</literal>. Will be 0 if the term is not present
    in the current document.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_term_positions_offsets_and_payloads" renderas="sect2">Term positions, offsets and payloads:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/advanced-scripting.asciidoc">Edit me</ulink></bridgehead>
<simpara>If you need information on the positions of terms in a field, call
<literal>_index['FIELD'].get('TERM', flag)</literal> where flag can be</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>_POSITIONS</literal>
</simpara>
</entry>
<entry>
<simpara>
if you need the positions of the term
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>_OFFSETS</literal>
</simpara>
</entry>
<entry>
<simpara>
if you need the offsets of the term
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>_PAYLOADS</literal>
</simpara>
</entry>
<entry>
<simpara>
if you need the payloads of the term
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>_CACHE</literal>
</simpara>
</entry>
<entry>
<simpara>
if you need to iterate over all positions several times
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>The iterator uses the underlying lucene classes to iterate over positions. For efficiency reasons, you can only iterate over positions once. If you need to iterate over the positions several times, set the <literal>_CACHE</literal> flag.</simpara>
<simpara>You can combine the operators with a <literal>|</literal> if you need more than one info. For
example, the following will return an object holding the positions and payloads,
as well as all statistics:</simpara>
<literallayout class="monospaced">`_index['FIELD'].get('TERM', _POSITIONS | _PAYLOADS)`</literallayout>
<simpara>Positions can be accessed with an iterator that returns an object
(<literal>POS_OBJECT</literal>) holding position, offsets and payload for each term position.</simpara>
<variablelist>
<varlistentry>
<term>
<literal>POS_OBJECT.position</literal>
</term>
<listitem>
<simpara>
    The position of the term.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>POS_OBJECT.startOffset</literal>
</term>
<listitem>
<simpara>
    The start offset of the term.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>POS_OBJECT.endOffset</literal>
</term>
<listitem>
<simpara>
    The end offset of the term.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>POS_OBJECT.payload</literal>
</term>
<listitem>
<simpara>
    The payload of the term.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>POS_OBJECT.payloadAsInt(missingValue)</literal>
</term>
<listitem>
<simpara>
    The payload of the term converted to integer. If the current position has
    no payload, the <literal>missingValue</literal> will be returned. Call this only if you
    know that your payloads are integers.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>POS_OBJECT.payloadAsFloat(missingValue)</literal>
</term>
<listitem>
<simpara>
    The payload of the term converted to float. If the current position has no
    payload, the <literal>missingValue</literal> will be returned. Call this only if you know
    that your payloads are floats.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>POS_OBJECT.payloadAsString()</literal>
</term>
<listitem>
<simpara>
    The payload of the term converted to string. If the current position has
    no payload, <literal>null</literal> will be returned. Call this only if you know that your
    payloads are strings.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>Example: sums up all payloads for the term <literal>foo</literal>.</simpara>
<programlisting language="groovy" linenumbering="unnumbered">termInfo = _index['my_field'].get('foo',_PAYLOADS);
score = 0;
for (pos in termInfo) {
    score = score + pos.payloadAsInt(0);
}
return score;</programlisting>
<bridgehead id="_term_vectors" renderas="sect2">Term vectors:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/scripting/advanced-scripting.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>_index</literal> variable can only be used to gather statistics for single terms. If you want to use information on all terms in a field, you must store the term vectors (see <xref linkend="term-vector"/>). To access them, call
<literal>_index.termVectors()</literal> to get a
<ulink url="https://lucene.apache.org/core/4_0_0/core/org/apache/lucene/index/Fields.html">Fields</ulink>
instance. This object can then be used as described in <ulink url="https://lucene.apache.org/core/4_0_0/core/org/apache/lucene/index/Fields.html">lucene doc</ulink> to iterate over fields and then for each field iterate over each term in the field.
The method will return null if the term vectors were not stored.</simpara>
</section>
</chapter>
<chapter id="modules-snapshots">
<title>Snapshot And Restore<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/snapshots.asciidoc">Edit me</ulink></title>
<simpara>The snapshot and restore module allows to create snapshots of individual
indices or an entire cluster into a remote repository like shared file system,
S3, or HDFS. These snapshots are great for backups because they can be restored
relatively quickly but they are not archival because they can only be restored
to versions of Elasticsearch that can read the index. That means that:</simpara>
<itemizedlist>
<listitem>
<simpara>
A snapshot of an index created in 2.x can be restored to 5.x.
</simpara>
</listitem>
<listitem>
<simpara>
A snapshot of an index created in 1.x can be restored to 2.x.
</simpara>
</listitem>
<listitem>
<simpara>
A snapshot of an index created in 1.x can <emphasis role="strong">not</emphasis> be restored to 5.x.
</simpara>
</listitem>
</itemizedlist>
<simpara>To restore a snapshot of an index created in 1.x to 5.x you can restore it to
a 2.x cluster and use <link linkend="reindex-from-remote">reindex-from-remote</link> to rebuild
the index in a 5.x cluster. This is as time consuming as restoring from
archival copies of the original data.</simpara>
<bridgehead id="_repositories" renderas="sect2">Repositories<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/snapshots.asciidoc">Edit me</ulink></bridgehead>
<simpara>Before any snapshot or restore operation can be performed, a snapshot repository should be registered in
Elasticsearch. The repository settings are repository-type specific. See below for details.</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /_snapshot/my_backup
{
  "type": "fs",
  "settings": {
        ... repository specific settings ...
  }
}</programlisting>
<simpara>Once a repository is registered, its information can be obtained using the following command:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_snapshot/my_backup</programlisting>
<remark> CONSOLE</remark>
<simpara>which returns:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "my_backup": {
    "type": "fs",
    "settings": {
      "compress": true,
      "location": "/mount/backups/my_backup"
    }
  }
}</programlisting>
<simpara>Information about multiple repositories can be fetched in one go by using a comma-delimited list of repository names.
Star wildcards are supported as well. For example, information about repositories that start with <literal>repo</literal> or that contain <literal>backup</literal>
can be obtained using the following command:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_snapshot/repo*,*backup*</programlisting>
<simpara>If a repository name is not specified, or <literal>_all</literal> is used as repository name Elasticsearch will return information about
all repositories currently registered in the cluster:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_snapshot</programlisting>
<simpara>or</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_snapshot/_all</programlisting>
<bridgehead id="_shared_file_system_repository" renderas="sect4">Shared File System Repository<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/snapshots.asciidoc">Edit me</ulink></bridgehead>
<simpara>The shared file system repository (<literal>"type": "fs"</literal>) uses the shared file system to store snapshots. In order to register
the shared file system repository it is necessary to mount the same shared filesystem to the same location on all
master and data nodes. This location (or one of its parent directories) must be registered in the <literal>path.repo</literal>
setting on all master and data nodes.</simpara>
<simpara>Assuming that the shared filesystem is mounted to <literal>/mount/backups/my_backup</literal>, the following setting should be added to
<literal>elasticsearch.yml</literal> file:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">path.repo: ["/mount/backups", "/mount/longterm_backups"]</programlisting>
<simpara>The <literal>path.repo</literal> setting supports Microsoft Windows UNC paths as long as at least server name and share are specified as
a prefix and back slashes are properly escaped:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">path.repo: ["\\\\MY_SERVER\\Snapshots"]</programlisting>
<simpara>After all nodes are restarted, the following command can be used to register the shared file system repository with
the name <literal>my_backup</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">$ curl -XPUT 'http://localhost:9200/_snapshot/my_backup' -d '{
    "type": "fs",
    "settings": {
        "location": "/mount/backups/my_backup",
        "compress": true
    }
}'</programlisting>
<simpara>If the repository location is specified as a relative path this path will be resolved against the first path specified
in <literal>path.repo</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">$ curl -XPUT 'http://localhost:9200/_snapshot/my_backup' -d '{
    "type": "fs",
    "settings": {
        "location": "my_backup",
        "compress": true
    }
}'</programlisting>
<simpara>The following settings are supported:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>location</literal>
</simpara>
</entry>
<entry>
<simpara>
Location of the snapshots. Mandatory.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>compress</literal>
</simpara>
</entry>
<entry>
<simpara>
Turns on compression of the snapshot files. Compression is applied only to metadata files (index mapping and settings). Data files are not compressed. Defaults to <literal>true</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>chunk_size</literal>
</simpara>
</entry>
<entry>
<simpara>
Big files can be broken down into chunks during snapshotting if needed. The chunk size can be specified in bytes or by
 using size value notation, i.e. 1g, 10m, 5k. Defaults to <literal>null</literal> (unlimited chunk size).
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max_restore_bytes_per_sec</literal>
</simpara>
</entry>
<entry>
<simpara>
Throttles per node restore rate. Defaults to <literal>40mb</literal> per second.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>max_snapshot_bytes_per_sec</literal>
</simpara>
</entry>
<entry>
<simpara>
Throttles per node snapshot rate. Defaults to <literal>40mb</literal> per second.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>readonly</literal>
</simpara>
</entry>
<entry>
<simpara>
Makes repository read-only.  Defaults to <literal>false</literal>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<bridgehead id="_read_only_url_repository" renderas="sect4">Read-only URL Repository<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/snapshots.asciidoc">Edit me</ulink></bridgehead>
<simpara>The URL repository (<literal>"type": "url"</literal>) can be used as an alternative read-only way to access data created by the shared file
system repository. The URL specified in the <literal>url</literal> parameter should point to the root of the shared filesystem repository.
The following settings are supported:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>url</literal>
</simpara>
</entry>
<entry>
<simpara>
Location of the snapshots. Mandatory.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>URL Repository supports the following protocols: "http", "https", "ftp", "file" and "jar". URL repositories with <literal>http:</literal>,
<literal>https:</literal>, and <literal>ftp:</literal> URLs has to be whitelisted by specifying allowed URLs in the <literal>repositories.url.allowed_urls</literal> setting.
This setting supports wildcards in the place of host, path, query, and fragment. For example:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">repositories.url.allowed_urls: ["http://www.example.org/root/*", "https://*.mydomain.com/*?*#*"]</programlisting>
<simpara>URL repositories with <literal>file:</literal> URLs can only point to locations registered in the <literal>path.repo</literal> setting similar to
shared file system repository.</simpara>
<bridgehead id="_repository_plugins" renderas="sect4">Repository plugins<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/snapshots.asciidoc">Edit me</ulink></bridgehead>
<simpara>Other repository backends are available in these official plugins:</simpara>
<itemizedlist>
<listitem>
<simpara>
<ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/repository-s3.html">repository-s3</ulink> for S3 repository support
</simpara>
</listitem>
<listitem>
<simpara>
<ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/repository-hdfs.html">repository-hdfs</ulink> for HDFS repository support in Hadoop environments
</simpara>
</listitem>
<listitem>
<simpara>
<ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/repository-azure.html">repository-azure</ulink> for Azure storage repositories
</simpara>
</listitem>
<listitem>
<simpara>
<ulink url="https://www.elastic.co/guide/en/elasticsearch/plugins/5.x/repository-gcs.html">repository-gcs</ulink> for Google Cloud Storage repositories
</simpara>
</listitem>
</itemizedlist>
<bridgehead id="_repository_verification" renderas="sect4">Repository Verification<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/snapshots.asciidoc">Edit me</ulink></bridgehead>
<simpara>When a repository is registered, it&#8217;s immediately verified on all master and data nodes to make sure that it is functional
on all nodes currently present in the cluster. The <literal>verify</literal> parameter can be used to explicitly disable the repository
verification when registering or updating a repository:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /_snapshot/s3_repository?verify=false
{
  "type": "s3",
  "settings": {
    "bucket": "my_s3_bucket",
    "region": "eu-west-1"
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The verification process can also be executed manually by running the following command:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /_snapshot/s3_repository/_verify</programlisting>
<remark> CONSOLE</remark>
<simpara>It returns a list of nodes where repository was successfully verified or an error message if verification process failed.</simpara>
<bridgehead id="_snapshot" renderas="sect2">Snapshot<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/snapshots.asciidoc">Edit me</ulink></bridgehead>
<simpara>A repository can contain multiple snapshots of the same cluster. Snapshots are identified by unique names within the
cluster. A snapshot with the name <literal>snapshot_1</literal> in the repository <literal>my_backup</literal> can be created by executing the following
command:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /_snapshot/my_backup/snapshot_1?wait_for_completion=true</programlisting>
<remark> CONSOLE</remark>
<simpara>The <literal>wait_for_completion</literal> parameter specifies whether or not the request should return immediately after snapshot
initialization (default) or wait for snapshot completion. During snapshot initialization, information about all
previous snapshots is loaded into the memory, which means that in large repositories it may take several seconds (or
even minutes) for this command to return even if the <literal>wait_for_completion</literal> parameter is set to <literal>false</literal>.</simpara>
<simpara>By default a snapshot of all open and started indices in the cluster is created. This behavior can be changed by
specifying the list of indices in the body of the snapshot request.</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /_snapshot/my_backup/snapshot_1
{
  "indices": "index_1,index_2",
  "ignore_unavailable": true,
  "include_global_state": false
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The list of indices that should be included into the snapshot can be specified using the <literal>indices</literal> parameter that
supports <link linkend="search-multi-index-type">multi index syntax</link>. The snapshot request also supports the
<literal>ignore_unavailable</literal> option. Setting it to <literal>true</literal> will cause indices that do not exist to be ignored during snapshot
creation. By default, when <literal>ignore_unavailable</literal> option is not set and an index is missing the snapshot request will fail.
By setting <literal>include_global_state</literal> to false it&#8217;s possible to prevent the cluster global state to be stored as part of
the snapshot. By default, the entire snapshot will fail if one or more indices participating in the snapshot don&#8217;t have
all primary shards available. This behaviour can be changed by setting <literal>partial</literal> to <literal>true</literal>.</simpara>
<simpara>The index snapshot process is incremental. In the process of making the index snapshot Elasticsearch analyses
the list of the index files that are already stored in the repository and copies only files that were created or
changed since the last snapshot. That allows multiple snapshots to be preserved in the repository in a compact form.
Snapshotting process is executed in non-blocking fashion. All indexing and searching operation can continue to be
executed against the index that is being snapshotted. However, a snapshot represents the point-in-time view of the index
at the moment when snapshot was created, so no records that were added to the index after the snapshot process was started
will be present in the snapshot. The snapshot process starts immediately for the primary shards that has been started
and are not relocating at the moment. Before version 1.2.0, the snapshot operation fails if the cluster has any relocating or
initializing primaries of indices participating in the snapshot. Starting with version 1.2.0, Elasticsearch waits for
relocation or initialization of shards to complete before snapshotting them.</simpara>
<simpara>Besides creating a copy of each index the snapshot process can also store global cluster metadata, which includes persistent
cluster settings and templates. The transient settings and registered snapshot repositories are not stored as part of
the snapshot.</simpara>
<simpara>Only one snapshot process can be executed in the cluster at any time. While snapshot of a particular shard is being
created this shard cannot be moved to another node, which can interfere with rebalancing process and allocation
filtering. Elasticsearch will only be able to move a shard to another node (according to the current allocation
filtering settings and rebalancing algorithm) once the snapshot is finished.</simpara>
<simpara>Once a snapshot is created information about this snapshot can be obtained using the following command:</simpara>
<programlisting language="sh" linenumbering="unnumbered">GET /_snapshot/my_backup/snapshot_1</programlisting>
<remark> CONSOLE</remark>
<simpara>Similar as for repositories, information about multiple snapshots can be queried in one go, supporting wildcards as well:</simpara>
<programlisting language="sh" linenumbering="unnumbered">GET /_snapshot/my_backup/snapshot_*,some_other_snapshot</programlisting>
<remark> CONSOLE</remark>
<simpara>All snapshots currently stored in the repository can be listed using the following command:</simpara>
<programlisting language="sh" linenumbering="unnumbered">GET /_snapshot/my_backup/_all</programlisting>
<remark> CONSOLE</remark>
<simpara>The command fails if some of the snapshots are unavailable. The boolean parameter <literal>ignore_unavailable</literal> can be used to
return all snapshots that are currently available.</simpara>
<simpara>A currently running snapshot can be retrieved using the following command:</simpara>
<programlisting language="sh" linenumbering="unnumbered">$ curl -XGET "localhost:9200/_snapshot/my_backup/_current"</programlisting>
<simpara>A snapshot can be deleted from the repository using the following command:</simpara>
<programlisting language="sh" linenumbering="unnumbered">DELETE /_snapshot/my_backup/snapshot_1</programlisting>
<remark> CONSOLE</remark>
<simpara>When a snapshot is deleted from a repository, Elasticsearch deletes all files that are associated with the deleted
snapshot and not used by any other snapshots. If the deleted snapshot operation is executed while the snapshot is being
created the snapshotting process will be aborted and all files created as part of the snapshotting process will be
cleaned. Therefore, the delete snapshot operation can be used to cancel long running snapshot operations that were
started by mistake.</simpara>
<simpara>A repository can be deleted using the following command:</simpara>
<programlisting language="sh" linenumbering="unnumbered">DELETE /_snapshot/my_backup</programlisting>
<remark> CONSOLE</remark>
<simpara>When a repository is deleted, Elasticsearch only removes the reference to the location where the repository is storing
the snapshots. The snapshots themselves are left untouched and in place.</simpara>
<bridgehead id="_restore" renderas="sect2">Restore<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/snapshots.asciidoc">Edit me</ulink></bridgehead>
<simpara>A snapshot can be restored using the following command:</simpara>
<programlisting language="sh" linenumbering="unnumbered">POST /_snapshot/my_backup/snapshot_1/_restore</programlisting>
<remark> CONSOLE</remark>
<simpara>By default, all indices in the snapshot are restored, and the cluster state is
<emphasis role="strong">not</emphasis> restored. It&#8217;s possible to select indices that should be restored as well
as to allow the global cluster state from being restored by using <literal>indices</literal> and
<literal>include_global_state</literal> options in the restore request body. The list of indices
supports <link linkend="search-multi-index-type">multi index syntax</link>. The <literal>rename_pattern</literal>
and <literal>rename_replacement</literal> options can be also used to rename indices on restore
using regular expression that supports referencing the original text as
explained
<ulink url="http://docs.oracle.com/javase/6/docs/api/java/util/regex/Matcher.html#appendReplacement(java.lang.StringBuffer,%20java.lang.String)">here</ulink>.
Set <literal>include_aliases</literal> to <literal>false</literal> to prevent aliases from being restored together
with associated indices</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /_snapshot/my_backup/snapshot_1/_restore
{
  "indices": "index_1,index_2",
  "ignore_unavailable": true,
  "include_global_state": true,
  "rename_pattern": "index_(.+)",
  "rename_replacement": "restored_index_$1"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>The restore operation can be performed on a functioning cluster. However, an
existing index can be only restored if it&#8217;s <link linkend="indices-open-close">closed</link> and
has the same number of shards as the index in the snapshot. The restore
operation automatically opens restored indices if they were closed and creates
new indices if they didn&#8217;t exist in the cluster. If cluster state is restored
with <literal>include_global_state</literal> (defaults to <literal>false</literal>), the restored templates that
don&#8217;t currently exist in the cluster are added and existing templates with the
same name are replaced by the restored templates. The restored persistent
settings are added to the existing persistent settings.</simpara>
<bridgehead id="_partial_restore" renderas="sect3">Partial restore<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/snapshots.asciidoc">Edit me</ulink></bridgehead>
<simpara>By default, the entire restore operation will fail if one or more indices participating in the operation don&#8217;t have
snapshots of all shards available. It can occur if some shards failed to snapshot for example. It is still possible to
restore such indices by setting <literal>partial</literal> to <literal>true</literal>. Please note, that only successfully snapshotted shards will be
restored in this case and all missing shards will be recreated empty.</simpara>
<bridgehead id="_changing_index_settings_during_restore" renderas="sect3">Changing index settings during restore<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/snapshots.asciidoc">Edit me</ulink></bridgehead>
<simpara>Most of index settings can be overridden during the restore process. For example, the following command will restore
the index <literal>index_1</literal> without creating any replicas while switching back to default refresh interval:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST /_snapshot/my_backup/snapshot_1/_restore
{
  "indices": "index_1",
  "index_settings": {
    "index.number_of_replicas": 0
  },
  "ignore_index_settings": [
    "index.refresh_interval"
  ]
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Please note, that some settings such as <literal>index.number_of_shards</literal> cannot be changed during restore operation.</simpara>
<bridgehead id="_restoring_to_a_different_cluster" renderas="sect3">Restoring to a different cluster<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/snapshots.asciidoc">Edit me</ulink></bridgehead>
<simpara>The information stored in a snapshot is not tied to a particular cluster or a cluster name. Therefore it&#8217;s possible to
restore a snapshot made from one cluster into another cluster. All that is required is registering the repository
containing the snapshot in the new cluster and starting the restore process. The new cluster doesn&#8217;t have to have the
same size or topology.  However, the version of the new cluster should be the same or newer (only 1 major version newer) than the cluster that was used to create the snapshot.  For example, you can restore a 1.x snapshot to a 2.x cluster, but not a 1.x snapshot to a 5.x cluster.</simpara>
<simpara>If the new cluster has a smaller size additional considerations should be made. First of all it&#8217;s necessary to make sure
that new cluster have enough capacity to store all indices in the snapshot. It&#8217;s possible to change indices settings
during restore to reduce the number of replicas, which can help with restoring snapshots into smaller cluster. It&#8217;s also
possible to select only subset of the indices using the <literal>indices</literal> parameter.  Prior to version 1.5.0 elasticsearch
didn&#8217;t check restored persistent settings making it possible to accidentally restore an incompatible
<literal>discovery.zen.minimum_master_nodes</literal> setting, and as a result disable a smaller cluster until the required number of
master eligible nodes is added.  Starting with version 1.5.0 incompatible settings are ignored.</simpara>
<simpara>If indices in the original cluster were assigned to particular nodes using
<link linkend="shard-allocation-filtering">shard allocation filtering</link>, the same rules will be enforced in the new cluster. Therefore
if the new cluster doesn&#8217;t contain nodes with appropriate attributes that a restored index can be allocated on, such
index will not be successfully restored unless these index allocation settings are changed during restore operation.</simpara>
<bridgehead id="_snapshot_status" renderas="sect2">Snapshot status<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/snapshots.asciidoc">Edit me</ulink></bridgehead>
<simpara>A list of currently running snapshots with their detailed status information can be obtained using the following command:</simpara>
<programlisting language="sh" linenumbering="unnumbered">GET /_snapshot/_status</programlisting>
<remark> CONSOLE</remark>
<simpara>In this format, the command will return information about all currently running snapshots. By specifying a repository name, it&#8217;s possible
to limit the results to a particular repository:</simpara>
<programlisting language="sh" linenumbering="unnumbered">GET /_snapshot/my_backup/_status</programlisting>
<remark> CONSOLE</remark>
<simpara>If both repository name and snapshot id are specified, this command will return detailed status information for the given snapshot even
if it&#8217;s not currently running:</simpara>
<programlisting language="sh" linenumbering="unnumbered">GET /_snapshot/my_backup/snapshot_1/_status</programlisting>
<remark> CONSOLE</remark>
<simpara>Multiple ids are also supported:</simpara>
<programlisting language="sh" linenumbering="unnumbered">GET /_snapshot/my_backup/snapshot_1,snapshot_2/_status</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_monitoring_snapshot_restore_progress" renderas="sect2">Monitoring snapshot/restore progress<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/snapshots.asciidoc">Edit me</ulink></bridgehead>
<simpara>There are several ways to monitor the progress of the snapshot and restores processes while they are running. Both
operations support <literal>wait_for_completion</literal> parameter that would block client until the operation is completed. This is
the simplest method that can be used to get notified about operation completion.</simpara>
<simpara>The snapshot operation can be also monitored by periodic calls to the snapshot info:</simpara>
<programlisting language="sh" linenumbering="unnumbered">GET /_snapshot/my_backup/snapshot_1</programlisting>
<remark> CONSOLE</remark>
<simpara>Please note that snapshot info operation uses the same resources and thread pool as the snapshot operation. So,
executing a snapshot info operation while large shards are being snapshotted can cause the snapshot info operation to wait
for available resources before returning the result. On very large shards the wait time can be significant.</simpara>
<simpara>To get more immediate and complete information about snapshots the snapshot status command can be used instead:</simpara>
<programlisting language="sh" linenumbering="unnumbered">GET /_snapshot/my_backup/snapshot_1/_status</programlisting>
<remark> CONSOLE</remark>
<simpara>While snapshot info method returns only basic information about the snapshot in progress, the snapshot status returns
complete breakdown of the current state for each shard participating in the snapshot.</simpara>
<simpara>The restore process piggybacks on the standard recovery mechanism of the Elasticsearch. As a result, standard recovery
monitoring services can be used to monitor the state of restore. When restore operation is executed the cluster
typically goes into <literal>red</literal> state. It happens because the restore operation starts with "recovering" primary shards of the
restored indices. During this operation the primary shards become unavailable which manifests itself in the <literal>red</literal> cluster
state. Once recovery of primary shards is completed Elasticsearch is switching to standard replication process that
creates the required number of replicas at this moment cluster switches to the <literal>yellow</literal> state. Once all required replicas
are created, the cluster switches to the <literal>green</literal> states.</simpara>
<simpara>The cluster health operation provides only a high level status of the restore process. It’s possible to get more
detailed insight into the current state of the recovery process by using <link linkend="indices-recovery">indices recovery</link> and
<link linkend="cat-recovery">cat recovery</link> APIs.</simpara>
<bridgehead id="_stopping_currently_running_snapshot_and_restore_operations" renderas="sect2">Stopping currently running snapshot and restore operations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/snapshots.asciidoc">Edit me</ulink></bridgehead>
<simpara>The snapshot and restore framework allows running only one snapshot or one restore operation at a time. If a currently
running snapshot was executed by mistake, or takes unusually long, it can be terminated using the snapshot delete operation.
The snapshot delete operation checks if the deleted snapshot is currently running and if it does, the delete operation stops
that snapshot before deleting the snapshot data from the repository.</simpara>
<programlisting language="sh" linenumbering="unnumbered">DELETE /_snapshot/my_backup/snapshot_1</programlisting>
<remark> CONSOLE</remark>
<simpara>The restore operation uses the standard shard recovery mechanism. Therefore, any currently running restore operation can
be canceled by deleting indices that are being restored. Please note that data for all deleted indices will be removed
from the cluster as a result of this operation.</simpara>
<bridgehead id="_effect_of_cluster_blocks_on_snapshot_and_restore_operations" renderas="sect2">Effect of cluster blocks on snapshot and restore operations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/snapshots.asciidoc">Edit me</ulink></bridgehead>
<simpara>Many snapshot and restore operations are affected by cluster and index blocks. For example, registering and unregistering
repositories require write global metadata access. The snapshot operation requires that all indices and their metadata as
well as the global metadata were readable. The restore operation requires the global metadata to be writable, however
the index level blocks are ignored during restore because indices are essentially recreated during restore.
Please note that a repository content is not part of the cluster and therefore cluster blocks don&#8217;t affect internal
repository operations such as listing or deleting snapshots from an already registered repository.</simpara>
</chapter>
<chapter id="modules-threadpool">
<title>Thread Pool<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/threadpool.asciidoc">Edit me</ulink></title>
<simpara>A node holds several thread pools in order to improve how threads memory consumption
are managed within a node. Many of these pools also have queues associated with them,
which allow pending requests to be held instead
of discarded.</simpara>
<simpara>There are several thread pools, but the important ones include:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>generic</literal>
</term>
<listitem>
<simpara>
    For generic operations (e.g., background node discovery).
    Thread pool type is <literal>scaling</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>index</literal>
</term>
<listitem>
<simpara>
    For index/delete operations. Thread pool type is <literal>fixed</literal>
    with a size of <literal># of available processors</literal>,
    queue_size of <literal>200</literal>.  The maximum size for this pool
    is <literal>1 + # of available processors</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>search</literal>
</term>
<listitem>
<simpara>
    For count/search/suggest operations. Thread pool type is <literal>fixed</literal>
    with a size of <literal>int((# of available_processors * 3) / 2) + 1</literal>,
    queue_size of <literal>1000</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>get</literal>
</term>
<listitem>
<simpara>
    For get operations. Thread pool type is <literal>fixed</literal>
    with a size of <literal># of available processors</literal>,
    queue_size of <literal>1000</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>bulk</literal>
</term>
<listitem>
<simpara>
    For bulk operations. Thread pool type is <literal>fixed</literal>
    with a size of <literal># of available processors</literal>,
    queue_size of <literal>50</literal>.  The maximum size for this pool
    is <literal>1 + # of available processors</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>percolate</literal>
</term>
<listitem>
<simpara>
    For percolate operations. Thread pool type is <literal>fixed</literal>
    with a size of <literal># of available processors</literal>,
    queue_size of <literal>1000</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>snapshot</literal>
</term>
<listitem>
<simpara>
    For snapshot/restore operations. Thread pool type is <literal>scaling</literal> with a
    keep-alive of <literal>5m</literal> and a max of <literal>min(5, (# of available processors)/2)</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>warmer</literal>
</term>
<listitem>
<simpara>
    For segment warm-up operations. Thread pool type is <literal>scaling</literal> with a
    keep-alive of <literal>5m</literal> and a max of <literal>min(5, (# of available processors)/2)</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>refresh</literal>
</term>
<listitem>
<simpara>
    For refresh operations. Thread pool type is <literal>scaling</literal> with a
    keep-alive of <literal>5m</literal> and a max of <literal>min(10, (# of available processors)/2)</literal>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>listener</literal>
</term>
<listitem>
<simpara>
    Mainly for java client executing of action when listener threaded is set to true.
    Thread pool type is <literal>scaling</literal> with a default max of <literal>min(10, (# of available processors)/2)</literal>.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>Changing a specific thread pool can be done by setting its type-specific parameters; for example, changing the <literal>index</literal>
thread pool to have more threads:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">thread_pool:
    index:
        size: 30</programlisting>
<bridgehead id="types" renderas="sect2">Thread pool types<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/threadpool.asciidoc">Edit me</ulink></bridgehead>
<simpara>The following are the types of thread pools and their respective parameters:</simpara>
<bridgehead id="_literal_fixed_literal" renderas="sect3"><literal>fixed</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/threadpool.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>fixed</literal> thread pool holds a fixed size of threads to handle the
requests with a queue (optionally bounded) for pending requests that
have no threads to service them.</simpara>
<simpara>The <literal>size</literal> parameter controls the number of threads, and defaults to the
number of cores times 5.</simpara>
<simpara>The <literal>queue_size</literal> allows to control the size of the queue of pending
requests that have no threads to execute them. By default, it is set to
<literal>-1</literal> which means its unbounded. When a request comes in and the queue is
full, it will abort the request.</simpara>
<programlisting language="yaml" linenumbering="unnumbered">thread_pool:
    index:
        size: 30
        queue_size: 1000</programlisting>
<bridgehead id="_literal_scaling_literal" renderas="sect3"><literal>scaling</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/threadpool.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>scaling</literal> thread pool holds a dynamic number of threads. This
number is proportional to the workload and varies between the value of
the <literal>core</literal> and <literal>max</literal> parameters.</simpara>
<simpara>The <literal>keep_alive</literal> parameter determines how long a thread should be kept
around in the thread pool without it doing any work.</simpara>
<programlisting language="yaml" linenumbering="unnumbered">thread_pool:
    warmer:
        core: 1
        max: 8
        keep_alive: 2m</programlisting>
<bridgehead id="processors" renderas="sect2">Processors setting<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/threadpool.asciidoc">Edit me</ulink></bridgehead>
<simpara>The number of processors is automatically detected, and the thread pool
settings are automatically set based on it. In some cases it can be
useful to override the number of detected processors. This can be done
by explicitly setting the <literal>processors</literal> setting.</simpara>
<programlisting language="yaml" linenumbering="unnumbered">processors: 2</programlisting>
<simpara>There are a few use-cases for explicitly overriding the <literal>processors</literal>
setting:</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>
If you are running multiple instances of Elasticsearch on the same
host but want Elasticsearch to size its thread pools as if it only has a
fraction of the CPU, you should override the <literal>processors</literal> setting to the
desired fraction (e.g., if you&#8217;re running two instances of Elasticsearch
on a 16-core machine, set <literal>processors</literal> to 8). Note that this is an
expert-level use-case and there&#8217;s a lot more involved than just setting
the <literal>processors</literal> setting as there are other considerations like changing
the number of garbage collector threads, pinning processes to cores,
etc.
</simpara>
</listitem>
<listitem>
<simpara>
The number of processors is by default bounded to 32. This means that
on systems that have more than 32 processors, Elasticsearch will size
its thread pools as if there are only 32 processors present. This
limitation was added to avoid creating too many threads on systems that
have not properly adjusted the <literal>ulimit</literal> for max number of processes. In
cases where you&#8217;ve adjusted the <literal>ulimit</literal> appropriately, you can override
this bound by explicitly setting the <literal>processors</literal> setting.
</simpara>
</listitem>
<listitem>
<simpara>
Sometimes the number of processors is wrongly detected and in such
cases explicitly setting the <literal>processors</literal> setting will workaround such
issues.
</simpara>
</listitem>
</orderedlist>
<simpara>In order to check the number of processors detected, use the nodes info
API with the <literal>os</literal> flag.</simpara>
</chapter>
<chapter id="modules-transport">
<title>Transport<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/transport.asciidoc">Edit me</ulink></title>
<simpara>The transport module is used for internal communication between nodes
within the cluster. Each call that goes from one node to the other uses
the transport module (for example, when an HTTP GET request is processed
by one node, and should actually be processed by another node that holds
the data).</simpara>
<simpara>The transport mechanism is completely asynchronous in nature, meaning
that there is no blocking thread waiting for a response. The benefit of
using asynchronous communication is first solving the
<ulink url="http://en.wikipedia.org/wiki/C10k_problem">C10k problem</ulink>, as well as
being the ideal solution for scatter (broadcast) / gather operations such
as search in ElasticSearch.</simpara>
<bridgehead id="_tcp_transport" renderas="sect2">TCP Transport<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/transport.asciidoc">Edit me</ulink></bridgehead>
<simpara>The TCP transport is an implementation of the transport module using
TCP. It allows for the following settings:</simpara>
<informaltable
frame="all"
rowsep="1" colsep="1"
>
<tgroup cols="2">
<colspec colname="col_1" colwidth="50*"/>
<colspec colname="col_2" colwidth="50*"/>
<thead>
<row>
<entry align="left" valign="top">Setting </entry>
<entry align="left" valign="top">Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>transport.tcp.port</literal></simpara></entry>
<entry align="left" valign="top"><simpara>A bind port range. Defaults to <literal>9300-9400</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>transport.publish_port</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The port that other nodes in the cluster
should use when communicating with this node. Useful when a cluster node
is behind a proxy or firewall and the <literal>transport.tcp.port</literal> is not directly
addressable from the outside. Defaults to the actual port assigned via
<literal>transport.tcp.port</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>transport.bind_host</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The host address to bind the transport service to. Defaults to <literal>transport.host</literal> (if set) or <literal>network.bind_host</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>transport.publish_host</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The host address to publish for nodes in the cluster to connect to. Defaults to <literal>transport.host</literal> (if set) or <literal>network.publish_host</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>transport.host</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Used to set the <literal>transport.bind_host</literal> and the <literal>transport.publish_host</literal> Defaults to <literal>transport.host</literal> or <literal>network.host</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>transport.tcp.connect_timeout</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The socket connect timeout setting (in
time setting format). Defaults to <literal>30s</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>transport.tcp.compress</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Set to <literal>true</literal> to enable compression (LZF)
between all nodes. Defaults to <literal>false</literal>.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>transport.ping_schedule</literal></simpara></entry>
<entry align="left" valign="top"><simpara>Schedule a regular ping message to ensure that connections are kept alive. Defaults to <literal>5s</literal> in the transport client and <literal>-1</literal> (disabled) elsewhere.</simpara></entry>
</row>
</tbody>
</tgroup>
</informaltable>
<simpara>It also uses the common
<link linkend="modules-network">network settings</link>.</simpara>
<bridgehead id="_tcp_transport_profiles" renderas="sect3">TCP Transport Profiles<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/transport.asciidoc">Edit me</ulink></bridgehead>
<simpara>Elasticsearch allows you to bind to multiple ports on different interfaces by the use of transport profiles. See this example configuration</simpara>
<programlisting language="yaml" linenumbering="unnumbered">transport.profiles.default.port: 9300-9400
transport.profiles.default.bind_host: 10.0.0.1
transport.profiles.client.port: 9500-9600
transport.profiles.client.bind_host: 192.168.0.1
transport.profiles.dmz.port: 9700-9800
transport.profiles.dmz.bind_host: 172.16.1.2</programlisting>
<simpara>The <literal>default</literal> profile is a special. It is used as fallback for any other profiles, if those do not have a specific configuration setting set.
Note that the default profile is how other nodes in the cluster will connect to this node usually. In the future this feature will allow to enable node-to-node communication via multiple interfaces.</simpara>
<simpara>The following parameters can be configured like that</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>port</literal>: The port to bind to
</simpara>
</listitem>
<listitem>
<simpara>
<literal>bind_host</literal>: The host to bind
</simpara>
</listitem>
<listitem>
<simpara>
<literal>publish_host</literal>: The host which is published in informational APIs
</simpara>
</listitem>
<listitem>
<simpara>
<literal>tcp_no_delay</literal>: Configures the <literal>TCP_NO_DELAY</literal> option for this socket
</simpara>
</listitem>
<listitem>
<simpara>
<literal>tcp_keep_alive</literal>: Configures the <literal>SO_KEEPALIVE</literal> option for this socket
</simpara>
</listitem>
<listitem>
<simpara>
<literal>reuse_address</literal>: Configures the <literal>SO_REUSEADDR</literal> option for this socket
</simpara>
</listitem>
<listitem>
<simpara>
<literal>tcp_send_buffer_size</literal>: Configures the send buffer size of the socket
</simpara>
</listitem>
<listitem>
<simpara>
<literal>tcp_receive_buffer_size</literal>: Configures the receive buffer size of the socket
</simpara>
</listitem>
</itemizedlist>
<bridgehead id="_transport_tracer" renderas="sect2">Transport Tracer<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/transport.asciidoc">Edit me</ulink></bridgehead>
<simpara>The transport module has a dedicated tracer logger which, when activated, logs incoming and out going requests. The log can be dynamically activated
by settings the level of the <literal>org.elasticsearch.transport.TransportService.tracer</literal> logger to <literal>TRACE</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XPUT localhost:9200/_cluster/settings -d '{
    "transient" : {
        "logger.org.elasticsearch.transport.TransportService.tracer" : "TRACE"
    }
}'</programlisting>
<simpara>You can also control which actions will be traced, using a set of include and exclude wildcard patterns. By default every request will be traced
except for fault detection pings:</simpara>
<programlisting language="js" linenumbering="unnumbered">curl -XPUT localhost:9200/_cluster/settings -d '{
    "transient" : {
        "transport.tracer.include" : "*"
        "transport.tracer.exclude" : "internal:discovery/zen/fd*"
    }
}'</programlisting>
</chapter>
<chapter id="modules-tribe">
<title>Tribe node<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/tribe.asciidoc">Edit me</ulink></title>
<simpara>The <emphasis>tribes</emphasis> feature allows a <emphasis>tribe node</emphasis> to act as a federated client across
multiple clusters.</simpara>
<simpara>The tribe node works by retrieving the cluster state from all connected
clusters and merging them into a global cluster state. With this information
at hand, it is able to perform read and write operations against the nodes in
all clusters as if they were local. Note that a tribe node needs to be able
to connect to each single node in every configured cluster.</simpara>
<simpara>The <literal>elasticsearch.yml</literal> config file for a tribe node just needs to list the
clusters that should be joined, for instance:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">tribe:
    t1: <co id="CO287-1"/>
        cluster.name:   cluster_one
    t2: <co id="CO287-2"/>
        cluster.name:   cluster_two</programlisting>
<calloutlist>
<callout arearefs="CO287-1 CO287-2">
<para>
<literal>t1</literal> and <literal>t2</literal> are arbitrary names representing the connection to each
    cluster.
</para>
</callout>
</calloutlist>
<simpara>The example above configures connections to two clusters, name <literal>t1</literal> and <literal>t2</literal>
respectively.  The tribe node will create a <link linkend="modules-node">node client</link> to
connect each cluster using <link linkend="unicast">unicast discovery</link> by default. Any
other settings for the connection can be configured under <literal>tribe.{name}</literal>, just
like the <literal>cluster.name</literal> in the example.</simpara>
<simpara>The merged global cluster state means that almost all operations work in the
same way as a single cluster: distributed search, suggest, percolation,
indexing, etc.</simpara>
<simpara>However, there are a few exceptions:</simpara>
<itemizedlist>
<listitem>
<simpara>
The merged view cannot handle indices with the same name in multiple
  clusters. By default it will pick one of them, see later for on_conflict options.
</simpara>
</listitem>
<listitem>
<simpara>
Master level read operations (eg <xref linkend="cluster-state"/>, <xref linkend="cluster-health"/>)
  will automatically execute with a local flag set to true since there is
  no master.
</simpara>
</listitem>
<listitem>
<simpara>
Master level write operations (eg <xref linkend="indices-create-index"/>) are not
  allowed. These should be performed on a single cluster.
</simpara>
</listitem>
</itemizedlist>
<simpara>The tribe node can be configured to block all write operations and all
metadata operations with:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">tribe:
    blocks:
        write:    true
        metadata: true</programlisting>
<simpara>The tribe node can also configure blocks on selected indices:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">tribe:
    blocks:
        write.indices:    hk*,ldn*
        metadata.indices: hk*,ldn*</programlisting>
<simpara>When there is a conflict and multiple clusters hold the same index, by default
the tribe node will pick one of them. This can be configured using the <literal>tribe.on_conflict</literal>
setting. It defaults to <literal>any</literal>, but can be set to <literal>drop</literal> (drop indices that have
a conflict), or <literal>prefer_[tribeName]</literal> to prefer the index from a specific tribe.</simpara>
<bridgehead id="_tribe_node_settings" renderas="sect2">Tribe node settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/modules/tribe.asciidoc">Edit me</ulink></bridgehead>
<simpara>The tribe node starts a node client for each listed cluster.  The following
configuration options are passed down from the tribe node to each node client:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>node.name</literal> (used to derive the <literal>node.name</literal> for each node client)
</simpara>
</listitem>
<listitem>
<simpara>
<literal>network.host</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>network.bind_host</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>network.publish_host</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>transport.host</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>transport.bind_host</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>transport.publish_host</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>path.home</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>path.conf</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>path.logs</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>path.scripts</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>shield.*</literal>
</simpara>
</listitem>
</itemizedlist>
<simpara>Almost any setting (except for <literal>path.*</literal>) may be configured at the node client
level itself, in which case it will override any passed through setting from
the tribe node.  Settings you may want to set at the node client level
include:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>network.host</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>network.bind_host</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>network.publish_host</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>transport.host</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>transport.bind_host</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>transport.publish_host</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>cluster.name</literal>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>discovery.zen.ping.unicast.hosts</literal>
</simpara>
</listitem>
</itemizedlist>
<programlisting language="yaml" linenumbering="unnumbered">path.scripts:   some/path/to/config <co id="CO288-1"/>
network.host:   192.168.1.5 <co id="CO288-2"/>

tribe:
  t1:
    cluster.name:   cluster_one
  t2:
    cluster.name:   cluster_two
    network.host:   10.1.2.3 <co id="CO288-3"/></programlisting>
<calloutlist>
<callout arearefs="CO288-1">
<para>
The <literal>path.scripts</literal> setting is inherited by both <literal>t1</literal> and <literal>t2</literal>.
</para>
</callout>
<callout arearefs="CO288-2">
<para>
The <literal>network.host</literal> setting is inherited by <literal>t1</literal>.
</para>
</callout>
<callout arearefs="CO288-3">
<para>
The <literal>t3</literal> node client overrides the inherited from the tribe node.
</para>
</callout>
</calloutlist>
</chapter>
</part>
<part id="index-modules">
<title>Index Modules <ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules.asciidoc">Edit me</ulink></title>
<partintro>
<simpara>Index Modules are modules created per index and control all aspects related to
an index.</simpara>
<bridgehead id="index-modules-settings" renderas="sect1">Index Settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules.asciidoc">Edit me</ulink></bridgehead>
<simpara>Index level settings can be set per-index.  Settings may be:</simpara>
<variablelist>
<varlistentry>
<term>
<emphasis>static</emphasis>
</term>
<listitem>
<simpara>
They can only be set at index creation time or on a
<link linkend="indices-open-close">closed index</link>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<emphasis>dynamic</emphasis>
</term>
<listitem>
<simpara>
They can be changed on a live index using the
<link linkend="indices-update-settings">update-index-settings</link> API.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<warning><simpara>Changing static or dynamic index settings on a closed index could
result in incorrect settings that are impossible to rectify without deleting
and recreating the index.</simpara></warning>
<bridgehead id="_static_index_settings" renderas="sect2">Static index settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules.asciidoc">Edit me</ulink></bridgehead>
<simpara>Below is a list of all <emphasis>static</emphasis> index settings that are not associated with any
specific index module:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>index.number_of_shards</literal>
</term>
<listitem>
<simpara>
    The number of primary shards that an index should have.  Defaults to 5.
    This setting can only be set at index creation time.  It cannot be
    changed on a closed index. Note: the number of shards are limited to <literal>1024</literal> per
    index. This limitation is a safety limit to prevent accidental creation of indices
    that can destabilize a cluster due to resource allocation. The limit can be modified
    by specifying <literal>export ES_JAVA_OPTS="-Des.index.max_number_of_shards=128"</literal> system property on every node that is
    part of the cluster.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>index.shard.check_on_startup</literal>
</term>
<listitem>
<simpara><phrase role="experimental">This functionality is experimental and may be changed or removed completely in a future release.</phrase> Whether or not shards should be checked for corruption before opening. When
corruption is detected, it will prevent the shard from being opened. Accepts:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>false</literal>
</term>
<listitem>
<simpara>
    (default) Don&#8217;t check for corruption when opening a shard.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>checksum</literal>
</term>
<listitem>
<simpara>
    Check for physical corruption.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>true</literal>
</term>
<listitem>
<simpara>
    Check for both physical and logical corruption. This is much more
    expensive in terms of CPU and memory usage.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>fix</literal>
</term>
<listitem>
<simpara>
    Check for both physical and logical corruption.  Segments that were reported
    as corrupted will be automatically removed. This option <emphasis role="strong">may result in data loss</emphasis>.
    Use with extreme caution!
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>Checking shards may take a lot of time on large indices.</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<anchor id="index-codec" xreflabel="[index-codec]"/> <literal>index.codec</literal>
</term>
<listitem>
<simpara>
    The <literal>default</literal> value compresses stored data with LZ4
    compression, but this can be set to <literal>best_compression</literal>
    which uses <ulink url="https://en.wikipedia.org/wiki/DEFLATE">DEFLATE</ulink> for a higher
    compression ratio, at the expense of slower stored fields performance.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="dynamic-index-settings" renderas="sect2">Dynamic index settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules.asciidoc">Edit me</ulink></bridgehead>
<simpara>Below is a list of all <emphasis>dynamic</emphasis> index settings that are not associated with any
specific index module:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>index.number_of_replicas</literal>
</term>
<listitem>
<simpara>
    The number of replicas each primary shard has.  Defaults to 1.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>index.auto_expand_replicas</literal>
</term>
<listitem>
<simpara>
    Auto-expand the number of replicas based on the number of available nodes.
    Set to a dash delimited lower and upper bound (e.g. <literal>0-5</literal>) or use <literal>all</literal>
    for the upper bound (e.g. <literal>0-all</literal>).  Defaults to <literal>false</literal> (i.e. disabled).
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>index.refresh_interval</literal>
</term>
<listitem>
<simpara>
    How often to perform a refresh operation, which makes recent changes to the
    index visible to search.  Defaults to <literal>1s</literal>.  Can be set to <literal>-1</literal> to disable
    refresh.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>index.max_result_window</literal>
</term>
<listitem>
<simpara>
    The maximum value of <literal>from + size</literal> for searches to this index. Defaults to
    <literal>10000</literal>. Search requests take heap memory and time proportional to
    <literal>from + size</literal> and this limits that memory. See
    <link linkend="search-request-scroll">Scroll</link> or <link linkend="search-request-search-after">Search After</link> for a more efficient alternative
    to raising this.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>index.max_rescore_window</literal>
</term>
<listitem>
<simpara>
    The maximum value of <literal>window_size</literal> for <literal>rescore`s in searches of this index.
    Defaults to `index.max_result_window</literal> which defaults to <literal>10000</literal>. Search
    requests take heap memory and time proportional to
    <literal>max(window_size, from + size)</literal> and this limits that memory.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>index.blocks.read_only</literal>
</term>
<listitem>
<simpara>
    Set to <literal>true</literal> to make the index and index metadata read only, <literal>false</literal> to
    allow writes and metadata changes.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>index.blocks.read</literal>
</term>
<listitem>
<simpara>
    Set to <literal>true</literal> to disable read operations against the index.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>index.blocks.write</literal>
</term>
<listitem>
<simpara>
    Set to <literal>true</literal> to disable write operations against the index.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>index.blocks.metadata</literal>
</term>
<listitem>
<simpara>
    Set to <literal>true</literal> to disable index metadata reads and writes.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>index.max_refresh_listeners</literal>
</term>
<listitem>
<simpara>
    Maximum number of refresh listeners available on each shard of the index.
    These listeners are used to implement <link linkend="docs-refresh"><literal>refresh=wait_for</literal></link>.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_settings_in_other_index_modules" renderas="sect2">Settings in other index modules<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules.asciidoc">Edit me</ulink></bridgehead>
<simpara>Other index settings are available in index modules:</simpara>
<variablelist>
<varlistentry>
<term>
<link linkend="analysis">Analysis</link>
</term>
<listitem>
<simpara>
    Settings to define analyzers, tokenizers, token filters and character
    filters.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="index-modules-allocation">Index shard allocation</link>
</term>
<listitem>
<simpara>
    Control over where, when, and how shards are allocated to nodes.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="index-modules-mapper">Mapping</link>
</term>
<listitem>
<simpara>
    Enable or disable dynamic mapping for an index.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="index-modules-merge">Merging</link>
</term>
<listitem>
<simpara>
    Control over how shards are merged by the background merge process.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="index-modules-similarity">Similarities</link>
</term>
<listitem>
<simpara>
    Configure custom similarity settings to customize how search results are
    scored.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="index-modules-slowlog">Slowlog</link>
</term>
<listitem>
<simpara>
    Control over how slow queries and fetch requests are logged.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="index-modules-store">Store</link>
</term>
<listitem>
<simpara>
    Configure the type of filesystem used to access shard data.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<link linkend="index-modules-translog">Translog</link>
</term>
<listitem>
<simpara>
    Control over the transaction log and background flush operations.
</simpara>
</listitem>
</varlistentry>
</variablelist>
</partintro>
<chapter id="index-modules-analysis">
<title>Analysis<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/analysis.asciidoc">Edit me</ulink></title>
<simpara>The index analysis module acts as a configurable registry of <emphasis>analyzers</emphasis>
that can be used in order to convert a string field into individual terms
which are:</simpara>
<itemizedlist>
<listitem>
<simpara>
added to the inverted index in order to make the document searchable
</simpara>
</listitem>
<listitem>
<simpara>
used by high level queries such as the <link linkend="query-dsl-match-query"><literal>match</literal> query</link>
  to generate search terms.
</simpara>
</listitem>
</itemizedlist>
<simpara>See <xref linkend="analysis"/> for configuration details.</simpara>
</chapter>
<chapter id="index-modules-allocation">
<title>Index Shard Allocation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/allocation.asciidoc">Edit me</ulink></title>
<simpara>This module provides per-index settings to control the allocation of shards to
nodes:</simpara>
<itemizedlist>
<listitem>
<simpara>
<link linkend="shard-allocation-filtering">Shard allocation filtering</link>: Controlling which shards are allocated to which nodes.
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="delayed-allocation">Delayed allocation</link>: Delaying allocation of unassigned shards caused by a node leaving.
</simpara>
</listitem>
<listitem>
<simpara>
<link linkend="allocation-total-shards">Total shards per node</link>: A hard limit on the number of shards from the same index per node.
</simpara>
</listitem>
</itemizedlist>
<section id="shard-allocation-filtering">
<title>Shard Allocation Filtering<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/allocation/filtering.asciidoc">Edit me</ulink></title>
<simpara>Shard allocation filtering allows you to specify which nodes are allowed
to host the shards of a particular index.</simpara>
<note><simpara>The per-index shard allocation filters explained below work in
conjunction with the cluster-wide allocation filters explained in
<xref linkend="shards-allocation"/>.</simpara></note>
<simpara>It is possible to assign arbitrary metadata attributes to each node at
startup.  For instance, nodes could be assigned a <literal>rack</literal> and a <literal>size</literal>
attribute as follows:</simpara>
<programlisting language="sh" linenumbering="unnumbered">bin/elasticsearch -Enode.attr.rack=rack1 -Enode.attr.size=big  <co id="CO289-1"/></programlisting>
<calloutlist>
<callout arearefs="CO289-1">
<para>
These attribute settings can also be specified in the <literal>elasticsearch.yml</literal> config file.
</para>
</callout>
</calloutlist>
<simpara>These metadata attributes can be used with the
<literal>index.routing.allocation.*</literal> settings to allocate an index to a particular
group of nodes.  For instance, we can move the index <literal>test</literal> to either <literal>big</literal> or
<literal>medium</literal> nodes as follows:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT test/_settings
{
  "index.routing.allocation.include.size": "big,medium"
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT test\n/]</remark>
<simpara>Alternatively, we can move the index <literal>test</literal> away from the <literal>small</literal> nodes with
an <literal>exclude</literal> rule:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT test/_settings
{
  "index.routing.allocation.exclude.size": "small"
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT test\n/]</remark>
<simpara>Multiple rules can be specified, in which case all conditions must be
satisfied.  For instance, we could move the index <literal>test</literal> to <literal>big</literal> nodes in
<literal>rack1</literal> with the following:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT test/_settings
{
  "index.routing.allocation.include.size": "big",
  "index.routing.allocation.include.rack": "rack1"
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT test\n/]</remark>
<note><simpara>If some conditions cannot be satisfied then shards will not be moved.</simpara></note>
<simpara>The following settings are <emphasis>dynamic</emphasis>, allowing live indices to be moved from
one set of nodes to another:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>index.routing.allocation.include.{attribute}</literal>
</term>
<listitem>
<simpara>
    Assign the index to a node whose <literal>{attribute}</literal> has at least one of the
    comma-separated values.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>index.routing.allocation.require.{attribute}</literal>
</term>
<listitem>
<simpara>
    Assign the index to a node whose <literal>{attribute}</literal> has <emphasis>all</emphasis> of the
    comma-separated values.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>index.routing.allocation.exclude.{attribute}</literal>
</term>
<listitem>
<simpara>
    Assign the index to a node whose <literal>{attribute}</literal> has <emphasis>none</emphasis> of the
    comma-separated values.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>These special attributes are also supported:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>_name</literal>
</simpara>
</entry>
<entry>
<simpara>
Match nodes by node name
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>_host_ip</literal>
</simpara>
</entry>
<entry>
<simpara>
Match nodes by host IP address (IP associated with hostname)
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>_publish_ip</literal>
</simpara>
</entry>
<entry>
<simpara>
Match nodes by publish IP address
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>_ip</literal>
</simpara>
</entry>
<entry>
<simpara>
Match either <literal>_host_ip</literal> or <literal>_publish_ip</literal>
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>_host</literal>
</simpara>
</entry>
<entry>
<simpara>
Match nodes by hostname
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>All attribute values can be specified with wildcards, eg:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT test/_settings
{
  "index.routing.allocation.include._ip": "192.168.2.*"
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[skip:indexes don't assign]</remark>
</section>
<section id="delayed-allocation">
<title>Delaying allocation when a node leaves<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/allocation/delayed.asciidoc">Edit me</ulink></title>
<simpara>When a node leaves the cluster for whatever reason, intentional or otherwise,
the master reacts by:</simpara>
<itemizedlist>
<listitem>
<simpara>
Promoting a replica shard to primary to replace any primaries that were on the node.
</simpara>
</listitem>
<listitem>
<simpara>
Allocating replica shards to replace the missing replicas (assuming there are enough nodes).
</simpara>
</listitem>
<listitem>
<simpara>
Rebalancing shards evenly across the remaining nodes.
</simpara>
</listitem>
</itemizedlist>
<simpara>These actions are intended to protect the cluster against data loss by
ensuring that every shard is fully replicated as soon as possible.</simpara>
<simpara>Even though we throttle concurrent recoveries both at the
<link linkend="recovery">node level</link> and at the <link linkend="shards-allocation">cluster level</link>, this
&#8220;shard-shuffle&#8221; can still put a lot of extra load on the cluster which
may not be necessary if the missing node is likely to return soon. Imagine
this scenario:</simpara>
<itemizedlist>
<listitem>
<simpara>
Node 5 loses network connectivity.
</simpara>
</listitem>
<listitem>
<simpara>
The master promotes a replica shard to primary for each primary that was on Node 5.
</simpara>
</listitem>
<listitem>
<simpara>
The master allocates new replicas to other nodes in the cluster.
</simpara>
</listitem>
<listitem>
<simpara>
Each new replica makes an entire copy of the primary shard across the network.
</simpara>
</listitem>
<listitem>
<simpara>
More shards are moved to different nodes to rebalance the cluster.
</simpara>
</listitem>
<listitem>
<simpara>
Node 5 returns after a few minutes.
</simpara>
</listitem>
<listitem>
<simpara>
The master rebalances the cluster by allocating shards to Node 5.
</simpara>
</listitem>
</itemizedlist>
<simpara>If the master had just waited for a few minutes, then the missing shards could
have been re-allocated to Node 5 with the minimum of network traffic.  This
process would be even quicker for idle shards (shards not receiving indexing
requests) which have been automatically <link linkend="indices-synced-flush">sync-flushed</link>.</simpara>
<simpara>The allocation of replica shards which become unassigned because a node has
left can be delayed with the <literal>index.unassigned.node_left.delayed_timeout</literal>
dynamic setting, which defaults to <literal>1m</literal>.</simpara>
<simpara>This setting can be updated on a live index (or on all indices):</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT _all/_settings
{
  "settings": {
    "index.unassigned.node_left.delayed_timeout": "5m"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT test\n/]</remark>
<simpara>With delayed allocation enabled, the above scenario changes to look like this:</simpara>
<itemizedlist>
<listitem>
<simpara>
Node 5 loses network connectivity.
</simpara>
</listitem>
<listitem>
<simpara>
The master promotes a replica shard to primary for each primary that was on Node 5.
</simpara>
</listitem>
<listitem>
<simpara>
The master logs a message that allocation of unassigned shards has been delayed, and for how long.
</simpara>
</listitem>
<listitem>
<simpara>
The cluster remains yellow because there are unassigned replica shards.
</simpara>
</listitem>
<listitem>
<simpara>
Node 5 returns after a few minutes, before the <literal>timeout</literal> expires.
</simpara>
</listitem>
<listitem>
<simpara>
The missing replicas are re-allocated to Node 5 (and sync-flushed shards recover almost immediately).
</simpara>
</listitem>
</itemizedlist>
<note><simpara>This setting will not affect the promotion of replicas to primaries, nor
will it affect the assignment of replicas that have not been assigned
previously. In particular, delayed allocation does not come into effect after a full cluster restart.
Also, in case of a master failover situation, elapsed delay time is forgotten
(i.e. reset to the full initial delay).</simpara></note>
<section id="_cancellation_of_shard_relocation">
<title>Cancellation of shard relocation<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/allocation/delayed.asciidoc">Edit me</ulink></title>
<simpara>If delayed allocation times out, the master assigns the missing shards to
another node which will start recovery.  If the missing node rejoins the
cluster, and its shards still have the same sync-id as the primary, shard
relocation will be cancelled and the synced shard will be used for recovery
instead.</simpara>
<simpara>For this reason, the default <literal>timeout</literal> is set to just one minute: even if shard
relocation begins, cancelling recovery in favour of the synced shard is cheap.</simpara>
</section>
<section id="_monitoring_delayed_unassigned_shards">
<title>Monitoring delayed unassigned shards<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/allocation/delayed.asciidoc">Edit me</ulink></title>
<simpara>The number of shards whose allocation has been delayed by this timeout setting
can be viewed with the <link linkend="cluster-health">cluster health API</link>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _cluster/health <co id="CO290-1"/></programlisting>
<remark> CONSOLE</remark>
<calloutlist>
<callout arearefs="CO290-1">
<para>
This request will return a <literal>delayed_unassigned_shards</literal> value.
</para>
</callout>
</calloutlist>
</section>
<section id="_removing_a_node_permanently">
<title>Removing a node permanently<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/allocation/delayed.asciidoc">Edit me</ulink></title>
<simpara>If a node is not going to return and you would like Elasticsearch to allocate
the missing shards immediately, just update the timeout to zero:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT _all/_settings
{
  "settings": {
    "index.unassigned.node_left.delayed_timeout": "0"
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[s/^/PUT test\n/]</remark>
<simpara>You can reset the timeout as soon as the missing shards have started to recover.</simpara>
</section>
</section>
<section id="recovery-prioritization">
<title>Index recovery prioritization<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/allocation/prioritization.asciidoc">Edit me</ulink></title>
<simpara>Unallocated shards are recovered in order of priority, whenever possible.
Indices are sorted into priority order as follows:</simpara>
<itemizedlist>
<listitem>
<simpara>
the optional <literal>index.priority</literal> setting (higher before lower)
</simpara>
</listitem>
<listitem>
<simpara>
the index creation date (higher before lower)
</simpara>
</listitem>
<listitem>
<simpara>
the index name (higher before lower)
</simpara>
</listitem>
</itemizedlist>
<simpara>This means that, by default, newer indices will be recovered before older indices.</simpara>
<simpara>Use the per-index dynamically updateable <literal>index.priority</literal> setting to customise
the index prioritization order.  For instance:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT index_1

PUT index_2

PUT index_3
{
  "settings": {
    "index.priority": 10
  }
}

PUT index_4
{
  "settings": {
    "index.priority": 5
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>In the above example:</simpara>
<itemizedlist>
<listitem>
<simpara>
<literal>index_3</literal> will be recovered first because it has the highest <literal>index.priority</literal>.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>index_4</literal> will be recovered next because it has the next highest priority.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>index_2</literal> will be recovered next because it was created more recently.
</simpara>
</listitem>
<listitem>
<simpara>
<literal>index_1</literal> will be recovered last.
</simpara>
</listitem>
</itemizedlist>
<simpara>This setting accepts an integer, and can be updated on a live index with the
<link linkend="indices-update-settings">update index settings API</link>:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT index_4/_settings
{
  "index.priority": 1
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
</section>
<section id="allocation-total-shards">
<title>Total Shards Per Node<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/allocation/total_shards.asciidoc">Edit me</ulink></title>
<simpara>The cluster-level shard allocator tries to spread the shards of a single index
across as many nodes as possible.  However, depending on how many shards and
indices you have, and how big they are, it may not always be possible to spread
shards evenly.</simpara>
<simpara>The following <emphasis>dynamic</emphasis> setting allows you to specify a hard limit on the total
number of shards from a single index allowed per node:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>index.routing.allocation.total_shards_per_node</literal>
</term>
<listitem>
<simpara>
    The maximum number of shards (replicas and primaries) that will be
    allocated to a single node.  Defaults to unbounded.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>You can also limit the amount of shards a node can have regardless of the index:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>cluster.routing.allocation.total_shards_per_node</literal>
</term>
<listitem>
<simpara>
    The maximum number of shards (replicas and primaries) that will be
    allocated to a single node globally.  Defaults to unbounded (-1).
</simpara>
</listitem>
</varlistentry>
</variablelist>
<warning>
<simpara>These settings impose a hard limit which can result in some shards not being
allocated.</simpara>
<simpara>Use with caution.</simpara>
</warning>
</section>
</chapter>
<chapter id="index-modules-mapper">
<title>Mapper<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/mapper.asciidoc">Edit me</ulink></title>
<simpara>The mapper module acts as a registry for the type mapping definitions
added to an index either when creating it or by using the put mapping
api. It also handles the dynamic mapping support for types that have no
explicit mappings pre defined. For more information about mapping
definitions, check out the <link linkend="mapping">mapping section</link>.</simpara>
</chapter>
<chapter id="index-modules-merge">
<title>Merge<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/merge.asciidoc">Edit me</ulink></title>
<simpara>A shard in elasticsearch is a Lucene index, and a Lucene index is broken down
into segments. Segments are internal storage elements in the index where the
index data is stored, and are immutable. Smaller segments are periodically
merged into larger segments to keep the index size at bay and to expunge
deletes.</simpara>
<simpara>The merge process uses auto-throttling to balance the use of hardware
resources between merging and other activities like search.</simpara>
<bridgehead id="merge-scheduling" renderas="sect2">Merge scheduling<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/merge.asciidoc">Edit me</ulink></bridgehead>
<simpara>The merge scheduler (ConcurrentMergeScheduler) controls the execution of merge
operations when they are needed.  Merges run in separate threads, and when the
maximum number of threads is reached, further merges will wait until a merge
thread becomes available.</simpara>
<simpara>The merge scheduler supports the following <emphasis>dynamic</emphasis> setting:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>index.merge.scheduler.max_thread_count</literal>
</term>
<listitem>
<simpara>
    The maximum number of threads that may be merging at once. Defaults to
    <literal>Math.max(1, Math.min(4, Runtime.getRuntime().availableProcessors() / 2))</literal>
    which works well for a good solid-state-disk (SSD).  If your index is on
    spinning platter drives instead, decrease this to 1.
</simpara>
</listitem>
</varlistentry>
</variablelist>
</chapter>
<chapter id="index-modules-similarity">
<title>Similarity module<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/similarity.asciidoc">Edit me</ulink></title>
<simpara>A similarity (scoring / ranking model) defines how matching documents
are scored. Similarity is per field, meaning that via the mapping one
can define a different similarity per field.</simpara>
<simpara>Configuring a custom similarity is considered a expert feature and the
builtin similarities are most likely sufficient as is described in
<xref linkend="similarity"/>.</simpara>
<bridgehead id="configuration" renderas="sect2">Configuring a similarity<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/similarity.asciidoc">Edit me</ulink></bridgehead>
<simpara>Most existing or custom Similarities have configuration options which
can be configured via the index settings as shown below. The index
options can be provided when creating an index or updating index
settings.</simpara>
<programlisting language="js" linenumbering="unnumbered">"similarity" : {
  "my_similarity" : {
    "type" : "DFR",
    "basic_model" : "g",
    "after_effect" : "l",
    "normalization" : "h2",
    "normalization.h2.c" : "3.0"
  }
}</programlisting>
<simpara>Here we configure the DFRSimilarity so it can be referenced as
<literal>my_similarity</literal> in mappings as is illustrate in the below example:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "book" : {
    "properties" : {
      "title" : { "type" : "text", "similarity" : "my_similarity" }
    }
}</programlisting>
<bridgehead id="_available_similarities" renderas="sect2">Available similarities<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/similarity.asciidoc">Edit me</ulink></bridgehead>
<bridgehead id="bm25" renderas="sect3">BM25 similarity (<emphasis role="strong">default</emphasis>)<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/similarity.asciidoc">Edit me</ulink></bridgehead>
<simpara>TF/IDF based similarity that has built-in tf normalization and
is supposed to work better for short fields (like names). See
<ulink url="http://en.wikipedia.org/wiki/Okapi_BM25">Okapi_BM25</ulink> for more details.
This similarity has the following options:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>k1</literal>
</simpara>
</entry>
<entry>
<simpara>
    Controls non-linear term frequency normalization
    (saturation). The default value is <literal>1.2</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>b</literal>
</simpara>
</entry>
<entry>
<simpara>
    Controls to what degree document length normalizes tf values.
    The default value is <literal>0.75</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>discount_overlaps</literal>
</simpara>
</entry>
<entry>
<simpara>
    Determines whether overlap tokens (Tokens with
    0 position increment) are ignored when computing norm. By default this
    is true, meaning overlap tokens do not count when computing norms.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>Type name: <literal>BM25</literal></simpara>
<bridgehead id="classic-similarity" renderas="sect3">Classic similarity<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/similarity.asciidoc">Edit me</ulink></bridgehead>
<simpara>The classic similarity that is based on the TF/IDF model. This
similarity has the following option:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>discount_overlaps</literal>
</term>
<listitem>
<simpara>
    Determines whether overlap tokens (Tokens with
    0 position increment) are ignored when computing norm. By default this
    is true, meaning overlap tokens do not count when computing norms.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<simpara>Type name: <literal>classic</literal></simpara>
<bridgehead id="drf" renderas="sect3">DFR similarity<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/similarity.asciidoc">Edit me</ulink></bridgehead>
<simpara>Similarity that implements the
<ulink url="http://lucene.apache.org/core/5_2_1/core/org/apache/lucene/search/similarities/DFRSimilarity.html">divergence
from randomness</ulink> framework. This similarity has the following options:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>basic_model</literal>
</simpara>
</entry>
<entry>
<simpara>
    Possible values: <literal>be</literal>, <literal>d</literal>, <literal>g</literal>, <literal>if</literal>, <literal>in</literal>, <literal>ine</literal> and <literal>p</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>after_effect</literal>
</simpara>
</entry>
<entry>
<simpara>
    Possible values: <literal>no</literal>, <literal>b</literal> and <literal>l</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>normalization</literal>
</simpara>
</entry>
<entry>
<simpara>
    Possible values: <literal>no</literal>, <literal>h1</literal>, <literal>h2</literal>, <literal>h3</literal> and <literal>z</literal>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>All options but the first option need a normalization value.</simpara>
<simpara>Type name: <literal>DFR</literal></simpara>
<bridgehead id="dfi" renderas="sect3">DFI similarity<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/similarity.asciidoc">Edit me</ulink></bridgehead>
<simpara>Similarity that implements the <ulink url="http://trec.nist.gov/pubs/trec21/papers/irra.web.nb.pdf">divergence from independence</ulink>
model.
This similarity has the following options:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>independence_measure</literal>
</simpara>
</entry>
<entry>
<simpara>
Possible values <literal>standardized</literal>, <literal>saturated</literal>, <literal>chisquared</literal>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>Type name: <literal>DFI</literal></simpara>
<bridgehead id="ib" renderas="sect3">IB similarity.<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/similarity.asciidoc">Edit me</ulink></bridgehead>
<simpara><ulink url="http://lucene.apache.org/core/5_2_1/core/org/apache/lucene/search/similarities/IBSimilarity.html">Information
based model</ulink> . The algorithm is based on the concept that the information content in any symbolic <emphasis>distribution</emphasis>
sequence is primarily determined by the repetitive usage of its basic elements.
For written texts this challenge would correspond to comparing the writing styles of different authors.
This similarity has the following options:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>distribution</literal>
</simpara>
</entry>
<entry>
<simpara>
Possible values: <literal>ll</literal> and <literal>spl</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>lambda</literal>
</simpara>
</entry>
<entry>
<simpara>
Possible values: <literal>df</literal> and <literal>ttf</literal>.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>normalization</literal>
</simpara>
</entry>
<entry>
<simpara>
Same as in <literal>DFR</literal> similarity.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>Type name: <literal>IB</literal></simpara>
<bridgehead id="lm_dirichlet" renderas="sect3">LM Dirichlet similarity.<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/similarity.asciidoc">Edit me</ulink></bridgehead>
<simpara><ulink url="http://lucene.apache.org/core/5_2_1/core/org/apache/lucene/search/similarities/LMDirichletSimilarity.html">LM
Dirichlet similarity</ulink> . This similarity has the following options:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>mu</literal>
</simpara>
</entry>
<entry>
<simpara>
Default to <literal>2000</literal>.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>Type name: <literal>LMDirichlet</literal></simpara>
<bridgehead id="lm_jelinek_mercer" renderas="sect3">LM Jelinek Mercer similarity.<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/similarity.asciidoc">Edit me</ulink></bridgehead>
<simpara><ulink url="http://lucene.apache.org/core/5_2_1/core/org/apache/lucene/search/similarities/LMJelinekMercerSimilarity.html">LM
Jelinek Mercer similarity</ulink> . The algorithm attempts to capture important patterns in the text, while leaving out noise. This similarity has the following options:</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>lambda</literal>
</simpara>
</entry>
<entry>
<simpara>
The optimal value depends on both the collection and the query. The optimal value is around <literal>0.1</literal>
for title queries and <literal>0.7</literal> for long queries. Default to <literal>0.1</literal>. When value approaches <literal>0</literal>, documents that match more query terms will be ranked higher than those that match fewer terms.
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>Type name: <literal>LMJelinekMercer</literal></simpara>
<bridgehead id="default-base" renderas="sect3">Default and Base Similarities<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/similarity.asciidoc">Edit me</ulink></bridgehead>
<simpara>By default, Elasticsearch will use whatever similarity is configured as
<literal>default</literal>. However, the similarity functions <literal>queryNorm()</literal> and <literal>coord()</literal>
are not per-field. Consequently, for expert users wanting to change the
implementation used for these two methods, while not changing the
<literal>default</literal>, it is possible to configure a similarity with the name
<literal>base</literal>. This similarity will then be used for the two methods.</simpara>
<simpara>You can change the default similarity for all fields in an index when
it is <link linkend="indices-create-index">created</link>:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /my_index
{
  "settings": {
    "index": {
      "similarity": {
        "default": {
          "type": "classic"
        }
      }
    }
  }
}</programlisting>
<simpara>If you want to change the default similarity after creating the index
you must <link linkend="indices-open-close">close</link> your index, send the follwing
request and <link linkend="indices-open-close">open</link> it again afterwards:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /my_index/_settings
{
  "settings": {
    "index": {
      "similarity": {
        "default": {
          "type": "classic"
        }
      }
    }
  }
}</programlisting>
</chapter>
<chapter id="index-modules-slowlog">
<title>Slow Log<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/slowlog.asciidoc">Edit me</ulink></title>
<bridgehead id="search-slow-log" renderas="sect2">Search Slow Log<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/slowlog.asciidoc">Edit me</ulink></bridgehead>
<simpara>Shard level slow search log allows to log slow search (query and fetch
phases) into a dedicated log file.</simpara>
<simpara>Thresholds can be set for both the query phase of the execution, and
fetch phase, here is a sample:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">index.search.slowlog.threshold.query.warn: 10s
index.search.slowlog.threshold.query.info: 5s
index.search.slowlog.threshold.query.debug: 2s
index.search.slowlog.threshold.query.trace: 500ms

index.search.slowlog.threshold.fetch.warn: 1s
index.search.slowlog.threshold.fetch.info: 800ms
index.search.slowlog.threshold.fetch.debug: 500ms
index.search.slowlog.threshold.fetch.trace: 200ms</programlisting>
<simpara>All of the above settings are <emphasis>dynamic</emphasis> and are set per-index.</simpara>
<simpara>By default, none are enabled (set to <literal>-1</literal>). Levels (<literal>warn</literal>, <literal>info</literal>,
<literal>debug</literal>, <literal>trace</literal>) allow to control under which logging level the log
will be logged. Not all are required to be configured (for example, only
<literal>warn</literal> threshold can be set). The benefit of several levels is the
ability to quickly "grep" for specific thresholds breached.</simpara>
<simpara>The logging is done on the shard level scope, meaning the execution of a
search request within a specific shard. It does not encompass the whole
search request, which can be broadcast to several shards in order to
execute. Some of the benefits of shard level logging is the association
of the actual execution on the specific machine, compared with request
level.</simpara>
<simpara>The logging file is configured by default using the following
configuration (found in <literal>log4j2.properties</literal>):</simpara>
<programlisting language="properties" linenumbering="unnumbered">appender.index_search_slowlog_rolling.type = RollingFile
appender.index_search_slowlog_rolling.name = index_search_slowlog_rolling
appender.index_search_slowlog_rolling.fileName = ${sys:es.logs}_index_search_slowlog.log
appender.index_search_slowlog_rolling.layout.type = PatternLayout
appender.index_search_slowlog_rolling.layout.pattern = [%d{ISO8601}][%-5p][%-25c] %.10000m%n
appender.index_search_slowlog_rolling.filePattern = ${sys:es.logs}_index_search_slowlog-%d{yyyy-MM-dd}.log
appender.index_search_slowlog_rolling.policies.type = Policies
appender.index_search_slowlog_rolling.policies.time.type = TimeBasedTriggeringPolicy
appender.index_search_slowlog_rolling.policies.time.interval = 1
appender.index_search_slowlog_rolling.policies.time.modulate = true

logger.index_search_slowlog_rolling.name = index.search.slowlog
logger.index_search_slowlog_rolling.level = trace
logger.index_search_slowlog_rolling.appenderRef.index_search_slowlog_rolling.ref = index_search_slowlog_rolling
logger.index_search_slowlog_rolling.additivity = false</programlisting>
<bridgehead id="index-slow-log" renderas="sect2">Index Slow log<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/slowlog.asciidoc">Edit me</ulink></bridgehead>
<simpara>The indexing slow log, similar in functionality to the search slow
log. The log file name ends with <literal>_index_indexing_slowlog.log</literal>. Log and
the thresholds are configured in the same way as the search slowlog.
Index slowlog sample:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">index.indexing.slowlog.threshold.index.warn: 10s
index.indexing.slowlog.threshold.index.info: 5s
index.indexing.slowlog.threshold.index.debug: 2s
index.indexing.slowlog.threshold.index.trace: 500ms
index.indexing.slowlog.level: info
index.indexing.slowlog.source: 1000</programlisting>
<simpara>All of the above settings are <emphasis>dynamic</emphasis> and are set per-index.</simpara>
<simpara>By default Elasticsearch will log the first 1000 characters of the _source in
the slowlog. You can change that with <literal>index.indexing.slowlog.source</literal>. Setting
it to <literal>false</literal> or <literal>0</literal> will skip logging the source entirely an setting it to
<literal>true</literal> will log the entire source regardless of size.</simpara>
<simpara>The index slow log file is configured by default in the <literal>log4j2.properties</literal>
file:</simpara>
<programlisting language="properties" linenumbering="unnumbered">appender.index_indexing_slowlog_rolling.type = RollingFile
appender.index_indexing_slowlog_rolling.name = index_indexing_slowlog_rolling
appender.index_indexing_slowlog_rolling.fileName = ${sys:es.logs}_index_indexing_slowlog.log
appender.index_indexing_slowlog_rolling.layout.type = PatternLayout
appender.index_indexing_slowlog_rolling.layout.pattern = [%d{ISO8601}][%-5p][%-25c] %marker%.10000m%n
appender.index_indexing_slowlog_rolling.filePattern = ${sys:es.logs}_index_indexing_slowlog-%d{yyyy-MM-dd}.log
appender.index_indexing_slowlog_rolling.policies.type = Policies
appender.index_indexing_slowlog_rolling.policies.time.type = TimeBasedTriggeringPolicy
appender.index_indexing_slowlog_rolling.policies.time.interval = 1
appender.index_indexing_slowlog_rolling.policies.time.modulate = true

logger.index_indexing_slowlog.name = index.indexing.slowlog.index
logger.index_indexing_slowlog.level = trace
logger.index_indexing_slowlog.appenderRef.index_indexing_slowlog_rolling.ref = index_indexing_slowlog_rolling
logger.index_indexing_slowlog.additivity = false</programlisting>
</chapter>
<chapter id="index-modules-store">
<title>Store<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/store.asciidoc">Edit me</ulink></title>
<simpara>The store module allows you to control how index data is stored and accessed on disk.</simpara>
<bridgehead id="file-system" renderas="sect2">File system storage types<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/store.asciidoc">Edit me</ulink></bridgehead>
<simpara>There are different file system implementations or <emphasis>storage types</emphasis>. By default,
elasticsearch will pick the best implementation based on the operating
environment.</simpara>
<simpara>This can be overridden for all indices by adding this to the
<literal>config/elasticsearch.yml</literal> file:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">index.store.type: niofs</programlisting>
<simpara>It is a <emphasis>static</emphasis> setting that can be set on a per-index basis at index
creation time:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /my_index
{
  "settings": {
    "index.store.type": "niofs"
  }
}</programlisting>
<warning role="experimental"><simpara>This is an expert-only setting and may be removed in the future.</simpara></warning>
<simpara>The following sections lists all the different storage types supported.</simpara>
<variablelist>
<varlistentry>
<term>
<literal>fs</literal>
</term>
<listitem>
<simpara>
Default file system implementation. This will pick the best implementation
depending on the operating environment: <literal>simplefs</literal> on Windows 32bit, <literal>niofs</literal>
on other 32bit systems and <literal>mmapfs</literal> on 64bit systems.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<anchor id="simplefs" xreflabel="[simplefs]"/><literal>simplefs</literal>
</term>
<listitem>
<simpara>
The Simple FS type is a straightforward implementation of file system
storage (maps to Lucene <literal>SimpleFsDirectory</literal>) using a random access file.
This implementation has poor concurrent performance (multiple threads
will bottleneck). It is usually better to use the <literal>niofs</literal> when you need
index persistence.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<anchor id="niofs" xreflabel="[niofs]"/><literal>niofs</literal>
</term>
<listitem>
<simpara>
The NIO FS type stores the shard index on the file system (maps to
Lucene <literal>NIOFSDirectory</literal>) using NIO. It allows multiple threads to read
from the same file concurrently. It is not recommended on Windows
because of a bug in the SUN Java implementation.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<anchor id="mmapfs" xreflabel="[mmapfs]"/><literal>mmapfs</literal>
</term>
<listitem>
<simpara>
The MMap FS type stores the shard index on the file system (maps to
Lucene <literal>MMapDirectory</literal>) by mapping a file into memory (mmap). Memory
mapping uses up a portion of the virtual memory address space in your
process equal to the size of the file being mapped. Before using this
class, be sure you have allowed plenty of
<link linkend="vm-max-map-count">virtual address space</link>.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<anchor id="default_fs" xreflabel="[default_fs]"/><literal>default_fs</literal> <phrase revisionflag="deleted" revision="5.0.0">Deprecated in 5.0.0. The <literal>default_fs</literal> store type is deprecated - use <literal>fs</literal> instead.</phrase>
</term>
<listitem>
<simpara>
The <literal>default</literal> type is deprecated and is aliased to <literal>fs</literal> for backward
compatibility.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<section id="_pre_loading_data_into_the_file_system_cache">
<title>Pre-loading data into the file system cache<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/store.asciidoc">Edit me</ulink></title>
<warning role="experimental"><simpara>This is an expert-only setting and may be removed in the future.</simpara></warning>
<simpara>By default, elasticsearch completely relies on the operating system file system
cache for caching I/O operations. It is possible to set <literal>index.store.preload</literal>
in order to tell the operating system to load the content of hot index
files into memory upon opening. This setting accept a comma-separated list of
files extensions: all files whose extension is in the list will be pre-loaded
upon opening. This can be useful to improve search performance of an index,
especially when the host operating system is restarted, since this causes the
file system cache to be trashed. However note that this may slow down the
opening of indices, as they will only become available after data have been
loaded into physical memory.</simpara>
<simpara>This setting is best-effort only and may not work at all depending on the store
type and host operating system.</simpara>
<simpara>The <literal>index.store.preload</literal> is a static setting that can either be set in the
<literal>config/elasticsearch.yml</literal>:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">index.store.preload: ["nvd", "dvd"]</programlisting>
<simpara>or in the index settings at index creation time:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /my_index
{
  "settings": {
    "index.store.preload": ["nvd", "dvd"]
  }
}</programlisting>
<simpara>The default value is the empty array, which means that nothing will be loaded
into the file-system cache eagerly. For indices that are actively searched,
you might want to set it to <literal>["nvd", "dvd"]</literal>, which will cause norms and doc
values to be loaded eagerly into physical memory. These are the two first
extensions to look at since elasticsearch performs random access on them.</simpara>
<simpara>A wildcard can be used in order to indicate that all files should be preloaded:
<literal>index.store.preload: ["*"]</literal>. Note however that it is generally not useful to
load all files into memory, in particular those for stored fields and term
vectors, so a better option might be to set it to
<literal>["nvd", "dvd", "tim", "doc", "dim"]</literal>, which will preload norms, doc values,
terms dictionaries, postings lists and points, which are the most important
parts of the index for search and aggregations.</simpara>
<simpara>Note that this setting can be dangerous on indices that are larger than the size
of the main memory of the host, as it would cause the filesystem cache to be
trashed upon reopens after large merges, which would make indexing and searching
<emphasis>slower</emphasis>.</simpara>
</section>
</chapter>
<chapter id="index-modules-translog">
<title>Translog<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/translog.asciidoc">Edit me</ulink></title>
<simpara>Changes to Lucene are only persisted to disk during a Lucene commit,
which is a relatively heavy operation and so cannot be performed after every
index or delete operation. Changes that happen after one commit and before another
will be lost in the event of process exit or HW failure.</simpara>
<simpara>To prevent this data loss, each shard has a <emphasis>transaction log</emphasis> or write ahead
log associated with it. Any index or delete operation is written to the
translog after being processed by the internal Lucene index.</simpara>
<simpara>In the event of a crash, recent transactions can be replayed from the
transaction log when the shard recovers.</simpara>
<simpara>An Elasticsearch flush is the process of performing a Lucene commit and
starting a new translog. It is done automatically in the background in order
to make sure the transaction log doesn&#8217;t grow too large, which would make
replaying its operations take a considerable amount of time during recovery.
It is also exposed through an API, though its rarely needed to be performed
manually.</simpara>
<bridgehead id="_flush_settings" renderas="sect2">Flush settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/translog.asciidoc">Edit me</ulink></bridgehead>
<simpara>The following <link linkend="indices-update-settings">dynamically updatable</link> settings
control how often the in-memory buffer is flushed to disk:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>index.translog.flush_threshold_size</literal>
</term>
<listitem>
<simpara>
Once the translog hits this size, a flush will happen. Defaults to <literal>512mb</literal>.
</simpara>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="_translog_settings_2" renderas="sect2">Translog settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/translog.asciidoc">Edit me</ulink></bridgehead>
<simpara>The data in the transaction log is only persisted to disk when the translog is
<literal>fsync</literal>ed and committed.  In the event of hardware failure, any data written
since the previous translog commit will be lost.</simpara>
<simpara>By default, Elasticsearch <literal>fsync</literal>s and commits the translog every 5 seconds if <literal>index.translog.durability</literal> is set
to <literal>async</literal> or if set to <literal>request</literal> (default) at the end of every <link linkend="docs-index_">index</link>, <link linkend="docs-delete">delete</link>,
<link linkend="docs-update">update</link>, or  <link linkend="docs-bulk">bulk</link> request.  In fact, Elasticsearch
will only report success of an index, delete, update, or bulk request to the
client after the transaction log has been successfully <literal>fsync</literal>ed and committed
on the primary and on every allocated replica.</simpara>
<simpara>The following <link linkend="indices-update-settings">dynamically updatable</link> per-index settings
control the behaviour of the transaction log:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>index.translog.sync_interval</literal>
</term>
<listitem>
<simpara>
How often the translog is <literal>fsync</literal>ed to disk and committed, regardless of
write operations. Defaults to <literal>5s</literal>. Values less than <literal>100ms</literal> are not allowed.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>index.translog.durability</literal>
</term>
<listitem>
<simpara>Whether or not to <literal>fsync</literal> and commit the translog after every index, delete,
update, or bulk request.  This setting accepts the following parameters:</simpara>
<variablelist>
<varlistentry>
<term>
<literal>request</literal>
</term>
<listitem>
<simpara>
    (default) <literal>fsync</literal> and commit after every request. In the event
    of hardware failure, all acknowledged writes will already have been
    committed to disk.
</simpara>
</listitem>
</varlistentry>
<varlistentry>
<term>
<literal>async</literal>
</term>
<listitem>
<simpara>
    <literal>fsync</literal> and commit in the background every <literal>sync_interval</literal>. In
    the event of hardware failure, all acknowledged writes since the last
    automatic commit will be discarded.
</simpara>
</listitem>
</varlistentry>
</variablelist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="corrupt-translog-truncation" renderas="sect2">What to do if the translog becomes corrupted?<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/index-modules/translog.asciidoc">Edit me</ulink></bridgehead>
<simpara>In some cases (a bad drive, user error) the translog can become corrupted. When
this corruption is detected by Elasticsearch due to mismatching checksums,
Elasticsearch will fail the shard and refuse to allocate that copy of the data
to the node, recovering from a replica if available.</simpara>
<simpara>If there is no copy of the data from which Elasticsearch can recover
successfully, a user may want to recover the data that is part of the shard at
the cost of losing the data that is currently contained in the translog. We
provide a command-line tool for this, <literal>elasticsearch-translog</literal>.</simpara>
<warning><simpara>The <literal>elasticsearch-translog</literal> tool should <emphasis role="strong">not</emphasis> be run while Elasticsearch is
running, and you will permanently lose the documents that were contained only in
the translog!</simpara></warning>
<simpara>In order to run the <literal>elasticsearch-translog</literal> tool, specify the <literal>truncate</literal>
subcommand as well as the directory for the corrupted translog with the <literal>-d</literal>
option:</simpara>
<programlisting language="js" linenumbering="unnumbered">$ bin/elasticsearch-translog truncate -d /var/lib/elasticsearchdata/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/
Checking existing translog files
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
!   WARNING: Elasticsearch MUST be stopped before running this tool   !
!                                                                     !
!   WARNING:    Documents inside of translog files will be lost       !
!                                                                     !
!   WARNING:          The following files will be DELETED!            !
!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
--&gt; data/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/translog-41.ckp
--&gt; data/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/translog-6.ckp
--&gt; data/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/translog-37.ckp
--&gt; data/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/translog-24.ckp
--&gt; data/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/translog-11.ckp

Continue and DELETE files? [y/N] y
Reading translog UUID information from Lucene commit from shard at [data/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/index]
Translog Generation: 3
Translog UUID      : AxqC4rocTC6e0fwsljAh-Q
Removing existing translog files
Creating new empty checkpoint at [data/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/translog.ckp]
Creating new empty translog at [data/nodes/0/indices/P45vf_YQRhqjfwLMUvSqDw/0/translog/translog-3.tlog]
Done.</programlisting>
<simpara>You can also use the <literal>-h</literal> option to get a list of all options and parameters
that the <literal>elasticsearch-translog</literal> tool supports.</simpara>
</chapter>
</part>
<part id="ingest">
<title>Ingest Node <ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest.asciidoc">Edit me</ulink></title>
<partintro>
<simpara>You can use ingest node to pre-process documents before the actual indexing takes place.
This pre-processing happens by an ingest node that intercepts bulk and index requests, applies the
transformations, and then passes the documents back to the index or bulk APIs.</simpara>
<simpara>You can enable ingest on any node or even have dedicated ingest nodes. Ingest is enabled by default
on all nodes. To disable ingest on a node, configure the following setting in the <literal>elasticsearch.yml</literal> file:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">node.ingest: false</programlisting>
<simpara>To pre-process documents before indexing, you <link linkend="pipeline">define a pipeline</link> that specifies
a series of <link linkend="ingest-processors">processors</link>. Each processor transforms the document in some way.
For example, you may have a pipeline that consists of one processor that removes a field from
the document followed by another processor that renames a field.</simpara>
<simpara>To use a pipeline, you simply specify the <literal>pipeline</literal> parameter on an index or bulk request to
tell the ingest node which pipeline to use. For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT my-index/my-type/my-id?pipeline=my_pipeline_id
{
  "foo": "bar"
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[catch:request]</remark>
<simpara>See <link linkend="ingest-apis">Ingest APIs</link> for more information about creating, adding, and deleting pipelines.</simpara>
</partintro>
<chapter id="pipeline">
<title>Pipeline Definition<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>A pipeline is a definition of  a series of <link linkend="ingest-processors">processors</link> that are to be executed
in the same order as they are declared. A pipeline consists of two main fields: a <literal>description</literal>
and a list of <literal>processors</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "description" : "...",
  "processors" : [ ... ]
}</programlisting>
<simpara>The <literal>description</literal> is a special field to store a helpful description of
what the pipeline does.</simpara>
<simpara>The <literal>processors</literal> parameter defines a list of processors to be executed in
order.</simpara>
</chapter>
<chapter id="ingest-apis">
<title>Ingest APIs<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>The following ingest APIs are available for managing pipelines:</simpara>
<itemizedlist>
<listitem>
<simpara>
<xref linkend="put-pipeline-api"/> to add or update a pipeline
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="get-pipeline-api"/> to return a specific pipeline
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="delete-pipeline-api"/> to delete a pipeline
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="simulate-pipeline-api"/> to simulate a call to a pipeline
</simpara>
</listitem>
</itemizedlist>
<section id="put-pipeline-api">
<title>Put Pipeline API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>The put pipeline API adds pipelines and updates existing pipelines in the cluster.</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT _ingest/pipeline/my-pipeline-id
{
  "description" : "describe pipeline",
  "processors" : [
    {
      "set" : {
        "field": "foo",
        "value": "bar"
      }
    }
  ]
}</programlisting>
<remark> CONSOLE</remark>
<note><simpara>The put pipeline API also instructs all ingest nodes to reload their in-memory representation of pipelines, so that
      pipeline changes take effect immediately.</simpara></note>
</section>
<section id="get-pipeline-api">
<title>Get Pipeline API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>The get pipeline API returns pipelines based on ID. This API always returns a local reference of the pipeline.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET _ingest/pipeline/my-pipeline-id</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Example response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "my-pipeline-id" : {
    "description" : "describe pipeline",
    "processors" : [
      {
        "set" : {
          "field" : "foo",
          "value" : "bar"
        }
      }
    ]
  }
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>For each returned pipeline, the source and the version are returned.
The version is useful for knowing which version of the pipeline the node has.
You can specify multiple IDs to return more than one pipeline. Wildcards are also supported.</simpara>
<bridgehead id="versioning-pipelines" renderas="sect3">Pipeline Versioning<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></bridgehead>
<simpara>Pipelines can optionally add a <literal>version</literal> number, which can be any integer value,
in order to simplify pipeline management by external systems. The <literal>version</literal>
field is completely optional and it is meant solely for external management of
pipelines. To unset a <literal>version</literal>, simply replace the pipeline without specifying
one.</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT _ingest/pipeline/my-pipeline-id
{
  "description" : "describe pipeline",
  "version" : 123,
  "processors" : [
    {
      "set" : {
        "field": "foo",
        "value": "bar"
      }
    }
  ]
}</programlisting>
<remark> CONSOLE</remark>
<simpara>To check for the <literal>version</literal>, you can
<link linkend="common-options-response-filtering">filter responses</link>
using <literal>filter_path</literal> to limit the response to just the <literal>version</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET /_ingest/pipeline/my-pipeline-id?filter_path=*.version</programlisting>
<remark> TEST[continued]</remark>
<simpara>This should give a small response that makes it both easy and inexpensive to parse:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "my-pipeline-id" : {
    "version" : 123
  }
}</programlisting>
<remark> TESTRESPONSE</remark>
</section>
<section id="delete-pipeline-api">
<title>Delete Pipeline API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>The delete pipeline API deletes pipelines by ID.</simpara>
<programlisting language="js" linenumbering="unnumbered">DELETE _ingest/pipeline/my-pipeline-id</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
</section>
<section id="simulate-pipeline-api">
<title>Simulate Pipeline API<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>The simulate pipeline API executes a specific pipeline against
the set of documents provided in the body of the request.</simpara>
<simpara>You can either specify an existing pipeline to execute
against the provided documents, or supply a pipeline definition in
the body of the request.</simpara>
<simpara>Here is the structure of a simulate request with a pipeline definition provided
in the body of the request:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _ingest/pipeline/_simulate
{
  "pipeline" : {
    // pipeline definition here
  },
  "docs" : [
    { /** first document **/ },
    { /** second document **/ },
    // ...
  ]
}</programlisting>
<simpara>Here is the structure of a simulate request against an existing pipeline:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _ingest/pipeline/my-pipeline-id/_simulate
{
  "docs" : [
    { /** first document **/ },
    { /** second document **/ },
    // ...
  ]
}</programlisting>
<simpara>Here is an example of a simulate request with a pipeline defined in the request
and its response:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _ingest/pipeline/_simulate
{
  "pipeline" :
  {
    "description": "_description",
    "processors": [
      {
        "set" : {
          "field" : "field2",
          "value" : "_value"
        }
      }
    ]
  },
  "docs": [
    {
      "_index": "index",
      "_type": "type",
      "_id": "id",
      "_source": {
        "foo": "bar"
      }
    },
    {
      "_index": "index",
      "_type": "type",
      "_id": "id",
      "_source": {
        "foo": "rab"
      }
    }
  ]
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "docs": [
      {
         "doc": {
            "_id": "id",
            "_ttl": null,
            "_parent": null,
            "_index": "index",
            "_routing": null,
            "_type": "type",
            "_timestamp": null,
            "_source": {
               "field2": "_value",
               "foo": "bar"
            },
            "_ingest": {
               "timestamp": "2016-01-04T23:53:27.186+0000"
            }
         }
      },
      {
         "doc": {
            "_id": "id",
            "_ttl": null,
            "_parent": null,
            "_index": "index",
            "_routing": null,
            "_type": "type",
            "_timestamp": null,
            "_source": {
               "field2": "_value",
               "foo": "rab"
            },
            "_ingest": {
               "timestamp": "2016-01-04T23:53:27.186+0000"
            }
         }
      }
   ]
}</programlisting>
<section id="ingest-verbose-param">
<title>Viewing Verbose Results<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>You can use the simulate pipeline API to see how each processor affects the ingest document
as it passes through the pipeline. To see the intermediate results of
each processor in the simulate request, you can add the <literal>verbose</literal> parameter
to the request.</simpara>
<simpara>Here is an example of a verbose request and its response:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _ingest/pipeline/_simulate?verbose
{
  "pipeline" :
  {
    "description": "_description",
    "processors": [
      {
        "set" : {
          "field" : "field2",
          "value" : "_value2"
        }
      },
      {
        "set" : {
          "field" : "field3",
          "value" : "_value3"
        }
      }
    ]
  },
  "docs": [
    {
      "_index": "index",
      "_type": "type",
      "_id": "id",
      "_source": {
        "foo": "bar"
      }
    },
    {
      "_index": "index",
      "_type": "type",
      "_id": "id",
      "_source": {
        "foo": "rab"
      }
    }
  ]
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
   "docs": [
      {
         "processor_results": [
            {
               "tag": "processor[set]-0",
               "doc": {
                  "_id": "id",
                  "_ttl": null,
                  "_parent": null,
                  "_index": "index",
                  "_routing": null,
                  "_type": "type",
                  "_timestamp": null,
                  "_source": {
                     "field2": "_value2",
                     "foo": "bar"
                  },
                  "_ingest": {
                     "timestamp": "2016-01-05T00:02:51.383+0000"
                  }
               }
            },
            {
               "tag": "processor[set]-1",
               "doc": {
                  "_id": "id",
                  "_ttl": null,
                  "_parent": null,
                  "_index": "index",
                  "_routing": null,
                  "_type": "type",
                  "_timestamp": null,
                  "_source": {
                     "field3": "_value3",
                     "field2": "_value2",
                     "foo": "bar"
                  },
                  "_ingest": {
                     "timestamp": "2016-01-05T00:02:51.383+0000"
                  }
               }
            }
         ]
      },
      {
         "processor_results": [
            {
               "tag": "processor[set]-0",
               "doc": {
                  "_id": "id",
                  "_ttl": null,
                  "_parent": null,
                  "_index": "index",
                  "_routing": null,
                  "_type": "type",
                  "_timestamp": null,
                  "_source": {
                     "field2": "_value2",
                     "foo": "rab"
                  },
                  "_ingest": {
                     "timestamp": "2016-01-05T00:02:51.384+0000"
                  }
               }
            },
            {
               "tag": "processor[set]-1",
               "doc": {
                  "_id": "id",
                  "_ttl": null,
                  "_parent": null,
                  "_index": "index",
                  "_routing": null,
                  "_type": "type",
                  "_timestamp": null,
                  "_source": {
                     "field3": "_value3",
                     "field2": "_value2",
                     "foo": "rab"
                  },
                  "_ingest": {
                     "timestamp": "2016-01-05T00:02:51.384+0000"
                  }
               }
            }
         ]
      }
   ]
}</programlisting>
</section>
</section>
</chapter>
<chapter id="accessing-data-in-pipelines">
<title>Accessing Data in Pipelines<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>The processors in a pipeline have read and write access to documents that pass through the pipeline.
The processors can access fields in the source of a document and the document&#8217;s metadata fields.</simpara>
<bridgehead id="accessing-source-fields" renderas="sect2">Accessing Fields in the Source<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></bridgehead>
<simpara>Accessing a field in the source is straightforward. You simply refer to fields by
their name. For example:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "set": {
    "field": "my_field"
    "value": 582.1
  }
}</programlisting>
<simpara>On top of this, fields from the source are always accessible via the <literal>_source</literal> prefix:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "set": {
    "field": "_source.my_field"
    "value": 582.1
  }
}</programlisting>
<bridgehead id="accessing-metadata-fields" renderas="sect2">Accessing Metadata Fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></bridgehead>
<simpara>You can access metadata fields in the same way that you access fields in the source. This
is possible because Elasticsearch doesn&#8217;t allow fields in the source that have the
same name as metadata fields.</simpara>
<simpara>The following example sets the <literal>_id</literal> metadata field of a document to <literal>1</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "set": {
    "field": "_id"
    "value": "1"
  }
}</programlisting>
<simpara>The following metadata fields are accessible by a processor: <literal>_index</literal>, <literal>_type</literal>, <literal>_id</literal>, <literal>_routing</literal>, <literal>_parent</literal>.</simpara>
<bridgehead id="accessing-ingest-metadata" renderas="sect2">Accessing Ingest Metadata Fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></bridgehead>
<simpara>Beyond metadata fields and source fields, ingest also adds ingest metadata to the documents that it processes.
These metadata properties are accessible under the <literal>_ingest</literal> key. Currently ingest adds the ingest timestamp
under the <literal>_ingest.timestamp</literal> key of the ingest metadata. The ingest timestamp is the time when Elasticsearch
received the index or bulk request to pre-process the document.</simpara>
<simpara>Any processor can add ingest-related metadata during document processing. Ingest metadata is transient
and is lost after a document has been processed by the pipeline. Therefore, ingest metadata won&#8217;t be indexed.</simpara>
<simpara>The following example adds a field with the name <literal>received</literal>. The value is the ingest timestamp:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "set": {
    "field": "received"
    "value": "{{_ingest.timestamp}}"
  }
}</programlisting>
<simpara>Unlike Elasticsearch metadata fields, the ingest metadata field name <literal>_ingest</literal> can be used as a valid field name
in the source of a document. Use <literal>_source._ingest</literal> to refer to the field in the source document. Otherwise, <literal>_ingest</literal>
will be interpreted as an ingest metadata field.</simpara>
<bridgehead id="accessing-template-fields" renderas="sect2">Accessing Fields and Metafields in Templates<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></bridgehead>
<simpara>A number of processor settings also support templating. Settings that support templating can have zero or more
template snippets. A template snippet begins with <literal>{{</literal> and ends with <literal>}}</literal>.
Accessing fields and metafields in templates is exactly the same as via regular processor field settings.</simpara>
<simpara>The following example adds a field named <literal>field_c</literal>. Its value is a concatenation of
the values of <literal>field_a</literal> and <literal>field_b</literal>.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "set": {
    "field": "field_c"
    "value": "{{field_a}} {{field_b}}"
  }
}</programlisting>
<simpara>The following example uses the value of the <literal>geoip.country_iso_code</literal> field in the source
to set the index that the document will be indexed into:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "set": {
    "field": "_index"
    "value": "{{geoip.country_iso_code}}"
  }
}</programlisting>
</chapter>
<chapter id="handling-failure-in-pipelines">
<title>Handling Failures in Pipelines<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>In its simplest use case, a pipeline defines a list of processors that
are executed sequentially, and processing halts at the first exception. This
behavior may not be desirable when failures are expected. For example, you may have logs
that don&#8217;t match the specified grok expression. Instead of halting execution, you may
want to index such documents into a separate index.</simpara>
<simpara>To enable this behavior, you can use the <literal>on_failure</literal> parameter. The <literal>on_failure</literal> parameter
defines a list of processors to be executed immediately following the failed processor.
You can specify this parameter at the pipeline level, as well as at the processor
level. If a processor specifies an <literal>on_failure</literal> configuration, whether
it is empty or not, any exceptions that are thrown by the processor are caught, and the
pipeline continues executing the remaining processors. Because you can define further processors
within the scope of an <literal>on_failure</literal> statement, you can nest failure handling.</simpara>
<simpara>The following example defines a pipeline that renames the <literal>foo</literal> field in
the processed document to <literal>bar</literal>. If the document does not contain the <literal>foo</literal> field, the processor
attaches an error message to the document for later analysis within
Elasticsearch.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "description" : "my first pipeline with handled exceptions",
  "processors" : [
    {
      "rename" : {
        "field" : "foo",
        "target_field" : "bar",
        "on_failure" : [
          {
            "set" : {
              "field" : "error",
              "value" : "field \"foo\" does not exist, cannot rename to \"bar\""
            }
          }
        ]
      }
    }
  ]
}</programlisting>
<simpara>The following example defines an <literal>on_failure</literal> block on a whole pipeline to change
the index to which failed documents get sent.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "description" : "my first pipeline with handled exceptions",
  "processors" : [ ... ],
  "on_failure" : [
    {
      "set" : {
        "field" : "_index",
        "value" : "failed-{{ _index }}"
      }
    }
  ]
}</programlisting>
<simpara>Alternatively instead of defining behaviour in case of processor failure, it is also possible
to ignore a failure and continue with the next processor by specifying the <literal>ignore_failure</literal> setting.</simpara>
<simpara>In case in the example below the field <literal>foo</literal> doesn&#8217;t exist the failure will be caught and the pipeline
continues to execute, which in this case means that the pipeline does nothing.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "description" : "my first pipeline with handled exceptions",
  "processors" : [
    {
      "rename" : {
        "field" : "foo",
        "target_field" : "bar",
        "ignore_failure" : true
      }
    }
  ]
}</programlisting>
<simpara>The <literal>ignore_failure</literal> can be set on any processor and defaults to <literal>false</literal>.</simpara>
<bridgehead id="accessing-error-metadata" renderas="sect2">Accessing Error Metadata From Processors Handling Exceptions<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></bridgehead>
<simpara>You may want to retrieve the actual error message that was thrown
by a failed processor. To do so you can access metadata fields called
<literal>on_failure_message</literal>, <literal>on_failure_processor_type</literal>, and <literal>on_failure_processor_tag</literal>. These fields are only accessible
from within the context of an <literal>on_failure</literal> block.</simpara>
<simpara>Here is an updated version of the example that you
saw earlier. But instead of setting the error message manually, the example leverages the <literal>on_failure_message</literal>
metadata field to provide the error message.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "description" : "my first pipeline with handled exceptions",
  "processors" : [
    {
      "rename" : {
        "field" : "foo",
        "to" : "bar",
        "on_failure" : [
          {
            "set" : {
              "field" : "error",
              "value" : "{{ _ingest.on_failure_message }}"
            }
          }
        ]
      }
    }
  ]
}</programlisting>
</chapter>
<chapter id="ingest-processors">
<title>Processors<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>All processors are defined in the following way within a pipeline definition:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "PROCESSOR_NAME" : {
    ... processor configuration options ...
  }
}</programlisting>
<simpara>Each processor defines its own configuration parameters, but all processors have
the ability to declare <literal>tag</literal> and <literal>on_failure</literal> fields. These fields are optional.</simpara>
<simpara>A <literal>tag</literal> is simply a string identifier of the specific instantiation of a certain
processor in a pipeline. The <literal>tag</literal> field does not affect the processor&#8217;s behavior,
but is very useful for bookkeeping and tracing errors to specific processors.</simpara>
<simpara>See <xref linkend="handling-failure-in-pipelines"/> to learn more about the <literal>on_failure</literal> field and error handling in pipelines.</simpara>
<simpara>The <link linkend="ingest-info">node info API</link> can be used to figure out what processors are available in a cluster.
The <link linkend="ingest-info">node info API</link> will provide a per node list of what processors are available.</simpara>
<simpara>Custom processors must be installed on all nodes. The put pipeline API will fail if a processor specified in a pipeline
doesn&#8217;t exist on all nodes. If you rely on custom processor plugins make sure to mark these plugins as mandatory by adding
<literal>plugin.mandatory</literal> setting to the <literal>config/elasticsearch.yml</literal> file, for example:</simpara>
<programlisting language="yaml" linenumbering="unnumbered">plugin.mandatory: ingest-attachment,ingest-geoip</programlisting>
<simpara>A node will not start if either of these plugins are not available.</simpara>
<simpara>The <link linkend="ingest-stats">node stats API</link> can be used to fetch ingest usage statistics, globally and on a per
pipeline basis. Useful to find out which pipelines are used the most or spent the most time on preprocessing.</simpara>
<section id="append-processor">
<title>Append Processor<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>Appends one or more values to an existing array if the field already exists and it is an array.
Converts a scalar to an array and appends one or more values to it if the field exists and it is a scalar.
Creates an array containing the provided values if the field doesn&#8217;t exist.
Accepts a single value or an array of values.</simpara>
<table id="append-options"
frame="all"
rowsep="1" colsep="1"
>
<title>Append Options</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"> Name      </entry>
<entry align="left" valign="top"> Required  </entry>
<entry align="left" valign="top"> Default  </entry>
<entry align="left" valign="top"> Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The field to be appended to</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>value</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The value to be appended</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<programlisting language="js" linenumbering="unnumbered">{
  "append": {
    "field": "field1"
    "value": ["item2", "item3", "item4"]
  }
}</programlisting>
</section>
<section id="convert-processor">
<title>Convert Processor<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>Converts an existing field&#8217;s value to a different type, such as converting a string to an integer.
If the field value is an array, all members will be converted.</simpara>
<simpara>The supported types include: <literal>integer</literal>, <literal>float</literal>, <literal>string</literal>, <literal>boolean</literal>, and <literal>auto</literal>.</simpara>
<simpara>Specifying <literal>boolean</literal> will set the field to true if its string value is equal to <literal>true</literal> (ignore case), to
false if its string value is equal to <literal>false</literal> (ignore case), or it will throw an exception otherwise.</simpara>
<simpara>Specifying <literal>auto</literal> will attempt to convert the string-valued <literal>field</literal> into the closest non-string type.
For example, a field whose value is <literal>"true"</literal> will be converted to its respective boolean type: <literal>true</literal>. And
a value of <literal>"242.15"</literal> will "automatically" be converted to <literal>242.15</literal> of type <literal>float</literal>. If a provided field cannot
be appropriately converted, the Convert Processor will still process successfully and leave the field value as-is. In
such a case, <literal>target_field</literal> will still be updated with the unconverted field value.</simpara>
<table id="convert-options"
frame="all"
rowsep="1" colsep="1"
>
<title>Convert Options</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"> Name             </entry>
<entry align="left" valign="top"> Required  </entry>
<entry align="left" valign="top"> Default  </entry>
<entry align="left" valign="top"> Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The field whose value is to be converted</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>target_field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara><literal>field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The field to assign the converted value to, by default <literal>field</literal> is updated in-place</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>type</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The type to convert the existing value to</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ignore_missing</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara><literal>false</literal></simpara></entry>
<entry align="left" valign="top"><simpara>If <literal>true</literal> and <literal>field</literal> does not exist or is <literal>null</literal>, the processor quietly exits without modifying the document</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<programlisting language="js" linenumbering="unnumbered">{
  "convert": {
    "field" : "foo"
    "type": "integer"
  }
}</programlisting>
</section>
<section id="date-processor">
<title>Date Processor<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>Parses dates from fields, and then uses the date or timestamp as the timestamp for the document.
By default, the date processor adds the parsed date as a new field called <literal>@timestamp</literal>. You can specify a
different field by setting the <literal>target_field</literal> configuration parameter. Multiple date formats are supported
as part of the same date processor definition. They will be used sequentially to attempt parsing the date field,
in the same order they were defined as part of the processor definition.</simpara>
<table id="date-options"
frame="all"
rowsep="1" colsep="1"
>
<title>Date options</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"> Name                   </entry>
<entry align="left" valign="top"> Required  </entry>
<entry align="left" valign="top"> Default             </entry>
<entry align="left" valign="top"> Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The field to get the date from.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>target_field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara>@timestamp</simpara></entry>
<entry align="left" valign="top"><simpara>The field that will hold the parsed date.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>formats</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>An array of the expected date formats. Can be a Joda pattern or one of the following formats: ISO8601, UNIX, UNIX_MS, or TAI64N.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>timezone</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara>UTC</simpara></entry>
<entry align="left" valign="top"><simpara>The timezone to use when parsing the date.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>locale</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara>ENGLISH</simpara></entry>
<entry align="left" valign="top"><simpara>The locale to use when parsing the date, relevant when parsing month names or week days.</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara>Here is an example that adds the parsed date to the <literal>timestamp</literal> field based on the <literal>initial_date</literal> field:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "description" : "...",
  "processors" : [
    {
      "date" : {
        "field" : "initial_date",
        "target_field" : "timestamp",
        "formats" : ["dd/MM/yyyy hh:mm:ss"],
        "timezone" : "Europe/Amsterdam"
      }
    }
  ]
}</programlisting>
</section>
<section id="date-index-name-processor">
<title>Date Index Name Processor<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>The purpose of this processor is to point documents to the right time based index based
on a date or timestamp field in a document by using the <link linkend="date-math-index-names">date math index name support</link>.</simpara>
<simpara>The processor sets the <literal>_index</literal> meta field with a date math index name expression based on the provided index name
prefix, a date or timestamp field in the documents being processed and the provided date rounding.</simpara>
<simpara>First, this processor fetches the date or timestamp from a field in the document being processed. Optionally,
date formatting can be configured on how the field&#8217;s value should be parsed into a date. Then this date,
the provided index name prefix and the provided date rounding get formatted into a date math index name expression.
Also here optionally date formatting can be specified on how the date should be formatted into a date math index name
expression.</simpara>
<simpara>An example pipeline that points documents to a monthly index that starts with a <literal>myindex-</literal> prefix based on a
date in the <literal>date1</literal> field:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT _ingest/pipeline/monthlyindex
{
  "description": "monthly date-time index naming",
  "processors" : [
    {
      "date_index_name" : {
        "field" : "date1",
        "index_name_prefix" : "myindex-",
        "date_rounding" : "M"
      }
    }
  ]
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Using that pipeline for an index request:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT /myindex/type/1?pipeline=monthlyindex
{
  "date1" : "2016-04-25T12:02:01.789Z"
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<programlisting language="js" linenumbering="unnumbered">{
  "_index" : "myindex-2016-04-01",
  "_type" : "type",
  "_id" : "1",
  "_version" : 1,
  "result" : "created",
  "_shards" : {
    "total" : 2,
    "successful" : 1,
    "failed" : 0
  },
  "created" : true
}</programlisting>
<remark> TESTRESPONSE</remark>
<simpara>The above request will not index this document into the <literal>myindex</literal> index, but into the <literal>myindex-2016-04-01</literal> index because
it was rounded by month. This is because the date-index-name-processor overrides the <literal>_index</literal> property of the document.</simpara>
<simpara>To see the date-math value of the index supplied in the actual index request which resulted in the above document being
indexed into <literal>myindex-2016-04-01</literal> we can inspect the effects of the processor using a simulate request.</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _ingest/pipeline/_simulate
{
  "pipeline" :
  {
    "description": "monthly date-time index naming",
    "processors" : [
      {
        "date_index_name" : {
          "field" : "date1",
          "index_name_prefix" : "myindex-",
          "date_rounding" : "M"
        }
      }
    ]
  },
  "docs": [
    {
      "_source": {
        "date1": "2016-04-25T12:02:01.789Z"
      }
    }
  ]
}</programlisting>
<remark> CONSOLE</remark>
<simpara>and the result:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "docs" : [
    {
      "doc" : {
        "_id" : "_id",
        "_index" : "&lt;myindex-{2016-04-25||/M{yyyy-MM-dd|UTC}}&gt;",
        "_type" : "_type",
        "_source" : {
          "date1" : "2016-04-25T12:02:01.789Z"
        },
        "_ingest" : {
          "timestamp" : "2016-11-08T19:43:03.850+0000"
        }
      }
    }
  ]
}</programlisting>
<remark> TESTRESPONSE[s/2016-11-08T19:43:03.850\+0000/$body.docs.0.doc._ingest.timestamp/]</remark>
<simpara>The above example shows that <literal>_index</literal> was set to <literal>&lt;myindex-{2016-04-25||/M{yyyy-MM-dd|UTC}}&gt;</literal>. Elasticsearch
understands this to mean <literal>2016-04-01</literal> as is explained in the <link linkend="date-math-index-names">date math index name documentation</link></simpara>
<table id="date-index-name-options"
frame="all"
rowsep="1" colsep="1"
>
<title>Date index name options</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"> Name                   </entry>
<entry align="left" valign="top"> Required  </entry>
<entry align="left" valign="top"> Default                      </entry>
<entry align="left" valign="top"> Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The field to get the date or timestamp from.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>index_name_prefix</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>A prefix of the index name to be prepended before the printed date.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>date_rounding</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>How to round the date when formatting the date into the index name. Valid values are: <literal>y</literal> (year), <literal>M</literal> (month), <literal>w</literal> (week), <literal>d</literal> (day), <literal>h</literal> (hour), <literal>m</literal> (minute) and <literal>s</literal> (second).</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara>`date_formats `</simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara>yyyy-MM-dd&#8217;T'HH:mm:ss.SSSZ</simpara></entry>
<entry align="left" valign="top"><simpara>An array of the expected date formats for parsing dates / timestamps in the document being preprocessed. Can be a Joda pattern or one of the following formats: ISO8601, UNIX, UNIX_MS, or TAI64N.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>timezone</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara>UTC</simpara></entry>
<entry align="left" valign="top"><simpara>The timezone to use when parsing the date and when date math index supports resolves expressions into concrete index names.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>locale</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara>ENGLISH</simpara></entry>
<entry align="left" valign="top"><simpara>The locale to use when parsing the date from the document being preprocessed, relevant when parsing month names or week days.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>index_name_format</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara>yyyy-MM-dd</simpara></entry>
<entry align="left" valign="top"><simpara>The format to be used when printing the parsed date into the index name. An valid Joda pattern is expected here.</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
</section>
<section id="fail-processor">
<title>Fail Processor<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>Raises an exception. This is useful for when
you expect a pipeline to fail and want to relay a specific message
to the requester.</simpara>
<table id="fail-options"
frame="all"
rowsep="1" colsep="1"
>
<title>Fail Options</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"> Name       </entry>
<entry align="left" valign="top"> Required  </entry>
<entry align="left" valign="top"> Default  </entry>
<entry align="left" valign="top"> Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>message</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The error message of the <literal>FailException</literal> thrown by the processor</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<programlisting language="js" linenumbering="unnumbered">{
  "fail": {
    "message": "an error message"
  }
}</programlisting>
</section>
<section id="foreach-processor">
<title>Foreach Processor<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara><phrase role="experimental">This processor may change or be replaced by something else that provides similar functionality. This
processor executes in its own context, which makes it different compared to all other processors and for features like
verbose simulation the subprocessor isn't visible. The reason we still expose this processor, is that it is the only
processor that can operate on an array.</phrase></simpara>
<simpara>Processes elements in an array of unknown length.</simpara>
<simpara>All processors can operate on elements inside an array, but if all elements of an array need to
be processed in the same way, defining a processor for each element becomes cumbersome and tricky
because it is likely that the number of elements in an array is unknown. For this reason the <literal>foreach</literal>
processor exists. By specifying the field holding array elements and a processor that
defines what should happen to each element, array fields can easily be preprocessed.</simpara>
<simpara>A processor inside the foreach processor works in the array element context and puts that in the ingest metadata
under the <literal>_ingest._value</literal> key. If the array element is a json object it holds all immediate fields of that json object.
and if the nested object is a value is <literal>_ingest._value</literal> just holds that value. Note that if a processor prior to the
<literal>foreach</literal> processor used <literal>_ingest._value</literal> key then the specified value will not be available to the processor inside
the <literal>foreach</literal> processor. The <literal>foreach</literal> processor does restore the original value, so that value is available to processors
after the <literal>foreach</literal> processor.</simpara>
<simpara>Note that any other field from the document are accessible and modifiable like with all other processors. This processor
just puts the current array element being read into <literal>_ingest._value</literal> ingest metadata attribute, so that it may be
pre-processed.</simpara>
<simpara>If the <literal>foreach</literal> processor fails to process an element inside the array, and no <literal>on_failure</literal> processor has been specified,
then it aborts the execution and leaves the array unmodified.</simpara>
<table id="foreach-options"
frame="all"
rowsep="1" colsep="1"
>
<title>Foreach Options</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"> Name          </entry>
<entry align="left" valign="top"> Required  </entry>
<entry align="left" valign="top"> Default  </entry>
<entry align="left" valign="top"> Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The array field</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>processor</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The processor to execute against each field</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara>Assume the following document:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "values" : ["foo", "bar", "baz"]
}</programlisting>
<simpara>When this <literal>foreach</literal> processor operates on this sample document:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "foreach" : {
    "field" : "values",
    "processor" : {
      "uppercase" : {
        "field" : "_ingest._value"
      }
    }
  }
}</programlisting>
<simpara>Then the document will look like this after preprocessing:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "values" : ["FOO", "BAR", "BAZ"]
}</programlisting>
<simpara>Let&#8217;s take a look at another example:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "persons" : [
    {
      "id" : "1",
      "name" : "John Doe"
    },
    {
      "id" : "2",
      "name" : "Jane Doe"
    }
  ]
}</programlisting>
<simpara>In this case, the <literal>id</literal> field needs to be removed,
so the following <literal>foreach</literal> processor is used:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "foreach" : {
    "field" : "persons",
    "processor" : {
      "remove" : {
        "field" : "_ingest._value.id"
      }
    }
  }
}</programlisting>
<simpara>After preprocessing the result is:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "persons" : [
    {
      "name" : "John Doe"
    },
    {
      "name" : "Jane Doe"
    }
  ]
}</programlisting>
<simpara>The wrapped processor can have a <literal>on_failure</literal> definition.
For example, the <literal>id</literal> field may not exist on all person objects.
Instead of failing the index request, you can use an <literal>on_failure</literal>
block to send the document to the <emphasis>failure_index</emphasis> index for later inspection:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "foreach" : {
    "field" : "persons",
    "processor" : {
      "remove" : {
        "field" : "_value.id",
        "on_failure" : [
          {
            "set" : {
              "field", "_index",
              "value", "failure_index"
            }
          }
        ]
      }
    }
  }
}</programlisting>
<simpara>In this example, if the <literal>remove</literal> processor does fail, then
the array elements that have been processed thus far will
be updated.</simpara>
</section>
<section id="grok-processor">
<title>Grok Processor<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>Extracts structured fields out of a single text field within a document. You choose which field to
extract matched fields from, as well as the grok pattern you expect will match. A grok pattern is like a regular
expression that supports aliased expressions that can be reused.</simpara>
<simpara>This tool is perfect for syslog logs, apache and other webserver logs, mysql logs, and in general, any log format
that is generally written for humans and not computer consumption.
This processor comes packaged with over
<ulink url="https://github.com/elastic/elasticsearch/tree/master/modules/ingest-common/src/main/resources/patterns">120 reusable patterns</ulink>.</simpara>
<simpara>If you need help building patterns to match your logs, you will find the <ulink url="http://grokdebug.herokuapp.com">http://grokdebug.herokuapp.com</ulink> and
<ulink url="http://grokconstructor.appspot.com/">http://grokconstructor.appspot.com/</ulink> applications quite useful!</simpara>
<section id="grok-basics">
<title>Grok Basics<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>Grok sits on top of regular expressions, so any regular expressions are valid in grok as well.
The regular expression library is Oniguruma, and you can see the full supported regexp syntax
<ulink url="https://github.com/kkos/oniguruma/blob/master/doc/RE">on the Onigiruma site</ulink>.</simpara>
<simpara>Grok works by leveraging this regular expression language to allow naming existing patterns and combining them into more
complex patterns that match your fields.</simpara>
<simpara>The syntax for reusing a grok pattern comes in three forms: <literal>%{SYNTAX:SEMANTIC}</literal>, <literal>%{SYNTAX}</literal>, <literal>%{SYNTAX:SEMANTIC:TYPE}</literal>.</simpara>
<simpara>The <literal>SYNTAX</literal> is the name of the pattern that will match your text. For example, <literal>3.44</literal> will be matched by the <literal>NUMBER</literal>
pattern and <literal>55.3.244.1</literal> will be matched by the <literal>IP</literal> pattern. The syntax is how you match. <literal>NUMBER</literal> and <literal>IP</literal> are both
patterns that are provided within the default patterns set.</simpara>
<simpara>The <literal>SEMANTIC</literal> is the identifier you give to the piece of text being matched. For example, <literal>3.44</literal> could be the
duration of an event, so you could call it simply <literal>duration</literal>. Further, a string <literal>55.3.244.1</literal> might identify
the <literal>client</literal> making a request.</simpara>
<simpara>The <literal>TYPE</literal> is the type you wish to cast your named field. <literal>int</literal> and <literal>float</literal> are currently the only types supported for coercion.</simpara>
<simpara>For example, you might want to match the following text:</simpara>
<programlisting language="js" linenumbering="unnumbered">3.44 55.3.244.1</programlisting>
<simpara>You may know that the message in the example is a number followed by an IP address. You can match this text by using the following
Grok expression.</simpara>
<programlisting language="js" linenumbering="unnumbered">%{NUMBER:duration} %{IP:client}</programlisting>
</section>
<section id="using-grok">
<title>Using the Grok Processor in a Pipeline<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<table id="grok-options"
frame="all"
rowsep="1" colsep="1"
>
<title>Grok Options</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"> Name                   </entry>
<entry align="left" valign="top"> Required  </entry>
<entry align="left" valign="top"> Default             </entry>
<entry align="left" valign="top"> Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The field to use for grok expression parsing</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>patterns</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>An ordered list of grok expression to match and extract named captures with. Returns on the first expression in the list that matches.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>pattern_definitions</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>A map of pattern-name and pattern tuples defining custom patterns to be used by the current processor. Patterns matching existing names will override the pre-existing definition.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>trace_match</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara>false</simpara></entry>
<entry align="left" valign="top"><simpara>when true, <literal>_ingest._grok_match_index</literal> will be inserted into your matched document&#8217;s metadata with the index into the pattern found in <literal>patterns</literal> that matched.</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ignore_missing</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara>false</simpara></entry>
<entry align="left" valign="top"><simpara>If <literal>true</literal> and <literal>field</literal> does not exist or is <literal>null</literal>, the processor quietly exits without modifying the document</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara>Here is an example of using the provided patterns to extract out and name structured fields from a string field in
a document.</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "message": "55.3.244.1 GET /index.html 15824 0.043"
}</programlisting>
<simpara>The pattern for this could be:</simpara>
<programlisting language="js" linenumbering="unnumbered">%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}</programlisting>
<simpara>Here is an example pipeline for processing the above document by using Grok:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "description" : "...",
  "processors": [
    {
      "grok": {
        "field": "message",
        "patterns": ["%{IP:client} %{WORD:method} %{URIPATHPARAM:request} %{NUMBER:bytes} %{NUMBER:duration}"]
      }
    }
  ]
}</programlisting>
<simpara>This pipeline will insert these named captures as new fields within the document, like so:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "message": "55.3.244.1 GET /index.html 15824 0.043",
  "client": "55.3.244.1",
  "method": "GET",
  "request": "/index.html",
  "bytes": 15824,
  "duration": "0.043"
}</programlisting>
</section>
<section id="custom-patterns">
<title>Custom Patterns and Pattern Files<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>The Grok processor comes pre-packaged with a base set of pattern. These patterns may not always have
what you are looking for. Pattern have a very basic format. Each entry describes has a name and the pattern itself.</simpara>
<simpara>You can add your own patterns to a processor definition under the <literal>pattern_definitions</literal> option.
Here is an example of a pipeline specifying custom pattern definitions:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "description" : "...",
  "processors": [
    {
      "grok": {
        "field": "message",
        "patterns": ["my %{FAVORITE_DOG:dog} is colored %{RGB:color}"]
        "pattern_definitions" : {
          "FAVORITE_DOG" : "beagle",
          "RGB" : "RED|GREEN|BLUE"
        }
      }
    }
  ]
}</programlisting>
</section>
<section id="trace-match">
<title>Providing Multiple Match Patterns<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>Sometimes one pattern is not enough to capture the potential structure of a field. Let&#8217;s assume we
want to match all messages that contain your favorite pet breeds of either cats or dogs. One way to accomplish
this is to provide two distinct patterns that can be matched, instead of one really complicated expression capturing
the same <literal>or</literal> behavior.</simpara>
<simpara>Here is an example of such a configuration executed against the simulate API:</simpara>
<programlisting language="js" linenumbering="unnumbered">POST _ingest/pipeline/_simulate
{
  "pipeline": {
  "description" : "parse multiple patterns",
  "processors": [
    {
      "grok": {
        "field": "message",
        "patterns": ["%{FAVORITE_DOG:pet}", "%{FAVORITE_CAT:pet}"],
        "pattern_definitions" : {
          "FAVORITE_DOG" : "beagle",
          "FAVORITE_CAT" : "burmese"
        }
      }
    }
  ]
},
"docs":[
  {
    "_source": {
      "message": "I love burmese cats!"
    }
  }
  ]
}</programlisting>
<remark> CONSOLE</remark>
<simpara>response:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "docs": [
    {
      "doc": {
        "_type": "_type",
        "_index": "_index",
        "_id": "_id",
        "_source": {
          "message": "I love burmese cats!",
          "pet": "burmese"
        },
        "_ingest": {
          "timestamp": "2016-11-08T19:43:03.850+0000"
        }
      }
    }
  ]
}</programlisting>
<remark> TESTRESPONSE[s/2016-11-08T19:43:03.850\+0000/$body.docs.0.doc._ingest.timestamp/]</remark>
<simpara>Both patterns will set the field <literal>pet</literal> with the appropriate match, but what if we want to trace which of our
patterns matched and populated our fields? We can do this with the <literal>trace_match</literal> parameter. Here is the output of
that same pipeline, but with <literal>"trace_match": true</literal> configured:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "docs": [
    {
      "doc": {
        "_type": "_type",
        "_index": "_index",
        "_id": "_id",
        "_source": {
          "message": "I love burmese cats!",
          "pet": "burmese"
        },
        "_ingest": {
          "_grok_match_index": "1",
          "timestamp": "2016-11-08T19:43:03.850+0000"
        }
      }
    }
  ]
}</programlisting>
<remark> TESTRESPONSE[s/2016-11-08T19:43:03.850\+0000/$body.docs.0.doc._ingest.timestamp/]</remark>
<simpara>In the above response, you can see that the index of the pattern that matched was <literal>"1"</literal>. This is to say that it was the
second (index starts at zero) pattern in <literal>patterns</literal> to match.</simpara>
<simpara>This trace metadata enables debugging which of the patterns matched. This information is stored in the ingest
metadata and will not be indexed.</simpara>
</section>
</section>
<section id="gsub-processor">
<title>Gsub Processor<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>Converts a string field by applying a regular expression and a replacement.
If the field is not a string, the processor will throw an exception.</simpara>
<table id="gsub-options"
frame="all"
rowsep="1" colsep="1"
>
<title>Gsub Options</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"> Name          </entry>
<entry align="left" valign="top"> Required  </entry>
<entry align="left" valign="top"> Default  </entry>
<entry align="left" valign="top"> Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The field to apply the replacement to</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>pattern</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The pattern to be replaced</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>replacement</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The string to replace the matching patterns with</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<programlisting language="js" linenumbering="unnumbered">{
  "gsub": {
    "field": "field1",
    "pattern": "\.",
    "replacement": "-"
  }
}</programlisting>
</section>
<section id="join-processor">
<title>Join Processor<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>Joins each element of an array into a single string using a separator character between each element.
Throws an error when the field is not an array.</simpara>
<table id="join-options"
frame="all"
rowsep="1" colsep="1"
>
<title>Join Options</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"> Name          </entry>
<entry align="left" valign="top"> Required  </entry>
<entry align="left" valign="top"> Default  </entry>
<entry align="left" valign="top"> Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The field to be separated</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>separator</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The separator character</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<programlisting language="js" linenumbering="unnumbered">{
  "join": {
    "field": "joined_array_field",
    "separator": "-"
  }
}</programlisting>
</section>
<section id="json-processor">
<title>JSON Processor<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>Converts a JSON string into a structured JSON object.</simpara>
<table id="json-options"
frame="all"
rowsep="1" colsep="1"
>
<title>Json Options</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"> Name           </entry>
<entry align="left" valign="top"> Required  </entry>
<entry align="left" valign="top"> Default  </entry>
<entry align="left" valign="top"> Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The field to be parsed</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>target_field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara><literal>field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The field to insert the converted structured object into</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<programlisting language="js" linenumbering="unnumbered">{
  "json": {
    "field": "{\"foo\": 2000}"
  }
}</programlisting>
</section>
<section id="lowercase-processor">
<title>Lowercase Processor<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>Converts a string to its lowercase equivalent.</simpara>
<table id="lowercase-options"
frame="all"
rowsep="1" colsep="1"
>
<title>Lowercase Options</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"> Name             </entry>
<entry align="left" valign="top"> Required  </entry>
<entry align="left" valign="top"> Default  </entry>
<entry align="left" valign="top"> Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The field to make lowercase</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ignore_missing</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara><literal>false</literal></simpara></entry>
<entry align="left" valign="top"><simpara>If <literal>true</literal> and <literal>field</literal> does not exist or is <literal>null</literal>, the processor quietly exits without modifying the document</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<programlisting language="js" linenumbering="unnumbered">{
  "lowercase": {
    "field": "foo"
  }
}</programlisting>
</section>
<section id="remove-processor">
<title>Remove Processor<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>Removes an existing field. If the field doesn&#8217;t exist, an exception will be thrown.</simpara>
<table id="remove-options"
frame="all"
rowsep="1" colsep="1"
>
<title>Remove Options</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"> Name      </entry>
<entry align="left" valign="top"> Required  </entry>
<entry align="left" valign="top"> Default  </entry>
<entry align="left" valign="top"> Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The field to be removed</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<programlisting language="js" linenumbering="unnumbered">{
  "remove": {
    "field": "foo"
  }
}</programlisting>
</section>
<section id="rename-processor">
<title>Rename Processor<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>Renames an existing field. If the field doesn&#8217;t exist or the new name is already used, an exception will be thrown.</simpara>
<table id="rename-options"
frame="all"
rowsep="1" colsep="1"
>
<title>Rename Options</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"> Name             </entry>
<entry align="left" valign="top"> Required  </entry>
<entry align="left" valign="top"> Default  </entry>
<entry align="left" valign="top"> Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The field to be renamed</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>target_field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The new name of the field</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ignore_missing</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara><literal>false</literal></simpara></entry>
<entry align="left" valign="top"><simpara>If <literal>true</literal> and <literal>field</literal> does not exist, the processor quietly exits without modifying the document</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<programlisting language="js" linenumbering="unnumbered">{
  "rename": {
    "field": "foo",
    "target_field": "foobar"
  }
}</programlisting>
</section>
<section id="script-processor">
<title>Script Processor<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>Allows inline, stored, and file scripts to be executed within ingest pipelines.</simpara>
<simpara>See <link linkend="modules-scripting-using">How to use scripts</link> to learn more about writing scripts. The Script Processor
leverages caching of compiled scripts for improved performance. Since the
script specified within the processor is potentially re-compiled per document, it is important
to understand how script caching works. To learn more about
caching see <link linkend="modules-scripting-using-caching">Script Caching</link>.</simpara>
<table id="script-options"
frame="all"
rowsep="1" colsep="1"
>
<title>Script Options</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"> Name                   </entry>
<entry align="left" valign="top"> Required  </entry>
<entry align="left" valign="top"> Default    </entry>
<entry align="left" valign="top"> Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>lang</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara>"painless"</simpara></entry>
<entry align="left" valign="top"><simpara>The scripting language</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>file</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The script file to refer to</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>id</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The stored script id to refer to</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>inline</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>An inline script to be executed</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>params</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>Script Parameters</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<simpara>One of <literal>file</literal>, <literal>id</literal>, <literal>inline</literal> options must be provided in order to properly reference a script to execute.</simpara>
<simpara>You can access the current ingest document from within the script context by using the <literal>ctx</literal> variable.</simpara>
<simpara>The following example sets a new field called <literal>field_a_plus_b_times_c</literal> to be the sum of two existing
numeric fields <literal>field_a</literal> and <literal>field_b</literal> multiplied by the parameter param_c:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "script": {
    "lang": "painless",
    "inline": "ctx.field_a_plus_b_times_c = (ctx.field_a + ctx.field_b) * params.param_c",
    "params": {
      "param_c": 10
    }
  }
}</programlisting>
</section>
<section id="set-processor">
<title>Set Processor<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>Sets one field and associates it with the specified value. If the field already exists,
its value will be replaced with the provided one.</simpara>
<table id="set-options"
frame="all"
rowsep="1" colsep="1"
>
<title>Set Options</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"> Name      </entry>
<entry align="left" valign="top"> Required  </entry>
<entry align="left" valign="top"> Default  </entry>
<entry align="left" valign="top"> Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The field to insert, upsert, or update</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>value</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The value to be set for the field</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>override</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara>true</simpara></entry>
<entry align="left" valign="top"><simpara>If processor will update fields with pre-existing non-null-valued field. When set to <literal>false</literal>, such fields will not be touched.</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<programlisting language="js" linenumbering="unnumbered">{
  "set": {
    "field": "field1",
    "value": 582.1
  }
}</programlisting>
</section>
<section id="split-processor">
<title>Split Processor<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>Splits a field into an array using a separator character. Only works on string fields.</simpara>
<table id="split-options"
frame="all"
rowsep="1" colsep="1"
>
<title>Split Options</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"> Name              </entry>
<entry align="left" valign="top"> Required  </entry>
<entry align="left" valign="top"> Default  </entry>
<entry align="left" valign="top"> Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The field to split</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>separator</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>A regex which matches the separator, eg <literal>,</literal> or <literal>\s+</literal></simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ignore_missing</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara><literal>false</literal></simpara></entry>
<entry align="left" valign="top"><simpara>If <literal>true</literal> and <literal>field</literal> does not exist, the processor quietly exits without modifying the document</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<programlisting language="js" linenumbering="unnumbered">{
  "split": {
    "field": "my_field",
    "separator": "\\s+" <co id="CO291-1"/>
  }
}</programlisting>
<calloutlist>
<callout arearefs="CO291-1">
<para>
Treat all consecutive whitespace characters as a single separator
</para>
</callout>
</calloutlist>
</section>
<section id="sort-processor">
<title>Sort Processor<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>Sorts the elements of an array ascending or descending.  Homogeneous arrays of numbers will be sorted
numerically, while arrays of strings or heterogeneous arrays of strings + numbers will be sorted lexicographically.
Throws an error when the field is not an array.</simpara>
<table id="sort-options"
frame="all"
rowsep="1" colsep="1"
>
<title>Sort Options</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"> Name    </entry>
<entry align="left" valign="top"> Required  </entry>
<entry align="left" valign="top"> Default  </entry>
<entry align="left" valign="top"> Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The field to be sorted</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>order</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara><literal>"asc"</literal></simpara></entry>
<entry align="left" valign="top"><simpara>The sort order to use. Accepts <literal>"asc"</literal> or <literal>"desc"</literal>.</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<programlisting language="js" linenumbering="unnumbered">{
  "sort": {
    "field": "field_to_sort",
    "order": "desc"
  }
}</programlisting>
</section>
<section id="trim-processor">
<title>Trim Processor<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>Trims whitespace from field.</simpara>
<note><simpara>This only works on leading and trailing whitespace.</simpara></note>
<table id="trim-options"
frame="all"
rowsep="1" colsep="1"
>
<title>Trim Options</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"> Name              </entry>
<entry align="left" valign="top"> Required  </entry>
<entry align="left" valign="top"> Default  </entry>
<entry align="left" valign="top"> Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The string-valued field to trim whitespace from</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ignore_missing</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara><literal>false</literal></simpara></entry>
<entry align="left" valign="top"><simpara>If <literal>true</literal> and <literal>field</literal> does not exist, the processor quietly exits without modifying the document</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<programlisting language="js" linenumbering="unnumbered">{
  "trim": {
    "field": "foo"
  }
}</programlisting>
</section>
<section id="uppercase-processor">
<title>Uppercase Processor<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>Converts a string to its uppercase equivalent.</simpara>
<table id="uppercase-options"
frame="all"
rowsep="1" colsep="1"
>
<title>Uppercase Options</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"> Name             </entry>
<entry align="left" valign="top"> Required  </entry>
<entry align="left" valign="top"> Default  </entry>
<entry align="left" valign="top"> Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The field to make uppercase</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>ignore_missing</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara><literal>false</literal></simpara></entry>
<entry align="left" valign="top"><simpara>If <literal>true</literal> and <literal>field</literal> does not exist or is <literal>null</literal>, the processor quietly exits without modifying the document</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<programlisting language="js" linenumbering="unnumbered">{
  "uppercase": {
    "field": "foo"
  }
}</programlisting>
</section>
<section id="dot-expand-processor">
<title>Dot Expander Processor<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/ingest/ingest-node.asciidoc">Edit me</ulink></title>
<simpara>Expands a field with dots into an object field. This processor allows fields
with dots in the name to be accessible by other processors in the pipeline.
Otherwise these &lt;&lt;accessing-data-in-pipelines,fields&gt; can&#8217;t be accessed by any processor.</simpara>
<table id="dot-expender-options"
frame="all"
rowsep="1" colsep="1"
>
<title>Dot Expand Options</title>
<tgroup cols="4">
<colspec colname="col_1" colwidth="25*"/>
<colspec colname="col_2" colwidth="25*"/>
<colspec colname="col_3" colwidth="25*"/>
<colspec colname="col_4" colwidth="25*"/>
<thead>
<row>
<entry align="left" valign="top"> Name     </entry>
<entry align="left" valign="top"> Required  </entry>
<entry align="left" valign="top"> Default  </entry>
<entry align="left" valign="top"> Description</entry>
</row>
</thead>
<tbody>
<row>
<entry align="left" valign="top"><simpara><literal>field</literal></simpara></entry>
<entry align="left" valign="top"><simpara>yes</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The field to expand into an object field</simpara></entry>
</row>
<row>
<entry align="left" valign="top"><simpara><literal>path</literal></simpara></entry>
<entry align="left" valign="top"><simpara>no</simpara></entry>
<entry align="left" valign="top"><simpara>-</simpara></entry>
<entry align="left" valign="top"><simpara>The field that contains the field to expand. Only required if the field to expand is part another object field, because the <literal>field</literal> option can only understand leaf fields.</simpara></entry>
</row>
</tbody>
</tgroup>
</table>
<programlisting language="js" linenumbering="unnumbered">{
  "dot_expander": {
    "field": "foo.bar"
  }
}</programlisting>
<simpara>For example the dot expand processor would turn this document:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "foo.bar" : "value"
}</programlisting>
<simpara>into:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "foo" : {
     "bar" : "value"
  }
}</programlisting>
<simpara>If there is already a <literal>bar</literal> field nested under <literal>foo</literal> then
this processor merges the the <literal>foo.bar</literal> field into it. If the field is
a scalar value then it will turn that field into an array field.</simpara>
<simpara>For example, the following document:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "foo.bar" : "value2",
  "foo" : {
    "bar" : "value1"
  }
}</programlisting>
<simpara>is transformed by the <literal>dot_expander</literal> processor into:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "foo" : {
    "bar" : ["value1", "value2"]
  }
}</programlisting>
<simpara>If any field outside of the leaf field conflicts with a pre-existing field of the same name,
then that field needs to be renamed first.</simpara>
<simpara>Consider the following document:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "foo": "value1",
  "foo.bar": "value2"
}</programlisting>
<simpara>Then the the <literal>foo</literal> needs to be renamed first before the <literal>dot_expander</literal>
processor is applied. So in order for the <literal>foo.bar</literal> field to properly
be expanded into the <literal>bar</literal> field under the <literal>foo</literal> field the following
pipeline should be used:</simpara>
<programlisting language="js" linenumbering="unnumbered">{
  "processors" : [
    {
      "rename" : {
        "field" : "foo",
        "target_field" : "foo.bar""
      }
    },
    {
      "dot_expander": {
        "field": "foo.bar"
      }
    }
  ]
}</programlisting>
<simpara>The reason for this is that Ingest doesn&#8217;t know how to automatically cast
a scalar field to an object field.</simpara>
</section>
</chapter>
</part>
<part id="how-to">
<title>How To <ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to.asciidoc">Edit me</ulink></title>
<partintro>
<simpara>Elasticsearch ships with defaults which are intended to give a good out of
the box experience. Full text search, highlighting, aggregations, indexing
should all just work without the user having to change anything.</simpara>
<simpara>Once you better understand how you want to use Elasticsearch, however,
there are a number of optimizations you can make to improve performance
for your use case.</simpara>
<simpara>This section provides guidance about which changes should and shouldn&#8217;t be
made.</simpara>
</partintro>
<chapter id="general-recommendations">
<title>General recommendations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/general.asciidoc">Edit me</ulink></title>
<bridgehead id="large-size" renderas="sect2">Don&#8217;t return large result sets<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/general.asciidoc">Edit me</ulink></bridgehead>
<simpara>Elasticsearch is designed as a search engine, which makes it very good at
getting back the top documents that match a query. However, it is not as good
for workloads that fall into the database domain, such as retrieving all
documents that match a particular query. If you need to do this, make sure to
use the <link linkend="search-request-scroll">Scroll</link> API.</simpara>
<bridgehead id="maximum-document-size" renderas="sect2">Avoid large documents<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/general.asciidoc">Edit me</ulink></bridgehead>
<simpara>Given that the default <link linkend="modules-http"><literal>http.max_context_length</literal></link> is set to
100MB, Elasticsearch will refuse to index any document that is larger than
that. You might decide to increase that particular setting, but Lucene still
has a limit of about 2GB.</simpara>
<simpara>Even without considering hard limits, large documents are usually not
practical. Large documents put more stress on network, memory usage and disk,
even for search requests that do not request the <literal>_source</literal> since Elasticsearch
needs to fetch the <literal>_id</literal> of the document in all cases, and the cost of getting
this field is bigger for large documents due to how the filesystem cache works.
Indexing this document can use an amount of memory that is a multiplier of the
original size of the document. Proximity search (phrase queries for instance)
and <link linkend="search-request-highlighting">highlighting</link> also become more expensive
since their cost directly depends on the size of the original document.</simpara>
<simpara>It is sometimes useful to reconsider what the unit of information should be.
For instance, the fact you want to make books searchable doesn&#8217;t necesarily
mean that a document should consist of a whole book. It might be a better idea
to use chapters or even paragraphs as documents, and then have a property in
these documents that identifies which book they belong to. This does not only
avoid the issues with large documents, it also makes the search experience
better. For instance if a user searches for two words <literal>foo</literal> and <literal>bar</literal>, a match
across different chapters is probably very poor, while a match within the same
paragraph is likely good.</simpara>
<bridgehead id="sparsity" renderas="sect2">Avoid sparsity<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/general.asciidoc">Edit me</ulink></bridgehead>
<simpara>The data-structures behind Lucene, which Elasticsearch relies on in order to
index and store data, work best with dense data, ie. when all documents have the
same fields. This is especially true for fields that have norms enabled (which
is the case for <literal>text</literal> fields by default) or doc values enabled (which is the
case for numerics, <literal>date</literal>, <literal>ip</literal> and <literal>keyword</literal> by default).</simpara>
<simpara>The reason is that Lucene internally identifies documents with so-called doc
ids, which are integers between 0 and the total number of documents in the
index. These doc ids are used for communication between the internal APIs of
Lucene: for instance searching on a term with a <literal>match</literal> query produces an
iterator of doc ids, and these doc ids are then used to retrieve the value of
the <literal>norm</literal> in order to compute a score for these documents. The way this <literal>norm</literal>
lookup is implemented currently is by reserving one byte for each document.
The <literal>norm</literal> value for a given doc id can then be retrieved by reading the
byte at index <literal>doc_id</literal>. While this is very efficient and helps Lucene quickly
have access to the <literal>norm</literal> values of every document, this has the drawback that
documents that do not have a value will also require one byte of storage.</simpara>
<simpara>In practice, this means that if an index has <literal>M</literal> documents, norms will require
<literal>M</literal> bytes of storage <emphasis role="strong">per field</emphasis>, even for fields that only appear in a small
fraction of the documents of the index. Although slightly more complex with doc
values due to the fact that doc values have multiple ways that they can be
encoded depending on the type of field and on the actual data that the field
stores, the problem is very similar. In case you wonder: <literal>fielddata</literal>, which was
used in Elasticsearch pre-2.0 before being replaced with doc values, also
suffered from this issue, except that the impact was only on the memory
footprint since <literal>fielddata</literal> was not explicitly materialized on disk.</simpara>
<simpara>Note that even though the most notable impact of sparsity is on storage
requirements, it also has an impact on indexing speed and search speed since
these bytes for documents that do not have a field still need to be written
at index time and skipped over at search time.</simpara>
<simpara>It is totally fine to have a minority of sparse fields in an index. But beware
that if sparsity becomes the rule rather than the exception, then the index
will not be as efficient as it could be.</simpara>
<simpara>This section mostly focused on <literal>norms</literal> and <literal>doc values</literal> because those are the
two features that are most affected by sparsity. Sparsity also affect the
efficiency of the inverted index (used to index <literal>text</literal>/<literal>keyword</literal> fields) and
dimensional points (used to index <literal>geo_point</literal> and numerics) but to a lesser
extent.</simpara>
<simpara>Here are some recommendations that can help avoid sparsity:</simpara>
<bridgehead id="_avoid_putting_unrelated_data_in_the_same_index" renderas="sect3">Avoid putting unrelated data in the same index<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/general.asciidoc">Edit me</ulink></bridgehead>
<simpara>You should avoid putting documents that have totally different structures into
the same index in order to avoid sparsity. It is often better to put these
documents into different indices, you could also consider giving fewer shards
to these smaller indices since they will contain fewer documents overall.</simpara>
<simpara>Note that this advice does not apply in the case that you need to use
parent/child relations between your documents since this feature is only
supported on documents that live in the same index.</simpara>
<bridgehead id="_normalize_document_structures" renderas="sect3">Normalize document structures<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/general.asciidoc">Edit me</ulink></bridgehead>
<simpara>Even if you really need to put different kinds of documents in the same index,
maybe there are opportunities to reduce sparsity. For instance if all documents
in the index have a timestamp field but some call it <literal>timestamp</literal> and others
call it <literal>creation_date</literal>, it would help to rename it so that all documents have
the same field name for the same data.</simpara>
<bridgehead id="_avoid_types" renderas="sect3">Avoid types<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/general.asciidoc">Edit me</ulink></bridgehead>
<simpara>Types might sound like a good way to store multiple tenants in a single index.
They are not: given that types store everything in a single index, having
multiple types that have different fields in a single index will also cause
problems due to sparsity as described above. If your types do not have very
similar mappings, you might want to consider moving them to a dedicated index.</simpara>
<bridgehead id="_disable_literal_norms_literal_and_literal_doc_values_literal_on_sparse_fields" renderas="sect3">Disable <literal>norms</literal> and <literal>doc_values</literal> on sparse fields<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/general.asciidoc">Edit me</ulink></bridgehead>
<simpara>If none of the above recommendations apply in your case, you might want to
check whether you actually need <literal>norms</literal> and <literal>doc_values</literal> on your sparse fields.
<literal>norms</literal> can be disabled if producing scores is not necessary on a field, this is
typically true for fields that are only used for filtering. <literal>doc_values</literal> can be
disabled on fields that are neither used for sorting nor for aggregations.
Beware that this decision should not be made lightly since these parameters
cannot be changed on a live index, so you would have to reindex if you realize
that you need <literal>norms</literal> or <literal>doc_values</literal>.</simpara>
</chapter>
<chapter id="recipes">
<title>Recipes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/recipes.asciidoc">Edit me</ulink></title>
<bridgehead id="mixing-exact-search-with-stemming" renderas="sect2">Mixing exact search with stemming<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/recipes.asciidoc">Edit me</ulink></bridgehead>
<simpara>When building a search application, stemming is often a must as it is desirable
for a query on <literal>skiing</literal> to match documents that contain <literal>ski</literal> or <literal>skis</literal>. But
what if a user wants to search for <literal>skiing</literal> specifically? The typical way to do
this would be to use a <link linkend="multi-fields">multi-field</link> in order to have the same
content indexed in two different ways:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "english_exact": {
          "tokenizer": "standard",
          "filter": [
            "lowercase"
          ]
        }
      }
    }
  },
  "mappings": {
    "type": {
      "properties": {
        "body": {
          "type": "text",
          "analyzer": "english",
          "fields": {
            "exact": {
              "type": "text",
              "analyzer": "english_exact"
            }
          }
        }
      }
    }
  }
}

PUT index/type/1
{
  "body": "Ski resort"
}

PUT index/type/2
{
  "body": "A pair of skis"
}

POST index/_refresh</programlisting>
<remark> CONSOLE</remark>
<simpara>With such a setup, searching for <literal>ski</literal> on <literal>body</literal> would return both documents:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET index/_search
{
  "query": {
    "simple_query_string": {
      "fields": [ "body" ],
      "query": "ski"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<programlisting language="js" linenumbering="unnumbered">{
  "took": 2,
  "timed_out": false,
  "_shards": {
    "total": 5,
    "successful": 5,
    "failed": 0
  },
  "hits": {
    "total": 2,
    "max_score": 0.25811607,
    "hits": [
      {
        "_index": "index",
        "_type": "type",
        "_id": "2",
        "_score": 0.25811607,
        "_source": {
          "body": "A pair of skis"
        }
      },
      {
        "_index": "index",
        "_type": "type",
        "_id": "1",
        "_score": 0.25811607,
        "_source": {
          "body": "Ski resort"
        }
      }
    ]
  }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 2,/"took": "$body.took",/]</remark>
<simpara>On the other hand, searching for <literal>ski</literal> on <literal>body.exact</literal> would only return
document <literal>1</literal> since the analysis chain of <literal>body.exact</literal> does not perform
stemming.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET index/_search
{
  "query": {
    "simple_query_string": {
      "fields": [ "body.exact" ],
      "query": "ski"
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<programlisting language="js" linenumbering="unnumbered">{
  "took": 1,
  "timed_out": false,
  "_shards": {
    "total": 5,
    "successful": 5,
    "failed": 0
  },
  "hits": {
    "total": 1,
    "max_score": 0.25811607,
    "hits": [
      {
        "_index": "index",
        "_type": "type",
        "_id": "1",
        "_score": 0.25811607,
        "_source": {
          "body": "Ski resort"
        }
      }
    ]
  }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 1,/"took": "$body.took",/]</remark>
<simpara>This is not something that is easy to expose to end users, as we would need to
have a way to figure out whether they are looking for an exact match or not and
redirect to the appropriate field accordingly. Also what to do if only parts of
the query need to be matched exactly while other parts should still take
stemming into account?</simpara>
<simpara>Fortunately, the <literal>query_string</literal> and <literal>simple_query_string</literal> queries have a feature
that allows to solve exactly this problem: <literal>quote_field_suffix</literal>. It allows to
tell Elasticsearch that words that appear in between quotes should be redirected
to a different field, see below:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET index/_search
{
  "query": {
    "simple_query_string": {
      "fields": [ "body" ],
      "quote_field_suffix": ".exact",
      "query": "\"ski\""
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<programlisting language="js" linenumbering="unnumbered">{
  "took": 2,
  "timed_out": false,
  "_shards": {
    "total": 5,
    "successful": 5,
    "failed": 0
  },
  "hits": {
    "total": 1,
    "max_score": 0.25811607,
    "hits": [
      {
        "_index": "index",
        "_type": "type",
        "_id": "1",
        "_score": 0.25811607,
        "_source": {
          "body": "Ski resort"
        }
      }
    ]
  }
}</programlisting>
<remark> TESTRESPONSE[s/"took": 2,/"took": "$body.took",/]</remark>
<simpara>In that case, since <literal>ski</literal> was in-between quotes, it was searched on the
<literal>body.exact</literal> field due to the <literal>quote_field_suffix</literal> parameter, so only document
<literal>1</literal> matched. This allows users to mix exact search with stemmed search as they
like.</simpara>
<bridgehead id="consistent-scoring" renderas="sect2">Getting consistent scoring<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/recipes.asciidoc">Edit me</ulink></bridgehead>
<simpara>The fact that Elasticsearch operates with shards and replicas adds challenges
when it comes to having good scoring.</simpara>
<bridgehead id="_scores_are_not_reproducible" renderas="sect3">Scores are not reproducible<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/recipes.asciidoc">Edit me</ulink></bridgehead>
<simpara>Say the same user runs the same request twice in a row and documents do not come
back in the same order both times, this is a pretty bad experience isn&#8217;t it?
Unfortunately this is something that can happen if you have replicas
(<literal>index.number_of_replicas</literal> is greater than 0). The reason is that Elasticsearch
selects the shards that the query should go to in a round-robin fashion, so it
is quite likely if you run the same query twice in a row that it will go to
different copies of the same shard.</simpara>
<simpara>Now why is it a problem? Index statistics are an important part of the score.
And these index statistics may be different across copies of the same shard
due to deleted documents. As you may know when documents are deleted or updated,
the old document is not immediately removed from the index, it is just marked
as deleted and it will only be removed from disk on the next time that the
segment this old document belongs to is merged. However for practical reasons,
those deleted documents are taken into account for index statistics. So imagine
that the primary shard just finished a large merge that removed lots of deleted
documents, then it might have index statistics that are sufficiently different
from the replica (which still have plenty of deleted documents) so that scores
are different too.</simpara>
<simpara>The recommended way to work around this issue is to use a string that identifies
the user that is logged is (a user id or session id for instance) as a
<link linkend="search-request-preference">preference</link>. This ensures that all queries of a
given user are always going to hit the same shards, so scores remain more
consistent across queries.</simpara>
<simpara>This work around has another benefit: when two documents have the same score,
they will be sorted by their internal Lucene doc id (which is unrelated to the
<literal>_id</literal> or <literal>_uid</literal>) by default. However these doc ids could be different across
copies of the same shard. So by always hitting the same shard, we would get
more consistent ordering of documents that have the same scores.</simpara>
<bridgehead id="_relevancy_looks_wrong" renderas="sect3">Relevancy looks wrong<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/recipes.asciidoc">Edit me</ulink></bridgehead>
<simpara>If you notice that two documents with the same content get different scores or
that an exact match is not ranked first, then the issue might be related to
sharding. By default, Elasticsearch makes each shard responsible for producing
its own scores. However since index statistics are an important contributor to
the scores, this only works well if shards have similar index statistics. The
assumption is that since documents are routed evenly to shards by default, then
index statistics should be very similar and scoring would work as expected.
However in the event that you either
 - use routing at index time,
 - query multiple <emphasis>indices</emphasis>,
 - or have too little data in your index
then there are good chances that all shards that are involved in the search
request do not have similar index statistics and relevancy could be bad.</simpara>
<simpara>If you have a small dataset, the easiest way to work around this issue is to
index everything into an index that has a single shard
(<literal>index.number_of_shards: 1</literal>). Then index statistics will be the same for all
documents and scores will be consistent.</simpara>
<simpara>Otherwise the recommended way to work around this issue is to use the
<link linkend="dfs-query-then-fetch"><literal>dfs_query_then_fetch</literal></link> search type. This will make
Elasticsearch perform an inital round trip to all involved shards, asking
them for their index statistics relatively to the query, then the coordinating
node will merge those statistics and send the merged statistics alongside the
request when asking shards to perform the <literal>query</literal> phase, so that shards can
use these global statistics rather than their own statistics in order to do the
scoring.</simpara>
<simpara>In most cases, this additional round trip should be very cheap. However in the
event that your query contains a very large number of fields/terms or fuzzy
queries, beware that gathering statistics alone might not be cheap since all
terms have to be looked up in the terms dictionaries in order to look up
statistics.</simpara>
</chapter>
<chapter id="tune-for-indexing-speed">
<title>Tune for indexing speed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/indexing-speed.asciidoc">Edit me</ulink></title>
<bridgehead id="_use_bulk_requests" renderas="sect2">Use bulk requests<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/indexing-speed.asciidoc">Edit me</ulink></bridgehead>
<simpara>Bulk requests will yield much better performance than single-document index
requests. In order to know the optimal size of a bulk request, you should run
a benchmark on a single node with a single shard. First try to index 100
documents at once, then 200, then 400, etc. doubling the number of documents
in a bulk request in every benchmark run. When the indexing speed starts to
plateau then you know you reached the optimal size of a bulk request for your
data. In case of tie, it is better to err in the direction of too few rather
than too many documents. Beware that too large bulk requests might put the
cluster under memory pressure when many of them are sent concurrently, so
it is advisable to avoid going beyond a couple tens of megabytes per request
even if larger requests seem to perform better.</simpara>
<bridgehead id="_use_multiple_workers_threads_to_send_data_to_elasticsearch" renderas="sect2">Use multiple workers/threads to send data to elasticsearch<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/indexing-speed.asciidoc">Edit me</ulink></bridgehead>
<simpara>A single thread sending bulk requests is unlikely to be able to max out the
indexing capacity of an elasticsearch cluster. In order to use all resources
of the cluster, you should send data from multiple threads or processes. In
addition to making better use of the resources of the cluster, this should
help reduce the cost of each fsync.</simpara>
<simpara>Make sure to watch for <literal>TOO_MANY_REQUESTS (429)</literal> response codes
(<literal>EsRejectedExecutionException</literal> with the Java client), which is the way that
elasticsearch tells you that it cannot keep up with the current indexing rate.
When it happens, you should pause indexing a bit before trying again, ideally
with randomized exponential backoff.</simpara>
<simpara>Similarly to sizing bulk requests, only testing can tell what the optimal
number of workers is. This can be tested by progressively increasing the
number of workers until either I/O or CPU is saturated on the cluster.</simpara>
<bridgehead id="_increase_the_refresh_interval" renderas="sect2">Increase the refresh interval<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/indexing-speed.asciidoc">Edit me</ulink></bridgehead>
<simpara>The default <link linkend="dynamic-index-settings"><literal>index.refresh_interval</literal></link> is <literal>1s</literal>, which
forces elasticsearch to create a new segment every second.
Increasing this value (to say, <literal>30s</literal>) will allow larger segments to flush and
decreases future merge pressure.</simpara>
<bridgehead id="_disable_refresh_and_replicas_for_initial_loads" renderas="sect2">Disable refresh and replicas for initial loads<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/indexing-speed.asciidoc">Edit me</ulink></bridgehead>
<simpara>If you need to load a large amount of data at once, you should disable refresh
by setting <literal>index.refresh_interval</literal> to <literal>-1</literal> and set <literal>index.number_of_replicas</literal>
to <literal>0</literal>. This will temporarily put your index at risk since the loss of any shard
will cause data loss, but at the same time indexing will be faster since
documents will be indexed only once. Once the initial loading is finished, you
can set <literal>index.refresh_interval</literal> and <literal>index.number_of_replicas</literal> back to their
original values.</simpara>
<bridgehead id="_disable_swapping" renderas="sect2">Disable swapping<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/indexing-speed.asciidoc">Edit me</ulink></bridgehead>
<simpara>You should make sure that the operating system is not swapping out the java
process by <link linkend="setup-configuration-memory">disabling swapping</link>.</simpara>
<bridgehead id="_give_memory_to_the_filesystem_cache" renderas="sect2">Give memory to the filesystem cache<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/indexing-speed.asciidoc">Edit me</ulink></bridgehead>
<simpara>The filesystem cache will be used in order to buffer I/O operations. You should
make sure to give at least half the memory of the machine running elasticsearch
to the filesystem cache.</simpara>
<bridgehead id="_use_auto_generated_ids" renderas="sect2">Use auto-generated ids<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/indexing-speed.asciidoc">Edit me</ulink></bridgehead>
<simpara>When indexing a document that has an explicit id, elasticsearch needs to check
whether a document with the same id already exists within the same shard, which
is a costly operation and gets even more costly as the index grows. By using
auto-generated ids, Elasticsearch can skip this check, which makes indexing
faster.</simpara>
<bridgehead id="_use_faster_hardware" renderas="sect2">Use faster hardware<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/indexing-speed.asciidoc">Edit me</ulink></bridgehead>
<simpara>If indexing is I/O bound, you should investigate giving more memory to the
filesystem cache (see above) or buying faster drives. In particular SSD drives
are known to perform better than spinning disks. Always use local storage,
remote filesystems such as <literal>NFS</literal> or <literal>SMB</literal> should be avoided. Also beware of
virtualized storage such as Amazon&#8217;s <literal>Elastic Block Storage</literal>. Virtualized
storage works very well with Elasticsearch, and it is appealing since it is so
fast and simple to set up, but it is also unfortunately inherently slower on an
ongoing basis when compared to dedicated local storage. If you put an index on
<literal>EBS</literal>, be sure to use provisioned IOPS otherwise operations could be quickly
throttled.</simpara>
<simpara>Stripe your index across multiple SSDs by configuring a RAID 0 array. Remember
that it will increase the risk of failure since the failure of any one SSD
destroys the index. However this is typically the right tradeoff to make:
optimize single shards for maximum performance, and then add replicas across
different nodes so there&#8217;s redundancy for any node failures. You can also use
<link linkend="modules-snapshots">snapshot and restore</link> to backup the index for further
insurance.</simpara>
<bridgehead id="_indexing_buffer_size" renderas="sect2">Indexing buffer size<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/indexing-speed.asciidoc">Edit me</ulink></bridgehead>
<simpara>If your node is doing only heavy indexing, be sure
<link linkend="indexing-buffer"><literal>indices.memory.index_buffer_size</literal></link> is large enough to give
at most 512 MB indexing buffer per shard doing heavy indexing (beyond that
indexing performance does not typically improve). Elasticsearch takes that
setting (a percentage of the java heap or an absolute byte-size), and
uses it as a shared buffer across all active shards. Very active shards will
naturally use this buffer more than shards that are performing lightweight
indexing.</simpara>
<simpara>The default is <literal>10%</literal> which is often plenty: for example, if you give the JVM
10GB of memory, it will give 1GB to the index buffer, which is enough to host
two shards that are heavily indexing.</simpara>
</chapter>
<chapter id="tune-for-search-speed">
<title>Tune for search speed<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/search-speed.asciidoc">Edit me</ulink></title>
<bridgehead id="_give_memory_to_the_filesystem_cache_2" renderas="sect2">Give memory to the filesystem cache<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/search-speed.asciidoc">Edit me</ulink></bridgehead>
<simpara>Elasticsearch heavily relies on the filesystem cache in order to make search
fast. In general, you should make sure that at least half the available memory
goes to the filesystem cache so that elasticsearch can keep hot regions of the
index in physical memory.</simpara>
<bridgehead id="_use_faster_hardware_2" renderas="sect2">Use faster hardware<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/search-speed.asciidoc">Edit me</ulink></bridgehead>
<simpara>If your search is I/O bound, you should investigate giving more memory to the
filesystem cache (see above) or buying faster drives. In particular SSD drives
are known to perform better than spinning disks. Always use local storage,
remote filesystems such as <literal>NFS</literal> or <literal>SMB</literal> should be avoided. Also beware of
virtualized storage such as Amazon&#8217;s <literal>Elastic Block Storage</literal>. Virtualized
storage works very well with Elasticsearch, and it is appealing since it is so
fast and simple to set up, but it is also unfortunately inherently slower on an
ongoing basis when compared to dedicated local storage. If you put an index on
<literal>EBS</literal>, be sure to use provisioned IOPS otherwise operations could be quickly
throttled.</simpara>
<simpara>If your search is CPU-bound, you should investigate buying faster CPUs.</simpara>
<bridgehead id="_document_modeling" renderas="sect2">Document modeling<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/search-speed.asciidoc">Edit me</ulink></bridgehead>
<simpara>Documents should be modeled so that search-time operations are as cheap as possible.</simpara>
<simpara>In particular, joins should be avoided. <link linkend="nested"><literal>nested</literal></link> can make queries
several times slower and <link linkend="mapping-parent-field">parent-child</link> relations can make
queries hundreds of times slower. So if the same questions can be answered without
joins by denormalizing documents, significant speedups can be expected.</simpara>
<bridgehead id="_pre_index_data" renderas="sect2">Pre-index data<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/search-speed.asciidoc">Edit me</ulink></bridgehead>
<simpara>You should leverage patterns in your queries to optimize the way data is indexed.
For instance, if all your documents have a <literal>price</literal> field and most queries run
<link linkend="search-aggregations-bucket-range-aggregation"><literal>range</literal></link> aggregations on a fixed
list of ranges, you could make this aggregation faster by pre-indexing the ranges
into the index and using a <link linkend="search-aggregations-bucket-terms-aggregation"><literal>terms</literal></link>
aggregations.</simpara>
<simpara>For instance, if documents look like:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT index/type/1
{
  "designation": "spoon",
  "price": 13
}</programlisting>
<remark> CONSOLE</remark>
<simpara>and search requests look like:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET index/_search
{
  "aggs": {
    "price_ranges": {
      "range": {
        "field": "price",
        "ranges": [
          { "to": 10 },
          { "from": 10, "to": 100 },
          { "from": 100 }
        ]
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>Then documents could be enriched by a <literal>price_range</literal> field at index time, which
should be mapped as a <link linkend="keyword"><literal>keyword</literal></link>:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT index
{
  "mappings": {
    "type": {
      "properties": {
        "price_range": {
          "type": "keyword"
        }
      }
    }
  }
}

PUT index/type/1
{
  "designation": "spoon",
  "price": 13,
  "price_range": "10-100"
}</programlisting>
<remark> CONSOLE</remark>
<simpara>And then search requests could aggregate this new field rather than running a
<literal>range</literal> aggregation on the <literal>price</literal> field.</simpara>
<programlisting language="js" linenumbering="unnumbered">GET index/_search
{
  "aggs": {
    "price_ranges": {
      "terms": {
        "field": "price_range"
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<bridgehead id="_mappings" renderas="sect2">Mappings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/search-speed.asciidoc">Edit me</ulink></bridgehead>
<simpara>The fact that some data is numeric does not mean it should always be mapped as a
<link linkend="number">numeric field</link>. Typically, fields storing identifiers such as an <literal>ISBN</literal>
or any number identifying a record from another database, might benefit from
being mapped as <link linkend="keyword"><literal>keyword</literal></link> rather than <literal>integer</literal> or <literal>long</literal>.</simpara>
<bridgehead id="_avoid_scripts" renderas="sect2">Avoid scripts<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/search-speed.asciidoc">Edit me</ulink></bridgehead>
<simpara>In general, scripts should be avoided. If they are absolutely needed, you
should prefer the <literal>painless</literal> and <literal>expressions</literal> engines.</simpara>
<bridgehead id="_search_rounded_dates" renderas="sect2">Search rounded dates<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/search-speed.asciidoc">Edit me</ulink></bridgehead>
<simpara>Queries on date fields that use <literal>now</literal> are typically not cacheable since the
range that is being matched changes all the time. However switching to a
rounded date is often acceptable in terms of user experience, and has the
benefit of making better use of the query cache.</simpara>
<simpara>For instance the below query:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT index/type/1
{
  "my_date": "2016-05-11T16:30:55.328Z"
}

GET index/_search
{
  "query": {
    "constant_score": {
      "filter": {
        "range": {
          "my_date": {
            "gte": "now-1h",
            "lte": "now"
          }
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>could be replaced with the following query:</simpara>
<programlisting language="js" linenumbering="unnumbered">GET index/_search
{
  "query": {
    "constant_score": {
      "filter": {
        "range": {
          "my_date": {
            "gte": "now-1h/m",
            "lte": "now/m"
          }
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>In that case we rounded to the minute, so if the current time is <literal>16:31:29</literal>,
the range query will match everything whose value of the <literal>my_date</literal> field is
between <literal>15:31:00</literal> and <literal>16:31:59</literal>. And if several users run a query that
contains this range in the same minute, the query cache could help speed things
up a bit. The longer the interval that is used for rounding, the more the query
cache can help, but beware that too aggressive rounding might also hurt user
experience.</simpara>
<note><simpara>It might be tempting to split ranges into a large cacheable part and
smaller not cacheable parts in order to be able to leverage the query cache,
as shown below:</simpara></note>
<programlisting language="js" linenumbering="unnumbered">GET index/_search
{
  "query": {
    "constant_score": {
      "filter": {
        "bool": {
          "should": [
            {
              "range": {
                "my_date": {
                  "gte": "now-1h",
                  "lte": "now-1h/m"
                }
              }
            },
            {
              "range": {
                "my_date": {
                  "gt": "now-1h/m",
                  "lt": "now/m"
                }
              }
            },
            {
              "range": {
                "my_date": {
                  "gte": "now/m",
                  "lte": "now"
                }
              }
            }
          ]
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<remark> TEST[continued]</remark>
<simpara>However such practice might make the query run slower in some cases since the
overhead introduced by the <literal>bool</literal> query may defeat the savings from better
leveraging the query cache.</simpara>
<bridgehead id="_force_merge_read_only_indices" renderas="sect2">Force-merge read-only indices<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/search-speed.asciidoc">Edit me</ulink></bridgehead>
<simpara>Indices that are read-only would benefit from being
<link linkend="indices-forcemerge">merged down to a single segment</link>. This is typically the
case with time-based indices: only the index for the current time frame is
getting new documents while older indices are read-only.</simpara>
<important><simpara>Don&#8217;t force-merge indices that are still being written to&#8201;&#8212;&#8201;leave
merging to the background merge process.</simpara></important>
<bridgehead id="_warm_up_global_ordinals" renderas="sect2">Warm up global ordinals<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/search-speed.asciidoc">Edit me</ulink></bridgehead>
<simpara>Global ordinals are a data-structure that is used in order to run
<link linkend="search-aggregations-bucket-terms-aggregation"><literal>terms</literal></link> aggregations on
<link linkend="keyword"><literal>keyword</literal></link> fields. They are loaded lazily in memory because
elasticsearch does not know which fields will be used in <literal>terms</literal> aggregations
and which fields won&#8217;t. You can tell elasticsearch to load global ordinals
eagerly at refresh-time by configuring mappings as described below:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT index
{
  "mappings": {
    "type": {
      "properties": {
        "foo": {
          "type": "keyword",
          "eager_global_ordinals": true
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_warm_up_the_filesystem_cache" renderas="sect2">Warm up the filesystem cache<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/search-speed.asciidoc">Edit me</ulink></bridgehead>
<simpara>If the machine running elasticsearch is restarted, the filesystem cache will be
empty, so it will take some time before the operating system loads hot regions
of the index into memory so that search operations are fast. You can explicitly
tell the operating system which files should be loaded into memory eagerly
depending on the file extension using the <link linkend="file-system"><literal>index.store.preload</literal></link>
setting.</simpara>
<warning><simpara>Loading data into the filesystem cache eagerly on too many indices or
too many files will make search <emphasis>slower</emphasis> if the filesystem cache is not large
enough to hold all the data. Use with caution.</simpara></warning>
</chapter>
<chapter id="tune-for-disk-usage">
<title>Tune for disk usage<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/disk-usage.asciidoc">Edit me</ulink></title>
<bridgehead id="_disable_the_features_you_do_not_need" renderas="sect2">Disable the features you do not need<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/disk-usage.asciidoc">Edit me</ulink></bridgehead>
<simpara>By default elasticsearch indexes and adds doc values to most fields so that they
can be searched and aggregated out of the box. For instance if you have a numeric
field called <literal>foo</literal> that you need to run histograms on but that you never need to
filter on, you can safely disable indexing on this field in your
<link linkend="mappings">mappings</link>:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT index
{
  "mappings": {
    "type": {
      "properties": {
        "foo": {
          "type": "integer",
          "index": false
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara><link linkend="text"><literal>text</literal></link> fields store normalization factors in the index in order to be
able to score documents. If you only need matching capabilities on a <literal>text</literal>
field but do not care about the produced scores, you can configure elasticsearch
to not write norms to the index:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT index
{
  "mappings": {
    "type": {
      "properties": {
        "foo": {
          "type": "text",
          "norms": false
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara><link linkend="text"><literal>text</literal></link> fields also store frequencies and positions in the index by
default. Frequencies are used to compute scores and positions are used to run
phrase queries. If you do not need to run phrase queries, you can tell
elasticsearch to not index positions:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT index
{
  "mappings": {
    "type": {
      "properties": {
        "foo": {
          "type": "text",
          "index_options": "freqs"
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<simpara>Furthermore if you do not care about scoring either, you can configure
elasticsearch to just index matching documents for every term. You will
still be able to search on this field, but phrase queries will raise errors
and scoring will assume that terms appear only once in every document.</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT index
{
  "mappings": {
    "type": {
      "properties": {
        "foo": {
          "type": "text",
          "norms": false,
          "index_options": "freqs"
        }
      }
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_don_8217_t_use_default_dynamic_string_mappings" renderas="sect2">Don&#8217;t use default dynamic string mappings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/disk-usage.asciidoc">Edit me</ulink></bridgehead>
<simpara>The default <link linkend="dynamic-mapping">dynamic string mappings</link> will index string fields
both as <link linkend="text"><literal>text</literal></link> and <link linkend="keyword"><literal>keyword</literal></link>. This is wasteful if you only
need one of them. Typically an <literal>id</literal> field will only need to be indexed as a
<literal>keyword</literal> while a <literal>body</literal> field will only need to be indexed as a <literal>text</literal> field.</simpara>
<simpara>This can be disabled by either configuring explicit mappings on string fields
or setting up dynamic templates that will map string fields as either <literal>text</literal>
or <literal>keyword</literal>.</simpara>
<simpara>For instance, here is a template that can be used in order to only map string
fields as <literal>keyword</literal>:</simpara>
<programlisting language="js" linenumbering="unnumbered">PUT index
{
  "mappings": {
    "type": {
      "dynamic_templates": [
        {
          "strings": {
            "match_mapping_type": "string",
            "mapping": {
              "type": "keyword"
            }
          }
        }
      ]
    }
  }
}</programlisting>
<remark> CONSOLE</remark>
<bridgehead id="_disable_literal__all_literal" renderas="sect2">Disable <literal>_all</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/disk-usage.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <link linkend="mapping-all-field"><literal>_all</literal></link> field indexes the value of all fields of a
document and can use significant space. If you never need to search against all
fields at the same time, it can be disabled.</simpara>
<bridgehead id="_use_literal_best_compression_literal" renderas="sect2">Use <literal>best_compression</literal><ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/disk-usage.asciidoc">Edit me</ulink></bridgehead>
<simpara>The <literal>_source</literal> and stored fields can easily take a non negligible amount of disk
space. They can be compressed more aggressively by using the <literal>best_compression</literal>
<link linkend="index-codec">codec</link>.</simpara>
<bridgehead id="_use_the_smallest_numeric_type_that_is_sufficient" renderas="sect2">Use the smallest numeric type that is sufficient<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/how-to/disk-usage.asciidoc">Edit me</ulink></bridgehead>
<simpara>The type that you pick for <link linkend="number">numeric data</link> can have a significant impact
on disk usage. In particular, integers should be stored using an integer type
(<literal>byte</literal>, <literal>short</literal>, <literal>integer</literal> or <literal>long</literal>) and floating points should either be
stored in a <literal>scaled_float</literal> if appropriate or in the smallest type that fits the
use-case: using <literal>float</literal> over <literal>double</literal>, or <literal>half_float</literal> over <literal>float</literal> will help
save storage.</simpara>
</chapter>
</part>
<part id="testing">
<title>Testing <ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/testing.asciidoc">Edit me</ulink></title>
<partintro>
<simpara>This section is about utilizing elasticsearch as part of your testing infrastructure.</simpara>
<bridgehead id="testing-header" renderas="sect1">Testing:<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/testing.asciidoc">Edit me</ulink></bridgehead>
<itemizedlist>
<listitem>
<simpara>
<xref linkend="testing-framework"/>
</simpara>
</listitem>
</itemizedlist>
</partintro>
<chapter id="testing-framework">
<title>Java Testing Framework<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/testing/testing-framework.asciidoc">Edit me</ulink></title>
<simpara id="testing-intro">Testing is a crucial part of your application, and as information retrieval itself is already a complex topic, there should not be any additional complexity in setting up a testing infrastructure, which uses elasticsearch. This is the main reason why we decided to release an additional file to the release, which allows you to use the same testing infrastructure we do in the elasticsearch core. The testing framework allows you to setup clusters with multiple nodes in order to check if your code covers everything needed to run in a cluster. The framework prevents you from writing complex code yourself to start, stop or manage several test nodes in a cluster. In addition there is another very important feature called randomized testing, which you are getting for free as it is part of the elasticsearch infrastructure.</simpara>
<section id="why-randomized-testing">
<title>why randomized testing?<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/testing/testing-framework.asciidoc">Edit me</ulink></title>
<simpara>The key concept of randomized testing is not to use the same input values for every testcase, but still be able to reproduce it in case of a failure. This allows to test with vastly different input variables in order to make sure, that your implementation is actually independent from your provided test data.</simpara>
<simpara>All of the tests are run using a custom junit runner, the <literal>RandomizedRunner</literal> provided by the randomized-testing project. If you are interested in the implementation being used, check out the <ulink url="http://labs.carrotsearch.com/randomizedtesting.html">RandomizedTesting webpage</ulink>.</simpara>
</section>
<section id="using-elasticsearch-test-classes">
<title>Using the elasticsearch test classes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/testing/testing-framework.asciidoc">Edit me</ulink></title>
<simpara>First, you need to include the testing dependency in your project, along with the elasticsearch dependency you have already added. If you use maven and its <literal>pom.xml</literal> file, it looks like this</simpara>
<programlisting language="xml" linenumbering="unnumbered">&lt;dependencies&gt;
  &lt;dependency&gt;
    &lt;groupId&gt;org.apache.lucene&lt;/groupId&gt;
    &lt;artifactId&gt;lucene-test-framework&lt;/artifactId&gt;
    &lt;version&gt;${lucene.version}&lt;/version&gt;
    &lt;scope&gt;test&lt;/scope&gt;
  &lt;/dependency&gt;
  &lt;dependency&gt;
    &lt;groupId&gt;org.elasticsearch.test&lt;/groupId&gt;
    &lt;artifactId&gt;framework&lt;/artifactId&gt;
    &lt;version&gt;${elasticsearch.version}&lt;/version&gt;
    &lt;scope&gt;test&lt;/scope&gt;
  &lt;/dependency&gt;
&lt;/dependencies&gt;</programlisting>
<simpara>Replace the elasticsearch version and the lucene version with the corresponding elasticsearch version and its accompanying lucene release.</simpara>
<simpara>We provide a few classes that you can inherit from in your own test classes which provide:</simpara>
<itemizedlist>
<listitem>
<simpara>
pre-defined loggers
</simpara>
</listitem>
<listitem>
<simpara>
randomized testing infrastructure
</simpara>
</listitem>
<listitem>
<simpara>
a number of helper methods
</simpara>
</listitem>
</itemizedlist>
</section>
<section id="unit-tests">
<title>unit tests<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/testing/testing-framework.asciidoc">Edit me</ulink></title>
<simpara>If your test is a well isolated unit test which doesn&#8217;t need a running elasticsearch cluster, you can use the <literal>ESTestCase</literal>. If you are testing lucene features, use <literal>ESTestCase</literal> and if you are testing concrete token streams, use the <literal>ESTokenStreamTestCase</literal> class. Those specific classes execute additional checks which ensure that no resources leaks are happening, after the test has run.</simpara>
</section>
<section id="integration-tests">
<title>integration tests<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/testing/testing-framework.asciidoc">Edit me</ulink></title>
<simpara>These kind of tests require firing up a whole cluster of nodes, before the tests can actually be run. Compared to unit tests they are obviously way more time consuming, but the test infrastructure tries to minimize the time cost by only restarting the whole cluster, if this is configured explicitly.</simpara>
<simpara>The class your tests have to inherit from is <literal>ESIntegTestCase</literal>. By inheriting from this class, you will no longer need to start elasticsearch nodes manually in your test, although you might need to ensure that at least a certain number of nodes are up. The integration test behaviour can be configured heavily by specifying different system properties on test runs. See the <literal>TESTING.asciidoc</literal> documentation in the <ulink url="https://github.com/elastic/elasticsearch/blob/master/TESTING.asciidoc">source repository</ulink> for more information.</simpara>
<section id="number-of-shards">
<title>number of shards<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/testing/testing-framework.asciidoc">Edit me</ulink></title>
<simpara>The number of shards used for indices created during integration tests is randomized between <literal>1</literal> and <literal>10</literal> unless overwritten upon index creation via index settings.
The rule of thumb is not to specify the number of shards unless needed, so that each test will use a different one all the time. Alternatively you can override the <literal>numberOfShards()</literal> method. The same applies to the <literal>numberOfReplicas()</literal> method.</simpara>
</section>
<section id="helper-methods">
<title>generic helper methods<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/testing/testing-framework.asciidoc">Edit me</ulink></title>
<simpara>There are a couple of helper methods in <literal>ESIntegTestCase</literal>, which will make your tests shorter and more concise.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>refresh()</literal>
</simpara>
</entry>
<entry>
<simpara>
Refreshes all indices in a cluster
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>ensureGreen()</literal>
</simpara>
</entry>
<entry>
<simpara>
Ensures a green health cluster state, waiting for relocations. Waits the default timeout of 30 seconds before failing.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>ensureYellow()</literal>
</simpara>
</entry>
<entry>
<simpara>
Ensures a yellow health cluster state, also waits for 30 seconds before failing.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>createIndex(name)</literal>
</simpara>
</entry>
<entry>
<simpara>
Creates an index with the specified name
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>flush()</literal>
</simpara>
</entry>
<entry>
<simpara>
Flushes all indices in a cluster
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>flushAndRefresh()</literal>
</simpara>
</entry>
<entry>
<simpara>
Combines <literal>flush()</literal> and <literal>refresh()</literal> calls
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>forceMerge()</literal>
</simpara>
</entry>
<entry>
<simpara>
Waits for all relocations and force merges all indices in the cluster to one segment.
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>indexExists(name)</literal>
</simpara>
</entry>
<entry>
<simpara>
Checks if given index exists
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>admin()</literal>
</simpara>
</entry>
<entry>
<simpara>
Returns an <literal>AdminClient</literal> for administrative tasks
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>clusterService()</literal>
</simpara>
</entry>
<entry>
<simpara>
Returns the cluster service java class
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>cluster()</literal>
</simpara>
</entry>
<entry>
<simpara>
Returns the test cluster class, which is explained in the next paragraphs
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
<section id="test-cluster-methods">
<title>test cluster methods<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/testing/testing-framework.asciidoc">Edit me</ulink></title>
<simpara>The <literal>InternalTestCluster</literal> class is the heart of the cluster functionality in a randomized test and allows you to configure a specific setting or replay certain types of outages to check, how your custom code reacts.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>ensureAtLeastNumNodes(n)</literal>
</simpara>
</entry>
<entry>
<simpara>
Ensure at least the specified number of nodes is running in the cluster
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>ensureAtMostNumNodes(n)</literal>
</simpara>
</entry>
<entry>
<simpara>
Ensure at most the specified number of nodes is running in the cluster
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>getInstance()</literal>
</simpara>
</entry>
<entry>
<simpara>
Get a guice instantiated instance of a class from a random node
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>getInstanceFromNode()</literal>
</simpara>
</entry>
<entry>
<simpara>
Get a guice instantiated instance of a class from a specified node
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>stopRandomNode()</literal>
</simpara>
</entry>
<entry>
<simpara>
Stop a random node in your cluster to mimic an outage
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>stopCurrentMasterNode()</literal>
</simpara>
</entry>
<entry>
<simpara>
Stop the current master node to force a new election
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>stopRandomNonMaster()</literal>
</simpara>
</entry>
<entry>
<simpara>
Stop a random non master node to mimic an outage
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>buildNode()</literal>
</simpara>
</entry>
<entry>
<simpara>
Create a new elasticsearch node
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>startNode(settings)</literal>
</simpara>
</entry>
<entry>
<simpara>
Create and start a new elasticsearch node
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
<section id="changing-node-settings">
<title>Changing node settings<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/testing/testing-framework.asciidoc">Edit me</ulink></title>
<simpara>If you want to ensure a certain configuration for the nodes, which are started as part of the <literal>EsIntegTestCase</literal>, you can override the <literal>nodeSettings()</literal> method</simpara>
<programlisting language="java" linenumbering="unnumbered">public class Mytests extends ESIntegTestCase {

  @Override
  protected Settings nodeSettings(int nodeOrdinal) {
      return Settings.builder().put(super.nodeSettings(nodeOrdinal))
             .put("node.mode", "network")
             .build();
  }

}</programlisting>
</section>
<section id="accessing-clients">
<title>Accessing clients<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/testing/testing-framework.asciidoc">Edit me</ulink></title>
<simpara>In order to execute any actions, you have to use a client. You can use the <literal>ESIntegTestCase.client()</literal> method to get back a random client. This client can be a <literal>TransportClient</literal> or a <literal>NodeClient</literal> - and usually you do not need to care as long as the action gets executed. There are several more methods for client selection inside of the <literal>InternalTestCluster</literal> class, which can be accessed using the <literal>ESIntegTestCase.internalCluster()</literal> method.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>iterator()</literal>
</simpara>
</entry>
<entry>
<simpara>
An iterator over all available clients
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>masterClient()</literal>
</simpara>
</entry>
<entry>
<simpara>
Returns a client which is connected to the master node
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>nonMasterClient()</literal>
</simpara>
</entry>
<entry>
<simpara>
Returns a client which is not connected to the master node
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>clientNodeClient()</literal>
</simpara>
</entry>
<entry>
<simpara>
Returns a client, which is running on a client node
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>client(String nodeName)</literal>
</simpara>
</entry>
<entry>
<simpara>
Returns a client to a given node
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>smartClient()</literal>
</simpara>
</entry>
<entry>
<simpara>
Returns a smart client
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
</section>
<section id="scoping">
<title>Scoping<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/testing/testing-framework.asciidoc">Edit me</ulink></title>
<simpara>By default the tests are run with unique cluster per test suite. Of course all indices and templates are deleted between each test. However, sometimes you need to start a new cluster for each test - for example, if you load a certain plugin, but you do not want to load it for every test.</simpara>
<simpara>You can use the <literal>@ClusterScope</literal> annotation at class level to configure this behaviour</simpara>
<programlisting language="java" linenumbering="unnumbered">@ClusterScope(scope=TEST, numDataNodes=1)
public class CustomSuggesterSearchTests extends ESIntegTestCase {
  // ... tests go here
}</programlisting>
<simpara>The above sample configures the test to use a new cluster for each test method. The default scope is <literal>SUITE</literal> (one cluster for all
test methods in the test). The <literal>numDataNodes</literal> settings allows you to only start a certain number of data nodes, which can speed up test
execution, as starting a new node is a costly and time consuming operation and might not be needed for this test.</simpara>
<simpara>By default, the testing infrastructure will randomly start dedicated master nodes. If you want to disable dedicated masters
you can set <literal>supportsDedicatedMasters=false</literal> in a similar fashion to the <literal>numDataNodes</literal> setting. If dedicated master nodes are not used,
data nodes will be allowed to become masters as well.</simpara>
</section>
<section id="changing-node-configuration">
<title>Changing plugins via configuration<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/testing/testing-framework.asciidoc">Edit me</ulink></title>
<simpara>As elasticsearch is using JUnit 4, using the <literal>@Before</literal> and <literal>@After</literal> annotations is not a problem. However you should keep in mind, that this does not have any effect in your cluster setup, as the cluster is already up and running when those methods are run. So in case you want to configure settings - like loading a plugin on node startup - before the node is actually running, you should overwrite the <literal>nodePlugins()</literal> method from the <literal>ESIntegTestCase</literal> class and return the plugin classes each node should load.</simpara>
<programlisting language="java" linenumbering="unnumbered">@Override
protected Collection&lt;Class&lt;? extends Plugin&gt;&gt; nodePlugins() {
  return pluginList(CustomSuggesterPlugin.class);
}</programlisting>
</section>
</section>
<section id="randomized-testing">
<title>Randomized testing<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/testing/testing-framework.asciidoc">Edit me</ulink></title>
<simpara>The code snippets you saw so far did not show any trace of randomized testing features, as they are carefully hidden under the hood. However when you are writing your own tests, you should make use of these features as well. Before starting with that, you should know, how to repeat a failed test with the same setup, how it failed. Luckily this is quite easy, as the whole mvn call is logged together with failed tests, which means you can simply copy and paste that line and run the test.</simpara>
<section id="generating-random-data">
<title>Generating random data<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/testing/testing-framework.asciidoc">Edit me</ulink></title>
<simpara>The next step is to convert your test using static test data into a test using randomized test data. The kind of data you could randomize varies a lot with the functionality you are testing against. Take a look at the following examples (note, that this list could go on for pages, as a distributed system has many, many moving parts):</simpara>
<itemizedlist>
<listitem>
<simpara>
Searching for data using arbitrary UTF8 signs
</simpara>
</listitem>
<listitem>
<simpara>
Changing your mapping configuration, index and field names with each run
</simpara>
</listitem>
<listitem>
<simpara>
Changing your response sizes/configurable limits with each run
</simpara>
</listitem>
<listitem>
<simpara>
Changing the number of shards/replicas when creating an index
</simpara>
</listitem>
</itemizedlist>
<simpara>So, how can you create random data. The most important thing to know is, that you never should instantiate your own <literal>Random</literal> instance, but use the one provided in the <literal>RandomizedTest</literal>, from which all elasticsearch dependent test classes inherit from.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>getRandom()</literal>
</simpara>
</entry>
<entry>
<simpara>
Returns the random instance, which can recreated when calling the test with specific parameters
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>randomBoolean()</literal>
</simpara>
</entry>
<entry>
<simpara>
Returns a random boolean
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>randomByte()</literal>
</simpara>
</entry>
<entry>
<simpara>
Returns a random byte
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>randomShort()</literal>
</simpara>
</entry>
<entry>
<simpara>
Returns a random short
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>randomInt()</literal>
</simpara>
</entry>
<entry>
<simpara>
Returns a random integer
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>randomLong()</literal>
</simpara>
</entry>
<entry>
<simpara>
Returns a random long
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>randomFloat()</literal>
</simpara>
</entry>
<entry>
<simpara>
Returns a random float
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>randomDouble()</literal>
</simpara>
</entry>
<entry>
<simpara>
Returns a random double
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>randomInt(max)</literal>
</simpara>
</entry>
<entry>
<simpara>
Returns a random integer between 0 and max
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>between()</literal>
</simpara>
</entry>
<entry>
<simpara>
Returns a random between the supplied range
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>atLeast()</literal>
</simpara>
</entry>
<entry>
<simpara>
Returns a random integer of at least the specified integer
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>atMost()</literal>
</simpara>
</entry>
<entry>
<simpara>
Returns a random integer of at most the specified integer
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>randomLocale()</literal>
</simpara>
</entry>
<entry>
<simpara>
Returns a random locale
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>randomTimeZone()</literal>
</simpara>
</entry>
<entry>
<simpara>
Returns a random timezone
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>randomFrom()</literal>
</simpara>
</entry>
<entry>
<simpara>
Returns a random element from a list/array
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>In addition, there are a couple of helper methods, allowing you to create random ASCII and Unicode strings, see methods beginning with <literal>randomAscii</literal>, <literal>randomUnicode</literal>, and <literal>randomRealisticUnicode</literal> in the random test class. The latter one tries to create more realistic unicode string by not being arbitrary random.</simpara>
<simpara>If you want to debug a specific problem with a specific random seed, you can use the <literal>@Seed</literal> annotation to configure a specific seed for a test. If you want to run a test more than once, instead of starting the whole test suite over and over again, you can use the <literal>@Repeat</literal> annotation with an arbitrary value. Each iteration than gets run with a different seed.</simpara>
</section>
</section>
<section id="assertions">
<title>Assertions<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/testing/testing-framework.asciidoc">Edit me</ulink></title>
<simpara>As many elasticsearch tests are checking for a similar output, like the amount of hits or the first hit or special highlighting, a couple of predefined assertions have been created. Those have been put into the <literal>ElasticsearchAssertions</literal> class. There is also a specific geo assertions in <literal>ElasticsearchGeoAssertions</literal>.</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>assertHitCount()</literal>
</simpara>
</entry>
<entry>
<simpara>
Checks hit count of a search or count request
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>assertAcked()</literal>
</simpara>
</entry>
<entry>
<simpara>
Ensure the a request has been acknowledged by the master
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>assertSearchHits()</literal>
</simpara>
</entry>
<entry>
<simpara>
Asserts a search response contains specific ids
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>assertMatchCount()</literal>
</simpara>
</entry>
<entry>
<simpara>
Asserts a matching count from a percolation response
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>assertFirstHit()</literal>
</simpara>
</entry>
<entry>
<simpara>
Asserts the first hit hits the specified matcher
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>assertSecondHit()</literal>
</simpara>
</entry>
<entry>
<simpara>
Asserts the second hit hits the specified matcher
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>assertThirdHit()</literal>
</simpara>
</entry>
<entry>
<simpara>
Asserts the third hits hits the specified matcher
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>assertSearchHit()</literal>
</simpara>
</entry>
<entry>
<simpara>
Assert a certain element in a search response hits the specified matcher
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>assertNoFailures()</literal>
</simpara>
</entry>
<entry>
<simpara>
Asserts that no shard failures have occurred in the response
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>assertFailures()</literal>
</simpara>
</entry>
<entry>
<simpara>
Asserts that shard failures have happened during a search request
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>assertHighlight()</literal>
</simpara>
</entry>
<entry>
<simpara>
Assert specific highlights matched
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>assertSuggestion()</literal>
</simpara>
</entry>
<entry>
<simpara>
Assert for specific suggestions
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>assertSuggestionSize()</literal>
</simpara>
</entry>
<entry>
<simpara>
Assert for specific suggestion count
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>assertThrows()</literal>
</simpara>
</entry>
<entry>
<simpara>
Assert a specific exception has been thrown
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>Common matchers</simpara>
<informaltable tabstyle="horizontal" frame="none" colsep="0" rowsep="0"><tgroup cols="2"><colspec colwidth="15*"/><colspec colwidth="85*"/><tbody valign="top">
<row>
<entry>
<simpara>
<literal>hasId()</literal>
</simpara>
</entry>
<entry>
<simpara>
Matcher to check for a search hit id
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>hasType()</literal>
</simpara>
</entry>
<entry>
<simpara>
Matcher to check for a search hit type
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>hasIndex()</literal>
</simpara>
</entry>
<entry>
<simpara>
Matcher to check for a search hit index
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>hasScore()</literal>
</simpara>
</entry>
<entry>
<simpara>
Matcher to check for a certain score of a hit
</simpara>
</entry>
</row>
<row>
<entry>
<simpara>
<literal>hasStatus()</literal>
</simpara>
</entry>
<entry>
<simpara>
Matcher to check for a certain <literal>RestStatus</literal> of a response
</simpara>
</entry>
</row>
</tbody></tgroup></informaltable>
<simpara>Usually, you would combine assertions and matchers in your test like this</simpara>
<programlisting language="java" linenumbering="unnumbered">SearchResponse searchResponse = client().prepareSearch() ...;
assertHitCount(searchResponse, 4);
assertFirstHit(searchResponse, hasId("4"));
assertSearchHits(searchResponse, "1", "2", "3", "4");</programlisting>
</section>
</chapter>
</part>
<glossary id="glossary">
<title>Glossary of terms<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/glossary.asciidoc">Edit me</ulink></title>
<glossentry>
<glossterm>
<anchor id="glossary-analysis" xreflabel="[glossary-analysis]"/> analysis 
</glossterm>
<glossdef>
<simpara>
  Analysis is the process of converting <link linkend="glossary-text">full text</link> to
  <link linkend="glossary-term">terms</link>. Depending on which analyzer is used, these phrases:
  <literal>FOO BAR</literal>, <literal>Foo-Bar</literal>, <literal>foo,bar</literal> will probably all result in the
  terms <literal>foo</literal> and <literal>bar</literal>. These terms are what is actually stored in
  the index.
 <?asciidoc-br?>
  A full text query (not a <link linkend="glossary-term">term</link> query) for <literal>FoO:bAR</literal> will
  also be analyzed to the terms <literal>foo</literal>,<literal>bar</literal> and will thus match the
  terms stored in the index.
 <?asciidoc-br?>
  It is this process of analysis (both at index time and at search time)
  that allows elasticsearch to perform full text queries.
 <?asciidoc-br?>
  Also see <link linkend="glossary-text">text</link> and <link linkend="glossary-term">term</link>.
</simpara>
</glossdef>
</glossentry>
<glossentry>
<glossterm>
<anchor id="glossary-cluster" xreflabel="[glossary-cluster]"/> cluster 
</glossterm>
<glossdef>
<simpara>
  A cluster consists of one or more <link linkend="glossary-node">nodes</link> which share the
  same cluster name. Each cluster has a single master node which is
  chosen automatically by the cluster and which can be replaced if the
  current master node fails.
</simpara>
</glossdef>
</glossentry>
<glossentry>
<glossterm>
<anchor id="glossary-document" xreflabel="[glossary-document]"/> document 
</glossterm>
<glossdef>
<simpara>
  A document is a JSON document which is stored in elasticsearch. It is
  like a row in a table in a relational database. Each document is
  stored in an <link linkend="glossary-index">index</link> and has a <link linkend="glossary-type">type</link> and an
  <link linkend="glossary-id">id</link>.
 <?asciidoc-br?>
  A document is a JSON object (also known in other languages as a hash /
  hashmap / associative array) which contains zero or more
  <link linkend="glossary-field">fields</link>, or key-value pairs.
 <?asciidoc-br?>
  The original JSON document that is indexed will be stored in the
  <link linkend="glossary-source_field"><literal>_source</literal> field</link>, which is returned by default when
  getting or searching for a document.
</simpara>
</glossdef>
</glossentry>
<glossentry>
<glossterm>
<anchor id="glossary-id" xreflabel="[glossary-id]"/> id 
</glossterm>
<glossdef>
<simpara>
  The ID of a <link linkend="glossary-document">document</link> identifies a document. The
  <literal>index/type/id</literal> of a document must be unique. If no ID is provided,
  then it will be auto-generated. (also see <link linkend="glossary-routing">routing</link>)
</simpara>
</glossdef>
</glossentry>
<glossentry>
<glossterm>
<anchor id="glossary-field" xreflabel="[glossary-field]"/> field 
</glossterm>
<glossdef>
<simpara>
  A <link linkend="glossary-document">document</link> contains a list of fields, or key-value
  pairs. The value can be a simple (scalar) value (eg a string, integer,
  date), or a nested structure like an array or an object. A field is
  similar to a column in a table in a relational database.
 <?asciidoc-br?>
  The <link linkend="glossary-mapping">mapping</link> for each field has a field <emphasis>type</emphasis> (not to
  be confused with document <link linkend="glossary-type">type</link>) which indicates the type
  of data that can be stored in that field, eg <literal>integer</literal>, <literal>string</literal>,
  <literal>object</literal>. The mapping also allows you to define (amongst other things)
  how the value for a field should be analyzed.
</simpara>
</glossdef>
</glossentry>
<glossentry>
<glossterm>
<anchor id="glossary-index" xreflabel="[glossary-index]"/> index 
</glossterm>
<glossdef>
<simpara>
  An index is like a <emphasis>table</emphasis> in a relational database. It has a
  <link linkend="glossary-mapping">mapping</link> which defines the <link linkend="glossary-field">fields</link> in the index,
  which are grouped by multiple <link linkend="glossary-type">type</link>.
 <?asciidoc-br?>
  An index is a logical namespace which maps to one or more
  <link linkend="glossary-primary-shard">primary shards</link> and can have zero or more
  <link linkend="glossary-replica-shard">replica shards</link>.
</simpara>
</glossdef>
</glossentry>
<glossentry>
<glossterm>
<anchor id="glossary-mapping" xreflabel="[glossary-mapping]"/> mapping 
</glossterm>
<glossdef>
<simpara>
  A mapping is like a <emphasis>schema definition</emphasis> in a relational database. Each
  <link linkend="glossary-index">index</link> has a mapping, which defines each <link linkend="glossary-type">type</link>
  within the index, plus a number of index-wide settings.
 <?asciidoc-br?>
  A mapping can either be defined explicitly, or it will be generated
  automatically when a document is indexed.
</simpara>
</glossdef>
</glossentry>
<glossentry>
<glossterm>
<anchor id="glossary-node" xreflabel="[glossary-node]"/> node 
</glossterm>
<glossdef>
<simpara>
  A node is a running instance of elasticsearch which belongs to a
  <link linkend="glossary-cluster">cluster</link>. Multiple nodes can be started on a single
  server for testing purposes, but usually you should have one node per
  server.
 <?asciidoc-br?>
  At startup, a node will use unicast to discover an existing cluster with
  the same cluster name and will try to join that cluster.
</simpara>
</glossdef>
</glossentry>
<glossentry>
<glossterm>
<anchor id="glossary-primary-shard" xreflabel="[glossary-primary-shard]"/> primary shard 
</glossterm>
<glossdef>
<simpara>
  Each document is stored in a single primary <link linkend="glossary-shard">shard</link>. When
  you index a document, it is indexed first on the primary shard, then
  on all <link linkend="glossary-replica-shard">replicas</link> of the primary shard.
 <?asciidoc-br?>
  By default, an <link linkend="glossary-index">index</link> has 5 primary shards. You can
  specify fewer or more primary shards to scale the number of
  <link linkend="glossary-document">documents</link> that your index can handle.
 <?asciidoc-br?>
  You cannot change the number of primary shards in an index, once the
  index is created.
 <?asciidoc-br?>
  See also <link linkend="glossary-routing">routing</link>
</simpara>
</glossdef>
</glossentry>
<glossentry>
<glossterm>
<anchor id="glossary-replica-shard" xreflabel="[glossary-replica-shard]"/> replica shard 
</glossterm>
<glossdef>
<simpara>
  Each <link linkend="glossary-primary-shard">primary shard</link> can have zero or more
  replicas. A replica is a copy of the primary shard, and has two
  purposes:
 <?asciidoc-br?>
</simpara>
<orderedlist numeration="arabic">
<listitem>
<simpara>
increase failover: a replica shard can be promoted to a primary
  shard if the primary fails
</simpara>
</listitem>
<listitem>
<simpara>
increase performance: get and search requests can be handled by
  primary or replica shards.
 <?asciidoc-br?>
  By default, each primary shard has one replica, but the number of
  replicas can be changed dynamically on an existing index. A replica
  shard will never be started on the same node as its primary shard.
</simpara>
</listitem>
</orderedlist>
</glossdef>
</glossentry>
<glossentry>
<glossterm>
<anchor id="glossary-routing" xreflabel="[glossary-routing]"/> routing 
</glossterm>
<glossdef>
<simpara>
  When you index a document, it is stored on a single
  <link linkend="glossary-primary-shard">primary shard</link>. That shard is chosen by hashing
  the <literal>routing</literal> value. By default, the <literal>routing</literal> value is derived from
  the ID of the document or, if the document has a specified parent
  document, from the ID of the parent document (to ensure that child and
  parent documents are stored on the same shard).
 <?asciidoc-br?>
  This value can be overridden by specifying a <literal>routing</literal> value at index
  time, or a <link linkend="mapping-routing-field">routing   field</link> in the <link linkend="glossary-mapping">mapping</link>.
</simpara>
</glossdef>
</glossentry>
<glossentry>
<glossterm>
<anchor id="glossary-shard" xreflabel="[glossary-shard]"/> shard 
</glossterm>
<glossdef>
<simpara>
  A shard is a single Lucene instance. It is a low-level “worker” unit
  which is managed automatically by elasticsearch. An index is a logical
  namespace which points to <link linkend="glossary-primary-shard">primary</link> and
  <link linkend="glossary-replica-shard">replica</link> shards.
 <?asciidoc-br?>
  Other than defining the number of primary and replica shards that an
  index should have, you never need to refer to shards directly.
  Instead, your code should deal only with an index.
 <?asciidoc-br?>
  Elasticsearch distributes shards amongst all <link linkend="glossary-node">nodes</link> in the
  <link linkend="glossary-cluster">cluster</link>, and can move shards automatically from one
  node to another in the case of node failure, or the addition of new
  nodes.
</simpara>
</glossdef>
</glossentry>
<glossentry>
<glossterm>
<anchor id="glossary-source_field" xreflabel="[glossary-source_field]"/> source field 
</glossterm>
<glossdef>
<simpara>
  By default, the JSON document that you index will be stored in the
  <literal>_source</literal> field and will be returned by all get and search requests.
  This allows you access to the original object directly from search
  results, rather than requiring a second step to retrieve the object
  from an ID.
</simpara>
</glossdef>
</glossentry>
<glossentry>
<glossterm>
<anchor id="glossary-term" xreflabel="[glossary-term]"/> term 
</glossterm>
<glossdef>
<simpara>
  A term is an exact value that is indexed in elasticsearch. The terms
  <literal>foo</literal>, <literal>Foo</literal>, <literal>FOO</literal> are NOT equivalent. Terms (i.e. exact values) can
  be searched for using <emphasis>term</emphasis> queries.<?asciidoc-br?>
   See also <link linkend="glossary-text">text</link> and <link linkend="glossary-analysis">analysis</link>.
</simpara>
</glossdef>
</glossentry>
<glossentry>
<glossterm>
<anchor id="glossary-text" xreflabel="[glossary-text]"/> text 
</glossterm>
<glossdef>
<simpara>
  Text (or full text) is ordinary unstructured text, such as this
  paragraph. By default, text will be <link linkend="glossary-analysis">analyzed</link> into
  <link linkend="glossary-term">terms</link>, which is what is actually stored in the index.
 <?asciidoc-br?>
  Text <link linkend="glossary-field">fields</link> need to be analyzed at index time in order to
  be searchable as full text, and keywords in full text queries must be
  analyzed at search time to produce (and search for) the same terms
  that were generated at index time.
 <?asciidoc-br?>
  See also <link linkend="glossary-term">term</link> and <link linkend="glossary-analysis">analysis</link>.
</simpara>
</glossdef>
</glossentry>
<glossentry>
<glossterm>
<anchor id="glossary-type" xreflabel="[glossary-type]"/> type 
</glossterm>
<glossdef>
<simpara>
  A type represents the <emphasis>type</emphasis> of document, e.g. an <literal>email</literal>, a <literal>user</literal>, or a <literal>tweet</literal>.
  The search API can filter documents by type.
  An <link linkend="glossary-index">index</link> can contain multiple types, and each type has a
  list of <link linkend="glossary-field">fields</link> that can be specified for
  <link linkend="glossary-document">documents</link> of that type.  Fields with the same
  name in different types in the same index must have the same <link linkend="glossary-mapping">mapping</link>
  (which defines how each field in the document is indexed and made searchable).
</simpara>
</glossdef>
</glossentry>
</glossary>
<part id="es-release-notes">
<title>Release Notes <ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes.asciidoc">Edit me</ulink></title>
<partintro>
<simpara>This section summarizes the changes in each release.</simpara>
<itemizedlist>
<listitem>
<simpara>
<xref linkend="release-notes-5.1.1"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="release-notes-5.1.0"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="release-notes-5.0.2"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="release-notes-5.0.1"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="release-notes-5.0.0"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="release-notes-5.0.0-GA"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="release-notes-5.0.0-rc1"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="release-notes-5.0.0-beta1"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="release-notes-5.0.0-alpha5"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="release-notes-5.0.0-alpha4"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="release-notes-5.0.0-alpha3"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="release-notes-5.0.0-alpha2"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="release-notes-5.0.0-alpha1"/>
</simpara>
</listitem>
<listitem>
<simpara>
<xref linkend="release-notes-5.0.0-alpha1-2x"/>
</simpara>
</listitem>
</itemizedlist>
</partintro>
<chapter id="release-notes-5.1.1">
<title>5.1.1 Release Notes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.1.1.asciidoc">Edit me</ulink></title>
<simpara>Also see <xref linkend="breaking-changes-5.0"/>.</simpara>
<bridgehead id="breaking-5.1.1" renderas="sect2">Breaking changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.1.1.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
Aliases
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Validate alias names the same as index names <ulink url="https://github.com/elastic/elasticsearch/pull/20771">#20771</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20748">#20748</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
CRUD
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fixed naming inconsistency for fields/stored_fields in the APIs <ulink url="https://github.com/elastic/elasticsearch/pull/20166">#20166</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/18943">#18943</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/20155">#20155</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Core
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove ignore system bootstrap checks <ulink url="https://github.com/elastic/elasticsearch/pull/20511">#20511</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Discovery
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove pluggability of ElectMasterService <ulink url="https://github.com/elastic/elasticsearch/pull/21031">#21031</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Exceptions
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove <literal>IndexTemplateAlreadyExistsException</literal> and <literal>IndexShardAlreadyExistsException</literal> <ulink url="https://github.com/elastic/elasticsearch/pull/21539">#21539</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21494">#21494</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Replace IndexAlreadyExistsException with ResourceAlreadyExistsException <ulink url="https://github.com/elastic/elasticsearch/pull/21494">#21494</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Internal
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
<literal>_flush</literal> should block by default <ulink url="https://github.com/elastic/elasticsearch/pull/20597">#20597</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20569">#20569</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Packaging
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Rename service.bat to elasticsearch-service.bat <ulink url="https://github.com/elastic/elasticsearch/pull/20496">#20496</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17528">#17528</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Lang Painless
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove all date <emphasis>now</emphasis> methods from Painless <ulink url="https://github.com/elastic/elasticsearch/pull/20766">#20766</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20762">#20762</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
REST
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove lenient stats parsing 5.x <ulink url="https://github.com/elastic/elasticsearch/pull/21576">#21576</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/20722">#20722</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/21410">#21410</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/21417">#21417</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Change separator for shards preference <ulink url="https://github.com/elastic/elasticsearch/pull/20786">#20786</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/20722">#20722</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/20769">#20769</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="breaking-java-5.1.1" renderas="sect2">Breaking Java changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.1.1.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
Core
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove ability to plug-in TransportService <ulink url="https://github.com/elastic/elasticsearch/pull/20505">#20505</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Exceptions
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Backport: Replace IndexAlreadyExistsException with ResourceAlreadyExistsException <ulink url="https://github.com/elastic/elasticsearch/pull/21601">#21601</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21494">#21494</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Internal
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Pass executor name to request interceptor to support async intercept calls <ulink url="https://github.com/elastic/elasticsearch/pull/21089">#21089</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove TransportService#registerRequestHandler leniency <ulink url="https://github.com/elastic/elasticsearch/pull/20469">#20469</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20468">#20468</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Network
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Unguice Transport and friends <ulink url="https://github.com/elastic/elasticsearch/pull/20526">#20526</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugins
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Plugins: Remove support for onModule <ulink url="https://github.com/elastic/elasticsearch/pull/21416">#21416</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Cleanup sub fetch phase extension point <ulink url="https://github.com/elastic/elasticsearch/pull/20382">#20382</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="deprecation-5.1.1" renderas="sect2">Deprecations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.1.1.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
Analysis
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Deprecating request parameters of _analyze API in 5.x <ulink url="https://github.com/elastic/elasticsearch/pull/20686">#20686</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20246">#20246</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
CRUD
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Deprecate VersionType.FORCE <ulink url="https://github.com/elastic/elasticsearch/pull/21078">#21078</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20995">#20995</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Core
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add deprecation logging for users that explicitly opt in for the <literal>default</literal> fs type. <ulink url="https://github.com/elastic/elasticsearch/pull/21617">#21617</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Mapping
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Deprecate <literal>timestamp</literal> and <literal>ttl</literal> on index requests. <ulink url="https://github.com/elastic/elasticsearch/pull/21826">#21826</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21670">#21670</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Query DSL
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add deprecation logging for lenient boolean queries <ulink url="https://github.com/elastic/elasticsearch/pull/21570">#21570</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21555">#21555</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add deprecation logging message for <emphasis>fuzzy</emphasis> query <ulink url="https://github.com/elastic/elasticsearch/pull/20993">#20993</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15760">#15760</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Search
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Deprecate ignored type parameter in search_shards api <ulink url="https://github.com/elastic/elasticsearch/pull/21730">#21730</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21688">#21688</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Settings
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add deprecation logging for the case that store throttling is used. <ulink url="https://github.com/elastic/elasticsearch/pull/21618">#21618</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="feature-5.1.1" renderas="sect2">New features<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.1.1.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
Analysis
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Expose Lucenes Ukrainian analyzer <ulink url="https://github.com/elastic/elasticsearch/pull/21176">#21176</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19433">#19433</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
CAT API
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Provides a cat api endpoint for templates. <ulink url="https://github.com/elastic/elasticsearch/pull/20545">#20545</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20467">#20467</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Discovery File
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
File-based discovery plugin <ulink url="https://github.com/elastic/elasticsearch/pull/20394">#20394</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20323">#20323</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Query DSL
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add "all fields" execution mode to simple_query_string query <ulink url="https://github.com/elastic/elasticsearch/pull/21341">#21341</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/19784">#19784</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/20925">#20925</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add support for <literal>quote_field_suffix</literal> to <literal>simple_query_string</literal>. <ulink url="https://github.com/elastic/elasticsearch/pull/21060">#21060</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18641">#18641</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add "all field" execution mode to query_string query <ulink url="https://github.com/elastic/elasticsearch/pull/20925">#20925</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19784">#19784</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Reindex API
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add automatic parallelization support to reindex and friends <ulink url="https://github.com/elastic/elasticsearch/pull/20767">#20767</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20624">#20624</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="enhancement-5.1.1" renderas="sect2">Enhancements<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.1.1.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
Aggregations
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Rescorer should be applied in the TopHits aggregation <ulink url="https://github.com/elastic/elasticsearch/pull/20978">#20978</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19317">#19317</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Allocation
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Balance step in BalancedShardsAllocator for a single shard <ulink url="https://github.com/elastic/elasticsearch/pull/21103">#21103</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Process more expensive allocation deciders last <ulink url="https://github.com/elastic/elasticsearch/pull/20724">#20724</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/12815">#12815</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Separates decision making from decision application in BalancedShardsAllocator  <ulink url="https://github.com/elastic/elasticsearch/pull/20634">#20634</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Split allocator decision making from decision application <ulink url="https://github.com/elastic/elasticsearch/pull/20431">#20431</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20347">#20347</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Analysis
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove AnalysisService and reduce it to a simple name to analyzer mapping <ulink url="https://github.com/elastic/elasticsearch/pull/20627">#20627</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/19827">#19827</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/19828">#19828</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
CAT API
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Adding built-in sorting capability to _cat apis. <ulink url="https://github.com/elastic/elasticsearch/pull/20658">#20658</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16975">#16975</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add health status parameter to cat indices API <ulink url="https://github.com/elastic/elasticsearch/pull/20393">#20393</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Cache
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Do not cache term queries. <ulink url="https://github.com/elastic/elasticsearch/pull/21566">#21566</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/16031">#16031</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/20116">#20116</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Parse alias filters on the coordinating node <ulink url="https://github.com/elastic/elasticsearch/pull/20916">#20916</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Circuit Breakers
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Cluster Settings Updates should not trigger circuit breakers. <ulink url="https://github.com/elastic/elasticsearch/pull/20827">#20827</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Cluster
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Cache successful shard deletion checks <ulink url="https://github.com/elastic/elasticsearch/pull/21438">#21438</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Skip shard management code when updating cluster state on client/tribe nodes <ulink url="https://github.com/elastic/elasticsearch/pull/20731">#20731</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add clusterUUID to RestMainAction output <ulink url="https://github.com/elastic/elasticsearch/pull/20503">#20503</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Core
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Reduce memory pressure when sending large terms queries. <ulink url="https://github.com/elastic/elasticsearch/pull/21776">#21776</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Install a security manager on startup <ulink url="https://github.com/elastic/elasticsearch/pull/21716">#21716</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Log node ID on startup <ulink url="https://github.com/elastic/elasticsearch/pull/21673">#21673</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Ensure source filtering automatons are only compiled once <ulink url="https://github.com/elastic/elasticsearch/pull/20857">#20857</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20839">#20839</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Improve scheduling fairness when batching cluster state changes with equal priority <ulink url="https://github.com/elastic/elasticsearch/pull/20775">#20775</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20768">#20768</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add production warning for pre-release builds <ulink url="https://github.com/elastic/elasticsearch/pull/20674">#20674</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add serial collector bootstrap check <ulink url="https://github.com/elastic/elasticsearch/pull/20558">#20558</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Do not log full bootstrap checks exception <ulink url="https://github.com/elastic/elasticsearch/pull/19989">#19989</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Exceptions
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add BWC layer for Exceptions <ulink url="https://github.com/elastic/elasticsearch/pull/21694">#21694</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21656">#21656</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Geo
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Optimize geo-distance sorting. <ulink url="https://github.com/elastic/elasticsearch/pull/20596">#20596</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20450">#20450</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Index APIs
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add date-math support to <literal>_rollover</literal> <ulink url="https://github.com/elastic/elasticsearch/pull/20709">#20709</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Ingest
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
add <literal>ignore_missing</literal> option to SplitProcessor <ulink url="https://github.com/elastic/elasticsearch/pull/20982">#20982</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/19995">#19995</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/20840">#20840</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
add ignore_missing option to convert,trim,lowercase,uppercase,grok,rename <ulink url="https://github.com/elastic/elasticsearch/pull/20194">#20194</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19995">#19995</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
introduce the JSON Processor <ulink url="https://github.com/elastic/elasticsearch/pull/20128">#20128</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20052">#20052</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Internal
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Rename ClusterState#lookupPrototypeSafe to <literal>lookupPrototype</literal> and remove "unsafe" unused variant <ulink url="https://github.com/elastic/elasticsearch/pull/21686">#21686</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
ShardActiveResponseHandler shouldn&#8217;t hold to an entire cluster state <ulink url="https://github.com/elastic/elasticsearch/pull/21470">#21470</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21394">#21394</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove unused ClusterService dependency from SearchPhaseController <ulink url="https://github.com/elastic/elasticsearch/pull/21421">#21421</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove special case in case no action filters are registered <ulink url="https://github.com/elastic/elasticsearch/pull/21251">#21251</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Use TimveValue instead of long for CacheBuilder methods <ulink url="https://github.com/elastic/elasticsearch/pull/20887">#20887</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove SearchContext#current and all it&#8217;s threadlocals <ulink url="https://github.com/elastic/elasticsearch/pull/20778">#20778</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19341">#19341</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove poor-mans compression in InternalSearchHit and friends <ulink url="https://github.com/elastic/elasticsearch/pull/20472">#20472</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Java REST Client
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Provide error message when rest request path is null <ulink url="https://github.com/elastic/elasticsearch/pull/21233">#21233</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21232">#21232</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Logging
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Log failure to connect to node at info instead of debug <ulink url="https://github.com/elastic/elasticsearch/pull/21809">#21809</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/6468">#6468</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Truncate log messages from the end <ulink url="https://github.com/elastic/elasticsearch/pull/21609">#21609</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21602">#21602</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Ensure logging is initialized in CLI tools <ulink url="https://github.com/elastic/elasticsearch/pull/20575">#20575</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Give useful error message if log config is missing <ulink url="https://github.com/elastic/elasticsearch/pull/20493">#20493</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Complete Elasticsearch logger names <ulink url="https://github.com/elastic/elasticsearch/pull/20457">#20457</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20326">#20326</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Logging shutdown hack <ulink url="https://github.com/elastic/elasticsearch/pull/20389">#20389</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20304">#20304</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Disable console logging <ulink url="https://github.com/elastic/elasticsearch/pull/20387">#20387</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Mapping
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Create the QueryShardContext lazily in DocumentMapperParser. <ulink url="https://github.com/elastic/elasticsearch/pull/21287">#21287</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
NOT CLASSIFIED
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
[TEST] Remove create special case in yaml test client <ulink url="https://github.com/elastic/elasticsearch/pull/21030">#21030</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20924">#20924</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
introduce test plugin to inject random search ext elements in search request tests <ulink url="https://github.com/elastic/elasticsearch/pull/20521">#20521</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17685">#17685</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Network
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Grant Netty permission to read system somaxconn <ulink url="https://github.com/elastic/elasticsearch/pull/21840">#21840</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Lazy resolve unicast hosts <ulink url="https://github.com/elastic/elasticsearch/pull/21630">#21630</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/14441">#14441</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/16412">#16412</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix handler name on message not fully read <ulink url="https://github.com/elastic/elasticsearch/pull/21478">#21478</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Handle rejected pings on shutdown gracefully <ulink url="https://github.com/elastic/elasticsearch/pull/20842">#20842</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Network: Allow to listen on virtual interfaces. <ulink url="https://github.com/elastic/elasticsearch/pull/19568">#19568</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/17473">#17473</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/19537">#19537</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Packaging
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add empty plugins dir for archive distributions <ulink url="https://github.com/elastic/elasticsearch/pull/21204">#21204</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20342">#20342</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make explicit missing settings for Windows service <ulink url="https://github.com/elastic/elasticsearch/pull/21200">#21200</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18317">#18317</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Change permissions on config files <ulink url="https://github.com/elastic/elasticsearch/pull/20966">#20966</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add quiet option to disable console logging <ulink url="https://github.com/elastic/elasticsearch/pull/20422">#20422</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/15315">#15315</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/16159">#16159</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/17220">#17220</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Lang Painless
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add Debug.explain to painless <ulink url="https://github.com/elastic/elasticsearch/pull/21723">#21723</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20263">#20263</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Implement the ?: operator in painless <ulink url="https://github.com/elastic/elasticsearch/pull/21506">#21506</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
In painless suggest a long constant if int won&#8217;t do <ulink url="https://github.com/elastic/elasticsearch/pull/21415">#21415</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21313">#21313</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Support decimal constants with trailing [dD] in painless <ulink url="https://github.com/elastic/elasticsearch/pull/21412">#21412</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21116">#21116</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Implement reading from null safe dereferences <ulink url="https://github.com/elastic/elasticsearch/pull/21239">#21239</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Painless negative offsets <ulink url="https://github.com/elastic/elasticsearch/pull/21080">#21080</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20870">#20870</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove more equivalents of the now method from the Painless whitelist. <ulink url="https://github.com/elastic/elasticsearch/pull/21047">#21047</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Disable regexes by default in painless <ulink url="https://github.com/elastic/elasticsearch/pull/20427">#20427</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20397">#20397</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Repository S3
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Make the default S3 buffer size depend on the available memory. <ulink url="https://github.com/elastic/elasticsearch/pull/21299">#21299</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugins
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Clarify that plugins can be closed <ulink url="https://github.com/elastic/elasticsearch/pull/21669">#21669</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Plugins: Convert custom discovery to pull based plugin <ulink url="https://github.com/elastic/elasticsearch/pull/21398">#21398</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Removing plugin that isn&#8217;t installed shouldn&#8217;t trigger usage information <ulink url="https://github.com/elastic/elasticsearch/pull/21272">#21272</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21250">#21250</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove pluggability of ZenPing <ulink url="https://github.com/elastic/elasticsearch/pull/21049">#21049</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Make UnicastHostsProvider extension pull based <ulink url="https://github.com/elastic/elasticsearch/pull/21036">#21036</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Revert "Display plugins versions" <ulink url="https://github.com/elastic/elasticsearch/pull/20807">#20807</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/18683">#18683</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/20668">#20668</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Provide error message when plugin id is missing <ulink url="https://github.com/elastic/elasticsearch/pull/20660">#20660</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Query DSL
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Using ObjectParser in MatchAllQueryBuilder and IdsQueryBuilder <ulink url="https://github.com/elastic/elasticsearch/pull/21273">#21273</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Expose splitOnWhitespace in <literal>Query String Query</literal> <ulink url="https://github.com/elastic/elasticsearch/pull/20965">#20965</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20841">#20841</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Throw error if query element doesn&#8217;t end with END_OBJECT <ulink url="https://github.com/elastic/elasticsearch/pull/20528">#20528</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20515">#20515</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove <literal>lowercase_expanded_terms</literal> and <literal>locale</literal> from query-parser options. <ulink url="https://github.com/elastic/elasticsearch/pull/20208">#20208</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/9978">#9978</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
REST
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add a REST spec for the create API <ulink url="https://github.com/elastic/elasticsearch/pull/20924">#20924</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add response params to REST params did you mean <ulink url="https://github.com/elastic/elasticsearch/pull/20753">#20753</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/20722">#20722</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/20747">#20747</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add did you mean to strict REST params <ulink url="https://github.com/elastic/elasticsearch/pull/20747">#20747</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20722">#20722</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Reindex API
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add "simple match" support for reindex-from-remote whitelist <ulink url="https://github.com/elastic/elasticsearch/pull/21004">#21004</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Make reindex-from-remote ignore unknown fields <ulink url="https://github.com/elastic/elasticsearch/pull/20591">#20591</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20504">#20504</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Scripting
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Wrap VerifyError in ScriptException <ulink url="https://github.com/elastic/elasticsearch/pull/21769">#21769</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Support binary field type in script values <ulink url="https://github.com/elastic/elasticsearch/pull/21484">#21484</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14469">#14469</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Mustache: Add {{#url}}{{/url}} function to URL encode strings <ulink url="https://github.com/elastic/elasticsearch/pull/20838">#20838</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Expose <literal>ctx._now</literal> in update scripts <ulink url="https://github.com/elastic/elasticsearch/pull/20835">#20835</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17895">#17895</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Search
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add indices and filter information to search shards api output <ulink url="https://github.com/elastic/elasticsearch/pull/21738">#21738</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20916">#20916</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
remove pointless catch exception in TransportSearchAction <ulink url="https://github.com/elastic/elasticsearch/pull/21689">#21689</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Optimize query with types filter in the URL (t/t/_search) <ulink url="https://github.com/elastic/elasticsearch/pull/20979">#20979</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Makes search action cancelable by task management API <ulink url="https://github.com/elastic/elasticsearch/pull/20405">#20405</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Search Templates
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add profile and explain parameters to template API <ulink url="https://github.com/elastic/elasticsearch/pull/20451">#20451</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Settings
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add precise logging on unknown or invalid settings <ulink url="https://github.com/elastic/elasticsearch/pull/20951">#20951</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20946">#20946</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Snapshot/Restore
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Abort snapshots on a node that leaves the cluster <ulink url="https://github.com/elastic/elasticsearch/pull/21084">#21084</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20876">#20876</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Stats
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove load average leniency <ulink url="https://github.com/elastic/elasticsearch/pull/21380">#21380</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Strengthen handling of unavailable cgroup stats <ulink url="https://github.com/elastic/elasticsearch/pull/21094">#21094</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21029">#21029</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add basic cgroup CPU metrics <ulink url="https://github.com/elastic/elasticsearch/pull/21029">#21029</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Task Manager
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add search task descriptions <ulink url="https://github.com/elastic/elasticsearch/pull/21740">#21740</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Tribe Node
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add support for merging custom meta data in tribe node <ulink url="https://github.com/elastic/elasticsearch/pull/21552">#21552</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/20544">#20544</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/20791">#20791</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/9372">#9372</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="bug-5.1.1" renderas="sect2">Bug fixes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.1.1.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
Aggregations
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Rewrite Queries/Filter in FilterAggregationBuilder and ensure client usage marks query as non-cachable <ulink url="https://github.com/elastic/elasticsearch/pull/21303">#21303</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21301">#21301</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Percentiles bucket fails for 100th percentile <ulink url="https://github.com/elastic/elasticsearch/pull/21218">#21218</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Thread safety for scripted significance heuristics <ulink url="https://github.com/elastic/elasticsearch/pull/21113">#21113</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18120">#18120</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fixes bug preventing script sort working on top_hits aggregation <ulink url="https://github.com/elastic/elasticsearch/pull/21023">#21023</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21022">#21022</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fixed writeable name from range to geo_distance <ulink url="https://github.com/elastic/elasticsearch/pull/20860">#20860</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix date_range aggregation to not cache if now is used <ulink url="https://github.com/elastic/elasticsearch/pull/20740">#20740</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
The <literal>top_hits</literal> aggregation should compile scripts only once. <ulink url="https://github.com/elastic/elasticsearch/pull/20738">#20738</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Allocation
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Allow master to assign primary shard to node that has shard store locked during shard state fetching <ulink url="https://github.com/elastic/elasticsearch/pull/21656">#21656</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19416">#19416</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Keep a shadow replicas' allocation id when it is promoted to primary <ulink url="https://github.com/elastic/elasticsearch/pull/20863">#20863</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20650">#20650</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
IndicesClusterStateService should clean local started when re-assigns an initializing shard with the same aid <ulink url="https://github.com/elastic/elasticsearch/pull/20687">#20687</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
IndexRoutingTable.initializeEmpty shouldn&#8217;t override supplied primary RecoverySource <ulink url="https://github.com/elastic/elasticsearch/pull/20638">#20638</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20637">#20637</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Update incoming recoveries stats when shadow replica is reinitialized <ulink url="https://github.com/elastic/elasticsearch/pull/20612">#20612</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>index.routing.allocation.initial_recovery</literal> limits replica allocation <ulink url="https://github.com/elastic/elasticsearch/pull/20589">#20589</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Analysis
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Can load non-PreBuiltTokenFilter in Analyze API <ulink url="https://github.com/elastic/elasticsearch/pull/20396">#20396</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Named analyzer should close the analyzer that it wraps <ulink url="https://github.com/elastic/elasticsearch/pull/20197">#20197</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
CAT API
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Consume <literal>full_id</literal> request parameter early <ulink url="https://github.com/elastic/elasticsearch/pull/21270">#21270</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21266">#21266</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
CRUD
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
MultiGet should not fail entirely if alias resolves to many indices <ulink url="https://github.com/elastic/elasticsearch/pull/20858">#20858</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20845">#20845</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fixed date math expression support in multi get requests. <ulink url="https://github.com/elastic/elasticsearch/pull/20659">#20659</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17957">#17957</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Cache
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix the request cache keys to not hold references to the SearchContext. <ulink url="https://github.com/elastic/elasticsearch/pull/21284">#21284</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Prevent requests that use scripts or now() from being cached <ulink url="https://github.com/elastic/elasticsearch/pull/20750">#20750</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20645">#20645</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Circuit Breakers
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
ClusterState publishing shouldn&#8217;t trigger circuit breakers <ulink url="https://github.com/elastic/elasticsearch/pull/20986">#20986</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/20827">#20827</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/20960">#20960</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Cluster
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove cluster update task when task times out <ulink url="https://github.com/elastic/elasticsearch/pull/21578">#21578</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21568">#21568</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Core
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add a StreamInput#readArraySize method that ensures sane array sizes <ulink url="https://github.com/elastic/elasticsearch/pull/21697">#21697</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Use a buffer to do character to byte conversion in StreamOutput#writeString <ulink url="https://github.com/elastic/elasticsearch/pull/21680">#21680</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21660">#21660</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix ShardInfo#toString <ulink url="https://github.com/elastic/elasticsearch/pull/21319">#21319</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Protect BytesStreamOutput against overflows of the current number of written bytes. <ulink url="https://github.com/elastic/elasticsearch/pull/21174">#21174</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21159">#21159</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Return target index name even if _rollover conditions are not met <ulink url="https://github.com/elastic/elasticsearch/pull/21138">#21138</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
.es_temp_file remains after system crash, causing it not to start again <ulink url="https://github.com/elastic/elasticsearch/pull/21007">#21007</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20992">#20992</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
StoreStatsCache should also ignore AccessDeniedException when checking file size <ulink url="https://github.com/elastic/elasticsearch/pull/20790">#20790</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17580">#17580</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Dates
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix time zone rounding edge case for DST overlaps <ulink url="https://github.com/elastic/elasticsearch/pull/21550">#21550</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20833">#20833</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Discovery
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add current cluster state version to zen pings and use them in master election <ulink url="https://github.com/elastic/elasticsearch/pull/20384">#20384</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20348">#20348</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Engine
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Die with dignity on the Lucene layer <ulink url="https://github.com/elastic/elasticsearch/pull/21721">#21721</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19272">#19272</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix <literal>InternalEngine#isThrottled</literal> to not always return <literal>false</literal>. <ulink url="https://github.com/elastic/elasticsearch/pull/21592">#21592</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Retrying replication requests on replica doesn&#8217;t call <literal>onRetry</literal> <ulink url="https://github.com/elastic/elasticsearch/pull/21189">#21189</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20211">#20211</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Take refresh IOExceptions into account when catching ACE in InternalEngine <ulink url="https://github.com/elastic/elasticsearch/pull/20546">#20546</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19975">#19975</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Highlighting
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix FiltersFunctionScoreQuery highlighting <ulink url="https://github.com/elastic/elasticsearch/pull/21827">#21827</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix highlighting on a stored keyword field <ulink url="https://github.com/elastic/elasticsearch/pull/21645">#21645</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21636">#21636</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix highlighting of MultiTermQuery within a FunctionScoreQuery <ulink url="https://github.com/elastic/elasticsearch/pull/20400">#20400</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20392">#20392</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Index APIs
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Validate the <literal>_rollover</literal> target index name early to also fail if dry_run=true <ulink url="https://github.com/elastic/elasticsearch/pull/21330">#21330</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21149">#21149</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Only negate index expression on all indices with preceding wildcard <ulink url="https://github.com/elastic/elasticsearch/pull/20898">#20898</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/19800">#19800</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/20033">#20033</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix IndexNotFoundException in multi index search request. <ulink url="https://github.com/elastic/elasticsearch/pull/20188">#20188</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/3839">#3839</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Index Templates
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix integer overflows when dealing with templates. <ulink url="https://github.com/elastic/elasticsearch/pull/21628">#21628</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21622">#21622</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Ingest
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
fix trace_match behavior for when there is only one grok pattern <ulink url="https://github.com/elastic/elasticsearch/pull/21413">#21413</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21371">#21371</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Stored scripts and ingest node configurations should be included into a snapshot <ulink url="https://github.com/elastic/elasticsearch/pull/21227">#21227</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21184">#21184</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
make painless the default scripting language for ScriptProcessor <ulink url="https://github.com/elastic/elasticsearch/pull/20981">#20981</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20943">#20943</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
no null values in ingest configuration error messages <ulink url="https://github.com/elastic/elasticsearch/pull/20616">#20616</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
JSON Processor was not properly added <ulink url="https://github.com/elastic/elasticsearch/pull/20613">#20613</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Inner Hits
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Skip adding a parent field to nested documents. <ulink url="https://github.com/elastic/elasticsearch/pull/21522">#21522</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21503">#21503</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Internal
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Rethrow ExecutionException from the loader to concurrent callers of Cache#computeIfAbsent <ulink url="https://github.com/elastic/elasticsearch/pull/21549">#21549</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Restore thread&#8217;s original context before returning to the ThreadPool <ulink url="https://github.com/elastic/elasticsearch/pull/21411">#21411</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix NPE in SearchContext.toString() <ulink url="https://github.com/elastic/elasticsearch/pull/21069">#21069</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Prevent AbstractArrays from release bytes more than once <ulink url="https://github.com/elastic/elasticsearch/pull/20819">#20819</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Source filtering should treat dots in field names as sub objects. <ulink url="https://github.com/elastic/elasticsearch/pull/20736">#20736</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20719">#20719</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
IndicesAliasesRequest should not implement CompositeIndicesRequest <ulink url="https://github.com/elastic/elasticsearch/pull/20726">#20726</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Ensure elasticsearch doesn&#8217;t start with unuspported indices <ulink url="https://github.com/elastic/elasticsearch/pull/20514">#20514</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20512">#20512</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Java API
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Transport client: Fix remove address to actually work <ulink url="https://github.com/elastic/elasticsearch/pull/21743">#21743</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add a HostFailureListener to notify client code if a node got disconnected <ulink url="https://github.com/elastic/elasticsearch/pull/21709">#21709</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21424">#21424</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix InternalSearchHit#hasSource to return the proper boolean value <ulink url="https://github.com/elastic/elasticsearch/pull/21441">#21441</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21419">#21419</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Null checked for source when calling sourceRef <ulink url="https://github.com/elastic/elasticsearch/pull/21431">#21431</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19279">#19279</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
ClusterAdminClient.prepareDeletePipeline method should accept pipeline id to delete <ulink url="https://github.com/elastic/elasticsearch/pull/21228">#21228</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
fix IndexResponse#toString to print out shards info <ulink url="https://github.com/elastic/elasticsearch/pull/20562">#20562</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Java REST Client
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Rest client: don&#8217;t reuse the same HttpAsyncResponseConsumer across multiple retries <ulink url="https://github.com/elastic/elasticsearch/pull/21378">#21378</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Logging
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Do not prematurely shutdown Log4j <ulink url="https://github.com/elastic/elasticsearch/pull/21519">#21519</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21514">#21514</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Assert status logger does not warn on Log4j usage <ulink url="https://github.com/elastic/elasticsearch/pull/21339">#21339</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix logger names for Netty <ulink url="https://github.com/elastic/elasticsearch/pull/21223">#21223</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20457">#20457</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix logger when you can not create an azure storage client <ulink url="https://github.com/elastic/elasticsearch/pull/20670">#20670</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/20633">#20633</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/20669">#20669</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Avoid unnecessary creation of prefix loggers <ulink url="https://github.com/elastic/elasticsearch/pull/20571">#20571</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20570">#20570</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix logging hierarchy configs <ulink url="https://github.com/elastic/elasticsearch/pull/20463">#20463</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix prefix logging <ulink url="https://github.com/elastic/elasticsearch/pull/20429">#20429</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Mapping
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fail to index fields with dots in field names when one of the intermediate objects is nested. <ulink url="https://github.com/elastic/elasticsearch/pull/21787">#21787</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21726">#21726</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Uncommitted mapping updates should not efect existing indices <ulink url="https://github.com/elastic/elasticsearch/pull/21306">#21306</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21189">#21189</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Allow position_gap_increment for fields in indices created prior to 5.0 <ulink url="https://github.com/elastic/elasticsearch/pull/20806">#20806</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/19510">#19510</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/20413">#20413</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Network
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
DiscoveryNode and TransportAddress should preserve host information <ulink url="https://github.com/elastic/elasticsearch/pull/21828">#21828</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Die with dignity on the network layer <ulink url="https://github.com/elastic/elasticsearch/pull/21720">#21720</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19272">#19272</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix connection close header handling <ulink url="https://github.com/elastic/elasticsearch/pull/20956">#20956</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20938">#20938</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Ensure port range is readable in the exception message <ulink url="https://github.com/elastic/elasticsearch/pull/20893">#20893</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Prevent double release in TcpTransport if send listener throws an exception <ulink url="https://github.com/elastic/elasticsearch/pull/20880">#20880</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Packaging
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Set vm.max_map_count on systemd package install <ulink url="https://github.com/elastic/elasticsearch/pull/21507">#21507</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Export ES_JVM_OPTIONS for SysV init <ulink url="https://github.com/elastic/elasticsearch/pull/21445">#21445</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21255">#21255</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Debian: configure start-stop-daemon to not go into background <ulink url="https://github.com/elastic/elasticsearch/pull/21343">#21343</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/12716">#12716</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/21300">#21300</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Generate POM files with non-wildcard excludes <ulink url="https://github.com/elastic/elasticsearch/pull/21234">#21234</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21170">#21170</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
[Packaging] Do not remove scripts directory on upgrade <ulink url="https://github.com/elastic/elasticsearch/pull/20452">#20452</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
[Package] Remove bin/lib/modules directories on RPM uninstall/upgrade <ulink url="https://github.com/elastic/elasticsearch/pull/20448">#20448</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Discovery EC2
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix ec2 discovery when used with IAM profiles. <ulink url="https://github.com/elastic/elasticsearch/pull/21048">#21048</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21039">#21039</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Ingest GeoIp
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
[ingest-geoip] update geoip to not include null-valued results from  <ulink url="https://github.com/elastic/elasticsearch/pull/20455">#20455</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Lang Painless
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Test fix for def equals in Painless <ulink url="https://github.com/elastic/elasticsearch/pull/21945">#21945</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21801">#21801</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix a VerifyError bug in Painless <ulink url="https://github.com/elastic/elasticsearch/pull/21765">#21765</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix Lambdas in Painless to be Able to Use Top-Level Variables Such as params and doc <ulink url="https://github.com/elastic/elasticsearch/pull/21635">#21635</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/20869">#20869</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/21479">#21479</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix String Concatenation Bug In Painless <ulink url="https://github.com/elastic/elasticsearch/pull/20623">#20623</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Mapper Attachment
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
NPE is raised when defining a non existing type within attachments type <ulink url="https://github.com/elastic/elasticsearch/pull/21848">#21848</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Repository S3
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fixes leading forward slash in S3 repository base_path <ulink url="https://github.com/elastic/elasticsearch/pull/20861">#20861</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugins
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Use sysprop like with es.path.home to pass conf dir <ulink url="https://github.com/elastic/elasticsearch/pull/18870">#18870</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18689">#18689</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Query DSL
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fixes date range query using epoch with timezone <ulink url="https://github.com/elastic/elasticsearch/pull/21542">#21542</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21501">#21501</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Allow overriding all-field leniency when <literal>lenient</literal> option is specified <ulink url="https://github.com/elastic/elasticsearch/pull/21504">#21504</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/20925">#20925</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/21341">#21341</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Max score should be updated when a rescorer is used <ulink url="https://github.com/elastic/elasticsearch/pull/20977">#20977</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20651">#20651</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fixes MultiMatchQuery so that it doesn&#8217;t provide a null context <ulink url="https://github.com/elastic/elasticsearch/pull/20882">#20882</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix silently accepting malformed queries <ulink url="https://github.com/elastic/elasticsearch/pull/20515">#20515</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20500">#20500</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix match_phrase_prefix query with single term on _all field <ulink url="https://github.com/elastic/elasticsearch/pull/20471">#20471</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20470">#20470</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
REST
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Strict level parsing for indices stats <ulink url="https://github.com/elastic/elasticsearch/pull/21577">#21577</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21024">#21024</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
The routing query string param is supported by mget but was missing from the rest spec <ulink url="https://github.com/elastic/elasticsearch/pull/21357">#21357</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
fix thread_pool_patterns path variable definition <ulink url="https://github.com/elastic/elasticsearch/pull/21332">#21332</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Read indices options in indices upgrade API <ulink url="https://github.com/elastic/elasticsearch/pull/21281">#21281</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21099">#21099</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
ensure the XContentBuilder is always closed in RestBuilderListener <ulink url="https://github.com/elastic/elasticsearch/pull/21124">#21124</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add correct Content-Length on HEAD requests <ulink url="https://github.com/elastic/elasticsearch/pull/21123">#21123</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21077">#21077</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make sure HEAD / has 0 Content-Length <ulink url="https://github.com/elastic/elasticsearch/pull/21077">#21077</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21075">#21075</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Whitelist node stats indices level parameter <ulink url="https://github.com/elastic/elasticsearch/pull/21024">#21024</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20722">#20722</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove lenient URL parameter parsing <ulink url="https://github.com/elastic/elasticsearch/pull/20722">#20722</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14719">#14719</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
XContentBuilder: Avoid building self-referencing objects <ulink url="https://github.com/elastic/elasticsearch/pull/20550">#20550</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/19475">#19475</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/20540">#20540</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Recovery
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix concurrency issues between cancelling a relocation and marking shard as relocated <ulink url="https://github.com/elastic/elasticsearch/pull/20443">#20443</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Reindex API
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Ignore IllegalArgumentException with assertVersionSerializable <ulink url="https://github.com/elastic/elasticsearch/pull/21409">#21409</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/20767">#20767</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/21350">#21350</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Bump reindex-from-remote&#8217;s buffer to 200mb <ulink url="https://github.com/elastic/elasticsearch/pull/21222">#21222</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21185">#21185</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix reindex-from-remote for parent/child from &lt;2.0 <ulink url="https://github.com/elastic/elasticsearch/pull/21070">#21070</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21044">#21044</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Scripting
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add support for booleans in scripts <ulink url="https://github.com/elastic/elasticsearch/pull/20950">#20950</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20949">#20949</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Native scripts should be created once per index, not per segment. <ulink url="https://github.com/elastic/elasticsearch/pull/20609">#20609</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Search
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix match_phrase_prefix on boosted fields <ulink url="https://github.com/elastic/elasticsearch/pull/21623">#21623</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21613">#21613</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Respect default search timeout <ulink url="https://github.com/elastic/elasticsearch/pull/21599">#21599</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/12211">#12211</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/21595">#21595</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove LateParsingQuery to prevent timestamp access after context is frozen <ulink url="https://github.com/elastic/elasticsearch/pull/21328">#21328</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21295">#21295</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make range queries round up upper bounds again. <ulink url="https://github.com/elastic/elasticsearch/pull/20582">#20582</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/20579">#20579</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/8889">#8889</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Throw error when trying to fetch fields from source and source is disabled <ulink url="https://github.com/elastic/elasticsearch/pull/20424">#20424</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/20093">#20093</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/20408">#20408</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Search Templates
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
SearchTemplateRequest to implement CompositeIndicesRequest <ulink url="https://github.com/elastic/elasticsearch/pull/21865">#21865</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21747">#21747</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Settings
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Handle spaces in <literal>action.auto_create_index</literal> gracefully <ulink url="https://github.com/elastic/elasticsearch/pull/21790">#21790</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21449">#21449</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix settings diff generation for affix and group settings <ulink url="https://github.com/elastic/elasticsearch/pull/21788">#21788</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Don&#8217;t reset non-dynamic settings unless explicitly requested <ulink url="https://github.com/elastic/elasticsearch/pull/21646">#21646</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21593">#21593</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix Setting.timeValue() method <ulink url="https://github.com/elastic/elasticsearch/pull/20696">#20696</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20662">#20662</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add a hard limit for <literal>index.number_of_shard</literal> <ulink url="https://github.com/elastic/elasticsearch/pull/20682">#20682</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Include complex settings in settings requests <ulink url="https://github.com/elastic/elasticsearch/pull/20622">#20622</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Snapshot/Restore
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fixes shard level snapshot metadata loading when index-N file is missing <ulink url="https://github.com/elastic/elasticsearch/pull/21813">#21813</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Ensures cleanup of temporary index-* generational blobs during snapshotting <ulink url="https://github.com/elastic/elasticsearch/pull/21469">#21469</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21462">#21462</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fixes get snapshot duplicates when asking for _all <ulink url="https://github.com/elastic/elasticsearch/pull/21340">#21340</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21335">#21335</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Keep snapshot restore state and routing table in sync (5.x backport) <ulink url="https://github.com/elastic/elasticsearch/pull/21131">#21131</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20836">#20836</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Stats
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove output_uuid parameter from cluster stats <ulink url="https://github.com/elastic/elasticsearch/pull/21020">#21020</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20722">#20722</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix FieldStats deserialization of <literal>ip</literal> field <ulink url="https://github.com/elastic/elasticsearch/pull/20522">#20522</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20516">#20516</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Task Manager
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Task cancellation command should wait for all child nodes to receive cancellation request before returning <ulink url="https://github.com/elastic/elasticsearch/pull/21397">#21397</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21126">#21126</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Tribe Node
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add socket permissions for tribe nodes <ulink url="https://github.com/elastic/elasticsearch/pull/21546">#21546</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/16392">#16392</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/21122">#21122</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="regression-5.1.1" renderas="sect2">Regressions<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.1.1.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
Highlighting
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Handle SynonymQuery extraction for the FastVectorHighlighter <ulink url="https://github.com/elastic/elasticsearch/pull/20829">#20829</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20781">#20781</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Discovery EC2
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix ec2 discovery when used with IAM profiles. <ulink url="https://github.com/elastic/elasticsearch/pull/21042">#21042</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21039">#21039</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Repository S3
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix s3 repository when used with IAM profiles <ulink url="https://github.com/elastic/elasticsearch/pull/21058">#21058</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21048">#21048</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugins
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Plugins: Add back user agent when downloading plugins <ulink url="https://github.com/elastic/elasticsearch/pull/20872">#20872</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="upgrade-5.1.1" renderas="sect2">Upgrades<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.1.1.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
Core
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Upgrade to lucene-6.3.0. <ulink url="https://github.com/elastic/elasticsearch/pull/21464">#21464</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Dates
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Update Joda Time to version 2.9.5 <ulink url="https://github.com/elastic/elasticsearch/pull/21468">#21468</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/20911">#20911</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/332">#332</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/373">#373</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/378">#378</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/379">#379</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/386">#386</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/394">#394</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/396">#396</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/397">#397</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/404">#404</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/69">#69</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Logging
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Upgrade Log4j 2 to version 2.7 <ulink url="https://github.com/elastic/elasticsearch/pull/20805">#20805</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20304">#20304</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
NOT CLASSIFIED
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Upgrade to lucene-6.3.0-snapshot-ed102d6 <ulink url="https://github.com/elastic/elasticsearch/pull/21150">#21150</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Network
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Upgrade to Netty 4.1.6 <ulink url="https://github.com/elastic/elasticsearch/pull/21051">#21051</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Ingest Attachment
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Update to Tika 1.14 <ulink url="https://github.com/elastic/elasticsearch/pull/21663">#21663</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/20710">#20710</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/21591">#21591</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
</chapter>
<chapter id="release-notes-5.1.0">
<title>5.1.0 Release Notes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.1.0.asciidoc">Edit me</ulink></title>
<simpara>Version 5.1.0 doesn&#8217;t exist because, for a short period of time, the Elastic
Yum and Apt repositories included unreleased binaries labeled 5.1.0. To avoid
confusion and upgrade issues for the people that have installed these without
realizing, we decided to skip the 5.1.0 version and release 5.1.1 instead.</simpara>
</chapter>
<chapter id="release-notes-5.0.2">
<title>5.0.2 Release Notes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.0.2.asciidoc">Edit me</ulink></title>
<simpara>Also see <xref linkend="breaking-changes-5.0"/>.</simpara>
<bridgehead id="enhancement-5.0.2" renderas="sect2">Enhancements<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.0.2.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
Core
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Install a security manager on startup <ulink url="https://github.com/elastic/elasticsearch/pull/21716">#21716</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Exceptions
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add BWC layer for Exceptions <ulink url="https://github.com/elastic/elasticsearch/pull/21694">#21694</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21656">#21656</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Logging
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Truncate log messages from the end <ulink url="https://github.com/elastic/elasticsearch/pull/21609">#21609</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21602">#21602</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Scripting
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Wrap VerifyError in ScriptException <ulink url="https://github.com/elastic/elasticsearch/pull/21769">#21769</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Snapshot/Restore
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Abort snapshots on a node that leaves the cluster <ulink url="https://github.com/elastic/elasticsearch/pull/21084">#21084</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20876">#20876</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="bug-5.0.2" renderas="sect2">Bug fixes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.0.2.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
Allocation
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Allow master to assign primary shard to node that has shard store locked during shard state fetching <ulink url="https://github.com/elastic/elasticsearch/pull/21656">#21656</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19416">#19416</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Cluster
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove cluster update task when task times out <ulink url="https://github.com/elastic/elasticsearch/pull/21578">#21578</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21568">#21568</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Core
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add a StreamInput#readArraySize method that ensures sane array sizes <ulink url="https://github.com/elastic/elasticsearch/pull/21697">#21697</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Use a buffer to do character to byte conversion in StreamOutput#writeString <ulink url="https://github.com/elastic/elasticsearch/pull/21680">#21680</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21660">#21660</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Engine
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Die with dignity on the Lucene layer <ulink url="https://github.com/elastic/elasticsearch/pull/21721">#21721</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19272">#19272</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix <literal>InternalEngine#isThrottled</literal> to not always return <literal>false</literal>. <ulink url="https://github.com/elastic/elasticsearch/pull/21592">#21592</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Index Templates
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix integer overflows when dealing with templates. <ulink url="https://github.com/elastic/elasticsearch/pull/21628">#21628</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21622">#21622</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Ingest
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
fix trace_match behavior for when there is only one grok pattern <ulink url="https://github.com/elastic/elasticsearch/pull/21413">#21413</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21371">#21371</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Internal
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Rethrow ExecutionException from the loader to concurrent callers of Cache#computeIfAbsent <ulink url="https://github.com/elastic/elasticsearch/pull/21549">#21549</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fixes potential NullPointerException on shard closing <ulink url="https://github.com/elastic/elasticsearch/pull/21515">#21515</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21084">#21084</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Java API
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Transport client: Fix remove address to actually work <ulink url="https://github.com/elastic/elasticsearch/pull/21743">#21743</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add a HostFailureListener to notify client code if a node got disconnected <ulink url="https://github.com/elastic/elasticsearch/pull/21709">#21709</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21424">#21424</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Logging
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Do not prematurely shutdown Log4j <ulink url="https://github.com/elastic/elasticsearch/pull/21519">#21519</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21514">#21514</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Network
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Die with dignity on the network layer <ulink url="https://github.com/elastic/elasticsearch/pull/21720">#21720</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19272">#19272</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Lang Painless
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix a VerifyError bug in Painless <ulink url="https://github.com/elastic/elasticsearch/pull/21765">#21765</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix Lambdas in Painless to be Able to Use Top-Level Variables Such as params and doc <ulink url="https://github.com/elastic/elasticsearch/pull/21635">#21635</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/20869">#20869</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/21479">#21479</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Search
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Respect default search timeout <ulink url="https://github.com/elastic/elasticsearch/pull/21599">#21599</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/12211">#12211</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/21595">#21595</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Settings
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Don&#8217;t reset non-dynamic settings unless explicitly requested <ulink url="https://github.com/elastic/elasticsearch/pull/21646">#21646</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21593">#21593</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Tribe Node
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add socket permissions for tribe nodes <ulink url="https://github.com/elastic/elasticsearch/pull/21546">#21546</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/16392">#16392</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/21122">#21122</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
</chapter>
<chapter id="release-notes-5.0.1">
<title>5.0.1 Release Notes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.0.1.asciidoc">Edit me</ulink></title>
<simpara>Also see <xref linkend="breaking-changes-5.0"/>.</simpara>
<bridgehead id="deprecation-5.0.1" renderas="sect2">Deprecations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.0.1.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
CRUD
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Deprecate VersionType.FORCE <ulink url="https://github.com/elastic/elasticsearch/pull/21078">#21078</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20995">#20995</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="enhancement-5.0.1" renderas="sect2">Enhancements<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.0.1.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
Aggregations
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Rescorer should be applied in the TopHits aggregation <ulink url="https://github.com/elastic/elasticsearch/pull/20978">#20978</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19317">#19317</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Internal
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
ShardActiveResponseHandler shouldn&#8217;t hold to an entire cluster state <ulink url="https://github.com/elastic/elasticsearch/pull/21470">#21470</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21394">#21394</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Network
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix handler name on message not fully read <ulink url="https://github.com/elastic/elasticsearch/pull/21478">#21478</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Packaging
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add empty plugins dir for archive distributions <ulink url="https://github.com/elastic/elasticsearch/pull/21204">#21204</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20342">#20342</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make explicit missing settings for Windows service <ulink url="https://github.com/elastic/elasticsearch/pull/21200">#21200</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18317">#18317</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Change permissions on config files <ulink url="https://github.com/elastic/elasticsearch/pull/20966">#20966</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Search
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Optimize query with types filter in the URL (t/t/_search) <ulink url="https://github.com/elastic/elasticsearch/pull/20979">#20979</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="bug-5.0.1" renderas="sect2">Bug fixes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.0.1.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
Aggregations
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Rewrite Queries/Filter in FilterAggregationBuilder and ensure client usage marks query as non-cachable <ulink url="https://github.com/elastic/elasticsearch/pull/21303">#21303</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21301">#21301</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Thread safety for scripted significance heuristics <ulink url="https://github.com/elastic/elasticsearch/pull/21113">#21113</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18120">#18120</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
<literal>ip_range</literal> aggregation should accept null bounds. <ulink url="https://github.com/elastic/elasticsearch/pull/21043">#21043</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21006">#21006</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
CAT API
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Consume <literal>full_id</literal> request parameter early <ulink url="https://github.com/elastic/elasticsearch/pull/21270">#21270</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21266">#21266</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Cache
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix the request cache keys to not hold references to the SearchContext. <ulink url="https://github.com/elastic/elasticsearch/pull/21284">#21284</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Circuit Breakers
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
ClusterState publishing shouldn&#8217;t trigger circuit breakers <ulink url="https://github.com/elastic/elasticsearch/pull/20986">#20986</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/20827">#20827</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/20960">#20960</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Core
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix ShardInfo#toString <ulink url="https://github.com/elastic/elasticsearch/pull/21319">#21319</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Protect BytesStreamOutput against overflows of the current number of written bytes. <ulink url="https://github.com/elastic/elasticsearch/pull/21174">#21174</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21159">#21159</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Return target index name even if _rollover conditions are not met <ulink url="https://github.com/elastic/elasticsearch/pull/21138">#21138</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Engine
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Retrying replication requests on replica doesn&#8217;t call <literal>onRetry</literal> <ulink url="https://github.com/elastic/elasticsearch/pull/21189">#21189</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20211">#20211</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Index APIs
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Validate the <literal>_rollover</literal> target index name early to also fail if dry_run=true <ulink url="https://github.com/elastic/elasticsearch/pull/21330">#21330</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21149">#21149</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Ingest
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Stored scripts and ingest node configurations should be included into a snapshot <ulink url="https://github.com/elastic/elasticsearch/pull/21227">#21227</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21184">#21184</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Internal
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Restore thread&#8217;s original context before returning to the ThreadPool <ulink url="https://github.com/elastic/elasticsearch/pull/21411">#21411</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Java API
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix InternalSearchHit#hasSource to return the proper boolean value <ulink url="https://github.com/elastic/elasticsearch/pull/21441">#21441</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21419">#21419</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Null checked for source when calling sourceRef <ulink url="https://github.com/elastic/elasticsearch/pull/21431">#21431</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19279">#19279</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
ClusterAdminClient.prepareDeletePipeline method should accept pipeline id to delete <ulink url="https://github.com/elastic/elasticsearch/pull/21228">#21228</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Java REST Client
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Rest client: don&#8217;t reuse the same HttpAsyncResponseConsumer across multiple retries <ulink url="https://github.com/elastic/elasticsearch/pull/21378">#21378</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Logging
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Assert status logger does not warn on Log4j usage <ulink url="https://github.com/elastic/elasticsearch/pull/21339">#21339</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix logger names for Netty <ulink url="https://github.com/elastic/elasticsearch/pull/21223">#21223</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20457">#20457</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Packaging
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Set vm.max_map_count on systemd package install <ulink url="https://github.com/elastic/elasticsearch/pull/21507">#21507</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Export ES_JVM_OPTIONS for SysV init <ulink url="https://github.com/elastic/elasticsearch/pull/21445">#21445</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21255">#21255</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Debian: configure start-stop-daemon to not go into background <ulink url="https://github.com/elastic/elasticsearch/pull/21343">#21343</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/12716">#12716</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/21300">#21300</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Generate POM files with non-wildcard excludes <ulink url="https://github.com/elastic/elasticsearch/pull/21234">#21234</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21170">#21170</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Query DSL
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Max score should be updated when a rescorer is used <ulink url="https://github.com/elastic/elasticsearch/pull/20977">#20977</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20651">#20651</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
REST
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
The routing query string param is supported by mget but was missing from the rest spec <ulink url="https://github.com/elastic/elasticsearch/pull/21357">#21357</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
fix thread_pool_patterns path variable definition <ulink url="https://github.com/elastic/elasticsearch/pull/21332">#21332</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
ensure the XContentBuilder is always closed in RestBuilderListener <ulink url="https://github.com/elastic/elasticsearch/pull/21124">#21124</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Reindex API
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Bump reindex-from-remote&#8217;s buffer to 200mb <ulink url="https://github.com/elastic/elasticsearch/pull/21222">#21222</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21185">#21185</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix reindex-from-remote for parent/child from &lt;2.0 <ulink url="https://github.com/elastic/elasticsearch/pull/21070">#21070</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21044">#21044</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Search
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fixes cachability problems with fetching TTL values when searching <ulink url="https://github.com/elastic/elasticsearch/pull/21493">#21493</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21457">#21457</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove LateParsingQuery to prevent timestamp access after context is frozen <ulink url="https://github.com/elastic/elasticsearch/pull/21328">#21328</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21295">#21295</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Snapshot/Restore
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Ensures cleanup of temporary index-* generational blobs during snapshotting <ulink url="https://github.com/elastic/elasticsearch/pull/21469">#21469</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21462">#21462</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fixes get snapshot duplicates when asking for _all <ulink url="https://github.com/elastic/elasticsearch/pull/21340">#21340</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/21335">#21335</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="upgrade-5.0.1" renderas="sect2">Upgrades<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.0.1.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
Core
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Upgrade to Lucene 6.2.1 <ulink url="https://github.com/elastic/elasticsearch/pull/21207">#21207</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Dates
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Update Joda Time to version 2.9.5 <ulink url="https://github.com/elastic/elasticsearch/pull/21468">#21468</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20911">#20911</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
</chapter>
<chapter id="release-notes-5.0.0">
<title>5.0.0 Combined Release Notes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.0.0-all.asciidoc">Edit me</ulink></title>
<simpara>The list below covers all changes from 5.0.0-alpha1 to 5.0.0 GA excluding changes which were already released in the 2.x series, which can be found in <xref linkend="release-notes-5.0.0-alpha1-2x"/>.</simpara>
<simpara>Also see <xref linkend="breaking-changes-5.0"/>.</simpara>
<bridgehead id="breaking-5.0.0" renderas="sect2">Breaking changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.0.0-all.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
Aggregations
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove size 0 options in aggregations <ulink url="https://github.com/elastic/elasticsearch/pull/18854">#18854</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18838">#18838</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Aliases
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
make get alias expand to open and closed indices by default <ulink url="https://github.com/elastic/elasticsearch/pull/15954">#15954</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14982">#14982</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove deprecated indices.get_aliases <ulink url="https://github.com/elastic/elasticsearch/pull/13906">#13906</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Allocation
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove DisableAllocationDecider <ulink url="https://github.com/elastic/elasticsearch/pull/13313">#13313</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Analysis
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove <literal>token_filter</literal> in _analyze API <ulink url="https://github.com/elastic/elasticsearch/pull/20285">#20285</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20283">#20283</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Removes support for adding aliases to analyzers <ulink url="https://github.com/elastic/elasticsearch/pull/19994">#19994</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18244">#18244</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Analyze API : Rename filters/token_filters/char_filter in Analyze API in master <ulink url="https://github.com/elastic/elasticsearch/pull/17843">#17843</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15189">#15189</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
CAT API
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Improve cat thread pool API <ulink url="https://github.com/elastic/elasticsearch/pull/19721">#19721</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19590">#19590</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Row-centric output for _cat/fielddata <ulink url="https://github.com/elastic/elasticsearch/pull/18068">#18068</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/10249">#10249</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add raw recovery progress to cat recovery API <ulink url="https://github.com/elastic/elasticsearch/pull/17064">#17064</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17022">#17022</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove host from cat nodes API <ulink url="https://github.com/elastic/elasticsearch/pull/16656">#16656</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/12959">#12959</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/16575">#16575</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Using the accept header in the request instead of content-type in _cat API. <ulink url="https://github.com/elastic/elasticsearch/pull/14421">#14421</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14195">#14195</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
CRUD
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fixed naming inconsistency for fields/stored_fields in the APIs <ulink url="https://github.com/elastic/elasticsearch/pull/20166">#20166</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/18943">#18943</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/20155">#20155</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Disallow creating indices starting with <emphasis>-</emphasis> or <emphasis>+</emphasis> <ulink url="https://github.com/elastic/elasticsearch/pull/20033">#20033</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19800">#19800</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Wait for changes to be visible by search <ulink url="https://github.com/elastic/elasticsearch/pull/17986">#17986</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/1063">#1063</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove object notation for core types. <ulink url="https://github.com/elastic/elasticsearch/pull/15684">#15684</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15388">#15388</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Cache
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove deprecated query cache settings <ulink url="https://github.com/elastic/elasticsearch/pull/15592">#15592</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Cluster
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Persistent Node Ids <ulink url="https://github.com/elastic/elasticsearch/pull/19140">#19140</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17811">#17811</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove validation errors from cluster health response <ulink url="https://github.com/elastic/elasticsearch/pull/17773">#17773</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16979">#16979</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove memory section <ulink url="https://github.com/elastic/elasticsearch/pull/17278">#17278</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/12049">#12049</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/16756">#16756</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Core
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove ignore system bootstrap checks <ulink url="https://github.com/elastic/elasticsearch/pull/20511">#20511</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove minimum master nodes bootstrap check <ulink url="https://github.com/elastic/elasticsearch/pull/20082">#20082</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Keep input time unit when parsing TimeValues <ulink url="https://github.com/elastic/elasticsearch/pull/19102">#19102</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove cluster name from data path <ulink url="https://github.com/elastic/elasticsearch/pull/18554">#18554</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17810">#17810</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add max number of processes check <ulink url="https://github.com/elastic/elasticsearch/pull/16919">#16919</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add mlockall bootstrap check <ulink url="https://github.com/elastic/elasticsearch/pull/16909">#16909</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
One log <ulink url="https://github.com/elastic/elasticsearch/pull/16703">#16703</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16585">#16585</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Engine
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Optimize indexing for the autogenerated ID append-only case <ulink url="https://github.com/elastic/elasticsearch/pull/20211">#20211</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19813">#19813</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove <literal>index.compound_on_flush</literal> setting and default to <literal>true</literal> <ulink url="https://github.com/elastic/elasticsearch/pull/15594">#15594</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/10778">#10778</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Exceptions
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Die with dignity <ulink url="https://github.com/elastic/elasticsearch/pull/19272">#19272</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19231">#19231</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Fielddata
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove "uninverted" and "binary" fielddata support for numeric and boolean fields. <ulink url="https://github.com/elastic/elasticsearch/pull/14082">#14082</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14113">#14113</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Geo
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Deprecate GeoDistance enums and remove geo distance script helpers <ulink url="https://github.com/elastic/elasticsearch/pull/19783">#19783</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Index APIs
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Removes write consistency level across replication action APIs in favor of wait_for_active_shards <ulink url="https://github.com/elastic/elasticsearch/pull/19454">#19454</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18985">#18985</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove <literal>GET</literal> option for /_forcemerge <ulink url="https://github.com/elastic/elasticsearch/pull/15223">#15223</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15165">#15165</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove /_optimize REST API endpoint <ulink url="https://github.com/elastic/elasticsearch/pull/14226">#14226</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13778">#13778</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Indexed Scripts/Templates
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Store indexed scripts in the cluster state instead of the <literal>.scripts</literal> index <ulink url="https://github.com/elastic/elasticsearch/pull/17650">#17650</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16651">#16651</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Inner Hits
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Also do not serialize <literal>_index</literal> key in search response for parent/child inner hits <ulink url="https://github.com/elastic/elasticsearch/pull/19011">#19011</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Don&#8217;t include <literal>_id</literal>, <literal>_type</literal> and <literal>_index</literal> keys in search response for inner hits <ulink url="https://github.com/elastic/elasticsearch/pull/18995">#18995</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18091">#18091</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Nested inner hits shouldn&#8217;t use relative paths <ulink url="https://github.com/elastic/elasticsearch/pull/18567">#18567</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16653">#16653</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Drop top level inner hits in favour of inner hits defined in the query dsl <ulink url="https://github.com/elastic/elasticsearch/pull/17816">#17816</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/11118">#11118</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Internal
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
<literal>_flush</literal> should block by default <ulink url="https://github.com/elastic/elasticsearch/pull/20597">#20597</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20569">#20569</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Actually bound the generic thread pool <ulink url="https://github.com/elastic/elasticsearch/pull/17017">#17017</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove support for pre 2.0 indices <ulink url="https://github.com/elastic/elasticsearch/pull/13799">#13799</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Logging
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Introduce Log4j 2 <ulink url="https://github.com/elastic/elasticsearch/pull/20235">#20235</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/16030">#16030</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/17697">#17697</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Mapping
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove <literal>_timestamp</literal> and <literal>_ttl</literal> on 5.x indices. <ulink url="https://github.com/elastic/elasticsearch/pull/18980">#18980</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18280">#18280</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add a soft limit on the mapping depth. <ulink url="https://github.com/elastic/elasticsearch/pull/17400">#17400</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Disable fielddata on text fields by defaults. <ulink url="https://github.com/elastic/elasticsearch/pull/17386">#17386</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add limit to total number of fields in mapping <ulink url="https://github.com/elastic/elasticsearch/pull/17357">#17357</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Change the field mapping index time boost into a query time boost. <ulink url="https://github.com/elastic/elasticsearch/pull/16900">#16900</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Deprecate string in favor of text/keyword. <ulink url="https://github.com/elastic/elasticsearch/pull/16877">#16877</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Term vector APIs should no longer update mappings <ulink url="https://github.com/elastic/elasticsearch/pull/16285">#16285</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove the <literal>format</literal> option of the <literal>_source</literal> field. <ulink url="https://github.com/elastic/elasticsearch/pull/15398">#15398</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove transform <ulink url="https://github.com/elastic/elasticsearch/pull/13657">#13657</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/12674">#12674</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Packaging
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Rename service.bat to elasticsearch-service.bat <ulink url="https://github.com/elastic/elasticsearch/pull/20496">#20496</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17528">#17528</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove -D handling in args for windows plugin script <ulink url="https://github.com/elastic/elasticsearch/pull/20378">#20378</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18207">#18207</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Set default min heap equal to default max heap <ulink url="https://github.com/elastic/elasticsearch/pull/20080">#20080</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/16334">#16334</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/17728">#17728</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/18311">#18311</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove allow running as root <ulink url="https://github.com/elastic/elasticsearch/pull/18694">#18694</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18688">#18688</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Require /bin/bash in packaging <ulink url="https://github.com/elastic/elasticsearch/pull/18259">#18259</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18251">#18251</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove plugin script parsing of system properties <ulink url="https://github.com/elastic/elasticsearch/pull/18207">#18207</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18140">#18140</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add JVM options configuration file <ulink url="https://github.com/elastic/elasticsearch/pull/17675">#17675</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17121">#17121</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Parent/Child
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Removed <literal>total</literal> score mode in favour for <literal>sum</literal> score mode. <ulink url="https://github.com/elastic/elasticsearch/pull/17174">#17174</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/13470">#13470</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/17083">#17083</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Removed pre 2.x parent child implementation <ulink url="https://github.com/elastic/elasticsearch/pull/13376">#13376</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Percolator
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove <literal>.percolator</literal> type in favour of <literal>percolator</literal> field type <ulink url="https://github.com/elastic/elasticsearch/pull/17560">#17560</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Change the percolate api to not dynamically add fields to mapping <ulink url="https://github.com/elastic/elasticsearch/pull/16077">#16077</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15751">#15751</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Delete By Query
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove Delete-By-Query plugin <ulink url="https://github.com/elastic/elasticsearch/pull/18516">#18516</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18469">#18469</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Lang Painless
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove all date <emphasis>now</emphasis> methods from Painless <ulink url="https://github.com/elastic/elasticsearch/pull/20766">#20766</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20762">#20762</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make Painless the Default Language <ulink url="https://github.com/elastic/elasticsearch/pull/20017">#20017</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19960">#19960</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugins
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Plugins cleanup <ulink url="https://github.com/elastic/elasticsearch/pull/18594">#18594</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18588">#18588</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Rename bin/plugin in bin/elasticsearch-plugin <ulink url="https://github.com/elastic/elasticsearch/pull/16454">#16454</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Change the inner structure of the plugins zip <ulink url="https://github.com/elastic/elasticsearch/pull/16453">#16453</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove multicast plugin <ulink url="https://github.com/elastic/elasticsearch/pull/16326">#16326</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16310">#16310</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Plugins: Remove site plugins <ulink url="https://github.com/elastic/elasticsearch/pull/16038">#16038</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Query DSL
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Lessen leniency of the query dsl. <ulink url="https://github.com/elastic/elasticsearch/pull/18276">#18276</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Function score query: remove deprecated support for boost_factor <ulink url="https://github.com/elastic/elasticsearch/pull/13510">#13510</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove support for deprecated queries. <ulink url="https://github.com/elastic/elasticsearch/pull/13418">#13418</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13326">#13326</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
REST
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Change separator for shards preference <ulink url="https://github.com/elastic/elasticsearch/pull/20786">#20786</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/20722">#20722</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/20769">#20769</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Parameter improvements to Cluster Health API wait for shards <ulink url="https://github.com/elastic/elasticsearch/pull/20223">#20223</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20216">#20216</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Switch indices.exists_type from <literal>{index}/{type}</literal> to <literal>{index}/_mapping/{type}</literal>. <ulink url="https://github.com/elastic/elasticsearch/pull/20055">#20055</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15613">#15613</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Only use <literal>PUT</literal> for index creation, not POST. <ulink url="https://github.com/elastic/elasticsearch/pull/20001">#20001</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/15613">#15613</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/18160">#18160</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove camelCase support <ulink url="https://github.com/elastic/elasticsearch/pull/17933">#17933</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/8988">#8988</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove <emphasis>case</emphasis> parameter from rest apis <ulink url="https://github.com/elastic/elasticsearch/pull/17774">#17774</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/8988">#8988</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Disallow unquoted field names <ulink url="https://github.com/elastic/elasticsearch/pull/15351">#15351</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/9800">#9800</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Limit the accepted length of the _id <ulink url="https://github.com/elastic/elasticsearch/pull/16036">#16036</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16034">#16034</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Scripting
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Hardcode painless as the default scripting lang and add legacy script default for stored scripts <ulink url="https://github.com/elastic/elasticsearch/pull/20310">#20310</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20122">#20122</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove deprecated 1.x script and template syntax <ulink url="https://github.com/elastic/elasticsearch/pull/19387">#19387</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13729">#13729</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Allow only a single extension for a scripting engine <ulink url="https://github.com/elastic/elasticsearch/pull/18332">#18332</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/10598">#10598</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove <emphasis>sandbox</emphasis> option for script settings, allow only registering a single language. <ulink url="https://github.com/elastic/elasticsearch/pull/18226">#18226</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/10598">#10598</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/17114">#17114</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Search
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Rename <literal>fields</literal> to <literal>stored_fields</literal> and add <literal>docvalue_fields</literal> <ulink url="https://github.com/elastic/elasticsearch/pull/18992">#18992</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18943">#18943</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove only node preference <ulink url="https://github.com/elastic/elasticsearch/pull/18875">#18875</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18822">#18822</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add search preference to prefer multiple nodes <ulink url="https://github.com/elastic/elasticsearch/pull/18872">#18872</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18822">#18822</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add a soft limit on the number of shards that can be queried in a single search request. <ulink url="https://github.com/elastic/elasticsearch/pull/17396">#17396</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove deprecated reverse option from sorting <ulink url="https://github.com/elastic/elasticsearch/pull/17282">#17282</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17047">#17047</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove some deprecations <ulink url="https://github.com/elastic/elasticsearch/pull/14331">#14331</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove search exists api <ulink url="https://github.com/elastic/elasticsearch/pull/13911">#13911</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/13682">#13682</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/13910">#13910</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove the scan and count search types. <ulink url="https://github.com/elastic/elasticsearch/pull/13310">#13310</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Search Refactoring
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove deprecated parameter from field sort builder. <ulink url="https://github.com/elastic/elasticsearch/pull/16573">#16573</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16127">#16127</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove "query" query and fix related parsing bugs <ulink url="https://github.com/elastic/elasticsearch/pull/14304">#14304</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13326">#13326</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Settings
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Default max local storage nodes to one <ulink url="https://github.com/elastic/elasticsearch/pull/19964">#19964</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/19679">#19679</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/19748">#19748</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Persistent Node Names <ulink url="https://github.com/elastic/elasticsearch/pull/19456">#19456</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19140">#19140</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove support for properties <ulink url="https://github.com/elastic/elasticsearch/pull/19398">#19398</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/19388">#19388</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/19391">#19391</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Rename boostrap.mlockall to bootstrap.memory_lock <ulink url="https://github.com/elastic/elasticsearch/pull/18669">#18669</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Register <literal>indices.query.bool.max_clause_count</literal> setting <ulink url="https://github.com/elastic/elasticsearch/pull/18341">#18341</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18336">#18336</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove settings and system properties entanglement <ulink url="https://github.com/elastic/elasticsearch/pull/18198">#18198</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18197">#18197</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove <literal>action.get.realtime</literal> setting <ulink url="https://github.com/elastic/elasticsearch/pull/17857">#17857</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/12543">#12543</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove ability to specify arbitrary node attributes with <literal>node.</literal> prefix <ulink url="https://github.com/elastic/elasticsearch/pull/17402">#17402</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17280">#17280</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Enforce <literal>discovery.zen.minimum_master_nodes</literal> is set when bound to a public ip <ulink url="https://github.com/elastic/elasticsearch/pull/17288">#17288</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Prevent index level setting from being configured on a node level <ulink url="https://github.com/elastic/elasticsearch/pull/17144">#17144</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16799">#16799</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove support for node.client setting <ulink url="https://github.com/elastic/elasticsearch/pull/16963">#16963</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16565">#16565</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove es.max-open-files flag <ulink url="https://github.com/elastic/elasticsearch/pull/16757">#16757</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/16506">#16506</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/483">#483</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Enforce node level limits if node is started in production env <ulink url="https://github.com/elastic/elasticsearch/pull/16733">#16733</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16727">#16727</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make settings validation strict <ulink url="https://github.com/elastic/elasticsearch/pull/16365">#16365</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove the ability to fsync on every operation and only schedule fsync task if really needed <ulink url="https://github.com/elastic/elasticsearch/pull/16257">#16257</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16152">#16152</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Script settings <ulink url="https://github.com/elastic/elasticsearch/pull/16197">#16197</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove index.flush_on_close entirely <ulink url="https://github.com/elastic/elasticsearch/pull/15977">#15977</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Restore chunksize of 512kb on recovery and remove configurability <ulink url="https://github.com/elastic/elasticsearch/pull/15235">#15235</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15161">#15161</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove ancient deprecated and alternative recovery settings <ulink url="https://github.com/elastic/elasticsearch/pull/15234">#15234</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Similarities
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Renames <literal>default</literal> similarity into <literal>classic</literal> <ulink url="https://github.com/elastic/elasticsearch/pull/15446">#15446</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15102">#15102</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Snapshot/Restore
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Change the default of <literal>include_global_state</literal> from true to false for snapshot restores <ulink url="https://github.com/elastic/elasticsearch/pull/18773">#18773</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18569">#18569</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fail closing or deleting indices during a full snapshot <ulink url="https://github.com/elastic/elasticsearch/pull/17021">#17021</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16321">#16321</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Stats
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Modify load average format <ulink url="https://github.com/elastic/elasticsearch/pull/15932">#15932</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15907">#15907</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Reintroduce five-minute and fifteen-minute load averages on Linux <ulink url="https://github.com/elastic/elasticsearch/pull/15907">#15907</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/12049">#12049</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/14741">#14741</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add system CPU percent to OS stats <ulink url="https://github.com/elastic/elasticsearch/pull/14741">#14741</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Term Vectors
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove DFS support from TermVector API <ulink url="https://github.com/elastic/elasticsearch/pull/16452">#16452</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Translog
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Drop support for simple translog and hard-wire buffer to 8kb <ulink url="https://github.com/elastic/elasticsearch/pull/15574">#15574</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Simplify translog-based flush settings <ulink url="https://github.com/elastic/elasticsearch/pull/15573">#15573</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Warmers
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove query warmers and the warmer API. <ulink url="https://github.com/elastic/elasticsearch/pull/15614">#15614</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15607">#15607</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="breaking-java-5.0.0" renderas="sect2">Breaking Java changes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.0.0-all.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
Aggregations
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
getKeyAsString and key_as_string should be the same for terms aggregation on boolean field <ulink url="https://github.com/elastic/elasticsearch/pull/15393">#15393</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Allocation
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Move parsing of allocation commands into REST and remove support for plugins to register allocation commands <ulink url="https://github.com/elastic/elasticsearch/pull/17802">#17802</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17894">#17894</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Simplify shard balancer interface <ulink url="https://github.com/elastic/elasticsearch/pull/17028">#17028</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/8954">#8954</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Analysis
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Simplify Analysis registration and configuration <ulink url="https://github.com/elastic/elasticsearch/pull/14355">#14355</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
CRUD
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Removing isCreated and isFound from the Java API <ulink url="https://github.com/elastic/elasticsearch/pull/19645">#19645</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/19566">#19566</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/19631">#19631</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Cache
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Refactor IndicesRequestCache to make it testable. <ulink url="https://github.com/elastic/elasticsearch/pull/16610">#16610</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fold IndexCacheModule into IndexModule <ulink url="https://github.com/elastic/elasticsearch/pull/14293">#14293</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Core
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove ability to plug-in TransportService <ulink url="https://github.com/elastic/elasticsearch/pull/20505">#20505</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Register thread pool settings <ulink url="https://github.com/elastic/elasticsearch/pull/18674">#18674</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/18613">#18613</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/9216">#9216</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Bootstrap does not set system properties <ulink url="https://github.com/elastic/elasticsearch/pull/17088">#17088</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/16579">#16579</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/16791">#16791</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove es.useLinkedTransferQueue <ulink url="https://github.com/elastic/elasticsearch/pull/16786">#16786</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Discovery
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Introduce node handshake <ulink url="https://github.com/elastic/elasticsearch/pull/15971">#15971</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/9061">#9061</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Include pings from client nodes in master election <ulink url="https://github.com/elastic/elasticsearch/pull/17329">#17329</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17325">#17325</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Highlighting
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Register Highlighter instances instead of classes <ulink url="https://github.com/elastic/elasticsearch/pull/18859">#18859</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Internal
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove TransportService#registerRequestHandler leniency <ulink url="https://github.com/elastic/elasticsearch/pull/20469">#20469</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20468">#20468</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Consolidate search parser registries <ulink url="https://github.com/elastic/elasticsearch/pull/20000">#20000</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Move all FetchSubPhases to o.e.search.fetch.subphase <ulink url="https://github.com/elastic/elasticsearch/pull/19702">#19702</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Squash the rest of o.e.rest.action <ulink url="https://github.com/elastic/elasticsearch/pull/19698">#19698</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Clean up BytesReference <ulink url="https://github.com/elastic/elasticsearch/pull/19196">#19196</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Cleanup ClusterService dependencies and detached from Guice <ulink url="https://github.com/elastic/elasticsearch/pull/18941">#18941</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Simplify SubFetchPhase interface <ulink url="https://github.com/elastic/elasticsearch/pull/18881">#18881</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Simplify FetchSubPhase registration and detach it from Guice <ulink url="https://github.com/elastic/elasticsearch/pull/18862">#18862</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove duplicate getters from DiscoveryNode and DiscoveryNodes <ulink url="https://github.com/elastic/elasticsearch/pull/17410">#17410</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16963">#16963</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Cli: Switch to jopt-simple <ulink url="https://github.com/elastic/elasticsearch/pull/17024">#17024</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/11564">#11564</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Replace ContextAndHeaders with a ThreadPool based ThreadLocal implementation <ulink url="https://github.com/elastic/elasticsearch/pull/15776">#15776</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove NodeBuilder <ulink url="https://github.com/elastic/elasticsearch/pull/15354">#15354</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix IndexSearcherWrapper interface to not depend on the EngineConfig <ulink url="https://github.com/elastic/elasticsearch/pull/14654">#14654</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Cleanup query parsing and remove IndexQueryParserService <ulink url="https://github.com/elastic/elasticsearch/pull/14452">#14452</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove circular dependency between IndicesService and IndicesStore <ulink url="https://github.com/elastic/elasticsearch/pull/14285">#14285</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove guice injection from IndexStore and friends <ulink url="https://github.com/elastic/elasticsearch/pull/14279">#14279</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Replace IndicesLifecycle with a per-index IndexEventListener <ulink url="https://github.com/elastic/elasticsearch/pull/14217">#14217</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13259">#13259</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Simplify similarity module and friends <ulink url="https://github.com/elastic/elasticsearch/pull/13942">#13942</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Refactor SearchRequest to be parsed on the coordinating node <ulink url="https://github.com/elastic/elasticsearch/pull/13859">#13859</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Java API
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add a dedicated client/transport project for transport-client <ulink url="https://github.com/elastic/elasticsearch/pull/19435">#19435</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19412">#19412</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove setRefresh <ulink url="https://github.com/elastic/elasticsearch/pull/18752">#18752</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/1063">#1063</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove the count api <ulink url="https://github.com/elastic/elasticsearch/pull/14166">#14166</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13928">#13928</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
IdsQueryBuilder to accept only non null ids and types <ulink url="https://github.com/elastic/elasticsearch/pull/13937">#13937</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Mapping
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
[Mapping] Several MappingService cleanups <ulink url="https://github.com/elastic/elasticsearch/pull/16133">#16133</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15924">#15924</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Network
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Factor out abstract TCPTransport* classes to reduce the netty footprint <ulink url="https://github.com/elastic/elasticsearch/pull/19096">#19096</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove ability to disable Netty gathering writes <ulink url="https://github.com/elastic/elasticsearch/pull/16774">#16774</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/7811">#7811</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Parent/Child
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Cleanup ParentFieldMapper <ulink url="https://github.com/elastic/elasticsearch/pull/16045">#16045</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Several other parent/child cleanups <ulink url="https://github.com/elastic/elasticsearch/pull/13470">#13470</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Percolator
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Move the percolator from core to its own module <ulink url="https://github.com/elastic/elasticsearch/pull/18511">#18511</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove percolator cache <ulink url="https://github.com/elastic/elasticsearch/pull/18434">#18434</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugins
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Cleanup sub fetch phase extension point <ulink url="https://github.com/elastic/elasticsearch/pull/20382">#20382</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove IndexTemplateFilter <ulink url="https://github.com/elastic/elasticsearch/pull/20072">#20072</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Switch custom ShardsAllocators to pull based model <ulink url="https://github.com/elastic/elasticsearch/pull/20071">#20071</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Make custom allocation deciders use pull based extensions <ulink url="https://github.com/elastic/elasticsearch/pull/20040">#20040</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Migrate query registration from push to pull <ulink url="https://github.com/elastic/elasticsearch/pull/19376">#19376</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add components getter as bridge between guice and new plugin init world <ulink url="https://github.com/elastic/elasticsearch/pull/19371">#19371</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove CustomNodeAttributes extension point <ulink url="https://github.com/elastic/elasticsearch/pull/19348">#19348</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add RepositoryPlugin interface for registering snapshot repositories <ulink url="https://github.com/elastic/elasticsearch/pull/19324">#19324</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Simplified repository api for snapshot/restore <ulink url="https://github.com/elastic/elasticsearch/pull/19292">#19292</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Switch most search extensions from push to pull <ulink url="https://github.com/elastic/elasticsearch/pull/19238">#19238</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Move RestHandler registration to ActionModule and ActionPlugin <ulink url="https://github.com/elastic/elasticsearch/pull/19165">#19165</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Pull actions from plugins <ulink url="https://github.com/elastic/elasticsearch/pull/19108">#19108</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Switch analysis from push to pull <ulink url="https://github.com/elastic/elasticsearch/pull/19073">#19073</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove guice from Mapper plugins <ulink url="https://github.com/elastic/elasticsearch/pull/19018">#19018</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fail to start if plugin tries broken onModule <ulink url="https://github.com/elastic/elasticsearch/pull/19025">#19025</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Simplify ScriptModule and script registration <ulink url="https://github.com/elastic/elasticsearch/pull/18903">#18903</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Cut over settings registration to a pull model <ulink url="https://github.com/elastic/elasticsearch/pull/18890">#18890</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Enforce isolated mode for all plugins <ulink url="https://github.com/elastic/elasticsearch/pull/17276">#17276</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Don&#8217;t use guice for QueryParsers <ulink url="https://github.com/elastic/elasticsearch/pull/15761">#15761</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove guice from the index level <ulink url="https://github.com/elastic/elasticsearch/pull/14518">#14518</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove shard-level injector <ulink url="https://github.com/elastic/elasticsearch/pull/13881">#13881</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Query DSL
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove the MissingQueryBuilder which was deprecated in 2.2.0. <ulink url="https://github.com/elastic/elasticsearch/pull/15364">#15364</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14112">#14112</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove NotQueryBuilder <ulink url="https://github.com/elastic/elasticsearch/pull/14204">#14204</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13761">#13761</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Scripting
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove o.e.script.Template class and move template query to lang-mustache module <ulink url="https://github.com/elastic/elasticsearch/pull/19425">#19425</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16314">#16314</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Move search template to lang-mustache module <ulink url="https://github.com/elastic/elasticsearch/pull/18765">#18765</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17906">#17906</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove LeafSearchScript.runAsFloat(): Nothing calls it. <ulink url="https://github.com/elastic/elasticsearch/pull/18364">#18364</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Search
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove FetchSubPhaseParseElement <ulink url="https://github.com/elastic/elasticsearch/pull/20350">#20350</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Refactor of query profile classes to make way for other profile implementations <ulink url="https://github.com/elastic/elasticsearch/pull/18370">#18370</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/10538">#10538</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Query refactoring: split parse phase into fromXContent and toQuery for all queries <ulink url="https://github.com/elastic/elasticsearch/pull/13788">#13788</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/10217">#10217</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Search Refactoring
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Refactored inner hits parsing and intoduced InnerHitBuilder <ulink url="https://github.com/elastic/elasticsearch/pull/17291">#17291</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove support for query_binary and filter_binary <ulink url="https://github.com/elastic/elasticsearch/pull/14433">#14433</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14308">#14308</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Validate query api: move query parsing to the coordinating node <ulink url="https://github.com/elastic/elasticsearch/pull/14384">#14384</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Settings
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove <literal>node.mode</literal> and <literal>node.local</literal> settings <ulink url="https://github.com/elastic/elasticsearch/pull/19428">#19428</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove Settings.settingsBuilder. <ulink url="https://github.com/elastic/elasticsearch/pull/17619">#17619</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Move remaining settings in NettyHttpServerTransport to the new infra <ulink url="https://github.com/elastic/elasticsearch/pull/16531">#16531</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Replace IndexSettings annotation with a full-fledged class <ulink url="https://github.com/elastic/elasticsearch/pull/14251">#14251</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix ping timeout settings inconsistencies <ulink url="https://github.com/elastic/elasticsearch/pull/13701">#13701</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/6579">#6579</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Snapshot/Restore
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Removes extra writeBlob method in BlobContainer <ulink url="https://github.com/elastic/elasticsearch/pull/19727">#19727</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18528">#18528</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Store
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Standardize state format type for global and index level metadata <ulink url="https://github.com/elastic/elasticsearch/pull/17123">#17123</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Suggesters
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove suggest threadpool <ulink url="https://github.com/elastic/elasticsearch/pull/17304">#17304</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17198">#17198</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove suggest transport action <ulink url="https://github.com/elastic/elasticsearch/pull/17198">#17198</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/10217">#10217</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="deprecation-5.0.0" renderas="sect2">Deprecations<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.0.0-all.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
CRUD
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Deprecate found and created in delete and index rest responses <ulink url="https://github.com/elastic/elasticsearch/pull/19633">#19633</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Discovery Azure Classic
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Deprecate discovery-azure and rename it to discovery-azure-classic <ulink url="https://github.com/elastic/elasticsearch/pull/19186">#19186</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19144">#19144</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Mapper Attachment
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Deprecate mapper-attachments plugin <ulink url="https://github.com/elastic/elasticsearch/pull/16948">#16948</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16910">#16910</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Query DSL
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Deprecate Indices query <ulink url="https://github.com/elastic/elasticsearch/pull/17710">#17710</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/12017">#12017</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Deprecate mlt, in and geo_bbox query name shortcuts <ulink url="https://github.com/elastic/elasticsearch/pull/17507">#17507</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Query Refactoring
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Splits <literal>phrase</literal> and <literal>phrase_prefix</literal> in match query into <literal>MatchPhraseQueryBuilder</literal> and <literal>MatchPhrasePrefixQueryBuilder</literal> <ulink url="https://github.com/elastic/elasticsearch/pull/17508">#17508</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Scripting
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Deprecate Groovy, Python, and Javascript <ulink url="https://github.com/elastic/elasticsearch/pull/20244">#20244</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20129">#20129</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Search
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Deprecate fuzzy query <ulink url="https://github.com/elastic/elasticsearch/pull/16211">#16211</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/15760">#15760</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/16121">#16121</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Templates
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Deprecate template query <ulink url="https://github.com/elastic/elasticsearch/pull/19607">#19607</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19390">#19390</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="feature-5.0.0" renderas="sect2">New features<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.0.0-all.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
Aggregations
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Split regular histograms from date histograms. <ulink url="https://github.com/elastic/elasticsearch/pull/19551">#19551</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/4847">#4847</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/8082">#8082</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Adds aggregation profiling to the profile API <ulink url="https://github.com/elastic/elasticsearch/pull/18414">#18414</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/10538">#10538</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
New Matrix Stats Aggregation module <ulink url="https://github.com/elastic/elasticsearch/pull/18300">#18300</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16826">#16826</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Aliases
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add an alias action to delete an index <ulink url="https://github.com/elastic/elasticsearch/pull/20184">#20184</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20064">#20064</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Allocation
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add API to explain why a shard is or isn&#8217;t assigned <ulink url="https://github.com/elastic/elasticsearch/pull/17305">#17305</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14593">#14593</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Analysis
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Exposing lucene 6.x minhash filter. <ulink url="https://github.com/elastic/elasticsearch/pull/20206">#20206</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20149">#20149</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add <literal>fingerprint</literal> token filter and <literal>fingerprint</literal> analyzer <ulink url="https://github.com/elastic/elasticsearch/pull/17873">#17873</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13325">#13325</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Circuit Breakers
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Circuit break on aggregation bucket numbers with request breaker <ulink url="https://github.com/elastic/elasticsearch/pull/19394">#19394</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14046">#14046</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Discovery
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add two phased commit to Cluster State publishing <ulink url="https://github.com/elastic/elasticsearch/pull/13062">#13062</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Geo
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Cut over geo_point field and queries to new LatLonPoint type <ulink url="https://github.com/elastic/elasticsearch/pull/20315">#20315</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20314">#20314</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Index APIs
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add rollover API to switch index aliases given some predicates <ulink url="https://github.com/elastic/elasticsearch/pull/18732">#18732</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18647">#18647</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Ingest
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
ingest-useragent plugin <ulink url="https://github.com/elastic/elasticsearch/pull/19074">#19074</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add a Sort ingest processor <ulink url="https://github.com/elastic/elasticsearch/pull/17999">#17999</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add date_index_name processor <ulink url="https://github.com/elastic/elasticsearch/pull/17973">#17973</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17814">#17814</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Merge feature/ingest branch into master branch <ulink url="https://github.com/elastic/elasticsearch/pull/16049">#16049</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14049">#14049</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Java REST Client
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Introduce async performRequest method <ulink url="https://github.com/elastic/elasticsearch/pull/19400">#19400</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Low level Rest Client <ulink url="https://github.com/elastic/elasticsearch/pull/18735">#18735</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/7743">#7743</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Mapping
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add <literal>scaled_float</literal>. <ulink url="https://github.com/elastic/elasticsearch/pull/19264">#19264</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/15939">#15939</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/1941">#1941</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Expose half-floats. <ulink url="https://github.com/elastic/elasticsearch/pull/18887">#18887</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add a text field. <ulink url="https://github.com/elastic/elasticsearch/pull/16637">#16637</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add a new <literal>keyword</literal> field. <ulink url="https://github.com/elastic/elasticsearch/pull/16589">#16589</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14113">#14113</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Percolator
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
index the query terms from the percolator query <ulink url="https://github.com/elastic/elasticsearch/pull/13646">#13646</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/12664">#12664</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Analysis ICU
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Adding support for customizing the rule file in ICU tokenizer <ulink url="https://github.com/elastic/elasticsearch/pull/13651">#13651</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13146">#13146</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Discovery File
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
File-based discovery plugin <ulink url="https://github.com/elastic/elasticsearch/pull/20394">#20394</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20323">#20323</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Ingest Attachment
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Ingest: Add attachment processor <ulink url="https://github.com/elastic/elasticsearch/pull/16490">#16490</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16303">#16303</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Mapper Attachment
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Migrate mapper attachments plugin to main repository <ulink url="https://github.com/elastic/elasticsearch/pull/14605">#14605</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Repository HDFS
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
HDFS Snapshot/Restore plugin <ulink url="https://github.com/elastic/elasticsearch/pull/15192">#15192</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15191">#15191</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Repository S3
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add support for path_style_access <ulink url="https://github.com/elastic/elasticsearch/pull/15114">#15114</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Query DSL
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Adds a rewrite phase to queries on the shard level <ulink url="https://github.com/elastic/elasticsearch/pull/16870">#16870</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/9526">#9526</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Reindex API
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Reindex from remote <ulink url="https://github.com/elastic/elasticsearch/pull/18585">#18585</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17447">#17447</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Port Delete By Query to Reindex infrastructure <ulink url="https://github.com/elastic/elasticsearch/pull/18329">#18329</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16883">#16883</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Merge reindex to master <ulink url="https://github.com/elastic/elasticsearch/pull/16861">#16861</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Scripting
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Exceptions and Infinite Loop Checking <ulink url="https://github.com/elastic/elasticsearch/pull/15936">#15936</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Added a new scripting language (PlanA) <ulink url="https://github.com/elastic/elasticsearch/pull/15136">#15136</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13084">#13084</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Scroll
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add the ability to partition a scroll in multiple slices. <ulink url="https://github.com/elastic/elasticsearch/pull/18237">#18237</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13494">#13494</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Search
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add the ability to disable the retrieval of the stored fields entirely <ulink url="https://github.com/elastic/elasticsearch/pull/20026">#20026</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add <literal>search_after</literal> parameter in the SearchAPI <ulink url="https://github.com/elastic/elasticsearch/pull/16125">#16125</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/8192">#8192</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Settings
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add infrastructure to transactionally apply and reset dynamic settings <ulink url="https://github.com/elastic/elasticsearch/pull/15278">#15278</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Snapshot/Restore
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add Google Cloud Storage repository plugin <ulink url="https://github.com/elastic/elasticsearch/pull/13578">#13578</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/12880">#12880</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Stats
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Extend field stats to report searchable/aggregatable fields <ulink url="https://github.com/elastic/elasticsearch/pull/17980">#17980</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17750">#17750</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
API for listing index file sizes <ulink url="https://github.com/elastic/elasticsearch/pull/16661">#16661</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16131">#16131</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Store
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Expose MMapDirectory.preLoad(). <ulink url="https://github.com/elastic/elasticsearch/pull/18880">#18880</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add primitive to shrink an index into a single shard <ulink url="https://github.com/elastic/elasticsearch/pull/18270">#18270</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Suggesters
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add support for returning documents with completion suggester <ulink url="https://github.com/elastic/elasticsearch/pull/19536">#19536</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/10746">#10746</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add document-oriented completion suggester <ulink url="https://github.com/elastic/elasticsearch/pull/14410">#14410</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/10746">#10746</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Task Manager
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add task cancellation mechanism <ulink url="https://github.com/elastic/elasticsearch/pull/16320">#16320</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Make the Task object available to the action caller <ulink url="https://github.com/elastic/elasticsearch/pull/16033">#16033</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Task Management: Add framework for registering and communicating with tasks <ulink url="https://github.com/elastic/elasticsearch/pull/15347">#15347</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15117">#15117</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Translog
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add <literal>elasticsearch-translog</literal> CLI tool with <literal>truncate</literal> command <ulink url="https://github.com/elastic/elasticsearch/pull/19342">#19342</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19123">#19123</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="enhancement-5.0.0" renderas="sect2">Enhancements<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.0.0-all.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
Aggregations
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Make the heuristic to compute the default shard size less aggressive. <ulink url="https://github.com/elastic/elasticsearch/pull/19659">#19659</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add _bucket_count option to buckets_path <ulink url="https://github.com/elastic/elasticsearch/pull/19571">#19571</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19553">#19553</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove AggregationStreams <ulink url="https://github.com/elastic/elasticsearch/pull/19507">#19507</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Migrate serial_diff aggregation to NamedWriteable <ulink url="https://github.com/elastic/elasticsearch/pull/19483">#19483</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Migrate most remaining pipeline aggregations to NamedWriteable <ulink url="https://github.com/elastic/elasticsearch/pull/19480">#19480</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Migrate moving_avg pipeline aggregation to NamedWriteable <ulink url="https://github.com/elastic/elasticsearch/pull/19420">#19420</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Migrate matrix_stats to NamedWriteable <ulink url="https://github.com/elastic/elasticsearch/pull/19418">#19418</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Migrate derivative pipeline aggregation to NamedWriteable <ulink url="https://github.com/elastic/elasticsearch/pull/19407">#19407</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Migrate top_hits, histogram, and ip_range aggregations to NamedWriteable <ulink url="https://github.com/elastic/elasticsearch/pull/19375">#19375</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Migrate nested, reverse_nested, and children aggregations to NamedWriteable <ulink url="https://github.com/elastic/elasticsearch/pull/19374">#19374</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Migrate geohash_grid and geo_bounds aggregations to NamedWriteable <ulink url="https://github.com/elastic/elasticsearch/pull/19372">#19372</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Clean up significant terms aggregation results <ulink url="https://github.com/elastic/elasticsearch/pull/19365">#19365</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Migrate range, date_range, and geo_distance aggregations to NamedWriteable <ulink url="https://github.com/elastic/elasticsearch/pull/19321">#19321</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Migrate terms aggregation to NamedWriteable <ulink url="https://github.com/elastic/elasticsearch/pull/19277">#19277</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Migrate sampler and missing aggregations to NamedWriteable <ulink url="https://github.com/elastic/elasticsearch/pull/19259">#19259</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Migrate global, filter, and filters aggregation to NamedWriteable <ulink url="https://github.com/elastic/elasticsearch/pull/19220">#19220</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Migrate the cardinality, scripted_metric, and geo_centroid aggregations to NamedWriteable <ulink url="https://github.com/elastic/elasticsearch/pull/19219">#19219</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Use a static default precision for the cardinality aggregation. <ulink url="https://github.com/elastic/elasticsearch/pull/19215">#19215</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Migrate more aggregations to NamedWriteable <ulink url="https://github.com/elastic/elasticsearch/pull/19199">#19199</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Migrate stats and extended stats to NamedWriteable <ulink url="https://github.com/elastic/elasticsearch/pull/19198">#19198</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Migrate sum, min, and max aggregations over to NamedWriteable <ulink url="https://github.com/elastic/elasticsearch/pull/19194">#19194</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Start migration away from aggregation streams <ulink url="https://github.com/elastic/elasticsearch/pull/19097">#19097</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Automatically set the collection mode to breadth_first in the terms aggregation when the cardinality of the field is unknown or smaller than the requested size. <ulink url="https://github.com/elastic/elasticsearch/pull/18779">#18779</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/9825">#9825</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Rename PipelineAggregatorBuilder to PipelineAggregationBuilder. <ulink url="https://github.com/elastic/elasticsearch/pull/18677">#18677</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18377">#18377</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
AggregatorBuilder and PipelineAggregatorBuilder do not need generics. <ulink url="https://github.com/elastic/elasticsearch/pull/18368">#18368</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18133">#18133</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Rename AggregatorBuilder to AggregationBuilder <ulink url="https://github.com/elastic/elasticsearch/pull/18377">#18377</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18367">#18367</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add the ability to use the breadth_first mode with nested aggregations (such as <literal>top_hits</literal>) which require access to score information. <ulink url="https://github.com/elastic/elasticsearch/pull/18127">#18127</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/9825">#9825</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make significant terms work on fields that are indexed with points. <ulink url="https://github.com/elastic/elasticsearch/pull/18031">#18031</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add tests and documentation for using <literal>time_zone</literal> in date range aggregation <ulink url="https://github.com/elastic/elasticsearch/pull/16955">#16955</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/10130">#10130</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fixes serialisation of Ranges <ulink url="https://github.com/elastic/elasticsearch/pull/16674">#16674</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Allocation
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Verify AllocationIDs in replication actions <ulink url="https://github.com/elastic/elasticsearch/pull/20320">#20320</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Mark shard as stale on non-replicated write, not on node shutdown <ulink url="https://github.com/elastic/elasticsearch/pull/20023">#20023</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18919">#18919</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add routing changes API to RoutingAllocation <ulink url="https://github.com/elastic/elasticsearch/pull/19992">#19992</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Primary shard allocator observes limits in forcing allocation <ulink url="https://github.com/elastic/elasticsearch/pull/19811">#19811</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19446">#19446</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Use primary terms as authority to fail shards <ulink url="https://github.com/elastic/elasticsearch/pull/19715">#19715</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add recovery source to ShardRouting <ulink url="https://github.com/elastic/elasticsearch/pull/19516">#19516</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Allow <literal>_shrink</literal> to N shards if source shards is a multiple of N <ulink url="https://github.com/elastic/elasticsearch/pull/18699">#18699</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Only filter intial recovery (post API) when shrinking an index <ulink url="https://github.com/elastic/elasticsearch/pull/18661">#18661</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Estimate shard size for shrinked indices <ulink url="https://github.com/elastic/elasticsearch/pull/18659">#18659</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Only fail relocation target shard if failing source shard is a primary <ulink url="https://github.com/elastic/elasticsearch/pull/18574">#18574</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16144">#16144</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Simplify delayed shard allocation <ulink url="https://github.com/elastic/elasticsearch/pull/18351">#18351</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18293">#18293</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Limit retries of failed allocations per index <ulink url="https://github.com/elastic/elasticsearch/pull/18467">#18467</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18417">#18417</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Immutable ShardRouting <ulink url="https://github.com/elastic/elasticsearch/pull/17821">#17821</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add the shard&#8217;s store status to the explain API <ulink url="https://github.com/elastic/elasticsearch/pull/17689">#17689</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17372">#17372</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Write shard state metadata as soon as shard is created / initializing <ulink url="https://github.com/elastic/elasticsearch/pull/16625">#16625</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14739">#14739</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Reuse existing allocation id for primary shard allocation <ulink url="https://github.com/elastic/elasticsearch/pull/16530">#16530</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14739">#14739</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove version in ShardRouting (now obsolete) <ulink url="https://github.com/elastic/elasticsearch/pull/16243">#16243</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14739">#14739</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Prefer nodes that previously held primary shard for primary shard allocation <ulink url="https://github.com/elastic/elasticsearch/pull/16096">#16096</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14739">#14739</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Extend reroute with an option to force assign stale primary shard copies <ulink url="https://github.com/elastic/elasticsearch/pull/15708">#15708</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14739">#14739</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Allocate primary shards based on allocation IDs <ulink url="https://github.com/elastic/elasticsearch/pull/15281">#15281</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14739">#14739</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Persist currently started allocation IDs to index metadata <ulink url="https://github.com/elastic/elasticsearch/pull/14964">#14964</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14739">#14739</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Use ObjectParser to parse AllocationID <ulink url="https://github.com/elastic/elasticsearch/pull/14962">#14962</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14831">#14831</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Persist allocation ID with shard state metadata on nodes <ulink url="https://github.com/elastic/elasticsearch/pull/14831">#14831</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14739">#14739</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Analysis
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Stop using cached component in _analyze API <ulink url="https://github.com/elastic/elasticsearch/pull/19929">#19929</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19827">#19827</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Specify custom char_filters/tokenizer/token_filters in the analyze API <ulink url="https://github.com/elastic/elasticsearch/pull/15671">#15671</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/8878">#8878</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add a MultiTermAwareComponent marker interface to analysis factories. <ulink url="https://github.com/elastic/elasticsearch/pull/19028">#19028</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/18064">#18064</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/9978">#9978</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add Flags Parameter for Char Filter <ulink url="https://github.com/elastic/elasticsearch/pull/18363">#18363</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18362">#18362</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Core: better error message when analyzer created without tokenizer or… <ulink url="https://github.com/elastic/elasticsearch/pull/18455">#18455</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15492">#15492</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Move AsciiFolding earlier in FingerprintAnalyzer filter chain <ulink url="https://github.com/elastic/elasticsearch/pull/18281">#18281</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18266">#18266</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Improve error message if resource files have illegal encoding <ulink url="https://github.com/elastic/elasticsearch/pull/17237">#17237</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17212">#17212</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Benchmark
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add client-benchmark-noop-api-plugin to stress clients even more in benchmarks <ulink url="https://github.com/elastic/elasticsearch/pull/20103">#20103</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
CAT API
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add health status parameter to cat indices API <ulink url="https://github.com/elastic/elasticsearch/pull/20393">#20393</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Includes the index UUID in the _cat/indices API <ulink url="https://github.com/elastic/elasticsearch/pull/19204">#19204</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19132">#19132</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add node name to Cat Recovery <ulink url="https://github.com/elastic/elasticsearch/pull/18187">#18187</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/8041">#8041</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add support for documented byte/size units and for micros as a time unit in _cat API <ulink url="https://github.com/elastic/elasticsearch/pull/17779">#17779</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add _cat/tasks <ulink url="https://github.com/elastic/elasticsearch/pull/17551">#17551</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Cat health supports ts=0 option <ulink url="https://github.com/elastic/elasticsearch/pull/13508">#13508</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/10109">#10109</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Expose http address in cat/nodes <ulink url="https://github.com/elastic/elasticsearch/pull/16770">#16770</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
[cat/recovery] Make recovery time a TimeValue() <ulink url="https://github.com/elastic/elasticsearch/pull/16743">#16743</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/9209">#9209</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
:CAT API: remove space at the end of a line <ulink url="https://github.com/elastic/elasticsearch/pull/15250">#15250</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/9464">#9464</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
CRUD
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Renaming operation to result and reworking responses  <ulink url="https://github.com/elastic/elasticsearch/pull/19704">#19704</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19664">#19664</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Adding _operation field to index, update, delete response. <ulink url="https://github.com/elastic/elasticsearch/pull/19566">#19566</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/19267">#19267</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/9642">#9642</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/9736">#9736</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
CRUD: Allow to get and set ttl as a time value/string <ulink url="https://github.com/elastic/elasticsearch/pull/15047">#15047</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Cache
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Enable option to use request cache for size &gt; 0 <ulink url="https://github.com/elastic/elasticsearch/pull/19472">#19472</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Cache FieldStats in the request cache <ulink url="https://github.com/elastic/elasticsearch/pull/18768">#18768</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18717">#18717</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Allow the query cache to be disabled. <ulink url="https://github.com/elastic/elasticsearch/pull/16268">#16268</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15802">#15802</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Enable the indices request cache by default <ulink url="https://github.com/elastic/elasticsearch/pull/17162">#17162</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/16870">#16870</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/17134">#17134</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Circuit Breakers
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Cluster Settings Updates should not trigger circuit breakers. <ulink url="https://github.com/elastic/elasticsearch/pull/20827">#20827</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Circuit break the number of inline scripts compiled per minute <ulink url="https://github.com/elastic/elasticsearch/pull/19694">#19694</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19396">#19396</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Cluster
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add clusterUUID to RestMainAction output <ulink url="https://github.com/elastic/elasticsearch/pull/20503">#20503</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Batch process node left and node failure <ulink url="https://github.com/elastic/elasticsearch/pull/19289">#19289</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19282">#19282</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Index creation waits for write consistency shards <ulink url="https://github.com/elastic/elasticsearch/pull/18985">#18985</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Inline reroute with process of node join/master election <ulink url="https://github.com/elastic/elasticsearch/pull/18938">#18938</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17270">#17270</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Index creation does not cause the cluster health to go RED <ulink url="https://github.com/elastic/elasticsearch/pull/18737">#18737</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/9106">#9106</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/9126">#9126</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Cluster Health class improvements <ulink url="https://github.com/elastic/elasticsearch/pull/18673">#18673</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Adds tombstones to cluster state for index deletions <ulink url="https://github.com/elastic/elasticsearch/pull/17265">#17265</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/16358">#16358</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/17435">#17435</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Enable acked indexing <ulink url="https://github.com/elastic/elasticsearch/pull/17038">#17038</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/7572">#7572</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Cluster Health should run on applied states, even if waitFor=0 <ulink url="https://github.com/elastic/elasticsearch/pull/17440">#17440</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Resolve index names to Index instances early <ulink url="https://github.com/elastic/elasticsearch/pull/17048">#17048</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove DiscoveryNode#shouldConnectTo method <ulink url="https://github.com/elastic/elasticsearch/pull/16898">#16898</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16815">#16815</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fail demoted primary shards and retry request <ulink url="https://github.com/elastic/elasticsearch/pull/16415">#16415</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14252">#14252</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Illegal shard failure requests <ulink url="https://github.com/elastic/elasticsearch/pull/16275">#16275</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Shard failure requests for non-existent shards <ulink url="https://github.com/elastic/elasticsearch/pull/16089">#16089</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14252">#14252</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add handling of channel failures when starting a shard <ulink url="https://github.com/elastic/elasticsearch/pull/16041">#16041</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15895">#15895</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Wait for new master when failing shard <ulink url="https://github.com/elastic/elasticsearch/pull/15748">#15748</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14252">#14252</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Master should wait on cluster state publication when failing a shard <ulink url="https://github.com/elastic/elasticsearch/pull/15468">#15468</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14252">#14252</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Split cluster state update tasks into roles <ulink url="https://github.com/elastic/elasticsearch/pull/14899">#14899</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13627">#13627</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add timeout mechanism for sending shard failures <ulink url="https://github.com/elastic/elasticsearch/pull/14707">#14707</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14252">#14252</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add listener mechanism for failures to send shard failed <ulink url="https://github.com/elastic/elasticsearch/pull/14295">#14295</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14252">#14252</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Core
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add production warning for pre-release builds <ulink url="https://github.com/elastic/elasticsearch/pull/20674">#20674</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add serial collector bootstrap check <ulink url="https://github.com/elastic/elasticsearch/pull/20558">#20558</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Rename Netty TCP transports thread factories from http_* to transport_* <ulink url="https://github.com/elastic/elasticsearch/pull/20207">#20207</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Do not log full bootstrap checks exception <ulink url="https://github.com/elastic/elasticsearch/pull/19989">#19989</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Mark halting the virtual machine as privileged <ulink url="https://github.com/elastic/elasticsearch/pull/19923">#19923</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/19272">#19272</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/19806">#19806</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Makes index creation more friendly <ulink url="https://github.com/elastic/elasticsearch/pull/19450">#19450</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/9126">#9126</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Clearer error when handling fractional time values <ulink url="https://github.com/elastic/elasticsearch/pull/19158">#19158</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19102">#19102</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Read Elasticsearch manifest via URL <ulink url="https://github.com/elastic/elasticsearch/pull/18999">#18999</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18996">#18996</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Throw if the local node is not set <ulink url="https://github.com/elastic/elasticsearch/pull/18963">#18963</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18962">#18962</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Bootstrap check for OnOutOfMemoryError and seccomp <ulink url="https://github.com/elastic/elasticsearch/pull/18756">#18756</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18736">#18736</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Log OS and JVM on startup <ulink url="https://github.com/elastic/elasticsearch/pull/18557">#18557</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add GC overhead logging <ulink url="https://github.com/elastic/elasticsearch/pull/18419">#18419</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Refactor JvmGcMonitorService for testing <ulink url="https://github.com/elastic/elasticsearch/pull/18378">#18378</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Default to server VM and add client VM check <ulink url="https://github.com/elastic/elasticsearch/pull/18155">#18155</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add system bootstrap checks escape hatch <ulink url="https://github.com/elastic/elasticsearch/pull/18088">#18088</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Avoid sliced locked contention in internal engine <ulink url="https://github.com/elastic/elasticsearch/pull/18060">#18060</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18053">#18053</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add heap size bootstrap check <ulink url="https://github.com/elastic/elasticsearch/pull/17728">#17728</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17490">#17490</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove hostname from NetworkAddress.format <ulink url="https://github.com/elastic/elasticsearch/pull/17601">#17601</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17604">#17604</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Bootstrapping bootstrap checks <ulink url="https://github.com/elastic/elasticsearch/pull/17595">#17595</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/17474">#17474</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/17570">#17570</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add max map count check <ulink url="https://github.com/elastic/elasticsearch/pull/16944">#16944</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove PROTOTYPE from BulkItemResponse.Failure <ulink url="https://github.com/elastic/elasticsearch/pull/17433">#17433</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17086">#17086</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Throw an exception if Writeable.Reader reads null <ulink url="https://github.com/elastic/elasticsearch/pull/17332">#17332</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove PROTOTYPE from RescorerBuilders <ulink url="https://github.com/elastic/elasticsearch/pull/17330">#17330</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Port Primary Terms to master <ulink url="https://github.com/elastic/elasticsearch/pull/17044">#17044</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/14062">#14062</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/14651">#14651</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/17038">#17038</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Use index UUID to lookup indices on IndicesService <ulink url="https://github.com/elastic/elasticsearch/pull/17001">#17001</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add -XX+AlwaysPreTouch JVM flag <ulink url="https://github.com/elastic/elasticsearch/pull/16937">#16937</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add max size virtual memory check <ulink url="https://github.com/elastic/elasticsearch/pull/16935">#16935</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Use and test relative time in TransportBulkAction <ulink url="https://github.com/elastic/elasticsearch/pull/16916">#16916</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Bump Elasticsearch version to 5.0.0-SNAPSHOT <ulink url="https://github.com/elastic/elasticsearch/pull/16862">#16862</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Assert that we can write in all data-path on startup <ulink url="https://github.com/elastic/elasticsearch/pull/16745">#16745</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add G1GC check on startup <ulink url="https://github.com/elastic/elasticsearch/pull/16737">#16737</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/10740">#10740</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Shards with heavy indexing should get more of the indexing buffer <ulink url="https://github.com/elastic/elasticsearch/pull/14121">#14121</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove and ban ImmutableMap <ulink url="https://github.com/elastic/elasticsearch/pull/13939">#13939</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Finish banning ImmutableSet <ulink url="https://github.com/elastic/elasticsearch/pull/13820">#13820</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Removes and bans ImmutableSet <ulink url="https://github.com/elastic/elasticsearch/pull/13754">#13754</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove and ban ImmutableMap#entrySet <ulink url="https://github.com/elastic/elasticsearch/pull/13724">#13724</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Forbid ForwardingSet <ulink url="https://github.com/elastic/elasticsearch/pull/13720">#13720</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Dates
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Improve TimeZoneRoundingTests error messages <ulink url="https://github.com/elastic/elasticsearch/pull/18895">#18895</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Support full range of Java Long for epoch DateTime <ulink url="https://github.com/elastic/elasticsearch/pull/18509">#18509</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17936">#17936</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Discovery
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Do not log cluster service errors at after joining a master <ulink url="https://github.com/elastic/elasticsearch/pull/19705">#19705</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Log warning if minimum_master_nodes set to less than quorum <ulink url="https://github.com/elastic/elasticsearch/pull/15625">#15625</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add a dedicate queue for incoming ClusterStates <ulink url="https://github.com/elastic/elasticsearch/pull/13303">#13303</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13062">#13062</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Engine
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Only try to read new segments info if we really flushed the index <ulink url="https://github.com/elastic/elasticsearch/pull/20474">#20474</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Use _refresh instead of reading from Translog in the RT GET case <ulink url="https://github.com/elastic/elasticsearch/pull/20102">#20102</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove writeLockTimeout from InternalEngine <ulink url="https://github.com/elastic/elasticsearch/pull/16930">#16930</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Don&#8217;t guard IndexShard#refresh calls by a check to isRefreshNeeded <ulink url="https://github.com/elastic/elasticsearch/pull/16118">#16118</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Never call a listerner under lock in InternalEngine <ulink url="https://github.com/elastic/elasticsearch/pull/15786">#15786</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Use System.nanoTime() to initialize Engine.lastWriteNanos <ulink url="https://github.com/elastic/elasticsearch/pull/14321">#14321</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Flush big merges automatically if shard is inactive <ulink url="https://github.com/elastic/elasticsearch/pull/14275">#14275</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove Engine.Create <ulink url="https://github.com/elastic/elasticsearch/pull/13955">#13955</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove the disabled autogenerated id optimization from InternalEngine <ulink url="https://github.com/elastic/elasticsearch/pull/13857">#13857</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Exceptions
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Improve startup exception <ulink url="https://github.com/elastic/elasticsearch/pull/20083">#20083</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Make NotMasterException a first class citizen <ulink url="https://github.com/elastic/elasticsearch/pull/19385">#19385</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Do not catch throwable <ulink url="https://github.com/elastic/elasticsearch/pull/19231">#19231</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Make the index-too-old exception more explicit <ulink url="https://github.com/elastic/elasticsearch/pull/18438">#18438</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add index name in IndexAlreadyExistsException default message <ulink url="https://github.com/elastic/elasticsearch/pull/18274">#18274</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix typos in exception/assert/log messages in core module. <ulink url="https://github.com/elastic/elasticsearch/pull/16649">#16649</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add field names to several mapping errors <ulink url="https://github.com/elastic/elasticsearch/pull/16508">#16508</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16378">#16378</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add serialization support for more important IOExceptions <ulink url="https://github.com/elastic/elasticsearch/pull/15766">#15766</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Adds exception objects to log messages. <ulink url="https://github.com/elastic/elasticsearch/pull/14827">#14827</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/10021">#10021</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add stack traces to logged exceptions where missing <ulink url="https://github.com/elastic/elasticsearch/pull/13825">#13825</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/10021">#10021</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove reflection hacks from ElasticsearchException <ulink url="https://github.com/elastic/elasticsearch/pull/13796">#13796</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Rename QueryParsingException to a more generic ParsingException <ulink url="https://github.com/elastic/elasticsearch/pull/13631">#13631</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add *Exception(Throwable cause) constructors/ call where appropriate <ulink url="https://github.com/elastic/elasticsearch/pull/13544">#13544</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/10021">#10021</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Expressions
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
improve date api for expressions/painless fields <ulink url="https://github.com/elastic/elasticsearch/pull/18658">#18658</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Support geo_point fields in lucene expressions <ulink url="https://github.com/elastic/elasticsearch/pull/18096">#18096</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add support for .empty to expressions, and some docs improvements <ulink url="https://github.com/elastic/elasticsearch/pull/18077">#18077</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Geo
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
GeoBoundingBoxQueryBuilder should throw IAE when topLeft and bottomRight are the same coordinate <ulink url="https://github.com/elastic/elasticsearch/pull/18668">#18668</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/18458">#18458</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/18631">#18631</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Enhanced lat/long error handling <ulink url="https://github.com/elastic/elasticsearch/pull/16833">#16833</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16137">#16137</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix a potential parsing problem in GeoDistanceSortParser <ulink url="https://github.com/elastic/elasticsearch/pull/17111">#17111</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Geo: Add validation of shapes to ShapeBuilders <ulink url="https://github.com/elastic/elasticsearch/pull/15551">#15551</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14416">#14416</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make remaining ShapeBuilders implement Writeable <ulink url="https://github.com/elastic/elasticsearch/pull/15010">#15010</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14416">#14416</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Geo: Remove internal <literal>translated</literal> flag from LineStringBuilder <ulink url="https://github.com/elastic/elasticsearch/pull/14969">#14969</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Make PointBuilder, CircleBuilder &amp; EnvelopeBuilder implement Writable  <ulink url="https://github.com/elastic/elasticsearch/pull/14933">#14933</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14416">#14416</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Merging BaseLineString and BasePolygonBuilder with subclass <ulink url="https://github.com/elastic/elasticsearch/pull/14887">#14887</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14482">#14482</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Moving static factory methods to ShapeBuilders <ulink url="https://github.com/elastic/elasticsearch/pull/14529">#14529</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove InternalLineStringBuilder and InternalPolygonBuilder <ulink url="https://github.com/elastic/elasticsearch/pull/14482">#14482</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14416">#14416</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Highlighting
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Switch Highlighting to ObjectParser  <ulink url="https://github.com/elastic/elasticsearch/pull/17363">#17363</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Use HighlightBuilder in SearchSourceBuilder <ulink url="https://github.com/elastic/elasticsearch/pull/15376">#15376</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15044">#15044</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Joint parsing of common global Hightlighter and subfield parameters <ulink url="https://github.com/elastic/elasticsearch/pull/15368">#15368</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15285">#15285</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Enable HighlightBuilder to create SearchContextHighlight <ulink url="https://github.com/elastic/elasticsearch/pull/15324">#15324</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add fromXContent method to HighlightBuilder <ulink url="https://github.com/elastic/elasticsearch/pull/15157">#15157</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Index APIs
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add date-math support to <literal>_rollover</literal> <ulink url="https://github.com/elastic/elasticsearch/pull/20709">#20709</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add Shrink request source parser to parse create index request body <ulink url="https://github.com/elastic/elasticsearch/pull/18802">#18802</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fail hot_threads in a better way if unsupported by JDK <ulink url="https://github.com/elastic/elasticsearch/pull/15909">#15909</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Index Templates
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add "version" field to Templates <ulink url="https://github.com/elastic/elasticsearch/pull/20353">#20353</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20171">#20171</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Parse and validate mappings on index template creation <ulink url="https://github.com/elastic/elasticsearch/pull/8802">#8802</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/2415">#2415</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Ingest
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add "version" field to Pipelines <ulink url="https://github.com/elastic/elasticsearch/pull/20343">#20343</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20171">#20171</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make it possible for Ingest Processors to access AnalysisRegistry <ulink url="https://github.com/elastic/elasticsearch/pull/20233">#20233</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
add ignore_missing option to convert,trim,lowercase,uppercase,grok,rename <ulink url="https://github.com/elastic/elasticsearch/pull/20194">#20194</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19995">#19995</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add support for parameters to the script ingest processor <ulink url="https://github.com/elastic/elasticsearch/pull/20136">#20136</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
introduce the JSON Processor <ulink url="https://github.com/elastic/elasticsearch/pull/20128">#20128</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20052">#20052</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Allow rename processor to turn leaf fields into branch fields <ulink url="https://github.com/elastic/elasticsearch/pull/20053">#20053</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19892">#19892</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
remove ability to set field value in script-processor configuration <ulink url="https://github.com/elastic/elasticsearch/pull/19981">#19981</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add REST _ingest/pipeline to get all pipelines <ulink url="https://github.com/elastic/elasticsearch/pull/19603">#19603</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19585">#19585</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Show ignored errors in verbose simulate result <ulink url="https://github.com/elastic/elasticsearch/pull/19404">#19404</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19319">#19319</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
update foreach processor to only support one applied processor. <ulink url="https://github.com/elastic/elasticsearch/pull/19402">#19402</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19345">#19345</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Skip the execution of an empty pipeline <ulink url="https://github.com/elastic/elasticsearch/pull/19200">#19200</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19192">#19192</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add <literal>ignore_failure</literal> option to all ingest processors <ulink url="https://github.com/elastic/elasticsearch/pull/18650">#18650</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18493">#18493</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
new ScriptProcessor for Ingest <ulink url="https://github.com/elastic/elasticsearch/pull/18193">#18193</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Expose underlying processor to blame for thrown exception within CompoundProcessor <ulink url="https://github.com/elastic/elasticsearch/pull/18342">#18342</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17823">#17823</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Avoid string concatentation in IngestDocument.FieldPath <ulink url="https://github.com/elastic/elasticsearch/pull/18108">#18108</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
add ability to specify multiple grok patterns <ulink url="https://github.com/elastic/elasticsearch/pull/18074">#18074</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17903">#17903</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
add ability to disable ability to override values of existing fields in set processor <ulink url="https://github.com/elastic/elasticsearch/pull/17902">#17902</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17659">#17659</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Streamline option naming for several processors <ulink url="https://github.com/elastic/elasticsearch/pull/17892">#17892</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17835">#17835</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
add automatic type conversion support to ConvertProcessor <ulink url="https://github.com/elastic/elasticsearch/pull/17263">#17263</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17139">#17139</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Give the foreach processor access to the rest of the document <ulink url="https://github.com/elastic/elasticsearch/pull/17172">#17172</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17147">#17147</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Added ingest statistics to node stats API <ulink url="https://github.com/elastic/elasticsearch/pull/16915">#16915</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add <literal>ingest_took</literal> to bulk response <ulink url="https://github.com/elastic/elasticsearch/pull/16876">#16876</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add ingest info to node info API, which contains a list of available processors <ulink url="https://github.com/elastic/elasticsearch/pull/16865">#16865</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Use diffs for ingest metadata in cluster state <ulink url="https://github.com/elastic/elasticsearch/pull/16847">#16847</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
hide null-valued metadata fields from WriteableIngestDocument#toXContent <ulink url="https://github.com/elastic/elasticsearch/pull/16557">#16557</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Ingest: use bulk thread pool for bulk request processing (was index before) <ulink url="https://github.com/elastic/elasticsearch/pull/16539">#16539</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16503">#16503</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add foreach processor <ulink url="https://github.com/elastic/elasticsearch/pull/16432">#16432</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
revert PipelineFactoryError handling with throwing ElasticsearchParseException in ingest pipeline creation <ulink url="https://github.com/elastic/elasticsearch/pull/16355">#16355</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add processor tags to on_failure metadata in ingest pipeline <ulink url="https://github.com/elastic/elasticsearch/pull/16324">#16324</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16202">#16202</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
catch processor/pipeline factory exceptions and return structured error responses <ulink url="https://github.com/elastic/elasticsearch/pull/16276">#16276</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16010">#16010</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Ingest: move get/put/delete pipeline methods to ClusterAdminClient <ulink url="https://github.com/elastic/elasticsearch/pull/16242">#16242</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Geoip processor: remove redundant latitude and longitude fields and make location an object with lat and lon subfields <ulink url="https://github.com/elastic/elasticsearch/pull/16173">#16173</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Inner Hits
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Change scriptFields member in InnerHitBuilder to set <ulink url="https://github.com/elastic/elasticsearch/pull/18092">#18092</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/5831">#5831</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Internal
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove poor-mans compression in InternalSearchHit and friends <ulink url="https://github.com/elastic/elasticsearch/pull/20472">#20472</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Don&#8217;t register SearchTransportService handlers more than once <ulink url="https://github.com/elastic/elasticsearch/pull/20468">#20468</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Unguice SearchModule <ulink url="https://github.com/elastic/elasticsearch/pull/20456">#20456</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Deguice SearchService and friends <ulink url="https://github.com/elastic/elasticsearch/pull/20423">#20423</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
NodeStats classes to implement Writeable rather then Streamable <ulink url="https://github.com/elastic/elasticsearch/pull/20327">#20327</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
More info classes to implement Writeable rather than Streamable <ulink url="https://github.com/elastic/elasticsearch/pull/20288">#20288</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20255">#20255</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Internal: Split disk threshold monitoring from decider <ulink url="https://github.com/elastic/elasticsearch/pull/20018">#20018</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Switching LockObtainFailedException over to ShardLockObtainFailedException <ulink url="https://github.com/elastic/elasticsearch/pull/19991">#19991</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19978">#19978</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
update and delete by query requests to implement IndicesRequest.Replaceable <ulink url="https://github.com/elastic/elasticsearch/pull/19961">#19961</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
VersionFetchSubPhase should not use Versions#loadDocIdAndVersion <ulink url="https://github.com/elastic/elasticsearch/pull/19944">#19944</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove useless PK lookup in IndicesTTLService <ulink url="https://github.com/elastic/elasticsearch/pull/19945">#19945</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
ignore some docker craziness in seccomp environment checks <ulink url="https://github.com/elastic/elasticsearch/pull/19754">#19754</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Make Priority an enum <ulink url="https://github.com/elastic/elasticsearch/pull/19448">#19448</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Snapshot UUIDs in blob names <ulink url="https://github.com/elastic/elasticsearch/pull/19421">#19421</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/18156">#18156</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/18815">#18815</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/19002">#19002</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/7540">#7540</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add RestController method for deprecating in one step <ulink url="https://github.com/elastic/elasticsearch/pull/19343">#19343</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Tighten ensure atomic move cleanup <ulink url="https://github.com/elastic/elasticsearch/pull/19309">#19309</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19036">#19036</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Enable checkstyle ModifierOrder <ulink url="https://github.com/elastic/elasticsearch/pull/19214">#19214</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Expose task information from NodeClient <ulink url="https://github.com/elastic/elasticsearch/pull/19189">#19189</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Changed rest handler interface to take NodeClient <ulink url="https://github.com/elastic/elasticsearch/pull/19170">#19170</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Deprecate ExceptionsHelper.detailedMessage <ulink url="https://github.com/elastic/elasticsearch/pull/19160">#19160</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19069">#19069</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Factor out ChannelBuffer from BytesReference <ulink url="https://github.com/elastic/elasticsearch/pull/19129">#19129</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Cleanup Compressor interface <ulink url="https://github.com/elastic/elasticsearch/pull/19125">#19125</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Hot methods redux <ulink url="https://github.com/elastic/elasticsearch/pull/19016">#19016</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16725">#16725</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove forked joda time BaseDateTime class <ulink url="https://github.com/elastic/elasticsearch/pull/18953">#18953</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Support optional ctor args in ConstructingObjectParser <ulink url="https://github.com/elastic/elasticsearch/pull/18725">#18725</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove thread pool from page cache recycler <ulink url="https://github.com/elastic/elasticsearch/pull/18664">#18664</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18613">#18613</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Do not automatically close XContent objects/arrays <ulink url="https://github.com/elastic/elasticsearch/pull/18549">#18549</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18433">#18433</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove use of a Fields class in snapshot responses <ulink url="https://github.com/elastic/elasticsearch/pull/18497">#18497</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Removes multiple toXContent entry points for SnapshotInfo <ulink url="https://github.com/elastic/elasticsearch/pull/18494">#18494</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Removes unused methods in the o/e/common/Strings class <ulink url="https://github.com/elastic/elasticsearch/pull/18346">#18346</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Determine content length eagerly in HttpServer <ulink url="https://github.com/elastic/elasticsearch/pull/18203">#18203</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Consolidate query generation in QueryShardContext <ulink url="https://github.com/elastic/elasticsearch/pull/18129">#18129</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Make reset in QueryShardContext private <ulink url="https://github.com/elastic/elasticsearch/pull/18113">#18113</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove Strings#splitStringToArray <ulink url="https://github.com/elastic/elasticsearch/pull/18110">#18110</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add toString() to GetResponse <ulink url="https://github.com/elastic/elasticsearch/pull/18102">#18102</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
ConstructingObjectParser adapts ObjectParser for ctor args <ulink url="https://github.com/elastic/elasticsearch/pull/17596">#17596</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17352">#17352</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Makes Script type writeable <ulink url="https://github.com/elastic/elasticsearch/pull/17908">#17908</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17753">#17753</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
FiltersAggregatorBuilder: Don&#8217;t create new context for inner parsing <ulink url="https://github.com/elastic/elasticsearch/pull/17851">#17851</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Clean up serialization on some stats <ulink url="https://github.com/elastic/elasticsearch/pull/17832">#17832</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17085">#17085</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Normalize registration for SignificanceHeuristics <ulink url="https://github.com/elastic/elasticsearch/pull/17830">#17830</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17085">#17085</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make (read|write)NamedWriteable public <ulink url="https://github.com/elastic/elasticsearch/pull/17829">#17829</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17682">#17682</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Use try-with-resource when creating new parser instances where possible <ulink url="https://github.com/elastic/elasticsearch/pull/17822">#17822</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Don&#8217;t pass XContentParser to ParseFieldRegistry#lookup <ulink url="https://github.com/elastic/elasticsearch/pull/17794">#17794</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Internal: Remove threadlocal from document parser <ulink url="https://github.com/elastic/elasticsearch/pull/17764">#17764</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Cut range aggregations to registerAggregation <ulink url="https://github.com/elastic/elasticsearch/pull/17757">#17757</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17085">#17085</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove ParseFieldMatcher from AbstractXContentParser <ulink url="https://github.com/elastic/elasticsearch/pull/17756">#17756</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17417">#17417</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove parser argument from methods where we already pass in a parse context <ulink url="https://github.com/elastic/elasticsearch/pull/17738">#17738</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Switch SearchAfterBuilder to writeGenericValue <ulink url="https://github.com/elastic/elasticsearch/pull/17735">#17735</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17085">#17085</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove StreamableReader <ulink url="https://github.com/elastic/elasticsearch/pull/17729">#17729</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17085">#17085</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Cleanup nested, has_child &amp; has_parent query builders for inner hits construction <ulink url="https://github.com/elastic/elasticsearch/pull/17719">#17719</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/11118">#11118</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make AllocationCommands NamedWriteables <ulink url="https://github.com/elastic/elasticsearch/pull/17661">#17661</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Isolate StreamableReader <ulink url="https://github.com/elastic/elasticsearch/pull/17656">#17656</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17085">#17085</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Create registration methods for aggregations similar to those for queries <ulink url="https://github.com/elastic/elasticsearch/pull/17653">#17653</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/17085">#17085</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/17389">#17389</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove PROTOTYPEs from QueryBuilders <ulink url="https://github.com/elastic/elasticsearch/pull/17632">#17632</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17085">#17085</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove registerQueryParser <ulink url="https://github.com/elastic/elasticsearch/pull/17608">#17608</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
ParseField#getAllNamesIncludedDeprecated to not return duplicate names <ulink url="https://github.com/elastic/elasticsearch/pull/17504">#17504</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Rework a query parser and improve registration <ulink url="https://github.com/elastic/elasticsearch/pull/17458">#17458</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Clean up QueryParseContext and don&#8217;t hold it inside QueryRewrite/ShardContext <ulink url="https://github.com/elastic/elasticsearch/pull/17417">#17417</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove PROTOTYPE from MLT.Item <ulink url="https://github.com/elastic/elasticsearch/pull/17481">#17481</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17085">#17085</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove PROTOTYPE from VersionType <ulink url="https://github.com/elastic/elasticsearch/pull/17480">#17480</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17085">#17085</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove PROTOTYPEs from highlighting <ulink url="https://github.com/elastic/elasticsearch/pull/17466">#17466</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17085">#17085</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove PROTOTYPEs from ingest <ulink url="https://github.com/elastic/elasticsearch/pull/17434">#17434</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17085">#17085</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Start to rework query registration <ulink url="https://github.com/elastic/elasticsearch/pull/17424">#17424</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Factor out slow logs into Search and IndexingOperationListeners <ulink url="https://github.com/elastic/elasticsearch/pull/17398">#17398</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove PROTOTYPE from Suggesters <ulink url="https://github.com/elastic/elasticsearch/pull/17370">#17370</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove PROTOTYPE from SortBuilders <ulink url="https://github.com/elastic/elasticsearch/pull/17337">#17337</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17085">#17085</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove PROTOTYPE from ShapeBuilders <ulink url="https://github.com/elastic/elasticsearch/pull/17336">#17336</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17085">#17085</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Replace FieldStatsProvider with a method on MappedFieldType. <ulink url="https://github.com/elastic/elasticsearch/pull/17334">#17334</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Stop using PROTOTYPE in NamedWriteableRegistry <ulink url="https://github.com/elastic/elasticsearch/pull/17284">#17284</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17085">#17085</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Support scheduled commands in current context <ulink url="https://github.com/elastic/elasticsearch/pull/17077">#17077</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Thread limits <ulink url="https://github.com/elastic/elasticsearch/pull/17003">#17003</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove leniency from segments info integrity checks <ulink url="https://github.com/elastic/elasticsearch/pull/16985">#16985</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16973">#16973</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Rename SearchServiceTransportAction to SearchTransportService <ulink url="https://github.com/elastic/elasticsearch/pull/16880">#16880</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Decouple the TransportService and ClusterService <ulink url="https://github.com/elastic/elasticsearch/pull/16872">#16872</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16788">#16788</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Refactor bootstrap checks <ulink url="https://github.com/elastic/elasticsearch/pull/16844">#16844</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/16733">#16733</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/16835">#16835</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add LifecycleRunnable <ulink url="https://github.com/elastic/elasticsearch/pull/16752">#16752</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Hot inlined methods in your area <ulink url="https://github.com/elastic/elasticsearch/pull/16725">#16725</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Move IndicesQueryCache and IndicesRequestCache into IndicesService <ulink url="https://github.com/elastic/elasticsearch/pull/16603">#16603</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Forbid use of java.security.MessageDigest#clone() <ulink url="https://github.com/elastic/elasticsearch/pull/16543">#16543</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16479">#16479</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make IndicesWarmer a private class of IndexService <ulink url="https://github.com/elastic/elasticsearch/pull/16470">#16470</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Simplify IndicesFieldDataCache and detach from guice <ulink url="https://github.com/elastic/elasticsearch/pull/16469">#16469</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Uppercase ells (<emphasis>L</emphasis>) in long literals <ulink url="https://github.com/elastic/elasticsearch/pull/16329">#16329</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16279">#16279</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
ShardId equality and hash code inconsistency <ulink url="https://github.com/elastic/elasticsearch/pull/16319">#16319</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16217">#16217</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Ensure all resources are closed on Node#close() <ulink url="https://github.com/elastic/elasticsearch/pull/16316">#16316</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13685">#13685</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make index uuid available in Index, ShardRouting &amp; ShardId <ulink url="https://github.com/elastic/elasticsearch/pull/16217">#16217</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Move RefreshTask into IndexService and use since task per index <ulink url="https://github.com/elastic/elasticsearch/pull/15933">#15933</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Make IndexingMemoryController private to IndicesService <ulink url="https://github.com/elastic/elasticsearch/pull/15877">#15877</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Cleanup IndexingOperationListeners infrastructure <ulink url="https://github.com/elastic/elasticsearch/pull/15875">#15875</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove and forbid use of j.u.c.ThreadLocalRandom <ulink url="https://github.com/elastic/elasticsearch/pull/15862">#15862</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15294">#15294</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix IntelliJ query builder type inference issues <ulink url="https://github.com/elastic/elasticsearch/pull/15429">#15429</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove and forbid use of Collections#shuffle(List) and Random#&lt;init&gt;() <ulink url="https://github.com/elastic/elasticsearch/pull/15299">#15299</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15287">#15287</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove and forbid use of the type-unsafe empty Collections fields <ulink url="https://github.com/elastic/elasticsearch/pull/15187">#15187</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Move IndicesService.canDeleteShardContent to use IndexSettings <ulink url="https://github.com/elastic/elasticsearch/pull/15150">#15150</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15059">#15059</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Simplify MonitorService construction and detach from guice <ulink url="https://github.com/elastic/elasticsearch/pull/15035">#15035</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Use Supplier for StreamInput#readOptionalStreamable <ulink url="https://github.com/elastic/elasticsearch/pull/14806">#14806</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add variable-length long encoding <ulink url="https://github.com/elastic/elasticsearch/pull/14780">#14780</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Extend usage of IndexSetting class <ulink url="https://github.com/elastic/elasticsearch/pull/14731">#14731</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14251">#14251</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fold SimilarityModule into IndexModule <ulink url="https://github.com/elastic/elasticsearch/pull/14284">#14284</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Move to lucene BoostQuery <ulink url="https://github.com/elastic/elasticsearch/pull/14264">#14264</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Use built-in method for computing hash code of longs <ulink url="https://github.com/elastic/elasticsearch/pull/14213">#14213</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Refactor ShardFailure listener infrastructure <ulink url="https://github.com/elastic/elasticsearch/pull/14206">#14206</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add methods for variable-length encoding integral arrays <ulink url="https://github.com/elastic/elasticsearch/pull/14087">#14087</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fold IndexAliasesService into IndexService <ulink url="https://github.com/elastic/elasticsearch/pull/14044">#14044</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove unneeded Module abstractions <ulink url="https://github.com/elastic/elasticsearch/pull/13944">#13944</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Query refactoring: simplify IndexQueryParserService parse methods <ulink url="https://github.com/elastic/elasticsearch/pull/13938">#13938</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13859">#13859</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove and forbid use of com.google.common.collect.Iterators <ulink url="https://github.com/elastic/elasticsearch/pull/13916">#13916</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove and forbid use of com.google.common.collect.ImmutableCollection <ulink url="https://github.com/elastic/elasticsearch/pull/13909">#13909</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove and forbid use of com.google.common.io.Resources <ulink url="https://github.com/elastic/elasticsearch/pull/13908">#13908</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove and forbid use of com.google.common.hash.* <ulink url="https://github.com/elastic/elasticsearch/pull/13907">#13907</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove and forbid use of com.google.common.net.InetAddresses <ulink url="https://github.com/elastic/elasticsearch/pull/13905">#13905</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove and forbid use of com.google.common.collect.EvictingQueue <ulink url="https://github.com/elastic/elasticsearch/pull/13903">#13903</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Replace Guava cache with simple concurrent LRU cache <ulink url="https://github.com/elastic/elasticsearch/pull/13879">#13879</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove ClusterSerivce and IndexSettingsService dependency from IndexShard <ulink url="https://github.com/elastic/elasticsearch/pull/13853">#13853</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Start making RecoverySourceHandler unittestable <ulink url="https://github.com/elastic/elasticsearch/pull/13840">#13840</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove IndexService dep. from IndexShard <ulink url="https://github.com/elastic/elasticsearch/pull/13797">#13797</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove ES internal deletion policies in favour of Lucenes implementations <ulink url="https://github.com/elastic/elasticsearch/pull/13794">#13794</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Move ShardTermVectorService to be on indices level as TermVectorService <ulink url="https://github.com/elastic/elasticsearch/pull/13786">#13786</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Move ShardPercolateService creation into IndexShard <ulink url="https://github.com/elastic/elasticsearch/pull/13777">#13777</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove <literal>ExpressionScriptCompilationException</literal> and <literal>ExpressionScriptExecutionException</literal> <ulink url="https://github.com/elastic/elasticsearch/pull/13742">#13742</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Reduced the number of ClusterStateUpdateTask variants <ulink url="https://github.com/elastic/elasticsearch/pull/13735">#13735</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add a BaseParser helper for stream parsing <ulink url="https://github.com/elastic/elasticsearch/pull/13615">#13615</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove and forbid use of com.google.common.primitives.Ints <ulink url="https://github.com/elastic/elasticsearch/pull/13596">#13596</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove and forbid use of com.google.common.math.LongMath <ulink url="https://github.com/elastic/elasticsearch/pull/13575">#13575</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove and forbid use of com.google.common.base.Joiner <ulink url="https://github.com/elastic/elasticsearch/pull/13572">#13572</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Replace and ban next batch of Guava classes <ulink url="https://github.com/elastic/elasticsearch/pull/13562">#13562</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove and forbid use of com.google.common.collect.Iterables <ulink url="https://github.com/elastic/elasticsearch/pull/13559">#13559</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Replace LoadingCache usage with a simple ConcurrentHashMap <ulink url="https://github.com/elastic/elasticsearch/pull/13552">#13552</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Use Supplier instead of Reflection <ulink url="https://github.com/elastic/elasticsearch/pull/13545">#13545</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove and forbid use of com.google.common.base.Preconditions <ulink url="https://github.com/elastic/elasticsearch/pull/13540">#13540</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove and forbid use of guava Function, Charsets, Collections2 <ulink url="https://github.com/elastic/elasticsearch/pull/13533">#13533</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove and forbid use of com.google.common.collect.ImmutableSortedMap <ulink url="https://github.com/elastic/elasticsearch/pull/13525">#13525</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove and forbid use of several com.google.common.util. classes <ulink url="https://github.com/elastic/elasticsearch/pull/13524">#13524</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Cleanup SearchRequest &amp; SearchRequestBuilder <ulink url="https://github.com/elastic/elasticsearch/pull/13518">#13518</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove and forbid use of com.google.common.collect.Queues <ulink url="https://github.com/elastic/elasticsearch/pull/13498">#13498</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove and forbid use of com.google.common.base.Preconditions#checkNotNull <ulink url="https://github.com/elastic/elasticsearch/pull/13493">#13493</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove and forbid use of com.google.common.collect.Sets <ulink url="https://github.com/elastic/elasticsearch/pull/13463">#13463</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove and forbid use of com.google.common.collect.Maps <ulink url="https://github.com/elastic/elasticsearch/pull/13438">#13438</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove use of underscore as an identifier <ulink url="https://github.com/elastic/elasticsearch/pull/13353">#13353</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove and forbid the use of com.google.common.base.Predicate(s)? <ulink url="https://github.com/elastic/elasticsearch/pull/13349">#13349</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/13314">#13314</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
This commit removes com.google.common.io <ulink url="https://github.com/elastic/elasticsearch/pull/13302">#13302</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Java API
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Ensure PutMappingRequest.buildFromSimplifiedDef input are pairs <ulink url="https://github.com/elastic/elasticsearch/pull/19837">#19837</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19836">#19836</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Start from a random node number so that clients do not overload the first node configured <ulink url="https://github.com/elastic/elasticsearch/pull/14143">#14143</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Switch QueryBuilders to new MatchPhraseQueryBuilder <ulink url="https://github.com/elastic/elasticsearch/pull/18753">#18753</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Improve adding clauses to <literal>span_near</literal> and <literal>span_or</literal> query <ulink url="https://github.com/elastic/elasticsearch/pull/18485">#18485</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18478">#18478</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
QueryBuilder does not need generics. <ulink url="https://github.com/elastic/elasticsearch/pull/18133">#18133</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove copy constructors from request classes and TransportMessage type <ulink url="https://github.com/elastic/elasticsearch/pull/16640">#16640</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15776">#15776</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Java REST Client
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add support for a RestClient path prefix <ulink url="https://github.com/elastic/elasticsearch/pull/20190">#20190</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add "Async" to the end of each Async RestClient method <ulink url="https://github.com/elastic/elasticsearch/pull/20172">#20172</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20168">#20168</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Allow RestClient to send array-based headers <ulink url="https://github.com/elastic/elasticsearch/pull/20151">#20151</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add response body to ResponseException error message <ulink url="https://github.com/elastic/elasticsearch/pull/19653">#19653</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19653">#19653</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Simplify Sniffer initialization and automatically create the default HostsSniffer <ulink url="https://github.com/elastic/elasticsearch/pull/19599">#19599</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove duplicate dependency declaration for http client <ulink url="https://github.com/elastic/elasticsearch/pull/19580">#19580</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19281">#19281</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add callback to customize http client settings <ulink url="https://github.com/elastic/elasticsearch/pull/19373">#19373</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Rest Client: add short performRequest method variants without params and/or body <ulink url="https://github.com/elastic/elasticsearch/pull/19340">#19340</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19312">#19312</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Logging
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Ensure logging is initialized in CLI tools <ulink url="https://github.com/elastic/elasticsearch/pull/20575">#20575</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Give useful error message if log config is missing <ulink url="https://github.com/elastic/elasticsearch/pull/20493">#20493</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Complete Elasticsearch logger names <ulink url="https://github.com/elastic/elasticsearch/pull/20457">#20457</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20326">#20326</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add node name to decider trace logging  <ulink url="https://github.com/elastic/elasticsearch/pull/20437">#20437</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20379">#20379</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Logging shutdown hack <ulink url="https://github.com/elastic/elasticsearch/pull/20389">#20389</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20304">#20304</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Disable console logging <ulink url="https://github.com/elastic/elasticsearch/pull/20387">#20387</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Skip loading of jansi from log4j2 <ulink url="https://github.com/elastic/elasticsearch/pull/20334">#20334</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Configure AWS SDK logging configuration <ulink url="https://github.com/elastic/elasticsearch/pull/20313">#20313</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20294">#20294</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Warn if unsupported logging configuration present <ulink url="https://github.com/elastic/elasticsearch/pull/20309">#20309</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Size limit deprecation logs <ulink url="https://github.com/elastic/elasticsearch/pull/20287">#20287</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/20235">#20235</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/20254">#20254</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Increase visibility of deprecation logger <ulink url="https://github.com/elastic/elasticsearch/pull/20254">#20254</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/11033">#11033</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add log message about enforcing bootstrap checks <ulink url="https://github.com/elastic/elasticsearch/pull/19451">#19451</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Improve logging for batched cluster state updates <ulink url="https://github.com/elastic/elasticsearch/pull/19255">#19255</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Send HTTP Warning Header(s) for any Deprecation Usage from a REST request <ulink url="https://github.com/elastic/elasticsearch/pull/17804">#17804</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17687">#17687</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Throw IllegalStateException when handshake fails due to version or cluster mismatch <ulink url="https://github.com/elastic/elasticsearch/pull/18676">#18676</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Mapping
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Automatically downgrade text and keyword to string on indexes imported from 2.x <ulink url="https://github.com/elastic/elasticsearch/pull/20177">#20177</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Do not parse numbers as both strings and numbers when not included in <literal>_all</literal>. <ulink url="https://github.com/elastic/elasticsearch/pull/20167">#20167</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Don&#8217;t index the <literal>_version</literal> field <ulink url="https://github.com/elastic/elasticsearch/pull/20132">#20132</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
The root object mapper should support updating <literal>numeric_detection</literal>, <literal>date_detection</literal> and <literal>dynamic_date_formats</literal>. <ulink url="https://github.com/elastic/elasticsearch/pull/20119">#20119</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20111">#20111</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Automatically upgrade analyzed string fields that have <literal>index_options</literal> or <literal>position_increment_gap</literal> set. <ulink url="https://github.com/elastic/elasticsearch/pull/20002">#20002</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19974">#19974</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Mappings: Support dots in field names in mapping parsing <ulink url="https://github.com/elastic/elasticsearch/pull/19899">#19899</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19443">#19443</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Save one utf8 conversion in KeywordFieldMapper. <ulink url="https://github.com/elastic/elasticsearch/pull/19867">#19867</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Do not parse the created version from the settings every time a field is parsed. <ulink url="https://github.com/elastic/elasticsearch/pull/19824">#19824</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Elasticsearch should reject dynamic templates with unknown <literal>match_mapping_type</literal>. <ulink url="https://github.com/elastic/elasticsearch/pull/17285">#17285</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16945">#16945</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Upgrade <literal>string</literal> fields to <literal>text</literal>/<literal>keyword</literal> even if <literal>include_in_all</literal> is set. <ulink url="https://github.com/elastic/elasticsearch/pull/19004">#19004</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18974">#18974</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Adds a methods to find (and dynamically create) the mappers for the parents of a field with dots in the field name <ulink url="https://github.com/elastic/elasticsearch/pull/18106">#18106</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15951">#15951</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Automatically upgrade analyzed strings with an analyzer to <literal>text</literal>. <ulink url="https://github.com/elastic/elasticsearch/pull/17861">#17861</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Support dots in field names when mapping already exists <ulink url="https://github.com/elastic/elasticsearch/pull/17759">#17759</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15951">#15951</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Use the new points API to index numeric fields. <ulink url="https://github.com/elastic/elasticsearch/pull/17746">#17746</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/11513">#11513</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/16751">#16751</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/17007">#17007</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/17700">#17700</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Simplify AllEntries, AllField and AllFieldMapper: <ulink url="https://github.com/elastic/elasticsearch/pull/17613">#17613</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Make <literal>parseMultiField</literal> part of <literal>parseField</literal>. <ulink url="https://github.com/elastic/elasticsearch/pull/17313">#17313</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Automatically add a sub keyword field to string dynamic mappings. <ulink url="https://github.com/elastic/elasticsearch/pull/17188">#17188</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove friction from the mapping changes in 5.0. <ulink url="https://github.com/elastic/elasticsearch/pull/16991">#16991</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Rework norms parameters for 5.0. <ulink url="https://github.com/elastic/elasticsearch/pull/16987">#16987</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Moved dynamic field handling in doc parsing to end of parsing <ulink url="https://github.com/elastic/elasticsearch/pull/16798">#16798</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove the MapperBuilders utility class. <ulink url="https://github.com/elastic/elasticsearch/pull/16609">#16609</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Make the <literal>index</literal> property a boolean. <ulink url="https://github.com/elastic/elasticsearch/pull/16161">#16161</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove the ability to enable doc values with the <literal>fielddata.format</literal> setting. <ulink url="https://github.com/elastic/elasticsearch/pull/16147">#16147</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Be stricter about parsing boolean values in mappings. <ulink url="https://github.com/elastic/elasticsearch/pull/16146">#16146</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix default doc values to be enabled when a field is not indexed. <ulink url="https://github.com/elastic/elasticsearch/pull/16141">#16141</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Dynamically map floating-point numbers as floats instead of doubles. <ulink url="https://github.com/elastic/elasticsearch/pull/15319">#15319</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13851">#13851</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Simplify MetaDataMappingService. <ulink url="https://github.com/elastic/elasticsearch/pull/15217">#15217</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove MergeMappingException. <ulink url="https://github.com/elastic/elasticsearch/pull/15177">#15177</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Network
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Avoid early initializing Netty <ulink url="https://github.com/elastic/elasticsearch/pull/19819">#19819</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/5644">#5644</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Network: Allow to listen on virtual interfaces. <ulink url="https://github.com/elastic/elasticsearch/pull/19568">#19568</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/17473">#17473</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/19537">#19537</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Explicitly tell Netty to not use unsafe <ulink url="https://github.com/elastic/elasticsearch/pull/19786">#19786</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/19562">#19562</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/5624">#5624</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Enable Netty 4 extensions <ulink url="https://github.com/elastic/elasticsearch/pull/19767">#19767</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19526">#19526</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Modularize netty <ulink url="https://github.com/elastic/elasticsearch/pull/19392">#19392</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Simplify TcpTransport interface by reducing send code to a single send method <ulink url="https://github.com/elastic/elasticsearch/pull/19223">#19223</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Do not start scheduled pings until transport start <ulink url="https://github.com/elastic/elasticsearch/pull/18702">#18702</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Packaging
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add quiet option to disable console logging <ulink url="https://github.com/elastic/elasticsearch/pull/20422">#20422</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/15315">#15315</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/16159">#16159</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/17220">#17220</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Explicitly disable Netty key set replacement <ulink url="https://github.com/elastic/elasticsearch/pull/20249">#20249</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove explicit parallel new GC flag <ulink url="https://github.com/elastic/elasticsearch/pull/18767">#18767</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Use JAVA_HOME or java.exe in PATH like the Linux scripts do <ulink url="https://github.com/elastic/elasticsearch/pull/18685">#18685</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/4913">#4913</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Don&#8217;t mkdir directly in deb init script <ulink url="https://github.com/elastic/elasticsearch/pull/18503">#18503</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18307">#18307</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Increase default heap size to 2g <ulink url="https://github.com/elastic/elasticsearch/pull/18311">#18311</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/16334">#16334</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/17686">#17686</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/18309">#18309</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Switch init.d scripts to use bash <ulink url="https://github.com/elastic/elasticsearch/pull/18308">#18308</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18259">#18259</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Switch scripts to use bash <ulink url="https://github.com/elastic/elasticsearch/pull/18251">#18251</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14002">#14002</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Further simplifications of plugin script <ulink url="https://github.com/elastic/elasticsearch/pull/18239">#18239</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18207">#18207</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Pass ES_JAVA_OPTS to JVM for plugins script <ulink url="https://github.com/elastic/elasticsearch/pull/18140">#18140</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16790">#16790</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove unnecessary sleep from init script restart <ulink url="https://github.com/elastic/elasticsearch/pull/17966">#17966</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Explicitly set packaging permissions <ulink url="https://github.com/elastic/elasticsearch/pull/17912">#17912</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17634">#17634</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
rpm uses non-portable <literal>--system</literal> flag to <literal>useradd</literal> <ulink url="https://github.com/elastic/elasticsearch/pull/14596">#14596</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14211">#14211</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Adding JAVA_HOME to documents and env config file <ulink url="https://github.com/elastic/elasticsearch/pull/11338">#11338</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/11291">#11291</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Added RPM metadata <ulink url="https://github.com/elastic/elasticsearch/pull/17477">#17477</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Elasticsearch ownership for data, logs, and configs <ulink url="https://github.com/elastic/elasticsearch/pull/17197">#17197</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/12688">#12688</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fail early on JDK with compiler bug <ulink url="https://github.com/elastic/elasticsearch/pull/16418">#16418</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/16097">#16097</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/16362">#16362</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make security non-optional <ulink url="https://github.com/elastic/elasticsearch/pull/16176">#16176</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove RuntimePermission("accessDeclaredMembers") <ulink url="https://github.com/elastic/elasticsearch/pull/15378">#15378</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove Guava as a dependency <ulink url="https://github.com/elastic/elasticsearch/pull/14055">#14055</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove Guava as a dependency <ulink url="https://github.com/elastic/elasticsearch/pull/14054">#14054</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Percolator
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Also support query term extract for queries wrapped inside a FunctionScoreQuery <ulink url="https://github.com/elastic/elasticsearch/pull/19184">#19184</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add support for synonym query to percolator query term extraction <ulink url="https://github.com/elastic/elasticsearch/pull/19066">#19066</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add percolator query extraction support for dismax query <ulink url="https://github.com/elastic/elasticsearch/pull/18845">#18845</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Improve percolate query performance by not verifying certain candidate matches <ulink url="https://github.com/elastic/elasticsearch/pull/18696">#18696</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Improve percolator query term extraction <ulink url="https://github.com/elastic/elasticsearch/pull/18610">#18610</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
PercolatorQueryBuilder cleanup by using MemoryIndex#fromDocument(&#8230;) helper <ulink url="https://github.com/elastic/elasticsearch/pull/17669">#17669</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/9386">#9386</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add scoring support to the percolator query <ulink url="https://github.com/elastic/elasticsearch/pull/17385">#17385</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13827">#13827</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add query extract support for the blended term query and the common terms query <ulink url="https://github.com/elastic/elasticsearch/pull/17347">#17347</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add support for several span queries in ExtractQueryTermsService <ulink url="https://github.com/elastic/elasticsearch/pull/17323">#17323</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add support for TermsQuery in ExtractQueryTermsService <ulink url="https://github.com/elastic/elasticsearch/pull/17316">#17316</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Replace percolate APIs with a percolator query <ulink url="https://github.com/elastic/elasticsearch/pull/16349">#16349</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/10741">#10741</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/11264">#11264</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/13176">#13176</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/13978">#13978</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/4317">#4317</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/7297">#7297</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Analysis Kuromoji
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add nbest options and NumberFilter <ulink url="https://github.com/elastic/elasticsearch/pull/17173">#17173</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Discovery EC2
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Use <literal>DefaultAWSCredentialsProviderChain</literal> AWS SDK class for credentials <ulink url="https://github.com/elastic/elasticsearch/pull/19561">#19561</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19556">#19556</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Support new Asia Pacific (Mumbai) ap-south-1 AWS region <ulink url="https://github.com/elastic/elasticsearch/pull/19112">#19112</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19110">#19110</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add support for proxy authentication for s3 and ec2 <ulink url="https://github.com/elastic/elasticsearch/pull/15293">#15293</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15268">#15268</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Discovery GCE
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Allow <literal>_gce_</literal> network when not using discovery gce <ulink url="https://github.com/elastic/elasticsearch/pull/15765">#15765</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15724">#15724</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Ingest Attachment
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Minor attachment processor improvements <ulink url="https://github.com/elastic/elasticsearch/pull/16574">#16574</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Lang Painless
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Disable regexes by default in painless <ulink url="https://github.com/elastic/elasticsearch/pull/20427">#20427</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20397">#20397</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Catch OutOfMemory and StackOverflow errors in Painless <ulink url="https://github.com/elastic/elasticsearch/pull/19936">#19936</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Change Painless Tree Structure for Variable/Method Chains <ulink url="https://github.com/elastic/elasticsearch/pull/19459">#19459</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add replaceAll and replaceFirst <ulink url="https://github.com/elastic/elasticsearch/pull/19070">#19070</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Painless Initializers <ulink url="https://github.com/elastic/elasticsearch/pull/19012">#19012</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add augmentation <ulink url="https://github.com/elastic/elasticsearch/pull/19003">#19003</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Infer lambda arguments/return type <ulink url="https://github.com/elastic/elasticsearch/pull/18983">#18983</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix explicit casts and improve tests. <ulink url="https://github.com/elastic/elasticsearch/pull/18958">#18958</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add lambda captures <ulink url="https://github.com/elastic/elasticsearch/pull/18954">#18954</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
improve Debugger to print code even if it hits exception <ulink url="https://github.com/elastic/elasticsearch/pull/18932">#18932</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/1">#1</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Move semicolon hack into lexer <ulink url="https://github.com/elastic/elasticsearch/pull/18931">#18931</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add flag support to regexes <ulink url="https://github.com/elastic/elasticsearch/pull/18927">#18927</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
improve lambda syntax (allow single expression) <ulink url="https://github.com/elastic/elasticsearch/pull/18924">#18924</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove useless dropArguments in megamorphic cache <ulink url="https://github.com/elastic/elasticsearch/pull/18913">#18913</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
non-capturing lambda support <ulink url="https://github.com/elastic/elasticsearch/pull/18911">#18911</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18824">#18824</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
fix bugs in operators and more improvements for the dynamic case <ulink url="https://github.com/elastic/elasticsearch/pull/18899">#18899</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
improve unary operators and cleanup tests <ulink url="https://github.com/elastic/elasticsearch/pull/18867">#18867</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18849">#18849</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add support for the find operator (=<subscript>) and the match operator (==</subscript>) <ulink url="https://github.com/elastic/elasticsearch/pull/18858">#18858</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove casts and boxing for dynamic math <ulink url="https://github.com/elastic/elasticsearch/pull/18849">#18849</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18847">#18847</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Refactor def math <ulink url="https://github.com/elastic/elasticsearch/pull/18847">#18847</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add support for /regex/ <ulink url="https://github.com/elastic/elasticsearch/pull/18842">#18842</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Array constructor references <ulink url="https://github.com/elastic/elasticsearch/pull/18831">#18831</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Method references to user functions <ulink url="https://github.com/elastic/elasticsearch/pull/18828">#18828</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add } as a delimiter.  <ulink url="https://github.com/elastic/elasticsearch/pull/18827">#18827</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18821">#18821</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add Lambda Stub Node <ulink url="https://github.com/elastic/elasticsearch/pull/18824">#18824</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add capturing method references <ulink url="https://github.com/elastic/elasticsearch/pull/18818">#18818</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18748">#18748</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add Functions to Painless <ulink url="https://github.com/elastic/elasticsearch/pull/18810">#18810</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add Method to Get New MethodWriters <ulink url="https://github.com/elastic/elasticsearch/pull/18771">#18771</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Static For Each <ulink url="https://github.com/elastic/elasticsearch/pull/18757">#18757</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Method reference support <ulink url="https://github.com/elastic/elasticsearch/pull/18748">#18748</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18578">#18578</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add support for the new Java 9 MethodHandles#arrayLength() factory <ulink url="https://github.com/elastic/elasticsearch/pull/18734">#18734</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Improve painless compile-time exceptions <ulink url="https://github.com/elastic/elasticsearch/pull/18711">#18711</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18600">#18600</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
add java.time packages to painless whitelist <ulink url="https://github.com/elastic/elasticsearch/pull/18621">#18621</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add Function Reference Stub to Painless <ulink url="https://github.com/elastic/elasticsearch/pull/18578">#18578</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
improve painless whitelist coverage of java api <ulink url="https://github.com/elastic/elasticsearch/pull/18533">#18533</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Definition cleanup <ulink url="https://github.com/elastic/elasticsearch/pull/18463">#18463</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Made def variable casting consistent with invokedynamic rules <ulink url="https://github.com/elastic/elasticsearch/pull/18425">#18425</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Use Java 9 Indy String Concats, if available <ulink url="https://github.com/elastic/elasticsearch/pull/18400">#18400</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18398">#18398</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add method overloading based on arity <ulink url="https://github.com/elastic/elasticsearch/pull/18385">#18385</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Refactor WriterUtils to extend ASM GeneratorAdapter <ulink url="https://github.com/elastic/elasticsearch/pull/18382">#18382</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Whitelist expansion <ulink url="https://github.com/elastic/elasticsearch/pull/18372">#18372</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove boxing when loading and storing values in "def" fields/arrays, remove boxing onsimple method calls of "def" methods <ulink url="https://github.com/elastic/elasticsearch/pull/18359">#18359</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Some cleanups <ulink url="https://github.com/elastic/elasticsearch/pull/18352">#18352</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Use isAssignableFrom instead of relying on ClassCastException <ulink url="https://github.com/elastic/elasticsearch/pull/18350">#18350</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Build descriptor of array and field load/store in code <ulink url="https://github.com/elastic/elasticsearch/pull/18338">#18338</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Rename the dynamic call site factory to DefBootstrap <ulink url="https://github.com/elastic/elasticsearch/pull/18335">#18335</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Cleanup of DynamicCallSite <ulink url="https://github.com/elastic/elasticsearch/pull/18323">#18323</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Improve exception stacktraces <ulink url="https://github.com/elastic/elasticsearch/pull/18319">#18319</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Make Line Number Available in Painless <ulink url="https://github.com/elastic/elasticsearch/pull/18298">#18298</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove input, support params instead <ulink url="https://github.com/elastic/elasticsearch/pull/18287">#18287</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Decouple ANTLR AST from Painless <ulink url="https://github.com/elastic/elasticsearch/pull/18286">#18286</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
_value support in painess? <ulink url="https://github.com/elastic/elasticsearch/pull/18284">#18284</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Long priority over Float <ulink url="https://github.com/elastic/elasticsearch/pull/18282">#18282</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
_score as double, not float <ulink url="https://github.com/elastic/elasticsearch/pull/18277">#18277</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add <emphasis>ctx</emphasis> keyword to painless. <ulink url="https://github.com/elastic/elasticsearch/pull/18264">#18264</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Painless doc access <ulink url="https://github.com/elastic/elasticsearch/pull/18262">#18262</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Retrieve _score directly from Scorer <ulink url="https://github.com/elastic/elasticsearch/pull/18258">#18258</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Implement needsScore() correctly. <ulink url="https://github.com/elastic/elasticsearch/pull/18247">#18247</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add synthetic length property as alias to Lists, so they can be used like arrays <ulink url="https://github.com/elastic/elasticsearch/pull/18241">#18241</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Use better typing for dynamic method calls <ulink url="https://github.com/elastic/elasticsearch/pull/18234">#18234</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Array load/store and length with invokedynamic <ulink url="https://github.com/elastic/elasticsearch/pull/18232">#18232</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18201">#18201</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Switch painless dynamic calls to invokedynamic, remove perf hack/cheat <ulink url="https://github.com/elastic/elasticsearch/pull/18201">#18201</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add fielddata accessors (.value/.values/.distance()/etc) <ulink url="https://github.com/elastic/elasticsearch/pull/18169">#18169</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
painless: optimize/simplify dynamic field and method access <ulink url="https://github.com/elastic/elasticsearch/pull/18151">#18151</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Painless: Single-Quoted Strings <ulink url="https://github.com/elastic/elasticsearch/pull/18150">#18150</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Painless Clean Up <ulink url="https://github.com/elastic/elasticsearch/pull/17428">#17428</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Make Painless a Module <ulink url="https://github.com/elastic/elasticsearch/pull/16755">#16755</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Minor Clean up <ulink url="https://github.com/elastic/elasticsearch/pull/16457">#16457</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove Extra String Concat Token <ulink url="https://github.com/elastic/elasticsearch/pull/16382">#16382</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Mapper Attachment
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
minor attachments cleanups: IDE test support and EPUB format <ulink url="https://github.com/elastic/elasticsearch/pull/14626">#14626</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Mapper Size
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add doc values support to the _size field in the mapper-size plugin <ulink url="https://github.com/elastic/elasticsearch/pull/19217">#19217</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18334">#18334</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Repository Azure
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Support global <literal>repositories.azure.</literal> settings <ulink url="https://github.com/elastic/elasticsearch/pull/15141">#15141</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13776">#13776</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add timeout settings (default to 5 minutes) <ulink url="https://github.com/elastic/elasticsearch/pull/15080">#15080</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14277">#14277</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove AbstractLegacyBlobContainer <ulink url="https://github.com/elastic/elasticsearch/pull/14650">#14650</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13434">#13434</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Repository HDFS
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
merge current hdfs improvements to master <ulink url="https://github.com/elastic/elasticsearch/pull/15588">#15588</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Repository S3
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Extract AWS Key from KeyChain instead of using potential null value <ulink url="https://github.com/elastic/elasticsearch/pull/19560">#19560</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/18703">#18703</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/19557">#19557</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Check that S3 setting <literal>buffer_size</literal> is always lower than <literal>chunk_size</literal> <ulink url="https://github.com/elastic/elasticsearch/pull/17274">#17274</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17244">#17244</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugins
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Revert "Display plugins versions" <ulink url="https://github.com/elastic/elasticsearch/pull/20807">#20807</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/18683">#18683</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/20668">#20668</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Provide error message when plugin id is missing <ulink url="https://github.com/elastic/elasticsearch/pull/20660">#20660</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Print message when removing plugin with config <ulink url="https://github.com/elastic/elasticsearch/pull/20338">#20338</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Plugins: Update official plugin location with unified release <ulink url="https://github.com/elastic/elasticsearch/pull/19996">#19996</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Allow plugins to upgrade global custom metadata on startup <ulink url="https://github.com/elastic/elasticsearch/pull/19962">#19962</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Switch aggregations from push to pull <ulink url="https://github.com/elastic/elasticsearch/pull/19839">#19839</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Display plugins versions <ulink url="https://github.com/elastic/elasticsearch/pull/18683">#18683</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add ScriptService to dependencies available for plugin components <ulink url="https://github.com/elastic/elasticsearch/pull/19770">#19770</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Make NamedWriteableRegistry immutable and add extension point for named writeables <ulink url="https://github.com/elastic/elasticsearch/pull/19764">#19764</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Log one plugin info per line <ulink url="https://github.com/elastic/elasticsearch/pull/19441">#19441</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Make rest headers registration pull based <ulink url="https://github.com/elastic/elasticsearch/pull/19440">#19440</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add resource watcher to services available for plugin components <ulink url="https://github.com/elastic/elasticsearch/pull/19401">#19401</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add some basic services to createComponents for plugins <ulink url="https://github.com/elastic/elasticsearch/pull/19380">#19380</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Make plugins closeable <ulink url="https://github.com/elastic/elasticsearch/pull/19137">#19137</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Plugins: Add status bar on download <ulink url="https://github.com/elastic/elasticsearch/pull/18695">#18695</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add did-you-mean for plugin cli <ulink url="https://github.com/elastic/elasticsearch/pull/18942">#18942</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18896">#18896</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Plugins: Remove name() and description() from api <ulink url="https://github.com/elastic/elasticsearch/pull/18906">#18906</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Emit nicer error message when trying to install unknown plugin <ulink url="https://github.com/elastic/elasticsearch/pull/18876">#18876</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17226">#17226</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add plugin information for Verbose mode <ulink url="https://github.com/elastic/elasticsearch/pull/18051">#18051</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16375">#16375</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Cli: Improve output for usage errors <ulink url="https://github.com/elastic/elasticsearch/pull/17938">#17938</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Cli: Add verbose output with zip url when installing plugin <ulink url="https://github.com/elastic/elasticsearch/pull/17662">#17662</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17529">#17529</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
PluginManager: Add xpack as official plugin <ulink url="https://github.com/elastic/elasticsearch/pull/17227">#17227</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
CliTool: Cleanup and document Terminal <ulink url="https://github.com/elastic/elasticsearch/pull/16443">#16443</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Plugin cli: Improve maven coordinates detection <ulink url="https://github.com/elastic/elasticsearch/pull/16384">#16384</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16376">#16376</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Enforce plugin zip does not contain zip entries outside of the plugin dir <ulink url="https://github.com/elastic/elasticsearch/pull/16361">#16361</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
CliTool: Allow unexpected exceptions to propagate <ulink url="https://github.com/elastic/elasticsearch/pull/16359">#16359</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Reduce complexity of plugin cli <ulink url="https://github.com/elastic/elasticsearch/pull/16336">#16336</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove Plugin.onIndexService. <ulink url="https://github.com/elastic/elasticsearch/pull/15029">#15029</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14896">#14896</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Open up QueryCache and SearcherWrapper extension points <ulink url="https://github.com/elastic/elasticsearch/pull/14303">#14303</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Query DSL
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Throw exception when multiple field names are provided as part of query short syntax <ulink url="https://github.com/elastic/elasticsearch/pull/19871">#19871</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19791">#19791</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Query parsers to throw exception when multiple field names are provided <ulink url="https://github.com/elastic/elasticsearch/pull/19791">#19791</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19547">#19547</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Allow empty json object in request body in <literal>_count</literal> API <ulink url="https://github.com/elastic/elasticsearch/pull/19595">#19595</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19422">#19422</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Treat zero token in <literal>common</literal> terms query as MatchNoDocsQuery <ulink url="https://github.com/elastic/elasticsearch/pull/18656">#18656</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Handle empty query bodies at parse time and remove EmptyQueryBuilder <ulink url="https://github.com/elastic/elasticsearch/pull/17624">#17624</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/17540">#17540</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/17541">#17541</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Enforce MatchQueryBuilder#maxExpansions() to be strictly positive <ulink url="https://github.com/elastic/elasticsearch/pull/18464">#18464</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Don&#8217;t allow <literal>fuzziness</literal> for <literal>multi_match</literal> types <literal>cross_fields</literal>, <literal>phrase</literal> and <literal>phrase_prefix</literal> <ulink url="https://github.com/elastic/elasticsearch/pull/18322">#18322</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/6866">#6866</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/7764">#7764</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add MatchNoDocsQuery, a query that matches no documents and prints the reason why in the toString method. <ulink url="https://github.com/elastic/elasticsearch/pull/17780">#17780</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Adds <literal>ignore_unmapped</literal> option to geo queries <ulink url="https://github.com/elastic/elasticsearch/pull/17751">#17751</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Adds <literal>ignore_unmapped</literal> option to nested and P/C queries <ulink url="https://github.com/elastic/elasticsearch/pull/17748">#17748</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
SimpleQueryParser should call MappedFieldType.termQuery when appropriate. <ulink url="https://github.com/elastic/elasticsearch/pull/17678">#17678</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
An <literal>exists</literal> query on an object should query a single term. <ulink url="https://github.com/elastic/elasticsearch/pull/17186">#17186</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17131">#17131</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Function Score Query: make parsing stricter <ulink url="https://github.com/elastic/elasticsearch/pull/16617">#16617</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16583">#16583</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Parsers should throw exception on unknown objects <ulink url="https://github.com/elastic/elasticsearch/pull/14255">#14255</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/10974">#10974</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
UNICODE_CHARACTER_CLASS fix <ulink url="https://github.com/elastic/elasticsearch/pull/11598">#11598</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/10146">#10146</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Query Refactoring
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add infrastructure to rewrite query builders <ulink url="https://github.com/elastic/elasticsearch/pull/16599">#16599</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Switch geo validation to enum <ulink url="https://github.com/elastic/elasticsearch/pull/13672">#13672</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13608">#13608</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
REST
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add a REST spec for the create API <ulink url="https://github.com/elastic/elasticsearch/pull/20924">#20924</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add response params to REST params did you mean <ulink url="https://github.com/elastic/elasticsearch/pull/20753">#20753</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/20722">#20722</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/20747">#20747</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add did you mean to strict REST params <ulink url="https://github.com/elastic/elasticsearch/pull/20747">#20747</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20722">#20722</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add exclusion support to response filtering <ulink url="https://github.com/elastic/elasticsearch/pull/19865">#19865</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Only write forced_refresh if we forced a refresh <ulink url="https://github.com/elastic/elasticsearch/pull/19669">#19669</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19629">#19629</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add Location header to the index, update, and create APIs <ulink url="https://github.com/elastic/elasticsearch/pull/19509">#19509</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19079">#19079</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add support for <literal>wait_for_events</literal> to the <literal>_cluster/health</literal> REST endpoint <ulink url="https://github.com/elastic/elasticsearch/pull/19432">#19432</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19419">#19419</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Rename Search Template REST spec names <ulink url="https://github.com/elastic/elasticsearch/pull/19178">#19178</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Adding status field in _msearch error request bodies <ulink url="https://github.com/elastic/elasticsearch/pull/18586">#18586</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18013">#18013</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add semicolon query string parameter delimiter <ulink url="https://github.com/elastic/elasticsearch/pull/18186">#18186</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18175">#18175</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Enable HTTP compression by default with compression level 3 <ulink url="https://github.com/elastic/elasticsearch/pull/18066">#18066</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/7309">#7309</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Allow JSON with unquoted field names by enabling system property <ulink url="https://github.com/elastic/elasticsearch/pull/17801">#17801</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17674">#17674</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
More robust handling of CORS HTTP Access Control <ulink url="https://github.com/elastic/elasticsearch/pull/16092">#16092</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add option to exclude based on paths in XContent <ulink url="https://github.com/elastic/elasticsearch/pull/16017">#16017</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Recovery
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Pass on maxUnsafeAutoIdTimestamp on recovery / relocation <ulink url="https://github.com/elastic/elasticsearch/pull/20300">#20300</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Non-blocking primary relocation hand-off <ulink url="https://github.com/elastic/elasticsearch/pull/19013">#19013</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/15900">#15900</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/18553">#18553</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
index shard should be able to cancel check index on close. <ulink url="https://github.com/elastic/elasticsearch/pull/18839">#18839</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/12011">#12011</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
TransportNodesListGatewayStartedShards should fall back to disk based index metadata if not found in cluster state <ulink url="https://github.com/elastic/elasticsearch/pull/17663">#17663</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17630">#17630</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Recover broken IndexMetaData as closed <ulink url="https://github.com/elastic/elasticsearch/pull/17187">#17187</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Relocation source should be marked as relocating before starting recovery to primary relocation target <ulink url="https://github.com/elastic/elasticsearch/pull/16500">#16500</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Operation counter for IndexShard <ulink url="https://github.com/elastic/elasticsearch/pull/15956">#15956</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15900">#15900</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Primary relocation handoff <ulink url="https://github.com/elastic/elasticsearch/pull/15900">#15900</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/15532">#15532</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/16274">#16274</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/19013">#19013</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove recovery threadpools and throttle outgoing recoveries on the master <ulink url="https://github.com/elastic/elasticsearch/pull/15372">#15372</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Refactor StoreRecoveryService to be a simple package private util class <ulink url="https://github.com/elastic/elasticsearch/pull/13766">#13766</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Reindex API
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Only ask for <literal>_version</literal> we need it <ulink url="https://github.com/elastic/elasticsearch/pull/19693">#19693</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19135">#19135</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Use fewer threads when reindexing-from-remote <ulink url="https://github.com/elastic/elasticsearch/pull/19636">#19636</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Support authentication with reindex-from-remote <ulink url="https://github.com/elastic/elasticsearch/pull/19310">#19310</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Support requests_per_second=-1 to mean no throttling in reindex <ulink url="https://github.com/elastic/elasticsearch/pull/19101">#19101</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19089">#19089</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Implement ctx.op = "delete" on _update_by_query and _reindex <ulink url="https://github.com/elastic/elasticsearch/pull/18614">#18614</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18043">#18043</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make Reindex cancellation tests more uniform <ulink url="https://github.com/elastic/elasticsearch/pull/18498">#18498</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Makes DeleteByQueryRequest implements IndicesRequest <ulink url="https://github.com/elastic/elasticsearch/pull/18466">#18466</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Teach reindex to retry on search failures <ulink url="https://github.com/elastic/elasticsearch/pull/18331">#18331</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18059">#18059</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove ReindexResponse in favor of BulkIndexByScrollResponse <ulink url="https://github.com/elastic/elasticsearch/pull/18205">#18205</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Stricter validation of Reindex&#8217;s requests_per_second <ulink url="https://github.com/elastic/elasticsearch/pull/18028">#18028</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Properly mark reindex&#8217;s child tasks as child tasks <ulink url="https://github.com/elastic/elasticsearch/pull/17770">#17770</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Make reindex throttling dynamic <ulink url="https://github.com/elastic/elasticsearch/pull/17262">#17262</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Throttling support for reindex <ulink url="https://github.com/elastic/elasticsearch/pull/17039">#17039</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add ingest pipeline support to reindex <ulink url="https://github.com/elastic/elasticsearch/pull/16932">#16932</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Scripting
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Parse script on storage instead of on retrieval <ulink url="https://github.com/elastic/elasticsearch/pull/20356">#20356</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Migrate elasticsearch native script examples to the main repo <ulink url="https://github.com/elastic/elasticsearch/pull/19334">#19334</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14662">#14662</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove ClusterState from compile api <ulink url="https://github.com/elastic/elasticsearch/pull/19136">#19136</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Mustache: Render Map as JSON <ulink url="https://github.com/elastic/elasticsearch/pull/18856">#18856</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18970">#18970</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Compile each Groovy script in its own classloader <ulink url="https://github.com/elastic/elasticsearch/pull/18918">#18918</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18572">#18572</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Include script field even if it value is null <ulink url="https://github.com/elastic/elasticsearch/pull/18384">#18384</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16408">#16408</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Skipping hidden files compilation for script service <ulink url="https://github.com/elastic/elasticsearch/pull/16286">#16286</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15269">#15269</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Rename Plan A to Painless <ulink url="https://github.com/elastic/elasticsearch/pull/16245">#16245</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add plumbing for script compile-time parameters <ulink url="https://github.com/elastic/elasticsearch/pull/15464">#15464</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Factor mustache &#8594; modules/lang-mustache <ulink url="https://github.com/elastic/elasticsearch/pull/15328">#15328</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Scroll
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add an index setting to limit the maximum number of slices allowed in a scroll request. <ulink url="https://github.com/elastic/elasticsearch/pull/18782">#18782</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Search
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Limit batch size when scrolling <ulink url="https://github.com/elastic/elasticsearch/pull/19367">#19367</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19249">#19249</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Record method counts while profiling query components <ulink url="https://github.com/elastic/elasticsearch/pull/18302">#18302</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Change default similarity to BM25 <ulink url="https://github.com/elastic/elasticsearch/pull/18948">#18948</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18944">#18944</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add a parameter to cap the number of searches the msearch api will concurrently execute <ulink url="https://github.com/elastic/elasticsearch/pull/18721">#18721</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Introduces GeoValidationMethod to GeoDistanceSortBuilder <ulink url="https://github.com/elastic/elasticsearch/pull/18036">#18036</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Switches from empty boolean query to matchNoDocs <ulink url="https://github.com/elastic/elasticsearch/pull/18007">#18007</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17981">#17981</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Allow binary sort values. <ulink url="https://github.com/elastic/elasticsearch/pull/17959">#17959</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/17971">#17971</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/6077">#6077</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fail query if it contains very large rescores <ulink url="https://github.com/elastic/elasticsearch/pull/17917">#17917</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17522">#17522</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Type filters should not have a performance impact when there is a single type. <ulink url="https://github.com/elastic/elasticsearch/pull/17350">#17350</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Store _all payloads on 1 byte instead of 4. <ulink url="https://github.com/elastic/elasticsearch/pull/16899">#16899</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Refuse to load fields from _source when using the <literal>fields</literal> option and support wildcards.  <ulink url="https://github.com/elastic/elasticsearch/pull/15017">#15017</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/10783">#10783</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/14489">#14489</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add response into ClearScrollResponse <ulink url="https://github.com/elastic/elasticsearch/pull/13835">#13835</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13817">#13817</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Shuffle shards for _only_nodes + support multiple specifications like cluster API  <ulink url="https://github.com/elastic/elasticsearch/pull/12575">#12575</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/12546">#12546</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/12700">#12700</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Search Refactoring
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Removes the now obsolete SearchParseElement implementations <ulink url="https://github.com/elastic/elasticsearch/pull/18233">#18233</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove RescoreParseElement <ulink url="https://github.com/elastic/elasticsearch/pull/17441">#17441</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove HighlighterParseElement <ulink url="https://github.com/elastic/elasticsearch/pull/17303">#17303</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Move top level parsing of sort element to SortBuilder <ulink url="https://github.com/elastic/elasticsearch/pull/17248">#17248</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Switch to using refactored SortBuilder instead of using BytesReference in serialization <ulink url="https://github.com/elastic/elasticsearch/pull/17205">#17205</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/17146">#17146</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/17257">#17257</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add build() method to SortBuilder implementations <ulink url="https://github.com/elastic/elasticsearch/pull/17146">#17146</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/10217">#10217</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Refactoring of Suggestions <ulink url="https://github.com/elastic/elasticsearch/pull/17096">#17096</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/10217">#10217</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Move sort <literal>order</literal> field up into SortBuilder <ulink url="https://github.com/elastic/elasticsearch/pull/17035">#17035</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Moves SortParser:parse(&#8230;) to only require QueryShardContext <ulink url="https://github.com/elastic/elasticsearch/pull/16999">#16999</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15178">#15178</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Change internal representation of suggesters  <ulink url="https://github.com/elastic/elasticsearch/pull/16873">#16873</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Make GeoDistanceSortBuilder serializable, 2nd try <ulink url="https://github.com/elastic/elasticsearch/pull/16572">#16572</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/15178">#15178</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/16151">#16151</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Move missing() from SortBuilder interface to class <ulink url="https://github.com/elastic/elasticsearch/pull/16225">#16225</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/15178">#15178</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/16151">#16151</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove deprecated parameters from ScriptSortBuilder <ulink url="https://github.com/elastic/elasticsearch/pull/16153">#16153</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15178">#15178</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Refactor GeoSortBuilder <ulink url="https://github.com/elastic/elasticsearch/pull/16151">#16151</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15178">#15178</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Refactor FieldSortBuilder <ulink url="https://github.com/elastic/elasticsearch/pull/16127">#16127</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15178">#15178</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make sort order enum writable. <ulink url="https://github.com/elastic/elasticsearch/pull/16124">#16124</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15178">#15178</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make DistanceUnit writable. <ulink url="https://github.com/elastic/elasticsearch/pull/16122">#16122</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15178">#15178</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
RescoreBuilder: Add parsing and creating of RescoreSearchContext <ulink url="https://github.com/elastic/elasticsearch/pull/16014">#16014</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15559">#15559</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make RescoreBuilder and nested QueryRescorer Writable <ulink url="https://github.com/elastic/elasticsearch/pull/15953">#15953</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15559">#15559</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Explain api: move query parsing to the coordinating node <ulink url="https://github.com/elastic/elasticsearch/pull/14270">#14270</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Switch query parsers to use ParseField  <ulink url="https://github.com/elastic/elasticsearch/pull/14249">#14249</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/8964">#8964</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Refactoring of Aggregations <ulink url="https://github.com/elastic/elasticsearch/pull/14136">#14136</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Sequence IDs
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Persist sequence number checkpoints <ulink url="https://github.com/elastic/elasticsearch/pull/18949">#18949</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/10708">#10708</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add sequence numbers to cat shards API <ulink url="https://github.com/elastic/elasticsearch/pull/18772">#18772</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Settings
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add precise logging on unknown or invalid settings <ulink url="https://github.com/elastic/elasticsearch/pull/20951">#20951</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20946">#20946</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make <literal>action.auto_create_index</literal> setting a dynamic cluster setting <ulink url="https://github.com/elastic/elasticsearch/pull/20274">#20274</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/7513">#7513</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Removes space between # and the setting in elasticsearch.yml <ulink url="https://github.com/elastic/elasticsearch/pull/20094">#20094</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20090">#20090</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Validates new dynamic settings from the current state <ulink url="https://github.com/elastic/elasticsearch/pull/19122">#19122</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19046">#19046</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Improve error message if a setting is not found <ulink url="https://github.com/elastic/elasticsearch/pull/18920">#18920</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18663">#18663</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Cleanup placeholder replacement <ulink url="https://github.com/elastic/elasticsearch/pull/17335">#17335</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Switch to registered Settings for all IndexingMemoryController settings <ulink url="https://github.com/elastic/elasticsearch/pull/17778">#17778</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17442">#17442</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add guard against null-valued settings <ulink url="https://github.com/elastic/elasticsearch/pull/17310">#17310</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17292">#17292</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Useful error message for null property placeholder <ulink url="https://github.com/elastic/elasticsearch/pull/17293">#17293</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17292">#17292</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Archive cluster level settings if unknown or broken <ulink url="https://github.com/elastic/elasticsearch/pull/17246">#17246</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Improve error message if setting is not found <ulink url="https://github.com/elastic/elasticsearch/pull/17230">#17230</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Improve upgrade experience of node level index settings <ulink url="https://github.com/elastic/elasticsearch/pull/17223">#17223</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17187">#17187</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Settings with complex matchers should not overlap <ulink url="https://github.com/elastic/elasticsearch/pull/16754">#16754</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Moves GCE settings to the new infra <ulink url="https://github.com/elastic/elasticsearch/pull/16722">#16722</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16720">#16720</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add filtering support within Setting class <ulink url="https://github.com/elastic/elasticsearch/pull/16629">#16629</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16598">#16598</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Migrate AWS settings to new settings infrastructure <ulink url="https://github.com/elastic/elasticsearch/pull/16602">#16602</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16293">#16293</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove <literal>gateway.initial_meta</literal> and always rely on min master nodes <ulink url="https://github.com/elastic/elasticsearch/pull/16446">#16446</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Rewrite SettingsFilter to be immutable <ulink url="https://github.com/elastic/elasticsearch/pull/16425">#16425</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Simplify azure settings <ulink url="https://github.com/elastic/elasticsearch/pull/16363">#16363</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Convert PageCacheRecycler settings <ulink url="https://github.com/elastic/elasticsearch/pull/16341">#16341</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Monitor settings <ulink url="https://github.com/elastic/elasticsearch/pull/16313">#16313</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Cut over tribe node settings to new settings infra <ulink url="https://github.com/elastic/elasticsearch/pull/16311">#16311</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Convert multcast plugin settings to the new infra <ulink url="https://github.com/elastic/elasticsearch/pull/16295">#16295</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Convert <literal>request.headers.*</literal> to the new settings infra <ulink url="https://github.com/elastic/elasticsearch/pull/16292">#16292</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Migrate Azure settings to new settings infrastructure <ulink url="https://github.com/elastic/elasticsearch/pull/16291">#16291</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Validate logger settings and allow them to be reset via API <ulink url="https://github.com/elastic/elasticsearch/pull/16289">#16289</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Switch NodeEnvironment&#8217;s settings to new settings <ulink url="https://github.com/elastic/elasticsearch/pull/16273">#16273</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Simplify AutoCreateIndex and add more tests <ulink url="https://github.com/elastic/elasticsearch/pull/16270">#16270</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Convert several pending settings <ulink url="https://github.com/elastic/elasticsearch/pull/16269">#16269</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Migrate query caching settings to the new settings infra. <ulink url="https://github.com/elastic/elasticsearch/pull/16267">#16267</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Convert <literal>action.auto_create_index</literal> and <literal>action.master.force_local</literal> to the new settings infra <ulink url="https://github.com/elastic/elasticsearch/pull/16263">#16263</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Convert <literal>cluster.routing.allocation.type</literal> and <literal>processors</literal> to the new settings infra. <ulink url="https://github.com/elastic/elasticsearch/pull/16238">#16238</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Validate tribe node settings on startup <ulink url="https://github.com/elastic/elasticsearch/pull/16237">#16237</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Move node.client, node.data, node.master, node.local and node.mode to new settings infra <ulink url="https://github.com/elastic/elasticsearch/pull/16230">#16230</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Moved http settings to the new settings infrastructure <ulink url="https://github.com/elastic/elasticsearch/pull/16188">#16188</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Migrate network service to the new infra <ulink url="https://github.com/elastic/elasticsearch/pull/16187">#16187</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Convert client.transport settings to new infra <ulink url="https://github.com/elastic/elasticsearch/pull/16183">#16183</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Move discovery.* settings to new Setting infrastructure <ulink url="https://github.com/elastic/elasticsearch/pull/16182">#16182</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Change over to o.e.common.settings.Setting for http settings <ulink url="https://github.com/elastic/elasticsearch/pull/16181">#16181</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Convert "path.*" and "pidfile" to new settings infra <ulink url="https://github.com/elastic/elasticsearch/pull/16180">#16180</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Migrate repository settings to the new settings API <ulink url="https://github.com/elastic/elasticsearch/pull/16178">#16178</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Convert "indices.*" settings to new infra. <ulink url="https://github.com/elastic/elasticsearch/pull/16177">#16177</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Migrate gateway settings to the new settings API. <ulink url="https://github.com/elastic/elasticsearch/pull/16175">#16175</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Convert several node and test level settings <ulink url="https://github.com/elastic/elasticsearch/pull/16172">#16172</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Run Metadata upgrade tool on every version <ulink url="https://github.com/elastic/elasticsearch/pull/16168">#16168</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Check for invalid index settings on metadata upgrade <ulink url="https://github.com/elastic/elasticsearch/pull/16156">#16156</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Validate the settings key if it&#8217;s simple chars separated by <literal>.</literal> <ulink url="https://github.com/elastic/elasticsearch/pull/16120">#16120</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Validate known global settings on startup <ulink url="https://github.com/elastic/elasticsearch/pull/16091">#16091</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Cut over all index scope settings to the new setting infrastrucuture <ulink url="https://github.com/elastic/elasticsearch/pull/16054">#16054</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/12790">#12790</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/12854">#12854</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/16032">#16032</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/6732">#6732</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove updatability of <literal>index.flush_on_close</literal> <ulink url="https://github.com/elastic/elasticsearch/pull/15964">#15964</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15955">#15955</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Move all dynamic settings and their config classes to the index level <ulink url="https://github.com/elastic/elasticsearch/pull/15955">#15955</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/6732">#6732</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Always require units for bytes and time settings <ulink url="https://github.com/elastic/elasticsearch/pull/15948">#15948</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/11437">#11437</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make MetaData parsing less lenient. <ulink url="https://github.com/elastic/elasticsearch/pull/15828">#15828</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Move async translog sync logic into IndexService <ulink url="https://github.com/elastic/elasticsearch/pull/15584">#15584</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove <literal>index.merge.scheduler.notify_on_failure</literal> and default to <literal>true</literal> <ulink url="https://github.com/elastic/elasticsearch/pull/15572">#15572</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15570">#15570</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove cache concurrency level settings that no longer apply <ulink url="https://github.com/elastic/elasticsearch/pull/14210">#14210</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/13717">#13717</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/7836">#7836</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Similarities
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Defining a global default similarity <ulink url="https://github.com/elastic/elasticsearch/pull/16682">#16682</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16594">#16594</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Snapshot/Restore
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Delete differing files in the store before restoring <ulink url="https://github.com/elastic/elasticsearch/pull/20220">#20220</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20148">#20148</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Adds ignoreUnavailable option to the snapshot status API <ulink url="https://github.com/elastic/elasticsearch/pull/20066">#20066</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18522">#18522</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Check restores in progress before deleting a snapshot <ulink url="https://github.com/elastic/elasticsearch/pull/19853">#19853</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Snapshot repository cleans up empty index folders <ulink url="https://github.com/elastic/elasticsearch/pull/19751">#19751</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
BlobContainer#writeBlob no longer can overwrite a blob <ulink url="https://github.com/elastic/elasticsearch/pull/19749">#19749</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15579">#15579</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
More resilient blob handling in snapshot repositories <ulink url="https://github.com/elastic/elasticsearch/pull/19706">#19706</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/18156">#18156</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/18815">#18815</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/19421">#19421</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/7540">#7540</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Adding repository index generational files <ulink url="https://github.com/elastic/elasticsearch/pull/19002">#19002</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18156">#18156</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Raised IOException on deleteBlob <ulink url="https://github.com/elastic/elasticsearch/pull/18815">#18815</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18530">#18530</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Adds UUIDs to snapshots <ulink url="https://github.com/elastic/elasticsearch/pull/18228">#18228</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18156">#18156</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Clarify the semantics of the BlobContainer interface <ulink url="https://github.com/elastic/elasticsearch/pull/18157">#18157</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15580">#15580</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Change BlobPath.buildAsString() method <ulink url="https://github.com/elastic/elasticsearch/pull/18461">#18461</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove the Snapshot class in favor of using SnapshotInfo <ulink url="https://github.com/elastic/elasticsearch/pull/18167">#18167</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18156">#18156</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Stats
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add mem section back to cluster stats <ulink url="https://github.com/elastic/elasticsearch/pull/20255">#20255</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17278">#17278</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add network types to cluster stats <ulink url="https://github.com/elastic/elasticsearch/pull/20144">#20144</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add missing field type in the FieldStats response. <ulink url="https://github.com/elastic/elasticsearch/pull/19241">#19241</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17750">#17750</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Expose the ClusterInfo object in the allocation explain output <ulink url="https://github.com/elastic/elasticsearch/pull/19106">#19106</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14405">#14405</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add total_indexing_buffer/_in_bytes to nodes info API <ulink url="https://github.com/elastic/elasticsearch/pull/18914">#18914</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18651">#18651</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Allow FieldStatsRequest to disable cache <ulink url="https://github.com/elastic/elasticsearch/pull/18900">#18900</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove index_writer_max_memory stat from segment stats <ulink url="https://github.com/elastic/elasticsearch/pull/18651">#18651</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/14121">#14121</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/7440">#7440</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Move DocStats under Engine to get more accurate numbers <ulink url="https://github.com/elastic/elasticsearch/pull/18587">#18587</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Do not return fieldstats information for fields that exist in the mapping but not in the index. <ulink url="https://github.com/elastic/elasticsearch/pull/18212">#18212</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17980">#17980</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add whether the shard state fetch is pending to the allocation explain API <ulink url="https://github.com/elastic/elasticsearch/pull/18119">#18119</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17372">#17372</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add Failure Details to every NodesResponse <ulink url="https://github.com/elastic/elasticsearch/pull/17964">#17964</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/3740">#3740</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add I/O statistics on Linux <ulink url="https://github.com/elastic/elasticsearch/pull/15915">#15915</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15296">#15296</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add points to SegmentStats. <ulink url="https://github.com/elastic/elasticsearch/pull/17775">#17775</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16974">#16974</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove FieldStats.Float. <ulink url="https://github.com/elastic/elasticsearch/pull/17749">#17749</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Show configured and remaining delay for an unassigned shard. <ulink url="https://github.com/elastic/elasticsearch/pull/17515">#17515</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17372">#17372</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
indexing stats now contain indexing ops from recovery  [ISSUE] <ulink url="https://github.com/elastic/elasticsearch/pull/17412">#17412</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Normalize unavailable load average <ulink url="https://github.com/elastic/elasticsearch/pull/16061">#16061</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/12049">#12049</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/14741">#14741</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/15907">#15907</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/15932">#15932</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/15934">#15934</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add load averages to OS stats on FreeBSD <ulink url="https://github.com/elastic/elasticsearch/pull/15934">#15934</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15917">#15917</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Expose pending cluster state queue size in node stats <ulink url="https://github.com/elastic/elasticsearch/pull/14040">#14040</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13610">#13610</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Store
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Use <literal>mmapfs</literal> by default. <ulink url="https://github.com/elastic/elasticsearch/pull/17616">#17616</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16983">#16983</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove support for legacy checksums <ulink url="https://github.com/elastic/elasticsearch/pull/16931">#16931</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Rename index folder to index_uuid <ulink url="https://github.com/elastic/elasticsearch/pull/16442">#16442</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/13264">#13264</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/13265">#13265</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/14512">#14512</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/14932">#14932</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/15853">#15853</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Suggesters
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Move SuggestUtils methods to their respective caller classes <ulink url="https://github.com/elastic/elasticsearch/pull/19914">#19914</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19906">#19906</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove payload option from completion suggester <ulink url="https://github.com/elastic/elasticsearch/pull/19877">#19877</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19536">#19536</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add bwc support for reading  pre-5.0 completion index <ulink url="https://github.com/elastic/elasticsearch/pull/17602">#17602</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Task Manager
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Rename Task Persistence into Storing Task Results <ulink url="https://github.com/elastic/elasticsearch/pull/19982">#19982</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fetch result when wait_for_completion <ulink url="https://github.com/elastic/elasticsearch/pull/18905">#18905</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Create get task API that falls back to the .tasks index <ulink url="https://github.com/elastic/elasticsearch/pull/18682">#18682</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add ability to store results for long running tasks <ulink url="https://github.com/elastic/elasticsearch/pull/17928">#17928</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Move parentTaskId into TransportRequest  <ulink url="https://github.com/elastic/elasticsearch/pull/17872">#17872</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Shorten the serialization of the empty TaskId <ulink url="https://github.com/elastic/elasticsearch/pull/17870">#17870</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Expose whether a task is cancellable in the _tasks list API <ulink url="https://github.com/elastic/elasticsearch/pull/17464">#17464</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17369">#17369</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add ability to group tasks by common parent <ulink url="https://github.com/elastic/elasticsearch/pull/17341">#17341</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add start time and duration to tasks <ulink url="https://github.com/elastic/elasticsearch/pull/16829">#16829</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Combine node name and task id into single string task id <ulink url="https://github.com/elastic/elasticsearch/pull/16744">#16744</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add task status <ulink url="https://github.com/elastic/elasticsearch/pull/16356">#16356</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16344">#16344</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Extend tracking of parent tasks to master node, replication and broadcast actions <ulink url="https://github.com/elastic/elasticsearch/pull/15931">#15931</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Translog
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fsync documents in an async fashion <ulink url="https://github.com/elastic/elasticsearch/pull/20145">#20145</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add checksumming and versions to the Translog&#8217;s Checkpoint files <ulink url="https://github.com/elastic/elasticsearch/pull/19797">#19797</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Beef up Translog testing with random channel exceptions <ulink url="https://github.com/elastic/elasticsearch/pull/18997">#18997</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Do not replay into translog on local recovery <ulink url="https://github.com/elastic/elasticsearch/pull/18547">#18547</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
FSync translog outside of the writers global lock <ulink url="https://github.com/elastic/elasticsearch/pull/18360">#18360</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove ChannelReference and simplify Views <ulink url="https://github.com/elastic/elasticsearch/pull/15898">#15898</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Simplify TranslogWriter to always write to a stream <ulink url="https://github.com/elastic/elasticsearch/pull/15771">#15771</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove TranslogService and fold it into synchronous IndexShard API <ulink url="https://github.com/elastic/elasticsearch/pull/13707">#13707</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="bug-5.0.0" renderas="sect2">Bug fixes<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.0.0-all.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
Aggregations
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fixed writeable name from range to geo_distance <ulink url="https://github.com/elastic/elasticsearch/pull/20860">#20860</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix date_range aggregation to not cache if now is used <ulink url="https://github.com/elastic/elasticsearch/pull/20740">#20740</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
The <literal>top_hits</literal> aggregation should compile scripts only once. <ulink url="https://github.com/elastic/elasticsearch/pull/20738">#20738</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix agg profiling when using breadth_first collect mode <ulink url="https://github.com/elastic/elasticsearch/pull/20156">#20156</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Throw exception when maxBounds greater than minBounds <ulink url="https://github.com/elastic/elasticsearch/pull/19855">#19855</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19833">#19833</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Undeprecates <literal>aggs</literal> in the search request <ulink url="https://github.com/elastic/elasticsearch/pull/19674">#19674</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19504">#19504</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Change how <literal>nested</literal> and <literal>reverse_nested</literal> aggs know about their nested depth level <ulink url="https://github.com/elastic/elasticsearch/pull/19550">#19550</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/11749">#11749</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/12410">#12410</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make ExtendedBounds immutable <ulink url="https://github.com/elastic/elasticsearch/pull/19490">#19490</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19481">#19481</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Aggregations fix: support include/exclude strings for IP and dates <ulink url="https://github.com/elastic/elasticsearch/pull/18408">#18408</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17705">#17705</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix xcontent rendering of ip terms aggs. <ulink url="https://github.com/elastic/elasticsearch/pull/18003">#18003</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17971">#17971</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Improving parsing of sigma param for Extended Stats Bucket Aggregation <ulink url="https://github.com/elastic/elasticsearch/pull/17562">#17562</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17499">#17499</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fixes NPE when no window is specified in moving average request <ulink url="https://github.com/elastic/elasticsearch/pull/17556">#17556</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17516">#17516</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fixes Filter and FiltersAggregation to work with empty query <ulink url="https://github.com/elastic/elasticsearch/pull/17542">#17542</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17518">#17518</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fixes the defaults for <literal>keyed</literal> in the percentiles aggregations <ulink url="https://github.com/elastic/elasticsearch/pull/17217">#17217</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Correct typo in class name of StatsAggregator <ulink url="https://github.com/elastic/elasticsearch/pull/15264">#15264</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14730">#14730</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Allocation
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Keep a shadow replicas' allocation id when it is promoted to primary <ulink url="https://github.com/elastic/elasticsearch/pull/20863">#20863</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20650">#20650</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
IndicesClusterStateService should clean local started when re-assigns an initializing shard with the same aid <ulink url="https://github.com/elastic/elasticsearch/pull/20687">#20687</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
IndexRoutingTable.initializeEmpty shouldn&#8217;t override supplied primary RecoverySource <ulink url="https://github.com/elastic/elasticsearch/pull/20638">#20638</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20637">#20637</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Update incoming recoveries stats when shadow replica is reinitialized <ulink url="https://github.com/elastic/elasticsearch/pull/20612">#20612</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>index.routing.allocation.initial_recovery</literal> limits replica allocation <ulink url="https://github.com/elastic/elasticsearch/pull/20589">#20589</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Upon being elected as master, prefer joins' node info to existing cluster state <ulink url="https://github.com/elastic/elasticsearch/pull/19743">#19743</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix NPE when initializing replica shard has no UnassignedInfo <ulink url="https://github.com/elastic/elasticsearch/pull/19491">#19491</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19488">#19488</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make shard store fetch less dependent on the current cluster state, both on master and non data nodes <ulink url="https://github.com/elastic/elasticsearch/pull/19044">#19044</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18938">#18938</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix recovery throttling to properly handle relocating non-primary shards <ulink url="https://github.com/elastic/elasticsearch/pull/18701">#18701</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18640">#18640</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Replica shards must be failed before primary shards <ulink url="https://github.com/elastic/elasticsearch/pull/15686">#15686</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Analysis
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Named analyzer should close the analyzer that it wraps <ulink url="https://github.com/elastic/elasticsearch/pull/20197">#20197</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Can load non-PreBuiltTokenFilter in Analyze API <ulink url="https://github.com/elastic/elasticsearch/pull/20396">#20396</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix analyzer alias processing <ulink url="https://github.com/elastic/elasticsearch/pull/19506">#19506</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19163">#19163</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Bulk
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add not-null precondition check in BulkRequest <ulink url="https://github.com/elastic/elasticsearch/pull/18347">#18347</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/12038">#12038</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
CAT API
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fixes cat tasks operation in detailed mode <ulink url="https://github.com/elastic/elasticsearch/pull/19759">#19759</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19755">#19755</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add index pattern wildcards support to _cat/shards <ulink url="https://github.com/elastic/elasticsearch/pull/19655">#19655</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19634">#19634</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
CRUD
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
GET operations should not extract fields from <literal>_source</literal>. <ulink url="https://github.com/elastic/elasticsearch/pull/20158">#20158</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/15017">#15017</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/20102">#20102</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Squash a race condition in RefreshListeners <ulink url="https://github.com/elastic/elasticsearch/pull/18806">#18806</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Prevent TransportReplicationAction to route request based on stale local routing table <ulink url="https://github.com/elastic/elasticsearch/pull/16274">#16274</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/12573">#12573</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/12574">#12574</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Resolves the conflict between alias routing and parent routing by applying the alias routing and ignoring the parent routing. <ulink url="https://github.com/elastic/elasticsearch/pull/15371">#15371</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/3068">#3068</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Cache
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Prevent requests that use scripts or now() from being cached <ulink url="https://github.com/elastic/elasticsearch/pull/20750">#20750</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20645">#20645</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Serialize index boost and phrase suggest collation keys in a consistent order <ulink url="https://github.com/elastic/elasticsearch/pull/20081">#20081</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19986">#19986</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Circuit Breakers
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Never trip circuit breaker in liveness request <ulink url="https://github.com/elastic/elasticsearch/pull/18627">#18627</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17951">#17951</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Free bytes reserved on request breaker <ulink url="https://github.com/elastic/elasticsearch/pull/18204">#18204</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18144">#18144</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Cluster
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fixes issue with dangling index being deleted instead of re-imported <ulink url="https://github.com/elastic/elasticsearch/pull/19666">#19666</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Allow routing table to be filtered by index pattern <ulink url="https://github.com/elastic/elasticsearch/pull/19688">#19688</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Use executor&#8217;s describeTasks method to log task information in cluster service <ulink url="https://github.com/elastic/elasticsearch/pull/19531">#19531</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Acknowledge index deletion requests based on standard cluster state acknowledgment <ulink url="https://github.com/elastic/elasticsearch/pull/18602">#18602</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/16442">#16442</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/18558">#18558</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Dangling indices are not imported if a tombstone for the index exists <ulink url="https://github.com/elastic/elasticsearch/pull/18250">#18250</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18249">#18249</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix issue with tombstones matching active indices in cluster state <ulink url="https://github.com/elastic/elasticsearch/pull/18058">#18058</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18054">#18054</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Shard state action channel exceptions <ulink url="https://github.com/elastic/elasticsearch/pull/16057">#16057</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15748">#15748</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Core
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Makes <literal>m</literal> case sensitive in TimeValue <ulink url="https://github.com/elastic/elasticsearch/pull/19649">#19649</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19619">#19619</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Guard against negative result from FileStore.getUsableSpace when picking data path for a new shard <ulink url="https://github.com/elastic/elasticsearch/pull/19554">#19554</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Handle rejected execution exception on reschedule <ulink url="https://github.com/elastic/elasticsearch/pull/19505">#19505</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix concurrency bug in IMC that could cause it to check too infrequently <ulink url="https://github.com/elastic/elasticsearch/pull/18357">#18357</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Iterables.flatten should not pre-cache the first iterator <ulink url="https://github.com/elastic/elasticsearch/pull/18355">#18355</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18353">#18353</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Avoid race while retiring executors <ulink url="https://github.com/elastic/elasticsearch/pull/18333">#18333</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Refactor UUID-generating methods out of Strings <ulink url="https://github.com/elastic/elasticsearch/pull/17837">#17837</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17819">#17819</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Node names cleanup <ulink url="https://github.com/elastic/elasticsearch/pull/17723">#17723</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17718">#17718</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
NullPointerException from IndexingMemoryController when a version conflict happens during recovery <ulink url="https://github.com/elastic/elasticsearch/pull/17569">#17569</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Handle RejectedExecution gracefully in TransportService during shutdown <ulink url="https://github.com/elastic/elasticsearch/pull/16965">#16965</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Discovery
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Update discovery nodes after cluster state is published <ulink url="https://github.com/elastic/elasticsearch/pull/20409">#20409</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add current cluster state version to zen pings and use them in master election <ulink url="https://github.com/elastic/elasticsearch/pull/20384">#20384</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20348">#20348</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Engine
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Take refresh IOExceptions into account when catching ACE in InternalEngine <ulink url="https://github.com/elastic/elasticsearch/pull/20546">#20546</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19975">#19975</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Don&#8217;t suppress AlreadyClosedException <ulink url="https://github.com/elastic/elasticsearch/pull/19975">#19975</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19861">#19861</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Expressions
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
replace ScriptException with a better one <ulink url="https://github.com/elastic/elasticsearch/pull/18600">#18600</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Geo
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Incomplete results when using geo_distance for large distances [ISSUE] <ulink url="https://github.com/elastic/elasticsearch/pull/17578">#17578</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix multi-field support for GeoPoint types <ulink url="https://github.com/elastic/elasticsearch/pull/15702">#15702</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15701">#15701</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Enforce distance in distance query is &gt; 0 [ISSUE] <ulink url="https://github.com/elastic/elasticsearch/pull/15135">#15135</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Highlighting
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Enable BoostingQuery with FVH highlighter <ulink url="https://github.com/elastic/elasticsearch/pull/19984">#19984</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19985">#19985</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Index APIs
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fixes active shard count check in the case of <literal>all</literal> shards <ulink url="https://github.com/elastic/elasticsearch/pull/19760">#19760</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add zero-padding to auto-generated rollover index name increment <ulink url="https://github.com/elastic/elasticsearch/pull/19610">#19610</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19484">#19484</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Ingest
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
no null values in ingest configuration error messages <ulink url="https://github.com/elastic/elasticsearch/pull/20616">#20616</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
JSON Processor was not properly added <ulink url="https://github.com/elastic/elasticsearch/pull/20613">#20613</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Don&#8217;t rebuild pipeline on every cluster state update <ulink url="https://github.com/elastic/elasticsearch/pull/20189">#20189</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add dotexpander processor <ulink url="https://github.com/elastic/elasticsearch/pull/20078">#20078</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix NPE when simulating a pipeline with no id <ulink url="https://github.com/elastic/elasticsearch/pull/19650">#19650</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Change foreach processor to use ingest metadata for array element <ulink url="https://github.com/elastic/elasticsearch/pull/19609">#19609</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19592">#19592</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
No other processors should be executed after on_failure is called <ulink url="https://github.com/elastic/elasticsearch/pull/19545">#19545</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
rethrow script compilation exceptions into ingest configuration exceptions <ulink url="https://github.com/elastic/elasticsearch/pull/19318">#19318</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Rename from <literal>ingest-useragent</literal> plugin to <literal>ingest-user-agent</literal> and its processor from <literal>useragent</literal> to <literal>user_agent</literal> <ulink url="https://github.com/elastic/elasticsearch/pull/19261">#19261</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix ignore_failure behavior in _simulate?verbose and more cleanup <ulink url="https://github.com/elastic/elasticsearch/pull/18987">#18987</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Pipeline Stats: Fix concurrent modification exception <ulink url="https://github.com/elastic/elasticsearch/pull/18177">#18177</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18126">#18126</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Validate properties values according to database type <ulink url="https://github.com/elastic/elasticsearch/pull/17940">#17940</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17683">#17683</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Ingest does not close its factories <ulink url="https://github.com/elastic/elasticsearch/pull/17626">#17626</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17625">#17625</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Handle regex parsing errors in Gsub and Grok Processors <ulink url="https://github.com/elastic/elasticsearch/pull/17260">#17260</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
add on_failure exception metadata to ingest document for verbose simulate <ulink url="https://github.com/elastic/elasticsearch/pull/16562">#16562</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
The IngestDocument copy constructor should make a deep copy <ulink url="https://github.com/elastic/elasticsearch/pull/16248">#16248</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16246">#16246</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Inner Hits
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Ensure that that InnerHitBuilder uses rewritten queries <ulink url="https://github.com/elastic/elasticsearch/pull/19360">#19360</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19353">#19353</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Internal
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Prevent AbstractArrays from release bytes more than once <ulink url="https://github.com/elastic/elasticsearch/pull/20819">#20819</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
IndicesAliasesRequest should not implement CompositeIndicesRequest <ulink url="https://github.com/elastic/elasticsearch/pull/20726">#20726</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Ensure elasticsearch doesn&#8217;t start with unuspported indices <ulink url="https://github.com/elastic/elasticsearch/pull/20514">#20514</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20512">#20512</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Remove ListTasksResponse#setDiscoveryNodes() <ulink url="https://github.com/elastic/elasticsearch/pull/19773">#19773</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19772">#19772</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Priority values should be unmodifiable <ulink url="https://github.com/elastic/elasticsearch/pull/19447">#19447</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Extract AbstractBytesReferenceTestCase <ulink url="https://github.com/elastic/elasticsearch/pull/19141">#19141</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add XPointValues <ulink url="https://github.com/elastic/elasticsearch/pull/18011">#18011</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18010">#18010</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix BulkItemResponse.Failure.toString <ulink url="https://github.com/elastic/elasticsearch/pull/17871">#17871</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Enable unmap hack for java 9 <ulink url="https://github.com/elastic/elasticsearch/pull/16986">#16986</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/1">#1</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix issues with failed cache loads <ulink url="https://github.com/elastic/elasticsearch/pull/14315">#14315</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Allow parser to move on the START_OBJECT token when parsing search source <ulink url="https://github.com/elastic/elasticsearch/pull/14145">#14145</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Ensure searcher is release if wrapping fails <ulink url="https://github.com/elastic/elasticsearch/pull/14107">#14107</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Avoid deadlocks in Cache#computeIfAbsent <ulink url="https://github.com/elastic/elasticsearch/pull/14091">#14091</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14090">#14090</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Java API
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
fix IndexResponse#toString to print out shards info <ulink url="https://github.com/elastic/elasticsearch/pull/20562">#20562</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add NamedWriteables from plugins to TransportClient <ulink url="https://github.com/elastic/elasticsearch/pull/19825">#19825</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19764">#19764</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix potential NPE in SearchSourceBuilder <ulink url="https://github.com/elastic/elasticsearch/pull/16905">#16905</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16902">#16902</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Java REST Client
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Rest Client: add slash to log line when missing between host and uri <ulink url="https://github.com/elastic/elasticsearch/pull/19325">#19325</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19314">#19314</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Rest Client: HostsSniffer to set http as default scheme <ulink url="https://github.com/elastic/elasticsearch/pull/19306">#19306</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Logging
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix logger when you can not create an azure storage client <ulink url="https://github.com/elastic/elasticsearch/pull/20670">#20670</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/20633">#20633</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/20669">#20669</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Avoid unnecessary creation of prefix loggers <ulink url="https://github.com/elastic/elasticsearch/pull/20571">#20571</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20570">#20570</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix logging hierarchy configs <ulink url="https://github.com/elastic/elasticsearch/pull/20463">#20463</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix prefix logging <ulink url="https://github.com/elastic/elasticsearch/pull/20429">#20429</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Hack around Log4j bug rendering exceptions <ulink url="https://github.com/elastic/elasticsearch/pull/20306">#20306</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20304">#20304</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Avoid prematurely triggering logger initialization <ulink url="https://github.com/elastic/elasticsearch/pull/20170">#20170</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Only log running out of slots when out of slots <ulink url="https://github.com/elastic/elasticsearch/pull/19637">#19637</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Mapping
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Allow position_gap_increment for fields in indices created prior to 5.0 <ulink url="https://github.com/elastic/elasticsearch/pull/20806">#20806</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/19510">#19510</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/20413">#20413</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Validate blank field name <ulink url="https://github.com/elastic/elasticsearch/pull/19860">#19860</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19251">#19251</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Better error message when mapping configures null <ulink url="https://github.com/elastic/elasticsearch/pull/18809">#18809</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18803">#18803</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make doc_values accessible for _type <ulink url="https://github.com/elastic/elasticsearch/pull/18220">#18220</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix and test handling of <literal>null_value</literal>. <ulink url="https://github.com/elastic/elasticsearch/pull/18090">#18090</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18085">#18085</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fail automatic string upgrade if the value of <literal>index</literal> is not recognized. <ulink url="https://github.com/elastic/elasticsearch/pull/18082">#18082</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18062">#18062</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix dynamic check to properly handle parents <ulink url="https://github.com/elastic/elasticsearch/pull/17864">#17864</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/17644">#17644</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/17854">#17854</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix array parsing to remove its context when finished parsing <ulink url="https://github.com/elastic/elasticsearch/pull/17768">#17768</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Disallow fielddata loading on text fields that are not indexed. <ulink url="https://github.com/elastic/elasticsearch/pull/17747">#17747</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Make dynamic template parsing less lenient. <ulink url="https://github.com/elastic/elasticsearch/pull/17249">#17249</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix dynamic mapper when its parent already has an update <ulink url="https://github.com/elastic/elasticsearch/pull/17065">#17065</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix copy_to when the target is a dynamic object field. <ulink url="https://github.com/elastic/elasticsearch/pull/15216">#15216</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/111237">#111237</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/11237">#11237</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Preserve existing mappings on batch mapping updates <ulink url="https://github.com/elastic/elasticsearch/pull/15130">#15130</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/14899">#14899</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/15129">#15129</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Network
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix connection close header handling <ulink url="https://github.com/elastic/elasticsearch/pull/20956">#20956</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20938">#20938</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Ensure port range is readable in the exception message <ulink url="https://github.com/elastic/elasticsearch/pull/20893">#20893</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix expect 100 continue header handling <ulink url="https://github.com/elastic/elasticsearch/pull/19904">#19904</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19834">#19834</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fixes netty4 module&#8217;s CORS config to use defaults  <ulink url="https://github.com/elastic/elasticsearch/pull/19874">#19874</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix various concurrency issues in transport <ulink url="https://github.com/elastic/elasticsearch/pull/19675">#19675</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Verify lower level transport exceptions don&#8217;t bubble up on disconnects <ulink url="https://github.com/elastic/elasticsearch/pull/19518">#19518</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19096">#19096</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Packaging
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
[Packaging] Do not remove scripts directory on upgrade <ulink url="https://github.com/elastic/elasticsearch/pull/20452">#20452</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
[Package] Remove bin/lib/modules directories on RPM uninstall/upgrade <ulink url="https://github.com/elastic/elasticsearch/pull/20448">#20448</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix handling of spaces for jvm.options on Windows <ulink url="https://github.com/elastic/elasticsearch/pull/19951">#19951</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19941">#19941</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Disable service in pre-uninstall <ulink url="https://github.com/elastic/elasticsearch/pull/19328">#19328</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove extra bin/ directory in bin folder <ulink url="https://github.com/elastic/elasticsearch/pull/18630">#18630</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Filter client/server VM options from jvm.options <ulink url="https://github.com/elastic/elasticsearch/pull/18473">#18473</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Preserve config files from RPM install <ulink url="https://github.com/elastic/elasticsearch/pull/18188">#18188</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18158">#18158</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix typo in message for variable setup ES_MAX_MEM <ulink url="https://github.com/elastic/elasticsearch/pull/18168">#18168</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Don&#8217;t run <literal>mkdir</literal> when $DATA_DIR contains a comma-separated list <ulink url="https://github.com/elastic/elasticsearch/pull/17419">#17419</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16992">#16992</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix exit code <ulink url="https://github.com/elastic/elasticsearch/pull/17082">#17082</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Set MAX_OPEN_FILES to 65536 <ulink url="https://github.com/elastic/elasticsearch/pull/17431">#17431</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17430">#17430</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
[windows] Service command still had positional start command <ulink url="https://github.com/elastic/elasticsearch/pull/17391">#17391</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Do not pass double-dash arguments on startup <ulink url="https://github.com/elastic/elasticsearch/pull/17087">#17087</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17084">#17084</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Parent/Child
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Make sure that no <literal>_parent#null</literal> gets introduces as default _parent mapping <ulink url="https://github.com/elastic/elasticsearch/pull/19470">#19470</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19389">#19389</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Percolator
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fail indexing percolator queries containing either a has_child or has_parent query <ulink url="https://github.com/elastic/elasticsearch/pull/20229">#20229</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/2960">#2960</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add support for MatchNoDocsQuery in percolator&#8217;s query terms extract service <ulink url="https://github.com/elastic/elasticsearch/pull/18492">#18492</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Let PercolatorQuery&#8217;s explain use the two phase iterator <ulink url="https://github.com/elastic/elasticsearch/pull/17315">#17315</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17314">#17314</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Discovery Azure Classic
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Make discovery-azure plugin work again <ulink url="https://github.com/elastic/elasticsearch/pull/19062">#19062</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/15630">#15630</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/18637">#18637</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Discovery EC2
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix EC2 discovery settings <ulink url="https://github.com/elastic/elasticsearch/pull/18690">#18690</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/18652">#18652</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/18662">#18662</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add TAG_SETTING to list of allowed tags for the ec2 discovery plugin. <ulink url="https://github.com/elastic/elasticsearch/pull/18257">#18257</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix EC2 Discovery settings <ulink url="https://github.com/elastic/elasticsearch/pull/17651">#17651</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16602">#16602</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Discovery GCE
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix NPE when GCE region is empty <ulink url="https://github.com/elastic/elasticsearch/pull/19176">#19176</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16967">#16967</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Ingest Attachment
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Adds content-length as number <ulink url="https://github.com/elastic/elasticsearch/pull/19927">#19927</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19924">#19924</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Ingest GeoIp
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
[ingest-geoip] update geoip to not include null-valued results from  <ulink url="https://github.com/elastic/elasticsearch/pull/20455">#20455</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Lang Painless
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix String Concatenation Bug In Painless <ulink url="https://github.com/elastic/elasticsearch/pull/20623">#20623</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix break bug in for/foreach loops. <ulink url="https://github.com/elastic/elasticsearch/pull/20146">#20146</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix compound assignment with string concats <ulink url="https://github.com/elastic/elasticsearch/pull/18933">#18933</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18929">#18929</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix horrible capture <ulink url="https://github.com/elastic/elasticsearch/pull/18907">#18907</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18899">#18899</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix Casting Bug <ulink url="https://github.com/elastic/elasticsearch/pull/18871">#18871</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove Grammar Ambiguities <ulink url="https://github.com/elastic/elasticsearch/pull/18531">#18531</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Remove if/else ANTLR ambiguity. <ulink url="https://github.com/elastic/elasticsearch/pull/18428">#18428</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix insanely slow compilation <ulink url="https://github.com/elastic/elasticsearch/pull/18410">#18410</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18398">#18398</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix Bug in Painless Assignment <ulink url="https://github.com/elastic/elasticsearch/pull/18379">#18379</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix bracket shortcuts <ulink url="https://github.com/elastic/elasticsearch/pull/18263">#18263</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Repository Azure
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Register group setting for repository-azure accounts <ulink url="https://github.com/elastic/elasticsearch/pull/19086">#19086</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix azure files removal <ulink url="https://github.com/elastic/elasticsearch/pull/18451">#18451</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/16472">#16472</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/18436">#18436</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Repository S3
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fixes leading forward slash in S3 repository base_path <ulink url="https://github.com/elastic/elasticsearch/pull/20861">#20861</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add missing permission to repository-s3 <ulink url="https://github.com/elastic/elasticsearch/pull/19128">#19128</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/18539">#18539</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/19121">#19121</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix repository S3 Settings and add more tests <ulink url="https://github.com/elastic/elasticsearch/pull/18703">#18703</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/18662">#18662</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/18690">#18690</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Store SMB
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix calling ensureOpen() on the wrong directory (master forwardport) <ulink url="https://github.com/elastic/elasticsearch/pull/16395">#16395</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16383">#16383</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugins
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Use sysprop like with es.path.home to pass conf dir <ulink url="https://github.com/elastic/elasticsearch/pull/18870">#18870</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18689">#18689</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Quote path to java binary <ulink url="https://github.com/elastic/elasticsearch/pull/17496">#17496</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17495">#17495</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
CliTool: Messages printed in Terminal should have percent char escaped <ulink url="https://github.com/elastic/elasticsearch/pull/16367">#16367</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Query DSL
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fixes MultiMatchQuery so that it doesn&#8217;t provide a null context <ulink url="https://github.com/elastic/elasticsearch/pull/20882">#20882</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix silently accepting malformed queries <ulink url="https://github.com/elastic/elasticsearch/pull/20515">#20515</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20500">#20500</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
query_string_query should take term length into consideration when fuzziness is auto <ulink url="https://github.com/elastic/elasticsearch/pull/20299">#20299</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15972">#15972</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Throw ParsingException if a query is wrapped in an array <ulink url="https://github.com/elastic/elasticsearch/pull/19750">#19750</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/12887">#12887</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Restore parameter name auto_generate_phrase_queries <ulink url="https://github.com/elastic/elasticsearch/pull/19514">#19514</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19512">#19512</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Resolve string dates and date math to millis before evaluating for rewrite in range query <ulink url="https://github.com/elastic/elasticsearch/pull/17239">#17239</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
<literal>constant_score</literal> query should throw error on more than one filter <ulink url="https://github.com/elastic/elasticsearch/pull/17135">#17135</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17126">#17126</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Single IPv4 addresses in IP field term queries <ulink url="https://github.com/elastic/elasticsearch/pull/16068">#16068</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16058">#16058</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make strategy optional in GeoShapeQueryBuilder readFrom and writeTo <ulink url="https://github.com/elastic/elasticsearch/pull/13963">#13963</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Query Refactoring
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Query refactoring: set has_parent &amp; has_child types context properly <ulink url="https://github.com/elastic/elasticsearch/pull/13863">#13863</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Make sure equivalent geohashCellQueries are equal after toQuery called <ulink url="https://github.com/elastic/elasticsearch/pull/13792">#13792</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
REST
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Remove lenient URL parameter parsing <ulink url="https://github.com/elastic/elasticsearch/pull/20722">#20722</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14719">#14719</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fixes CORS handling so that it uses the defaults <ulink url="https://github.com/elastic/elasticsearch/pull/19522">#19522</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19520">#19520</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Get XContent params from request in Nodes rest actions <ulink url="https://github.com/elastic/elasticsearch/pull/18860">#18860</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18794">#18794</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fixes reading of CORS pre-flight headers and methods <ulink url="https://github.com/elastic/elasticsearch/pull/17523">#17523</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17483">#17483</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Recovery
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix concurrency issues between cancelling a relocation and marking shard as relocated <ulink url="https://github.com/elastic/elasticsearch/pull/20443">#20443</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Move <literal>reset recovery</literal> into RecoveriesCollection <ulink url="https://github.com/elastic/elasticsearch/pull/19466">#19466</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19473">#19473</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix replica-primary inconsistencies when indexing during primary relocation with ongoing replica recoveries <ulink url="https://github.com/elastic/elasticsearch/pull/19287">#19287</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19248">#19248</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Invoke <literal>IndexingOperationListeners</literal> also when recovering from store or remote <ulink url="https://github.com/elastic/elasticsearch/pull/17406">#17406</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Prevent interruption while store checks lucene files for consistency <ulink url="https://github.com/elastic/elasticsearch/pull/16308">#16308</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Mark shard as recovering on the cluster state thread <ulink url="https://github.com/elastic/elasticsearch/pull/14276">#14276</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/13766">#13766</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/14115">#14115</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Reindex API
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix reindex with transport client <ulink url="https://github.com/elastic/elasticsearch/pull/19997">#19997</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/19773">#19773</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/19979">#19979</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix a race condition in reindex&#8217;s rethrottle <ulink url="https://github.com/elastic/elasticsearch/pull/18731">#18731</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18744">#18744</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Reindex should never report negative throttled_until <ulink url="https://github.com/elastic/elasticsearch/pull/17799">#17799</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17783">#17783</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Reindex should gracefully handle when _source is disabled <ulink url="https://github.com/elastic/elasticsearch/pull/17667">#17667</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/17666">#17666</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Scripting
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Add support for booleans in scripts <ulink url="https://github.com/elastic/elasticsearch/pull/20950">#20950</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20949">#20949</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix Javascript OOM build Failure <ulink url="https://github.com/elastic/elasticsearch/pull/20307">#20307</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix propagating the default value for script settings <ulink url="https://github.com/elastic/elasticsearch/pull/20183">#20183</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20159">#20159</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Catch and wrap AssertionError and NoClassDefFoundError in groovy scripts <ulink url="https://github.com/elastic/elasticsearch/pull/19958">#19958</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/19806">#19806</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/19923">#19923</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Search
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Do not cache script queries. <ulink url="https://github.com/elastic/elasticsearch/pull/20799">#20799</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20763">#20763</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Throw error when trying to fetch fields from source and source is disabled <ulink url="https://github.com/elastic/elasticsearch/pull/20424">#20424</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/20093">#20093</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/20408">#20408</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Source filtering should keep working when the source contains numbers greater than <literal>Long.MAX_VALUE</literal>. <ulink url="https://github.com/elastic/elasticsearch/pull/20278">#20278</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/11508">#11508</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix NPE when running a range query on a <literal>scaled_float</literal> with no upper bound. <ulink url="https://github.com/elastic/elasticsearch/pull/20253">#20253</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix NPE during search with source filtering if the source is disabled. <ulink url="https://github.com/elastic/elasticsearch/pull/20093">#20093</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/7758">#7758</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Restore assignment of time value when deserializing a scroll instance <ulink url="https://github.com/elastic/elasticsearch/pull/19977">#19977</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18820">#18820</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix explain output for dfs query <ulink url="https://github.com/elastic/elasticsearch/pull/19972">#19972</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/15369">#15369</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Don&#8217;t recursively count children profile timings <ulink url="https://github.com/elastic/elasticsearch/pull/19397">#19397</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18693">#18693</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
fix explain in function_score if no function filter matches <ulink url="https://github.com/elastic/elasticsearch/pull/19185">#19185</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix NPEs due to disabled source <ulink url="https://github.com/elastic/elasticsearch/pull/18957">#18957</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Require timeout units when parsing query body <ulink url="https://github.com/elastic/elasticsearch/pull/19077">#19077</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19075">#19075</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Close SearchContext if query rewrite failed <ulink url="https://github.com/elastic/elasticsearch/pull/18727">#18727</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix parsing single <literal>rescore</literal> element in SearchSourceBuilder <ulink url="https://github.com/elastic/elasticsearch/pull/18440">#18440</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18439">#18439</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fail queries on not indexed fields. <ulink url="https://github.com/elastic/elasticsearch/pull/18014">#18014</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix for search after <ulink url="https://github.com/elastic/elasticsearch/pull/16271">#16271</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Do not be lenient when parsing CIDRs <ulink url="https://github.com/elastic/elasticsearch/pull/14874">#14874</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/14862">#14862</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Settings
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix Setting.timeValue() method <ulink url="https://github.com/elastic/elasticsearch/pull/20696">#20696</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20662">#20662</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Add a hard limit for <literal>index.number_of_shard</literal> <ulink url="https://github.com/elastic/elasticsearch/pull/20682">#20682</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Include complex settings in settings requests <ulink url="https://github.com/elastic/elasticsearch/pull/20622">#20622</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Fix filter cache setting to allow percentages <ulink url="https://github.com/elastic/elasticsearch/pull/20335">#20335</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20330">#20330</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Move cluster.routing.allocation.same_shard.host setting to new settings infrastructure <ulink url="https://github.com/elastic/elasticsearch/pull/20046">#20046</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20045">#20045</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Validate settings against dynamic updaters on the master <ulink url="https://github.com/elastic/elasticsearch/pull/19088">#19088</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19046">#19046</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Register "cloud.node.auto_attributes" setting in EC2 discovery plugin <ulink url="https://github.com/elastic/elasticsearch/pull/18678">#18678</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Use object equality to compare versions in IndexSettings <ulink url="https://github.com/elastic/elasticsearch/pull/18103">#18103</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
fix exists method for list settings when using numbered setting format <ulink url="https://github.com/elastic/elasticsearch/pull/17949">#17949</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
convert settings for ResourceWatcherService to new infrastructure <ulink url="https://github.com/elastic/elasticsearch/pull/17948">#17948</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Register bootstrap settings <ulink url="https://github.com/elastic/elasticsearch/pull/16513">#16513</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add settings filtering to node info requests <ulink url="https://github.com/elastic/elasticsearch/pull/16445">#16445</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Ban write access to system properties <ulink url="https://github.com/elastic/elasticsearch/pull/14914">#14914</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Snapshot/Restore
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Better handling of an empty shard&#8217;s segments_N file <ulink url="https://github.com/elastic/elasticsearch/pull/18784">#18784</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18707">#18707</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix race condition in snapshot initialization <ulink url="https://github.com/elastic/elasticsearch/pull/18426">#18426</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18121">#18121</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix the semantics for the BlobContainer interface <ulink url="https://github.com/elastic/elasticsearch/pull/17878">#17878</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/15579">#15579</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/15580">#15580</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Stats
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix FieldStats deserialization of <literal>ip</literal> field <ulink url="https://github.com/elastic/elasticsearch/pull/20522">#20522</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20516">#20516</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix serialization bug in allocation explain API. <ulink url="https://github.com/elastic/elasticsearch/pull/19494">#19494</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Allocation explain: Also serialize <literal>includeDiskInfo</literal> field <ulink url="https://github.com/elastic/elasticsearch/pull/19492">#19492</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Add missing builder.endObject() in FsInfo <ulink url="https://github.com/elastic/elasticsearch/pull/18443">#18443</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/15915">#15915</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/18433">#18433</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Store
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Tighten up concurrent store metadata listing and engine writes <ulink url="https://github.com/elastic/elasticsearch/pull/19684">#19684</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19416">#19416</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Make static Store access shard lock aware <ulink url="https://github.com/elastic/elasticsearch/pull/19416">#19416</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18938">#18938</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Catch assertion errors on commit and turn it into a real exception <ulink url="https://github.com/elastic/elasticsearch/pull/19357">#19357</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19356">#19356</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Task Manager
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Shard level tasks in Bulk Action lose reference to their parent tasks <ulink url="https://github.com/elastic/elasticsearch/pull/17743">#17743</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Take filterNodeIds into consideration while sending task requests to nodes <ulink url="https://github.com/elastic/elasticsearch/pull/17081">#17081</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Term Vectors
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix calculation of took time of term vectors request <ulink url="https://github.com/elastic/elasticsearch/pull/17817">#17817</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/12565">#12565</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Translog
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Fix RAM usage estimation of LiveVersionMap. <ulink url="https://github.com/elastic/elasticsearch/pull/20123">#20123</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19787">#19787</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Fix translog replay multiple operations same doc <ulink url="https://github.com/elastic/elasticsearch/pull/18611">#18611</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/18547">#18547</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/18623">#18623</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Snapshotting and sync could cause a dead lock TranslogWriter <ulink url="https://github.com/elastic/elasticsearch/pull/18481">#18481</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/1">#1</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/18360">#18360</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/2">#2</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Move translog recover outside of the engine <ulink url="https://github.com/elastic/elasticsearch/pull/17422">#17422</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Mark shard active during recovery; push settings after engine finally inits <ulink url="https://github.com/elastic/elasticsearch/pull/16250">#16250</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/14121">#14121</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/16209">#16209</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="regression-5.0.0" renderas="sect2">Regressions<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.0.0-all.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
Highlighting
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Handle SynonymQuery extraction for the FastVectorHighlighter <ulink url="https://github.com/elastic/elasticsearch/pull/20829">#20829</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20781">#20781</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
<bridgehead id="upgrade-5.0.0" renderas="sect2">Upgrades<ulink role="edit_me" url="/mnt/docs/docs/.repos/.temp/JGF5rMru3R/docs/reference/release-notes/5.0.0-all.asciidoc">Edit me</ulink></bridgehead>
<variablelist>
<varlistentry>
<term>
Core
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Upgrade to Lucene 6.2.0 <ulink url="https://github.com/elastic/elasticsearch/pull/20147">#20147</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/20092">#20092</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Update to jackson 2.8.1 <ulink url="https://github.com/elastic/elasticsearch/pull/18939">#18939</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/18076">#18076</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Upgrade to Lucene 6.1.0. <ulink url="https://github.com/elastic/elasticsearch/pull/18926">#18926</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Upgrade to lucene-6.1.0-snapshot-3a57bea. <ulink url="https://github.com/elastic/elasticsearch/pull/18786">#18786</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Upgrade to Lucene 6.0.1. <ulink url="https://github.com/elastic/elasticsearch/pull/18648">#18648</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/17535">#17535</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/28">#28</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Upgrade to lucene 6 release <ulink url="https://github.com/elastic/elasticsearch/pull/17657">#17657</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Upgrade to lucene-6.0.0-f0aa4fc. <ulink url="https://github.com/elastic/elasticsearch/pull/17075">#17075</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
upgrade to lucene 6.0.0-snapshot-bea235f <ulink url="https://github.com/elastic/elasticsearch/pull/16964">#16964</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Upgrade to Jackson 2.7.1 <ulink url="https://github.com/elastic/elasticsearch/pull/16801">#16801</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16294">#16294</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Ingest
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Update MaxMind geoip2 version to 2.6 <ulink url="https://github.com/elastic/elasticsearch/pull/16837">#16837</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/16801">#16801</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Internal
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Bump master (3.0-snapshot) to java 8 <ulink url="https://github.com/elastic/elasticsearch/pull/13314">#13314</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Network
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Upgrade to Netty 4.1.5 <ulink url="https://github.com/elastic/elasticsearch/pull/20222">#20222</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/19786">#19786</ulink>)
</simpara>
</listitem>
<listitem>
<simpara>
Dependencies: Upgrade to netty 4.1.4 <ulink url="https://github.com/elastic/elasticsearch/pull/19689">#19689</ulink>
</simpara>
</listitem>
<listitem>
<simpara>
Introduce Netty 4 <ulink url="https://github.com/elastic/elasticsearch/pull/19526">#19526</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/3226">#3226</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Packaging
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Upgrade JNA to 4.2.2 and remove optionality <ulink url="https://github.com/elastic/elasticsearch/pull/19045">#19045</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13245">#13245</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Plugin Discovery EC2
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Update aws sdk to 1.10.69 and add use_throttle_retries repository setting <ulink url="https://github.com/elastic/elasticsearch/pull/17784">#17784</ulink> (issues: <ulink url="https://github.com/elastic/elasticsearch/issues/538">#538</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/586">#586</ulink>, <ulink url="https://github.com/elastic/elasticsearch/issues/589">#589</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Scripting
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Dependencies: Updates to mustache 0.9.3 <ulink url="https://github.com/elastic/elasticsearch/pull/20337">#20337</ulink>
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
<varlistentry>
<term>
Search Templates
</term>
<listitem>
<itemizedlist>
<listitem>
<simpara>
Update mustache.java to version 0.9.1 <ulink url="https://github.com/elastic/elasticsearch/pull/14053">#14053</ulink> (issue: <ulink url="https://github.com/elastic/elasticsearch/issues/13224">#13224</ulink>)
</simpara>
</listitem>
</itemizedlist>
</listitem>
</varlistentry>
</variablelist>
</chapter>
</part>
</book>
