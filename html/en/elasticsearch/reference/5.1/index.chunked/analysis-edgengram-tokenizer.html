<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"><html xmlns="http://www.w3.org/1999/xhtml"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" /><title xmlns="">Edge NGram Tokenizer
        | Elasticsearch Reference [5.1]
      | Elastic
    </title><meta name="generator" content="DocBook XSL Stylesheets V1.78.1" /><link rel="home" href="index.html" title="Elasticsearch Reference [5.1]" /><link rel="up" href="analysis-tokenizers.html" title="Tokenizers" /><link rel="prev" href="analysis-ngram-tokenizer.html" title="NGram Tokenizer" /><link rel="next" href="analysis-keyword-tokenizer.html" title="Keyword Tokenizer" /><meta xmlns="" name="description" content="Get started with the documentation for Elasticsearch, Kibana, Logstash, Beats, X-Pack, Elastic Cloud, Elasticsearch for Apache Hadoop, and our language clients." /><meta xmlns="" name="DC.type" content="Docs/Elasticsearch/Reference/5.1" /></head><body><div xmlns="" class="page_header">You are looking at documentation for an older release.
Not what you want? See the
<a href="../current/index.html">current release documentation</a>.
</div><div xmlns="" class="breadcrumbs"><span class="breadcrumb-link"><a href="index.html">Elasticsearch Reference
      [5.1]
    </a></span> » <span class="breadcrumb-link"><a href="analysis.html">Analysis</a></span> » <span class="breadcrumb-link"><a href="analysis-tokenizers.html">Tokenizers</a></span> » <span class="breadcrumb-node">Edge NGram Tokenizer</span></div><div xmlns="" class="navheader"><span class="prev"><a href="analysis-ngram-tokenizer.html">
              « 
              NGram Tokenizer</a>
           
        </span><span class="next">
           
          <a href="analysis-keyword-tokenizer.html">Keyword Tokenizer
               »
            </a></span></div><div class="section"><div class="titlepage"><div><div><h2 class="title"><a id="analysis-edgengram-tokenizer"></a>Edge NGram Tokenizer<a xmlns="" href="https://github.com/elastic/elasticsearch/edit/5.1/docs/reference/analysis/tokenizers/edgengram-tokenizer.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h2></div></div></div><p>The <code class="literal">edge_ngram</code> tokenizer first breaks text down into words whenever it
encounters one of a list of specified characters, then it emits
<a class="ulink" href="https://en.wikipedia.org/wiki/N-gram" target="_top">N-grams</a> of each word where the start of
the N-gram is anchored to the beginning of the word.</p><p>Edge N-Grams are useful for <span class="emphasis"><em>search-as-you-type</em></span> queries.</p><div xmlns="" class="tip admon"><div class="icon"><img alt="Tip" src="images/icons/tip.png" /></div><div class="admon_content"><p xmlns="http://www.w3.org/1999/xhtml">When you need <span class="emphasis"><em>search-as-you-type</em></span> for text which has a widely known
order, such as movie or song titles, the
<a class="link" href="search-suggesters-completion.html" title="Completion Suggester">completion suggester</a> is a much more efficient
choice than edge N-grams.  Edge N-grams have the advantage when trying to
autocomplete words that can appear in any order.</p></div></div><h3><a id="_example_output_16"></a>Example output<a xmlns="" href="https://github.com/elastic/elasticsearch/edit/5.1/docs/reference/analysis/tokenizers/edgengram-tokenizer.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3><p>With the default settings, the <code class="literal">edge_ngram</code> tokenizer treats the initial text as a
single token and produces N-grams with minimum length <code class="literal">1</code> and maximum length
<code class="literal">2</code>:</p><div xmlns="" class="pre_wrapper"><pre xmlns="http://www.w3.org/1999/xhtml" class="programlisting prettyprint lang-js">POST _analyze
{
  "tokenizer": "edge_ngram",
  "text": "Quick Fox"
}</pre></div><div xmlns="" class="console_widget" data-snippet=":CONSOLE:"></div><p>The above sentence would produce the following terms:</p><div xmlns="" class="pre_wrapper"><pre xmlns="http://www.w3.org/1999/xhtml" class="programlisting prettyprint lang-text">[ Q, Qu ]</pre></div><div xmlns="" class="note admon"><div class="icon"><img alt="Note" src="images/icons/note.png" /></div><div class="admon_content"><p xmlns="http://www.w3.org/1999/xhtml">These default gram lengths are almost entirely useless.  You need to
configure the <code class="literal">edge_ngram</code> before using it.</p></div></div><h3><a id="_configuration_17"></a>Configuration<a xmlns="" href="https://github.com/elastic/elasticsearch/edit/5.1/docs/reference/analysis/tokenizers/edgengram-tokenizer.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3><p>The <code class="literal">edge_ngram</code> tokenizer accepts the following parameters:</p><div class="horizontal"><table cellpadding="4px" border="0"><colgroup><col /><col /></colgroup><tbody valign="top"><tr><td valign="top">
<p>
<code class="literal">min_gram</code>
</p>
</td><td valign="top">
<p>
    Minimum length of characters in a gram.  Defaults to <code class="literal">1</code>.
</p>
</td></tr><tr><td valign="top">
<p>
<code class="literal">max_gram</code>
</p>
</td><td valign="top">
<p>
    Maximum length of characters in a gram.  Defaults to <code class="literal">2</code>.
</p>
</td></tr><tr><td valign="top">
<p>
<code class="literal">token_chars</code>
</p>
</td><td valign="top">
<p>
    Character classes that should be included in a token.  Elasticsearch
    will split on characters that don’t belong to the classes specified.
    Defaults to <code class="literal">[]</code> (keep all characters).
</p>
<p>Character classes may be any of the following:</p>
<div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
<code class="literal">letter</code> —      for example <code class="literal">a</code>, <code class="literal">b</code>, <code class="literal">ï</code> or <code class="literal">京</code>
</li><li class="listitem">
<code class="literal">digit</code> —       for example <code class="literal">3</code> or <code class="literal">7</code>
</li><li class="listitem">
<code class="literal">whitespace</code> —  for example <code class="literal">" "</code> or <code class="literal">"\n"</code>
</li><li class="listitem">
<code class="literal">punctuation</code> — for example <code class="literal">!</code> or <code class="literal">"</code>
</li><li class="listitem">
<code class="literal">symbol</code> —      for example <code class="literal">$</code> or <code class="literal">√</code>
</li></ul></div>
</td></tr></tbody></table></div><h3><a id="_example_configuration_10"></a>Example configuration<a xmlns="" href="https://github.com/elastic/elasticsearch/edit/5.1/docs/reference/analysis/tokenizers/edgengram-tokenizer.asciidoc" class="edit_me" title="Edit this page on GitHub" rel="nofollow">edit</a></h3><p>In this example, we configure the <code class="literal">edge_ngram</code> tokenizer to treat letters and
digits as tokens, and to produce grams with minimum length <code class="literal">2</code> and maximum
length <code class="literal">10</code>:</p><div xmlns="" class="pre_wrapper"><pre xmlns="http://www.w3.org/1999/xhtml" class="programlisting prettyprint lang-js">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "tokenizer": "my_tokenizer"
        }
      },
      "tokenizer": {
        "my_tokenizer": {
          "type": "edge_ngram",
          "min_gram": 2,
          "max_gram": 10,
          "token_chars": [
            "letter",
            "digit"
          ]
        }
      }
    }
  }
}

POST my_index/_analyze
{
  "analyzer": "my_analyzer",
  "text": "2 Quick Foxes."
}</pre></div><div xmlns="" class="console_widget" data-snippet=":CONSOLE:"></div><p>The above example produces the following terms:</p><div xmlns="" class="pre_wrapper"><pre xmlns="http://www.w3.org/1999/xhtml" class="programlisting prettyprint lang-text">[ Qu, Qui, Quic, Quick, Fo, Fox, Foxe, Foxes ]</pre></div><p>Usually we recommend using the same <code class="literal">analyzer</code> at index time and at search
time. In the case of the <code class="literal">edge_ngram</code> tokenizer, the advice is different.  It
only makes sense to use the <code class="literal">edge_ngram</code> tokenizer at index time, to ensure
that partial words are available for matching in the index.  At search time,
just search for the terms the user has typed in, for instance: <code class="literal">Quick Fo</code>.</p><p>Below is an example of how to set up a field for <span class="emphasis"><em>search-as-you-type</em></span>:</p><div xmlns="" class="pre_wrapper"><pre xmlns="http://www.w3.org/1999/xhtml" class="programlisting prettyprint lang-js">PUT my_index
{
  "settings": {
    "analysis": {
      "analyzer": {
        "autocomplete": {
          "tokenizer": "autocomplete",
          "filter": [
            "lowercase"
          ]
        },
        "autocomplete_search": {
          "tokenizer": "lowercase"
        }
      },
      "tokenizer": {
        "autocomplete": {
          "type": "edge_ngram",
          "min_gram": 2,
          "max_gram": 10,
          "token_chars": [
            "letter"
          ]
        }
      }
    }
  },
  "mappings": {
    "doc": {
      "properties": {
        "title": {
          "type": "text",
          "analyzer": "autocomplete",
          "search_analyzer": "autocomplete_search"
        }
      }
    }
  }
}

PUT my_index/doc/1
{
  "title": "Quick Foxes" <a id="CO277-1"></a><span xmlns=""><img src="images/icons/callouts/1.png" alt="" /></span>
}

POST my_index/_refresh

GET my_index/_search
{
  "query": {
    "match": {
      "title": {
        "query": "Quick Fo", <a id="CO277-2"></a><span xmlns=""><img src="images/icons/callouts/2.png" alt="" /></span>
        "operator": "and"
      }
    }
  }
}</pre></div><div xmlns="" class="console_widget" data-snippet=":CONSOLE:"></div><div class="calloutlist"><table border="0" summary="Callout list"><tr><td width="5%" valign="top" align="left"><p><a href="#CO277-1"><span xmlns=""><img src="images/icons/callouts/1.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
The <code class="literal">autocomplete</code> analyzer indexes the terms <code class="literal">[qu, qui, quic, quick, fo, fox, foxe, foxes]</code>.
</p></td></tr><tr><td width="5%" valign="top" align="left"><p><a href="#CO277-2"><span xmlns=""><img src="images/icons/callouts/2.png" alt="" /></span></a> </p></td><td valign="top" align="left"><p>
The <code class="literal">autocomplete_search</code> analyzer searches for the terms <code class="literal">[quick, fo]</code>, both of which appear in the index.
</p></td></tr></table></div></div><div xmlns="" class="navfooter"><span class="prev"><a href="analysis-ngram-tokenizer.html">
              « 
              NGram Tokenizer</a>
           
        </span><span class="next">
           
          <a href="analysis-keyword-tokenizer.html">Keyword Tokenizer
               »
            </a></span></div></body></html>